Updated_GPT4_Query_Original_WoS_695_Health_Marked_Final;;;;;
Authors;Article Title;Abstract;Publication Year;Mig Review;GPT4 Review
"An, SB; Doan, T; Lee, JH; Kim, J; Kim, YJ; Kim, Y; Yoon, C; Jung, SKY; Kim, D; Kwon, S; Kim, HJ; Ahn, J; Park, C";A comparison of synthetic data approaches using utility and disclosure risk measures;This paper investigates synthetic data generation methods and their evaluation measures. There have been increasing demands for releasing various types of data to the public for different purposes. At the same time, there are also unavoidable concerns about leaking critical or sensitive information. Many synthetic data gener-ation methods have been proposed over the years in order to address these concerns and implemented in some countries, including Korea. The current study aims to introduce and compare three representative synthetic data generation approaches: Sequential regression, nonparametric Bayesian multiple imputations, and deep generative models. Several evaluation metrics that measure the utility and disclosure risk of synthetic data are also reviewed. We provide empirical comparisons of the three synthetic data generation approaches with respect to various eval-uation measures. The findings of this work will help practitioners to have a better understanding of the advantages and disadvantages of those synthetic data methods.;2023;Not health related;Not health related
"Eigenschink, P; Reutterer, T; Vamosi, S; Vamosi, R; Sun, C; Kalcher, K";Deep Generative Models for Synthetic Data: A Survey;A growing interest in synthetic data has stimulated the development and advancement of a large variety of deep generative models for a wide range of applications. However, as this research has progressed, its streams have become more specialized and disconnected from one another. This is why models for synthesizing text data for natural language processing cannot readily be compared to models for synthesizing health records anymore. To mitigate this isolation, we propose a data-driven evaluation framework for generative models for synthetic sequential data, an important and challenging sub-category of synthetic data, based on five high-level criteria: representativeness, novelty, realism, diversity and coherence of a synthetic data-set relative to the original data-set regardless of the models' internal structures. The criteria reflect requirements different domains impose on synthetic data and allow model users to assess the quality of synthetic data across models. In a critical review of generative models for sequential data, we examine and compare the importance of each performance criterion in numerous domains. We find that realism and coherence are more important for synthetic data natural language, speech and audio processing tasks. At the same time, novelty and representativeness are more important for healthcare and mobility data. We also find that measurement of representativeness is often accomplished using statistical metrics, realism by using human judgement, and novelty using privacy tests.;2023;Health related;Health related
"Osuala, R; Skorupko, G; Lazrak, N; Garrucho, L; García, E; Joshi, S; Jouide, S; Rutherford, M; Prior, F; Kushibar, K; Díaz, O; Lekadir, K";medigan: a Python library of pretrained generative models for medical image synthesis;Purpose: Deep learning has shown great promise as the backbone of clinical decision support systems. Synthetic data generated by generative models can enhance the performance and capabilities of data-hungry deep learning models. However, there is (1) limited availability of (synthetic) datasets and (2) generative models are complex to train, which hinders their adoption in research and clinical applications. To reduce this entry barrier, we explore generative model sharing to allow more researchers to access, generate, and benefit from synthetic data.Approach: We propose medigan, a one-stop shop for pretrained generative models implemented as an open-source framework-agnostic Python library. After gathering end-user requirements, design decisions based on usability, technical feasibility, and scalability are formulated. Subsequently, we implement medigan based on modular components for generative model (i) execution, (ii) visualization, (iii) search & ranking, and (iv) contribution. We integrate pretrained models with applications across modalities such as mammography, endoscopy, x-ray, and MRI.Results: The scalability and design of the library are demonstrated by its growing number of integrated and readily-usable pretrained generative models, which include 21 models utilizing nine different generative adversarial network architectures trained on 11 different datasets. We further analyze three medigan applications, which include (a) enabling community-wide sharing of restricted data, (b) investigating generative model evaluation metrics, and (c) improving clinical downstream tasks. In (b), we extract Frechet inception distances (FID) demonstrating FID variability based on image normalization and radiology-specific feature extractors.Conclusion: medigan allows researchers and developers to create, increase, and domain-adapt their training data in just a few lines of code. Capable of enriching and accelerating the development of clinical machine learning models, we show medigan's viability as platform for generative model sharing. Our multimodel synthetic data experiments uncover standards for assessing and reporting metrics, such as FID, in image synthesis studies.;2023;Health related;Health related
"Achuthan, S; Chatterjee, R; Kotnala, S; Mohanty, A; Bhattacharya, S; Salgia, R; Kulkarni, P";Leveraging deep learning algorithms for synthetic data generation to design and analyze biological networks;The use of synthetic data is gaining an increasingly prominent role in data and machine learning workflows to build better models and conduct analyses with greater statistical inference. In the domains of healthcare and biomedical research, synthetic data may be seen in structured and unstructured formats. Concomitant with the adoption of synthetic data, a sub-discipline of machine learning known as deep learning has taken the world by storm. At a larger scale, deep learning methods tend to outperform traditional methods in regression and classification tasks. These techniques are also used in generative modeling and are thus prime candidates for generating synthetic data in both structured and unstructured formats. Here, we emphasize the generation of synthetic data in healthcare and biomedical research using deep learning methods for unstructured data formats such as text and images. Deep learning methods leverage the neural network algorithm, and in the context of generative modeling, several neural network architectures can create new synthetic data for a problem at hand including, but not limited to, recurrent neural networks (RNNs), variational autoencoders (VAEs), and generative adversarial networks (GANs). To better understand these methods, we will look at specific case studies such as generating realistic clinical notes of a patient, the generation of synthetic DNA sequences, as well as to enrich experimental data collected during the study of heterotypic cultures of cancer cells.;2022;Health related;Health related
"Nickerson, K; Tricco, T; Kolokolova, A; Shoeleh, F; Robertson, C; Hawkin, J; Hu, T";Banksformer: A Deep Generative Model for Synthetic Transaction Sequences;Synthetic data are generated data that closely model realworld measurements, and can be a valuable substitute for real data in domains where it is costly to obtain real data or privacy concerns exist. Synthetic data has traditionally been generated using computational simulations, but deep generative models (DGMs) are increasingly used to create high-quality synthetic data. In this work, we tackle the problem of generating synthetic, multivariate sequences of banking transactions. A key challenge in modeling transactional sequences with DGMs is that transactions occur at irregular intervals and may depend on timestamp-based features, such as the time of day or day of the week. Relationships between date-based features are often poorly represented in data generated using state-of-the-art sequence DGMs, such as DoppelGANger [17] and TimeGAN [31]. To remedy this, we propose a novel DGM, called Banksformer (Code available at github.com/BigTuna08/Banksformer ecml 2022), which is able to emulate date-based patterns found in transactional data significantly better than other DGMs. We demonstrate Banksformers' ability to generate high-quality synthetic sequences of banking transactions by conducting a multi-faceted evaluation that compares synthetic data generated by Banksformer to data from other comparable DGMs, across two datasets of banking transactions.;2023;Not health related;Not health related
"Kim, Y; Lee, JH; Kim, C; Jin, KN; Park, CM";GAN based ROI conditioned Synthesis of Medical Image for Data Augmentation;Synthetic data is considered to be a promising solution for data privacy and scarcity. Some studies have shown that synthetic data generated from a simple GAN-based model enables privacy-preserving data sharing and data augmentation also in the medical imaging field. However, there are some limitations in applying this approach to real world situations: 1) Since generative models needs large amount of data to be trained, it is hard to be applied for small data situation. 2) Even after successfully training generative models, it is hard to guarantee which class the synthesized data corresponds to, especially for non-conditional generative models, so it needs to be re-labeled. Here, we propose GAN based ROI conditioned synthesis of medical Image for data augmentation. We used StyleGAN2 to learn the distribution of CXR and Bayesian image reconstruction for ROI-conditioned synthesis from the distribution. In the 4-class classification of CXRs showing normal, pneumonia, pleural effusion, and pneumothorax, using synthetic data for data sharing showed comparable performance to centralized learning, slightly better in terms of AUROC. Also, using synthetic data for augmentation, the accuracy and AUROC showed up to 6.5% and 8.9% increases, respectively.;2023;Health related;Health related
"Stadler, T; Oprisanu, B; Troncoso, C";Synthetic Data - Anonymisation Groundhog Day;Synthetic data has been advertised as a silver-bullet solution to privacy-preserving data publishing that addresses the shortcomings of traditional anonymisation techniques. The promise is that synthetic data drawn from generative models preserves the statistical properties of the original dataset but, at the same time, provides perfect protection against privacy attacks. In this work, we present the first quantitative evaluation of the privacy gain of synthetic data publishing and compare it to that of previous anonymisation techniques. Our evaluation of a wide range of state-of-the-art generative models demonstrates that synthetic data either does not prevent inference attacks or does not retain data utility. In other words, we empirically show that synthetic data does not provide a better tradeoff between privacy and utility than traditional anonymisation techniques. Furthermore, in contrast to traditional anonymisation, the privacy-utility tradeoff of synthetic data publishing is hard to predict. Because it is impossible to predict what signals a synthetic dataset will preserve and what information will be lost, synthetic data leads to a highly variable privacy gain and unpredictable utility loss. In summary, we find that synthetic data is far from the holy grail of privacy-preserving data publishing.;2022;Not health related;Not health related
"Patki, N; Wedge, R; Veeramachaneni, K";The Synthetic data vault;The goal of this paper is to build a system that automatically creates synthetic data to enable data science endeavors. To achieve this, we present the Synthetic Data Vault (SDV), a system that builds generative models of relational databases. We are able to sample from the model and create synthetic data, hence the name SDV. When implementing the SDV, we also developed an algorithm that computes statistics at the intersection of related database tables. We then used a state-of-the-art multivariate modeling approach to model this data. The SDV iterates through all possible relations, ultimately creating a model for the entire database. Once this model is computed, the same relational information allows the SDV to synthesize data by sampling from any part of the database. After building the SDV, we used it to generate synthetic data for five different publicly available datasets. We then published these datasets, and asked data scientists to develop predictive models for them as part of a crowdsourced experiment. By analyzing the outcomes, we show that synthetic data can successfully replace original data for data science. Our analysis indicates that there is no significant difference in the work produced by data scientists who used synthetic data as opposed to real data. We conclude that the SDV is a viable solution for synthetic data generation.;2016;Not health related;Not health related
"Ghosheh, GO; Thwaites, CL; Zhu, TT";Synthesizing Electronic Health Records for Predictive Models in Low-Middle-Income Countries (LMICs);The spread of machine learning models, coupled with by the growing adoption of electronic health records (EHRs), has opened the door for developing clinical decision support systems. However, despite the great promise of machine learning for healthcare in low-middle-income countries (LMICs), many data-specific limitations, such as the small size and irregular sampling, hinder the progress in such applications. Recently, deep generative models have been proposed to generate realistic-looking synthetic data, including EHRs, by learning the underlying data distribution without compromising patient privacy. In this study, we first use a deep generative model to generate synthetic data based on a small dataset (364 patients) from a LMIC setting. Next, we use synthetic data to build models that predict the onset of hospital-acquired infections based on minimal information collected at patient ICU admission. The performance of the diagnostic model trained on the synthetic data outperformed models trained on the original and oversampled data using techniques such as SMOTE. We also experiment with varying the size of the synthetic data and observe the impact on the performance and interpretability of the models. Our results show the promise of using deep generative models in enabling healthcare data owners to develop and validate models that serve their needs and applications, despite limitations in dataset size.;2023;Health related;Health related
"Carvajal-Patiño, D; Ramos-Pollán, R";Synthetic data generation with deep generative models to enhance predictive tasks in trading strategies;This work develops machine learning (ML) predictive models on price signals for financial instruments and their integration into trading strategies. In general, ML models have been shown powerful when trained with large amounts of data. In practice, the time-series nature of financial datasets limits the effective amount of data available to train, validate and retrain models since special care must be taken not to include future data in any way. In this setting, we develop deep generative models to produce synthetic time-series data, enhancing the amount of data available for training predictive models. Synthetic data obtained this way replicates the distribution properties of real historical data, leads to better performance, and enables thorough validation of predictive models for price signals. We leverage machine-generated predictive signals on synthetic data to build trading strategies. We show consistent improvement leading up to profits in our simulations for commodities and forex exchange markets.;2022;Not health related;Not health related
"Plesovskaya, E; Ivanov, S";An Empirical Analysis of KDE-based Generative Models on Small Datasets;One of the approaches to deal with the small dataset problem is synthetic data generation. Kernel density estimation is a common method to approximate the underlying probability distribution of a small dataset. The present paper aims to analyze the generation capability of KDE-based models by evaluating their samples. For this purpose, we introduce a framework for synthetic dataset quality estimation which also accounts for the overfitting of a generative model. The performance of KDE is analyzed on samples from theoretical distributions and real datasets. The results state that KDE generates synthetic samples of a good quality and outperforms its competitors on small datasets.Abstract One of the approaches to deal with the small dataset problem is synthetic data generation. Kernel density estimation is a common method to approximate the underlying probability distribution of a small dataset. The present paper aims to analyze the generation capability of KDE-based models by evaluating their samples. For this purpose, we introduce a framework for synthetic dataset quality estimation which also accounts for the overfitting of a generative model. The performance of KDE is analyzed on samples from theoretical distributions and real datasets. The results state that KDE generates synthetic samples of a good quality and outperforms its competitors on small datasets. (C) 2021 The Authors. Published by ELSEVIER B.V.;2021;Not health related;Not health related
"Le, TA; Baydin, AG; Zinkov, R; Wood, F";Using Synthetic Data to Train Neural Networks is Model-Based Reasoning;We draw a formal connection between using synthetic training data to optimize neural network parameters and approximate, Bayesian, model-based reasoning. In particular, training a neural network using synthetic data can be viewed as learning a proposal distribution generator for approximate inference in the synthetic-data generative model. We demonstrate this connection in a recognition task where we develop a novel Captcha-breaking architecture and train it using synthetic data, demonstrating both state-of-the-art performance and a way of computing task-specific posterior uncertainty. Using a neural network trained this way, we also demonstrate successful breaking of real-world Captchas currently used by Facebook and Wikipedia. Reasoning from these empirical results and drawing connections with Bayesian modeling, we discuss the robustness of synthetic data results and suggest important considerations for ensuring good neural network generalization when training with synthetic data.;2017;Not health related;Not health related
"Boutros, F; Struc, V; Fierrez, J; Damer, N";Synthetic data for face recognition: Current state and future prospects;Over the past years, deep learning capabilities and the availability of large-scale training datasets advanced rapidly, leading to breakthroughs in face recognition accuracy. However, these technologies are foreseen to face a major challenge in the next years due to the legal and ethical concerns about using authentic biometric data in AI model training and evaluation along with increasingly utilizing data-hungry state-of-the-art deep learning models. With the recent advances in deep generative models and their success in generating realistic and high-resolution synthetic image data, privacy-friendly synthetic data has been recently proposed as an alternative to privacy-sensitive authentic data to overcome the challenges of using authentic data in face recognition development. This work aims at providing a clear and structured picture of the use-cases taxonomy of synthetic face data in face recognition along with the recent emerging advances of face recognition models developed on the bases of synthetic data. We also discuss the challenges facing the use of synthetic data in face recognition development and several future prospects of synthetic data in the domain of face recognition.(C) 2023 Elsevier B.V. All rights reserved.;2023;Not health related;Not health related
"Visani, G; Graffi, G; Alfero, M; Bagli, E; Chesani, F; Capuzzo, D";Enabling Synthetic Data adoption in regulated domains;The switch from a Model-Centric to a Data-Centric mindset is putting emphasis on data and its quality rather than algorithms, bringing forward new challenges. In particular, the sensitive nature of the information in highly regulated scenarios needs to be accounted for. Specific approaches to address the privacy issue have been developed, as Privacy Enhancing Technologies. However, they frequently cause loss of information, putting forward a crucial trade-off among data quality and privacy. A clever way to bypass such a conundrum relies on Synthetic Data: data obtained from a generative process, learning the real data properties. Both Academia and Industry realized the importance of evaluating synthetic data quality: without all-round reliable metrics, the innovative data generation task has no proper objective function to maximize. Despite that, the topic remains under-explored. For this reason, we systematically catalog the important traits of synthetic data quality and privacy, and devise a specific methodology to test them. The result is DAISYnt (aDoption of Artificial Intelligence SYnthesis): a comprehensive suite of advanced tests, which sets a de facto standard for synthetic data evaluation. As a practical use-case, a variety of generative algorithms have been trained on real-world Credit Bureau Data. The best model has been assessed, using DAISYnt on the different synthetic replicas. Further potential uses, among others, entail auditing and fine-tuning of generative models or ensuring high quality of a given synthetic dataset. From a prescriptive viewpoint, eventually, DAISYnt may pave the way to synthetic data adoption in highly regulated domains, ranging from Finance to Healthcare, through Insurance and Education.;2022;Not health related;Health related
"Razghandi, M; Zhou, H; Erol-Kantarci, M; Turgut, D";Variational Autoencoder Generative Adversarial Network for Synthetic Data Generation in Smart Home;Data is the fuel of data science and machine learning techniques for smart grid applications, similar to many other fields. However, the availability of data can be an issue due to privacy concerns, data size, data quality, and so on. To this end, in this paper, we propose a Variational AutoEncoder Generative Adversarial Network (VAE-GAN) as a smart grid data generative model which is capable of learning various types of data distributions and generating plausible samples from the same distribution without performing any prior analysis on the data before the training phase. We compared the Kullback-Leibler (KL) divergence, maximum mean discrepancy (MMD), and Wasserstein distance between the synthetic data (electrical load and PV production) distribution generated by the proposed model, vanilla GAN network, and the real data distribution, to evaluate the performance of our model. Furthermore, we used five key statistical parameters to describe the smart grid data distribution and compared them between synthetic data generated by both models and real data. Experiments indicate that the proposed synthetic data generative model outperforms the vanilla GAN network. The distribution of VAE-GAN synthetic data is the most comparable to that of real data.;2022;Not health related;Not health related
"de Jesus, DAR; Mandal, P; Senjyu, T; Kamalasadan, S";Unsupervised Hybrid Deep Generative Models for Photovoltaic Synthetic Data Generation;This paper contributes to the field of deep generative learning applied to solar photovoltaic (PV) synthetic data generation problems by exploring Deep Generative Model (DGM) that combines Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN), i.e., VAEGAN. We build upon knowledge in the area of deep learning to incorporate our Hybrid Deep Neural Network (HDNN), combining convolutional and Long Short-Term Memory (LSTM) layers at the encoding level for producing robust latent representations and subsequently high-quality synthetic PV data samples. The major advantage of these approaches is that it allows the DGMs to perform better feature extraction as well as to capture the historical trends in data effectively. The simulations on actual data acquired from a real PV system demonstrate the effectiveness of the DGMs to produce high-quality samples for multiple seasons of the year.;2021;Not health related;Not health related
"Tay, SS; Xu, XY; Foo, CS; Low, BKH";Incentivizing Collaboration in Machine Learning via Synthetic Data Rewards;This paper presents a novel collaborative generative modeling (CGM) framework that incentivizes collaboration among self-interested parties to contribute data to a pool for training a generative model (e.g., GAN), from which synthetic data are drawn and distributed to the parties as rewards commensurate to their contributions. Distributing synthetic data as rewards (instead of trained models or money) offers task- and model-agnostic benefits for downstream learning tasks and is less likely to violate data privacy regulation. To realize the framework, we firstly propose a data valuation function using maximum mean discrepancy (MMD) that values data based on its quantity and quality in terms of its closeness to the true data distribution and provide theoretical results guiding the kernel choice in our MMD-based data valuation function. Then, we formulate the reward scheme as a linear optimization problem that when solved, guarantees certain incentives such as fairness in the CGM framework. We devise a weighted sampling algorithm for generating synthetic data to be distributed to each party as reward such that the value of its data and the synthetic data combined matches its assigned reward value by the reward scheme. We empirically show using simulated and real-world datasets that the parties' synthetic data rewards are commensurate to their contributions.;2022;Not health related;Not health related
"Newlin, M; Reith, M; DeYoung, M";Synthetic Data Generation With Machine Learning for Network Intrusion Detection Systems;Machine learning is becoming an integral part of cybersecurity today, particularly in the area of network anomaly detection. However, machine learning techniques require large volumes of data to be effective. Although there are some datasets available for training Network Intrusion Detection Systems (NIDS), many of them are outdated or do not contain enough useful information for training/classification of NIDS. Therefore, generating synthetic data that is realistic is imperative for training effective intrusion detection systems. Currently, the most common methods for generating synthetic data are simulation or emulation through a software package like OPNET, and then machine learning is used to analyze the dataset for correctness. This paper argues for an approach to utilize machine learning to develop models in order to generate the datasets themselves for NIDS, which is an approach that is not commonly used. In this paper, we discuss some of the well-known available datasets, the features that make up a good dataset, the reasons for utilizing generative modeling to synthesize network data and lay out a basic approach to developing generative models for synthetic data by leveraging machine learning.;2019;Not health related;Not health related
"Figueira, A; Vaz, B";Survey on Synthetic Data Generation, Evaluation Methods and GANs;Synthetic data consists of artificially generated data. When data are scarce, or of poor quality, synthetic data can be used, for example, to improve the performance of machine learning models. Generative adversarial networks (GANs) are a state-of-the-art deep generative models that can generate novel synthetic samples that follow the underlying data distribution of the original dataset. Reviews on synthetic data generation and on GANs have already been written. However, none in the relevant literature, to the best of our knowledge, has explicitly combined these two topics. This survey aims to fill this gap and provide useful material to new researchers in this field. That is, we aim to provide a survey that combines synthetic data generation and GANs, and that can act as a good and strong starting point for new researchers in the field, so that they have a general overview of the key contributions and useful references. We have conducted a review of the state-of-the-art by querying four major databases: Web of Sciences (WoS), Scopus, IEEE Xplore, and ACM Digital Library. This allowed us to gain insights into the most relevant authors, the most relevant scientific journals in the area, the most cited papers, the most significant research areas, the most important institutions, and the most relevant GAN architectures. GANs were thoroughly reviewed, as well as their most common training problems, their most important breakthroughs, and a focus on GAN architectures for tabular data. Further, the main algorithms for generating synthetic data, their applications and our thoughts on these methods are also expressed. Finally, we reviewed the main techniques for evaluating the quality of synthetic data (especially tabular data) and provided a schematic overview of the information presented in this paper.;2022;Not health related;Not health related
"Li, MC; Zhuang, D; Chang, JM";MC-GEN: Multi-level clustering for private synthetic data generation;With the development of machine learning and data science, data sharing is very common between companies and research institutes to avoid data scarcity. However, sharing original datasets that contain private information can cause privacy leakage. A reliable solution is to utilize private synthetic datasets which preserve statistical information from original datasets. In this paper, we propose MC-GEN, a privacy-preserving synthetic data generation method under differential privacy guarantee for machine learning classification tasks. MC-GEN applies multi-level clustering and differential private generative model to improve the utility of synthetic data. In the experimental evaluation, we evaluated the effects of parameters and the effectiveness of MC-GEN. The results showed that MC-GEN can achieve significant effectiveness under certain privacy guarantees on multiple classification tasks. Moreover, we compare MC-GEN with three existing methods. The results showed that MC-GEN outperforms other methods in terms of utility. (c) 2023 Elsevier B.V. All rights reserved.;2023;Not health related;Not health related
"Zhu, KW; Cheng, SB; Kovalchuk, N; Simmons, M; Guo, YK; Matar, OK; Arcucci, R";Analyzing drop coalescence in microfluidic devices with a deep learning generative model;Predicting drop coalescence based on process parameters is crucial for experimental design in chemical engineering. However, predictive models can suffer from the lack of training data and more importantly, the label imbalance problem. In this study, we propose the use of deep learning generative models to tackle this bottleneck by training the predictive models using generated synthetic data. A novel generative model, named double space conditional variational autoencoder (DSCVAE) is developed for labelled tabular data. By introducing label constraints in both the latent and the original space, DSCVAE is capable of generating consistent and realistic samples compared to the standard conditional variational autoencoder (CVAE). Two predictive models, namely random forest and gradient boosting classifiers, are enhanced on synthetic data and their performances are evaluated based on real experimental data. Numerical results show that a considerable improvement in prediction accuracy can be achieved by using synthetic data and the proposed DSCVAE clearly outperforms the standard CVAE. This research clearly provides more insights into handling imbalanced data for classification problems, especially in chemical engineering.;2023;Not health related;Not health related
"Ganev, G; Oprisanu, B; De Cristofaro, E";Robin Hood and Matthew Effects: Differential Privacy Has Disparate Impact on Synthetic Data;"Generative models trained with Differential Privacy (DP) can be used to generate synthetic data while minimizing privacy risks. We analyze the impact of DP on these models vis-a-vis underrepresented classes/subgroups of data, specifically, studying: 1) the size of classes/subgroups in the synthetic data, and 2) the accuracy of classification tasks run on them. We also evaluate the effect of various levels of imbalance and privacy budgets. Our analysis uses three state-of-the-art DP models (PrivBayes, DP-WGAN, and PATE-GAN) and shows that DP yields opposite size distributions in the generated synthetic data. It affects the gap between the majority and minority classes/subgroups; in some cases by reducing it (a Robin Hood effect) and, in others, by increasing it (a Matthew effect). Either way, this leads to (similar) disparate impacts on the accuracy of classification tasks on the synthetic data, affecting disproportionately more the underrepresented subparts of the data. Consequently, when training models on synthetic data, one might incur the risk of treating different subpopulations unevenly, leading to unreliable or unfair conclusions.";2022;Not health related;Not health related
"Dankar, FK; Ibrahim, M";Fake It Till You Make It: Guidelines for Effective Synthetic Data Generation;Synthetic data provides a privacy protecting mechanism for the broad usage and sharing of healthcare data for secondary purposes. It is considered a safe approach for the sharing of sensitive data as it generates an artificial dataset that contains no identifiable information. Synthetic data is increasing in popularity with multiple synthetic data generators developed in the past decade, yet its utility is still a subject of research. This paper is concerned with evaluating the effect of various synthetic data generation and usage settings on the utility of the generated synthetic data and its derived models. Specifically, we investigate (i) the effect of data pre-processing on the utility of the synthetic data generated, (ii) whether tuning should be applied to the synthetic datasets when generating supervised machine learning models, and (iii) whether sharing preliminary machine learning results can improve the synthetic data models. Lastly, (iv) we investigate whether one utility measure (Propensity score) can predict the accuracy of the machine learning models generated from the synthetic data when employed in real life. We use two popular measures of synthetic data utility, propensity score and classification accuracy, to compare the different settings. We adopt a recent mechanism for the calculation of propensity, which looks carefully into the choice of model for the propensity score calculation. Accordingly, this paper takes a new direction with investigating the effect of various data generation and usage settings on the quality of the generated data and its ensuing models. The goal is to inform on the best strategies to follow when generating and using synthetic data.;2021;Health related;Health related
"Schaudt, D; Späte, C; von Schwerin, R; Reichert, M; von Schwerin, M; Beer, M; Kloth, C";A Critical Assessment of Generative Models for Synthetic Data Augmentation on Limited Pneumonia X-ray Data;In medical imaging, deep learning models serve as invaluable tools for expediting diagnoses and aiding specialized medical professionals in making clinical decisions. However, effectively training deep learning models typically necessitates substantial quantities of high-quality data, a resource often lacking in numerous medical imaging scenarios. One way to overcome this deficiency is to artificially generate such images. Therefore, in this comparative study we train five generative models to artificially increase the amount of available data in such a scenario. This synthetic data approach is evaluated on a a downstream classification task, predicting four causes for pneumonia as well as healthy cases on 1082 chest X-ray images. Quantitative and medical assessments show that a Generative Adversarial Network (GAN)-based approach significantly outperforms more recent diffusion-based approaches on this limited dataset with better image quality and pathological plausibility. We show that better image quality surprisingly does not translate to improved classification performance by evaluating five different classification models and varying the amount of additional training data. Class-specific metrics like precision, recall, and F1-score show a substantial improvement by using synthetic images, emphasizing the data rebalancing effect of less frequent classes. However, overall performance does not improve for most models and configurations, except for a DreamBooth approach which shows a +0.52 improvement in overall accuracy. The large variance of performance impact in this study suggests a careful consideration of utilizing generative models for limited data scenarios, especially with an unexpected negative correlation between image quality and downstream classification improvement.;2023;Health related;Health related
"Nezhad, FH; Rotalinti, Y; Myles, P; Tucker, A";Privacy Assessment of Synthetic Patient Data;In this paper, we quantify the privacy gain of synthetic patient data drawn from two generative models, MST and PrivBayes, which is based on real anonymized primary care patient data. This evaluation is implemented for two types of inference attacks, namely membership and attribute inference attacks using a new toolbox, TAPAS. The aim is to quantitatively evaluate the privacy gain of each attack where these two differentially private generators and different threat models are used with a focus on black-box knowledge. The evaluation that was carried out in this paper demonstrates that vulnerabilities of synthetic patient data depend on the different attack scenarios, threat models, and algorithms used to generate the synthetic patient data. It was shown empirically that although the synthetic patient data achieved high privacy gain in most attack scenarios, it does not behave uniformly against adversarial attacks, and some records and outliers remain vulnerable depending on the attack scenario. Moreover, it was shown that the PrivBayes generator is the more robust generator in comparison to MST in terms of the privacy-preservation of synthetic data.;2023;Health related;Health related
"El Emam, K; Mosquera, L; Fang, X; El-Hussuna, A";Utility Metrics for Evaluating Synthetic Health Data Generation Methods: Validation Study;Background: A regular task by developers and users of synthetic data generation (SDG) methods is to evaluate and compare the utility of these methods. Multiple utility metrics have been proposed and used to evaluate synthetic data. However, they have not been validated in general or for comparing SDG methods. Objective: This study evaluates the ability of common utility metrics to rank SDG methods according to performance on a specific analytic workload. The workload of interest is the use of synthetic data for logistic regression prediction models, which is a very frequent workload in health research. Methods: We evaluated 6 utility metrics on 30 different health data sets and 3 different SDG methods (a Bayesian network, a Generative Adversarial Network, and sequential tree synthesis). These metrics were computed by averaging across 20 synthetic data sets from the same generative model. The metrics were then tested on their ability to rank the SDG methods based on prediction performance. Prediction performance was defined as the difference between each of the area under the receiver operating characteristic curve and area under the precision-recall curve values on synthetic data logistic regression prediction models versus real data models. Results: The utility metric best able to rank SDG methods was the multivariate Hellinger distance based on a Gaussian copula representation of real and synthetic joint distributions. Conclusions: This study has validated a generative model utility metric, the multivariate Hellinger distance, which can be used to reliably rank competing SDG methods on the same data set. The Hellinger distance metric can be used to evaluate and compare alternate SDG methods.;2022;Health related;Health related
"Vie, JJ; Rigaux, T; Minn, S";Privacy-Preserving Synthetic Educational Data Generation;Institutions collect massive learning traces but they may not disclose it for privacy issues. Synthetic data generation opens new opportunities for research in education. In this paper we present a generative model for educational data that can preserve the privacy of participants, and an evaluation framework for comparing synthetic data generators. We show how naive pseudonymization can lead to re-identification threats and suggest techniques to guarantee privacy. We evaluate our method on existing massive educational open datasets.;2022;Not health related;Not health related
"Cheng, Y; Gong, YS; Liu, YS; Song, BS; Zou, Q";Molecular design in drug discovery: a comprehensive review of deep generative models;Deep generative models have been an upsurge in the deep learning community since they were proposed. These models are designed for generating new synthetic data including images, videos and texts by fitting the data approximate distributions. In the last few years, deep generative models have shown superior performance in drug discovery especially de novo molecular design. In this study, deep generative models are reviewed to witness the recent advances of de novo molecular design for drug discovery. In addition, we divide those models into two categories based on molecular representations in silico. Then these two classical types of models are reported in detail and discussed about both pros and cons. We also indicate the current challenges in deep generative models for de novo molecular design. De novo molecular design automatically is promising but a long road to be explored.;2021;Not health related;Not health related
"Derus, N; Curti, N; Giampieri, E; Dall'olio, D; Sala, C; Castellani, G";SYNTHETIC DATA GENERATION AND CLASSIFICATION OF HISTOPATHOLOGICAL IMAGES;Histopathology involves the analysis of microscopic tissue images for diagnosing and studying the progress of diseases, such as cancers. Recently, Artificial Intelligence algorithms reached encouraging success in diagnosing diseases related to these medical images. However, research in this area can be hampered by several problems. Indeed, due to the sensitive nature of medical data, it is challenging to access real datasets, making it impossible to train Deep Learning models. Moreover, real datasets often contain biases or imbalances that hinder the generalization of the results on new unseen data. Variational Autoencoders are a popular class of probabilistic generative models that enable consistent training and a useful latent representation of the original input. However, there are theoretical and practical obstacles that hinder their generative potential. Here, we consider different approaches to address the challenges of synthetic data generation of histopathology images and discuss the potential impact in improving the performance of diagnosis models.;2023;Health related;Health related
"Espinosa, E; Figueira, A";On the Quality of Synthetic Generated Tabular Data;Class imbalance is a common issue while developing classification models. In order to tackle this problem, synthetic data have recently been developed to enhance the minority class. These artificially generated samples aim to bolster the representation of the minority class. However, evaluating the suitability of such generated data is crucial to ensure their alignment with the original data distribution. Utility measures come into play here to quantify how similar the distribution of the generated data is to the original one. For tabular data, there are various evaluation methods that assess different characteristics of the generated data. In this study, we collected utility measures and categorized them based on the type of analysis they performed. We then applied these measures to synthetic data generated from two well-known datasets, Adults Income, and Liar+. We also used five well-known generative models, Borderline SMOTE, DataSynthesizer, CTGAN, CopulaGAN, and REaLTabFormer, to generate the synthetic data and evaluated its quality using the utility measures. The measurements have proven to be informative, indicating that if one synthetic dataset is superior to another in terms of utility measures, it will be more effective as an augmentation for the minority class when performing classification tasks.;2023;Not health related;Not health related
"El Emam, K; Mosquera, L; Fang, X";Validating a membership disclosure metric for synthetic health data;Background One of the increasingly accepted methods to evaluate the privacy of synthetic data is by measuring the risk of membership disclosure. This is a measure of the F1 accuracy that an adversary would correctly ascertain that a target individual from the same population as the real data is in the dataset used to train the generative model, and is commonly estimated using a data partitioning methodology with a 0.5 partitioning parameter. Objective Validate the membership disclosure F1 score, evaluate and improve the parametrization of the partitioning method, and provide a benchmark for its interpretation. Materials and methods We performed a simulated membership disclosure attack on 4 population datasets: an Ontario COVID-19 dataset, a state hospital discharge dataset, a national health survey, and an international COVID-19 behavioral survey. Two generative methods were evaluated: sequential synthesis and a generative adversarial network. A theoretical analysis and a simulation were used to determine the correct partitioning parameter that would give the same F1 score as a ground truth simulated membership disclosure attack. Results The default 0.5 parameter can give quite inaccurate membership disclosure values. The proportion of records from the training dataset in the attack dataset must be equal to the sampling fraction of the real dataset from the population. The approach is demonstrated on 7 clinical trial datasets. Conclusions Our proposed parameterization, as well as interpretation and generative model training guidance provide a theoretically and empirically grounded basis for evaluating and managing membership disclosure risk for synthetic data. Lay Summary Membership disclosure is considered an important type of privacy risk for synthetic data. A commonly applied methodology for evaluating membership disclosure is the partitioning method. We demonstrate theoretically and empirically through a simulation on 4 population datasets that current parameterizations of this method can potentially give inaccurate estimates of risk, and propose a more grounded parametrization. We further provide an interpretable version of that metric, a benchmark for deciding when membership disclosure is acceptably small, and a proposed metric to manage utility and membership disclosure risk during the training of generative models which generate the synthetic datasets. Finally, we demonstrate its application on 7 oncology clinical trial datasets.;2022;Health related;Health related
"Zhang, ZQ; Yan, C; Malin, BA";Membership inference attacks against synthetic health data;Synthetic data generation has emerged as a promising method to protect patient privacy while sharing individual-level health data. Intuitively, sharing synthetic data should reduce disclosure risks because no explicit linkage is retained between the synthetic records and the real data upon which it is based. However, the risks associated with synthetic data are still evolving, and what seems protected today may not be tomorrow. In this paper, we show that membership inference attacks, whereby an adversary infers if the data from certain target individuals (known to the adversary a priori) were relied upon by the synthetic data generation process, can be substantially enhanced through state-of-the-art machine learning frameworks, which calls into question the protective nature of existing synthetic data generators. Specifically, we formulate the membership inference problem from the perspective of the data holder, who aims to perform a disclosure risk assessment prior to sharing any health data. To support such an assessment, we introduce a framework for effective membership inference against synthetic health data without specific assumptions about the generative model or a welldefined data structure, leveraging the principles of contrastive representation learning. To illustrate the potential for such an attack, we conducted experiments against synthesis approaches using two datasets derived from several health data resources (Vanderbilt University Medical Center, the All of Us Research Program) to determine the upper bound of risk brought by an adversary who invokes an optimal strategy. The results indicate that partially synthetic data are vulnerable to membership inference at a very high rate. By contrast, fully synthetic data are only marginally susceptible and, in most cases, could be deemed sufficiently protected from membership inference.;2022;Health related;Health related
"Dash, S; Yale, A; Guyon, I; Bennett, KP";Medical Time-Series Data Generation Using Generative Adversarial Networks;Medical data is rarely made publicly available due to high de-identification costs and risks. Access to such data is highly regulated due to it's sensitive nature. These factors impede the development of data-driven advancements in the healthcare domain. Synthetic medical data which can maintain the utility of the real data while simultaneously preserving privacy can be an ideal substitute for advancing research. Medical data is longitudinal in nature, with a single patient having multiple temporal events, influenced by static covariates like age, gender, comorbidities, etc. Extending existing time-series generative models to generate medical data can be challenging due to this influence of patient covariates. We propose a workflow wherein we leverage existing generative models to generate such data. We demonstrate this approach by generating synthetic versions of several time-series datasets where static covariates influence the temporal values. We use a state-of-the-art benchmark as a comparative baseline. Our methodology for empirically evaluating synthetic time-series data shows that the synthetic data generated with our workflow has higher resemblance and utility. We also demonstrate how stratification by covariates is required to gain a deeper understanding of synthetic data quality and underscore the importance of including this analysis in evaluation of synthetic medical data quality.;2020;Health related;Health related
"Smith, B; Van Steelandt, S; Khojandi, A";Evaluating the Impact of Health Care Data Completeness for Deep Generative Models;Background Deep generative models (DGMs) present a promising avenue for generating realistic, synthetic data to augment existing health care datasets. However, exactly how the completeness of the original dataset affects the quality of the generated synthetic data is unclear.Objectives In this paper, we investigate the effect of data completeness on samples generated by the most common DGM paradigms.Methods We create both cross-sectional and panel datasets with varying missingness and subset rates and train generative adversarial networks, variational autoencoders, and autoregressive models (Transformers) on these datasets. We then compare the distributions of generated data with original training data to measure similarity.Results We find that increased incompleteness is directly correlated with increased dissimilarity between original and generated samples produced through DGMs.Conclusions Care must be taken when using DGMs to generate synthetic data as data completeness issues can affect the quality of generated data in both panel and cross-sectional datasets.;2023;Health related;Health related
"El Emam, K; Mosquera, L; Bass, J";Evaluating Identity Disclosure Risk in Fully Synthetic Health Data: Model Development and Validation;"Background: There has been growing interest in data synthesis for enabling the sharing of data for secondary analysis; however, there is a need for a comprehensive privacy risk model for fully synthetic data: If the generative models have been overfit, then it is possible to identify individuals from synthetic data and learn something new about them. Objective: The purpose of this study is to develop and apply a methodology for evaluating the identity disclosure risks of fully synthetic data. Methods: A full risk model is presented, which evaluates both identity disclosure and the ability of an adversary to learn something new if there is a match between a synthetic record and a real person. We term this meaningful identity disclosure risk. The model is applied on samples from the Washington State Hospital discharge database (2007) and the Canadian COVID-19 cases database. Both of these datasets were synthesized using a sequential decision tree process commonly used to synthesize health and social science data. Results: The meaningful identity disclosure risk for both of these synthesized samples was below the commonly used 0.09 risk threshold (0.0198 and 0.0086, respectively), and 4 times and 5 times lower than the risk values for the original datasets, respectively. Conclusions: We have presented a comprehensive identity disclosure risk model for fully synthetic data. The results for this synthesis method on 2 datasets demonstrate that synthesis can reduce meaningful identity disclosure risks considerably. The risk model can be applied in the future to evaluate the privacy of fully synthetic data.";2020;Health related;Health related
"Hernandez-Matamoros, A; Fujita, H; Perez-Meana, H";A novel approach to create synthetic biomedical signals using BiRNN;"Human health is threatened by several diseases for this reason automated medical diagnosis systems has been developed several years ago. These systems need databases, the creation of these databases is tedious, arduous and stops being done so the created database is incomplete or unbalanced. Sometimes the databases are private to protect the private information of the patients, among other problems. For this reason, the researchers have started to use synthetic data. The synthetic data have been applied by different hospitals in the USA. The creation of synthetic data has different problems like the synthetic data are generated using rules defined by the user, the proposed approaches only can create one kind of data, the proposals require input from domain experts, among others. To address these kinds of problems, we propose a novel approach, which consists of the Bidirectional Recurrent Neural Network and the statistical stage to generate synthetic biomedical signals. The approach is able to create 5 kinds of biomedical signals (ECG, EEG, BCG, PPG, and Respiratory Impedance). Our approach is able to create synthetic data for patients or for specific events. The performance of our approach is compared with other generative models (GAN's) through evaluation metrics. The created synthetic data are used to construct models; these models are able to successfully differentiate between different signals with high accuracies. (C) 2020 Elsevier Inc. All rights reserved.";2020;Health related;Health related
"Ock, J; No, H; Kim, S";Poster: Exploring Synthetic Data Generation for Anomaly Detection in the 5G NWDAF Architecture;The transition of paradigm from non-standalone to standalone mode in 5G network creates an opportunity to utilize innovative machine learning and AI-based technology for network traffic analysis. In particular, NWDAF plays a key role in leveraging AI-based models to optimize and enhance the 5G core network functions, including anomaly detection and load balancing. However, it is challenging to ensure the sufficient performance of prediction algorithms under dynamic conditions in NWDAF without guaranteeing the quality and quantity of training data, but only a select group has access to the 5G dataset. To overcome this issue, this paper proposes an approach to generate high-quality synthetic 5G NWDAF data using CTGAN, a specialized generative model that creates synthetic output based on tabular input data. We provide preliminary results of leveraging CTGAN to generate 5G synthetic data and evaluate the synthesizing quality for anomaly detection.;2023;Not health related;Not health related
"Carden, S; Livsey, J";Small-sample reinforcement learning: Improving policies using synthetic data;Reinforcement learning (RL) concerns algorithms tasked with learning optimal control policies by interacting with or observing a system. In computer science and other fields in which RL originated, large sample sizes are the norm, because data can be generated at will from a generative model. Recently, RL methods have been adapted for use in clinical trials, resulting in much smaller sample sizes. Nonparametric methods are common in RL, but are likely to over-generalize when limited data is available. This paper proposes a novel methodology for learning optimal policies by leveraging the researcher's partial knowledge about the probability transition structure into an approximate generative model from which synthetic data can be produced. Our method is applied to a scenario where the researcher must create a medical prescription policy for managing a disease with sporadically appearing symptoms.;2017;Health related;Health related
"Chan, MH; Noor, MHM";A unified generative model using generative adversarial network for activity recognition;The recent advancement of deep learning methods has seen a significant increase in recognition accuracy in many important applications such as human activity recognition. However, deep learning methods require a vast amount of sensor data to automatically extract the most salient features for activity classification. Therefore, in this paper, a unified generative model is proposed to generate verisimilar data of different activities for activity recognition. The proposed generative model not only able to generate data that have a similar pattern, but also data with diverse characteristics. This allows for data augmentation in activity classification to improve the overall recognition accuracy. Three similarity measures are proposed to assess the quality of the synthetic data in addition to two visual evaluation methods. The proposed generative model was evaluated on a public dataset. The training data was prepared by systematically varying the combination of original and synthetic data. Results have shown that classification using the hybrid training data achieved a comparable recognition accuracy with the classification using the original training data. The performance of the classifiers maintained at the recognition accuracy of 85%.;2021;Not health related;Not health related
"Gong, ZC; Chen, HH";Model-Based Oversampling for Imbalanced Sequence Classification;Sequence classification is critical in the data mining communities. It becomes more challenging when the class distribution is imbalanced, which occurs in many real-world applications. Oversampling algorithms try to re-balance the skewed class by generating synthetic data for minority classes, but most of existing oversampling approaches could not consider the temporal structure of sequences, or handle multivariate and long sequences. To address these problems, this paper proposes a novel oversampling algorithm based on the 'generative' models of sequences. In particular, a recurrent neural network was employed to learn the generative mechanics for sequences as representations for the corresponding sequences. These generative models are then utilized to form a kernel to capture the similarity between different sequences. Finally, oversampling is performed in the kernel feature space to generate synthetic data. The proposed approach can handle highly imbalanced sequential data and is robust to noise. The competitiveness of the proposed approach is demonstrated by experiments on both synthetic data and benchmark data, including univariate and multi-variate sequences.;2016;Not health related;Not health related
"Ross, A; Chen, NN; Hang, EZ; Glassman, EL; Doshi-Velez, F";Evaluating the Interpretability of Generative Models by Interactive Reconstruction;For machine learning models to be most useful in numerous sociotechnical systems, many have argued that they must be human-interpretable. However, despite increasing interest in interpretability, there remains no firm consensus on how to measure it. This is especially true in representation learning, where interpretability research has focused on disentanglement measures only applicable to synthetic datasets and not grounded in human factors. We introduce a task to quantify the human-interpretability of generative model representations, where users interactively modify representations to reconstruct target instances. On synthetic datasets, we find performance on this task much more reliably differentiates entangled and disentangled models than baseline approaches. On a real dataset, we find it differentiates between representation learning methods widely believed but never shown to produce more or less interpretable models. In both cases, we ran small-scale think-aloud studies and large-scale experiments on Amazon Mechanical Turk to confirm that our qualitative and quantitative results agreed.;2021;Not health related;Not health related
"Neo, ERK; Low, JSC; Goodship, V; Coles, SR; Debattista, K";Cross-modal generative models for multi-modal plastic sorting;Automated sorting through chemometric analysis of plastic spectral data could be a key strategy towards improving plastic waste management. Deep learning is a promising chemometric tool, but further development through multi-modal deep learning has been limited by lack of data availability. A new Multi-modal Plastic Spectral Database (MMPSD) consisting of Fourier Transform Infrared (FTIR), Raman and Laser-induced Break-down Spectroscopy (LIBS) data for each sample in the database is introduced in this work. MMPSD serves as the basis for novel cross-modality generative model technique termed Spectral Conversion Autoencoders (SCAE), which generates synthetic data from data of another modality. SCAE is advantageous over traditional generative models like Variational Autoencoders (VAE), as it can generate class specific synthetic data without the need to train multiple models for each data class. MMPSD also facilitated the exploration of multi-modal deep learning, which improved the classification accuracy as compared to an uni-modal approach from 0.933 to 0.970. SCAE can further be combined with multi-modal methods to achieve a higher accuracy of 0.963 while still using a single sensor to reduce costs, which can be applied for multi-modal augmentation from FTIR sensors used in industrial sorting.;2023;Not health related;Not health related
"Estacio, L; Ehlke, M; Tack, A; Castro, E; Lamecker, H; Mora, R; Zachow, S";UNSUPERVISED DETECTION OF DISTURBANCES IN 2D RADIOGRAPHS;We present a method based on a generative model for detection of disturbances such as prosthesis, screws, zippers, and metals in 2D radiographs. The generative model is trained in an unsupervised fashion using clinical radiographs as well as simulated data, none of which contain disturbances. Our approach employs a latent space consistency loss which has the benefit of identifying similarities, and is enforced to reconstruct X-rays without disturbances. In order to detect images with disturbances, an anomaly score is computed also employing the Frechet distance between the input X-ray and the reconstructed one using our generative model. Validation was performed using clinical pelvis radiographs. We achieved an AUC of 0.77 and 0.83 with clinical and synthetic data, respectively. The results demonstrated a good accuracy of our method for detecting outliers as well as the advantage of utilizing synthetic data.;2021;Health related;Health related
"El Kababji, S; Mitsakakis, N; Fang, X; Beltran-Bless, AA; Pond, G; Vandermeer, L; Radhakrishnan, D; Mosquera, L; Paterson, A; Shepherd, L; Chen, B; Barlow, WE; Gralow, J; Savard, MF; Clemons, M; El Emam, K";Evaluating the Utility and Privacy of Synthetic Breast Cancer Clinical Trial Data Sets;PURPOSE There is strong interest from patients, researchers, the pharmaceutical industry, medical journal editors, funders of research, and regulators in sharing clinical trial data for secondary analysis. However, data access remains a challenge because of concerns about patient privacy. It has been argued that synthetic data generation (SDG) is an effective way to address these privacy concerns. There is a dearth of evidence supporting this on oncology clinical trial data sets, and on the utility of privacy-preserving synthetic data. The objective of the proposed study is to validate the utility and privacy risks of synthetic clinical trial data sets across multiple SDG techniques. METHODS We synthesized data sets from eight breast cancer clinical trial data sets using three types of generative models: sequential synthesis, conditional generative adversarial network, and variational autoencoder. Synthetic data utility was evaluated by replicating the published analyses on the synthetic data and assessing concordance of effect estimates and CIs between real and synthetic data. Privacy was evaluated by measuring attribution disclosure risk and membership disclosure risk. RESULTS Utility was highest using the sequential synthesis method where all results were replicable and the CI overlap most similar or higher for seven of eight data sets. Both types of privacy risks were low across all three types of generative models. DISCUSSION Synthetic data using sequential synthesis methods can act as a proxy for real clinical trial data sets, and simultaneously have low privacy risks. This type of generative model can be one way to enable broader sharing of clinical trial data.;2023;Health related;Health related
"Yang, R; Ma, XB; Bai, XY; Su, XD";Differential Privacy Images Protection Based on Generative Adversarial Network;In recent years, as image data are widely used in data analysis tasks, the problem of privacy disclosure is becoming more and more serious. However, the privacy protection technology of image data is still immature. In this paper, we propose a privacy protection framework named dp-WGAN for image data. This framework uses differential privacy and generative adversarial network to train a generative model with privacy protection function. Using this generative model, synthetic data with similar characteristics to sensitive data can be obtained, and synthetic data is published instead sensitive data to complete all kinds of data analysis tasks. Through extensive empirical evaluation on benchmark datasets, we demonstrate that dp-WGAN can provide strong privacy protection for sensitive data and produce high-quality synthetic data.;2020;Not health related;Not health related
"Suroso, DJ; Cherntanomwong, P; Sooraksa, P";Synthesis of a Small Fingerprint Database through a Deep Generative Model for Indoor Localisation;deep learning (DL), the deep generative model is helpful for data augmentation objectives to tackle the lack of datasets that have a significant impact on learning performance. Data augmentation or synthesis is expected to solve the issue in a small/sparse database. The problem of databasing also exists in the fingerprint-based indoor localisation system. The dense offline fingerprint database must be constructed with the accuracy requirement. However, this will affect the high cost, massive laborious work, and increase the complexity of the system. Therefore, this paper proposes to address these issues by generating synthetic data via a deep generative model. The generative adversarial network (GAN) is selected to generate the synthetic fingerprint database for indoor localisation. Our database consideration consists of power-based parameters, i.e., the received signal strength indicator (RSSI) from Wi-Fi devices obtained from the actual measurement campaign. Some of the literature mainly discusses how GAN works in a vast and complex dataset. Here, we consider applying GAN in a relatively small dataset and for a simple setup. Our results show that by only using the 20 % fraction of actual RSSI data combined with the synthetic RSSI, the accuracy validation performance is slightly higher than when using all actual data usage. Moreover, in only 60 % of actual data usage and in combination with 625 samples of synthetic data, the accuracy performance is improved to 0.73 (1.37 times higher than the use of all actual data, 0.53). Thus, this result proves that the challenges of offline fingerprint databases can be alleviated by data synthesis through GAN by using only a small dataset.;2023;Not health related;Not health related
"Abedi, M; Hempel, L; Sadeghi, S; Kirsten, T";GAN-Based Approaches for Generating Structured Data in the Medical Domain;Modern machine and deep learning methods require large datasets to achieve reliable and robust results. This requirement is often difficult to meet in the medical field, due to data sharing limitations imposed by privacy regulations or the presence of a small number of patients (e.g., rare diseases). To address this data scarcity and to improve the situation, novel generative models such as Generative Adversarial Networks (GANs) have been widely used to generate synthetic data that mimic real data by representing features that reflect health-related information without reference to real patients. In this paper, we consider several GAN models to generate synthetic data used for training binary (malignant/benign) classifiers, and compare their performances in terms of classification accuracy with cases where only real data are considered. We aim to investigate how synthetic data can improve classification accuracy, especially when a small amount of data is available. To this end, we have developed and implemented an evaluation framework where binary classifiers are trained on extended datasets containing both real and synthetic data. The results show improved accuracy for classifiers trained with generated data from more advanced GAN models, even when limited amounts of original data are available.;2022;Health related;Health related
"Chen, C; Bose, A; Cheng, SF; Sinha, A";Multiscale Generative Models: Improving Performance of a Generative Model Using Feedback from Other Dependent Generative Models;Realistic fine-grained multi-agent simulation of real-world complex systems is crucial for many downstream tasks such as reinforcement learning. Recent work has used generative models (GANs in particular) for providing high-fidelity simulation of real-world systems. However, such generative models are often monolithic and miss out on modeling the interaction in multi-agent systems. In this work, we take a first step towards building multiple interacting generative models (GANs) that reflects the interaction in real world. We build and analyze a hierarchical set-up where a higher-level GAN is conditioned on the output of multiple lower-level GANs. We present a technique of using feedback from the higher-level GAN to improve performance of lower-level GANs. We mathematically characterize the conditions under which our technique is impactful, including understanding the transfer learning nature of our set-up. We present three distinct experiments on synthetic data, time series data, and image domain, revealing the wide applicability of our technique.;2022;Not health related;Not health related
"Imtiaz, S; Arsalan, M; Vlassov, V; Sadre, R";Synthetic and Private Smart Health Care Data Generation using GANs;With the rapid advancements in machine learning, the health care paradigm is shifting from treatment towards prevention. The smart health care industry relies on the availability of large-scale health datasets in order to benefit from machine learning-based services. As a consequence, preserving the individuals' privacy becomes vital for sharing sensitive personal information. Synthetic datasets with generative models are considered to be one of the most promising solutions for privacy-preserving data sharing. Among the generative models, generative adversarial networks (GANs) have emerged as the most impressive models for synthetic data generation in recent times. However, smart health care data is attributed with unique challenges such as volume, velocity, and various data types and distributions. We propose a GAN coupled with differential privacy mechanisms for generating a realistic and private smart health care dataset. The proposed approach is not only able to generate realistic synthetic data samples but also the differentially private data samples under different settings: learning from a noisy distribution or noising the learned distribution. We tested and evaluated our proposed approach using a real-world Fitbit dataset. Our results indicate that our proposed approach is able to generate quality synthetic and differentially private dataset that preserves the statistical properties of the original dataset.;2021;Health related;Health related
"Chale, M; Bastian, ND";Generating realistic cyber data for training and evaluating machine learning classifiers for network intrusion detection systems;"Cyberspace operations, in conjunction with artificial intelligence and machine learning enhanced cyberspace infrastructure, make it possible to connect sensors directly to shooters independent of human control. These technologies serve as the pivot around which cyber data from the military's Internet of Battlefield Things, for example, will be turned into actionable insight and knowledge and, ultimately, an information advantage for the military. As such, network intrusion detection systems must detect, evaluate, and respond to malicious cyber traffic at machine speed. Generative adversarial networks and variational autoencoders are fit as generative models with labeled cyber data from a real military enterprise network. These generative models are used to create realistic, synthetic cyber data. A combination of real and synthetic cyber data sets are then used to train several machine learning models for network intrusion detection. Purely synthetic data is shown to be statistically similar to the real data. There is no statistically significant difference in the performance of classifiers trained with real data versus a combination of real and synthetic data; however, classifiers trained with only synthetic data underperformed. To avoid a decrease in intrusion detection performance, classifiers must be trained with at least 15% real data.";2022;Not health related;Not health related
"Ampanavos, S; Malkawi, A";Early-Phase Performance-Driven Design Using Generative Models;Current performance-driven building design methods are not widely adopted outside the research field for several reasons that make them difficult to integrate into a typical design process. In the early design phase, in particular, the time intensity and the cognitive load associated with optimization and form parametrization are incompatible with design exploration, which requires quick iteration. This research introduces a novel method for performance-driven geometry generation that can afford interaction directly in the 3d modeling environment, eliminating the need for explicit parametrization, and is multiple orders faster than the equivalent form optimization. The method uses Machine Learning techniques to train a generative model offline. The generative model learns a distribution of optimal performing geometries and their simulation contexts based on a dataset that addresses the performance(s) of interest. By navigating the generative model's latent space, geometries with the desired characteristics can be quickly generated. A case study is presented, demonstrating the generation of a synthetic dataset and the use of a Variational Autoencoder (VAE) as a generative model for geometries with optimal solar gain. The results show that the VAE-generated geometries perform on average at least as well as the optimized ones, suggesting that the introduced method shows a feasible path towards more intuitive and interactive early-phase performance-driven design assistance.;2022;Not health related;Not health related
"Ramachandran, A; Lumetta, SS; Klee, E; Chen, DM";A recurrent Markov state-space generative model for sequences;While the Hidden Markov Model (HMM) is a versatile generative model of sequences capable of performing many exact inferences efficiently, it is not suited for capturing complex long-term structure in the data. Advanced state-space models based on Deep Neural Networks (DNN) overcome this limitation but cannot perform exact inferences. In this article, we present a new generative model for sequences that combines both aspects, the ability to perform exact inferences and the ability to model long-term structure, by augmenting the HMM with a deterministic, continuous state variable modeled through a Recurrent Neural Network. We empirically study the performance of the model on (i) synthetic data comparing it to the HMM, (ii) a supervised learning task in bioinformatics where it outperforms two DNN-based regressors and (iii) in the generative modeling of music where it outperforms many prominent DNN-based generative models.;2019;Not health related;Not health related
"Ma, C; Zhang, C";Identifiable Generative Models for Missing Not at Random Data Imputation;Real-world datasets often have missing values associated with complex generative processes, where the cause of the missingness may not be fully observed. This is known as missing not at random (MNAR) data. However, many imputation methods do not take into account the missingness mechanism, resulting in biased imputation values when MNAR data is present. Although there are a few methods that have considered the MNAR scenario, their model's identifiability under MNAR is generally not guaranteed. That is, model parameters can not be uniquely determined even with infinite data samples, hence the imputation results given by such models can still be biased. This issue is especially overlooked by many modern deep generative models. In this work, we fill in this gap by systematically analyzing the identifiability of generative models under MNAR. Furthermore, we propose a practical deep generative model which can provide identifiability guarantees under mild assumptions, for a wide range of MNAR mechanisms. Our method demonstrates a clear advantage for tasks on both synthetic data and multiple real-world scenarios with MNAR data.;2021;Not health related;Not health related
"Chen, YT; Hsu, CY; Yu, CM; Barhamgi, M; Perera, C";On the Private Data Synthesis Through Deep Generative Models for Data Scarcity of Industrial Internet of Things;Due to the data-driven intelligence from the recent deep learning based approaches, the huge amount of data collected from various kinds of sensors from industrial devices have the potential to revolutionize the current technologies used in the industry. To improve the efficiency and quality of machines, the machine manufacturer needs to acquire the history of the machine operation process. However, due to the business secrecy, the factories are not willing to do so. One promising solution to the abovementioned difficulty is the synthetic dataset and an informatic network structure, both through deep generative models such as differentially private generative adversarial networks. Hence, this article initiates the study of the utility difference between the abovementioned two kinds. We carry out an empirical study and find that the classifier generated by private informatic network structure is more accurate than the classifier generated by private synthetic data, with approximately 0.31-7.66%.;2023;Not health related;Not health related
"Di Maggio, LG; Brusa, E; Delprete, C";Zero-Shot Generative AI for Rotating Machinery Fault Diagnosis: Synthesizing Highly Realistic Training Data via Cycle-Consistent Adversarial Networks;The Intelligent Fault Diagnosis of rotating machinery calls for a substantial amount of training data, posing challenges in acquiring such data for damaged industrial machinery. This paper presents a novel approach for generating synthetic data using a Generative Adversarial Network (GAN) with cycle consistency loss function known as cycleGAN. The proposed method aims to generate synthetic data that could effectively replace real experimental data. The generative model is trained to transform wavelet images of simulated vibrational signals into authentic data obtained from machinery with damaged bearings. The utilization of Maximum Mean Discrepancy (MMD) and Frechet Inception Distance (FID) demonstrates a noteworthy resemblance between synthetic and real experimental data. Also, the generative model enables the synthesis of data that may have been entirely lacking from the experimental observation, indicating generative zero-shot learning capabilities. The efficacy of synthetic data in training diagnosis algorithms by means of Transfer Learning (TL) on Convolutional Neural Networks (CNNs) has been demonstrated to be comparable to that of real data. The study has been validated by means of the test rig for medium-sized industrial bearings accessible at the Politecnico di Torino.;2023;Not health related;Not health related
"Burks, R III; Islam, KA; Li, J; Lu, Y";Data Augmentation with Generative Models for Improved Malware Detection: A Comparative Study;Generative Models have been very accommodating when it comes to generating artificial data. Two of the most popular and promising models are the Generative Adversarial Network (GAN) and Variational Autoencoder (VAE) models. They both play critical roles in classification problems by generating synthetic data to train classifier more accurately. Malware detection is the process of determining whether or not software is malicious on the host's system and diagnosing what type of attack it is. Without adequate amount of training data, it makes malware detection less efficient. In this paper, we compare the two generative models to generate synthetic training data to boost the Residual Network (ResNet-18) classifier for malware detection. Experiment results show that adding synthetic malware samples generated by VAE to the training data improved the accuracy of ResNet-18 by 2% as it compared to 6% by GAN.;2019;Not health related;Not health related
"Xin, BZ; Geng, YY; Hu, T; Chen, S; Yang, W; Wang, SW; Huang, LS";Federated synthetic data generation with differential privacy;Distributed machine learning has attracted much attention in the last decade with the widespread use of the Internet of Things. As a generative model, Generative Adversarial Network (GAN) has excellent empir-ical performance. However, the distributed storage of data and the fact that data cannot be shared for pri-vacy reasons in a federated learning setting bring new challenges to training GAN. To address this issue, we propose private FL-GAN, a differentially private GAN based on federated learning. By strategically combining the Lipschitz condition with differential privacy sensitivity, our model can generate high-quality synthetic data without sacrificing the training data's privacy. When communication between cli-ents becomes the main bottleneck for federated learning, we propose to use a serialized model-training paradigm, which significantly reduces communication costs. Considering the distributed data is often non-IID in reality, which poses challenges to modeling, we further propose universal private FL-GAN to approach this problem. We not only theoretically prove that our algorithms can provide strict privacy guarantees with differential privacy, but also experimentally demonstrate that our models can generate satisfactory data while protecting the privacy of the training data, even if the data is non-IID. (c) 2021 Elsevier B.V. All rights reserved.;2022;Not health related;Not health related
Steinhoff, J;Toward a political economy of synthetic data: A data-intensive capitalism that is not a surveillance capitalism?;Surveillance of human subjects is how data-intensive companies obtain much of their data, yet surveillance increasingly meets with social and regulatory resistance. Data-intensive companies are thus seeking other ways to meet their data needs. This article explores one of these: the creation of synthetic data, or data produced artificially as an alternative to real-world data. I show that capital is already heavily invested in synthetic data. I argue that its appeal goes beyond circumventing surveillance to accord with a structural tendency within capitalism toward the autonomization of the circuit of capital. By severing data from human subjectivity, synthetic data contributes to the automation of the production of automation technologies like machine learning. A shift from surveillance to synthesis, I argue, has epistemological, ontological, and political economic consequences for a society increasingly structured around data-intensive capital.;2022;Not health related;Not health related
"Ramamoorthi, R; Arvo, J";Creating generative models from range images;We describe a new approach for creating concise high-level generative models from range images or other approximate representations of real objects. Using data from a variety of acquisition techniques and a user-defined class of models, our method produces a compact object representation that is intuitive and easy to edit. The algorithm has two inter-related phases: recognition, which chooses an appropriate model within a user-specified hierarchy, and parameter estimation, which adjusts the model to best fit the data. Since the approach is model-based, it is relatively insensitive to noise and missing data. We describe practical heuristics for automatically making tradeoffs between simplicity and accuracy to select the best model in a given hierarchy. We also describe a general and efficient technique for optimizing a model by refining its constituent curves. We demonstrate our approach for model recovery using both real and synthetic data and several generative model hierarchies.;1999;Not health related;Not health related
"Nik, AHZ; Riegler, MA; Halvorsen, P; Storås, AM";Generation of Synthetic Tabular Healthcare Data Using Generative Adversarial Networks;High-quality tabular data is a crucial requirement for developing data-driven applications, especially healthcare-related ones, because most of the data nowadays collected in this context is in tabular form. However, strict data protection laws complicates the access to medical datasets. Thus, synthetic data has become an ideal alternative for data scientists and healthcare professionals to circumvent such hurdles. Although many healthcare institutions still use the classical de-identification and anonymization techniques for generating synthetic data, deep learning-based generative models such as generative adversarial networks (GANs) have shown a remarkable performance in generating tabular datasets with complex structures. This paper examines the GANs' potential and applicability within the healthcare industry, which often faces serious challenges with insufficient training data and patient records sensitivity. We investigate several state-of-the-art GAN-based models proposed for tabular synthetic data generation. Healthcare datasets with different sizes, numbers of variables, column data types, feature distributions, and inter-variable correlations are examined. Moreover, a comprehensive evaluation framework is defined to evaluate the quality of the synthetic records and the viability of each model in preserving the patients' privacy. The results indicate that the proposed models can generate synthetic datasets that maintain the statistical characteristics, model compatibility and privacy of the original data. Moreover, synthetic tabular healthcare datasets can be a viable option in many data-driven applications. However, there is still room for further improvements in designing a perfect architecture for generating synthetic tabular data.;2023;Health related;Health related
"Krepelka, M; Vrany, J";Synthesizing Vehicle Speed-Related Features with Neural Networks;In today's automotive industry, digital technology trends such as Big Data, Digital Twin, and Hardware-in-the-loop simulations using synthetic data offer opportunities that have the potential to transform the entire industry towards being more software-oriented and thus more effective and environmentally friendly. In this paper, we propose generative models to synthesize car features related to vehicle speed: brake pressure, percentage of the pressed throttle pedal, engaged gear, and engine RPM. Synthetic data are essential to digitize Hardware-in-the-loop integration testing of the vehicle's dashboard, navigation, or infotainment and for Digital Twin simulations. We trained models based on Multilayer Perceptron and bidirectional Long-Short Term Memory neural network for each feature. These models were evaluated on a real-world dataset and demonstrated sufficient accuracy in predicting the desired features. Combining our current research with previous work on generating a speed profile for an arbitrary trip, where Open Street Map data and elevation data are available, allows us to digitally drive this trip. At the time of writing, we are unaware of any similar data-driven approach for generating desired speed-related features.;2023;Not health related;Not health related
"Boutros, F; Huber, M; Siebke, P; Rieber, T; Damer, N";SFace: Privacy-friendly and Accurate Face Recognition using Synthetic Data;Recent deep face recognition models proposed in the literature utilized large-scale public datasets such as MSCeleb-1M and VGGFace2 for training very deep neural networks, achieving state-of-the-art performance on mainstream benchmarks. Recently, many of these datasets, e.g., MS-Celeb-1M and VGGFace2, are retracted due to credible privacy and ethical concerns. This motivates this work to propose and investigate the feasibility of using a privacy-friendly synthetically generated face dataset to train face recognition models. Towards this end, we utilize a class-conditional generative adversarial network to generate class-labeled synthetic face images, namely SFace. To address the privacy aspect of using such data to train a face recognition model, we provide extensive evaluation experiments on the identity relation between the synthetic dataset and the original authentic dataset used to train the generative model. Our reported evaluation proved that associating an identity of the authentic dataset to one with the same class label in the synthetic dataset is hardly possible. We also propose to train face recognition on our privacy-friendly dataset, SFace, using three different learning strategies, multi-class classification, label-free knowledge transfer, and combined learning of multi-class classification and knowledge transfer. The reported evaluation results on five authentic face benchmarks demonstrated that the privacy-friendly synthetic dataset has a high potential to be used for training face recognition models, achieving, for example, a verification accuracy of 91.87% on LFW using multi-class classification and 99.13% using the combined learning strategy. The training code and the synthetic face image dataset are publicly released(1.);2022;Not health related;Not health related
"Liu, CL; Ventre, C; Polukarov, M";Synthetic Data Augmentation for Deep Reinforcement Learning in Financial Trading;Despite the eye-catching advances in the area, deploying Deep Reinforcement Learning (DRL) in financial markets remains a challenging task. Model-based techniques often fall short due to epistemic uncertainty, whereas model-free approaches require large amount of data that is often unavailable. Motivated by the recent research on the generation of realistic synthetic financial data, we explore the possibility of using augmented synthetic datasets for training DRL agents without direct access to the real financial data. With our novel approach, termed synthetic data augmented reinforcement learning for trading (SDARL4T), we test whether the performance of DRL for financial trading can be enhanced, by attending to both profitability and generalization abilities. We show that DRL agents trained with SDARL4T make a profit which is comparable, and often much larger, than that obtained by the agents trained on real data, while guaranteeing similar robustness. These results support the adoption of our framework in real-world uses of DRL for trading.;2022;Not health related;Not health related
"Zhu, YP; Shen, XY; Du, PL";Denoising-Based Decoupling-Contrastive Learning for Ubiquitous Synthetic Face Images;With the improvement of generative models such as GPT-4, GANs, and diffusion models, synthetic face images are increasingly pervading the current digital environment. Various face editing software based on generative models is already commercially available, which can edit face image attributes, including changing age, makeup, hair, scars, gender, etc. Existing face recognition methods tend to employ synthetic face images to augment datasets during large-scale training. However, the involvement of low-quality synthetic data can impair the feature extraction ability, consequently affecting recognition performance. Furthermore, face editing can potentially be applied for illegal or criminal purposes, such as criminals uploading edited face images to disguise themselves, thereby reducing the accuracy of face recognition models. To mitigate the negative impact of synthetic face images, we propose a denoising-based decoupling-contrastive learning (DDCL) method for extracting more benign features from synthetic data. By designing a siamese network structure with two branches, the framework extracts robust features from natural and synthetic images with the contrastive learning mechanism. Subsequently, the bi-directional coding-based feature decoupling module filters out features of synthetic images before proceeding to identity recognition. Experimental results demonstrate that our method can alleviate the negative impact of synthetic face images and achieve the highest recognition accuracy for both synthetic and natural data.;2023;Not health related;Not health related
"Pozi, MSM; Abu Bakar, A; Ismail, R; Yussof, S; Rahim, FA; Ramli, R";Shifting Dataset To Preserve Data Privacy;Data analytic is very valuable in any domain that produces large amount of data making demands on full datasets to be revealed for analytic purposes are rising. Regardless, the privacy of the released dataset should be preserved. New techniques using synthetic data as a mean to preserve the privacy has been identified as appropriate approach to fulfill the demand. In this paper, a privacy-preserving data synthetic framework for data analytic is proposed. Using a generative model that captures the density function of data attributes, the privacy-preserving synthetic data is produced. We performed classification task through various machine learning classifiers in measuring the data utility of the new privacy-preserving synthesized data.;2018;Not health related;Not health related
"Alcaraz, JML; Strodthoff, N";Diffusion-based conditional ECG generation with structured state space models;Generating synthetic data is a promising solution for addressing privacy concerns that arise when distributing sensitive health data. In recent years, diffusion models have become the new standard for generating various types of data, while structured state space models have emerged as a powerful approach for capturing long-term dependencies in time series. Our proposed solution, SSSD-ECG, combines these two technologies to generate synthetic 12-lead electrocardiograms (ECGs) based on over 70 ECG statements. As reliable baselines are lacking, we also propose conditional variants of two state-of-the-art unconditional generative models. We conducted a thorough evaluation of the quality of the generated samples by assessing pre-trained classifiers on the generated data and by measuring the performance of a classifier trained only on synthetic data. SSSD-ECG outperformed its GAN-based competitors. Our approach was further validated through experiments that included conditional class interpolation and a clinical Turing test, which demonstrated the high quality of SSSD-ECG samples across a wide range of conditions.;2023;Health related;Health related
"Jafari, SM; Cevik, M; Basar, A";Improved _-GAN architecture for generating 3D connected volumes with an application to radiosurgery treatment planning;Generative Adversarial Networks (GANs) have gained significant attention in several computer vision tasks for generating high-quality synthetic data. Various medical applications including diagnostic imaging and radiation therapy can benefit greatly from synthetic data generation due to data scarcity in the domain. However, medical image data is typically kept in 3D space, and generative models suffer from the curse of dimensionality issues in generating such synthetic data. In this paper, we investigate the potential of GANs for generating connected 3D volumes. We propose an improved version of 3D alpha-GAN by incorporating various architectural enhancements. On a synthetic dataset of connected 3D spheres and ellipsoids, our model can generate fully connected 3D shapes with similar geometrical characteristics to that of training data. We also show that our 3D GAN model can successfully generate high-quality 3D tumor volumes and associated treatment specifications (e.g., isocenter locations). Similar moment invariants to the training data as well as fully connected 3D shapes confirm that improved 3D alpha-GAN implicitly learns the training data distribution, and generates realistic-looking samples. The capability of improved 3D alpha-GAN makes it a valuable source for generating synthetic medical image data that can help future research in this domain.;2023;Health related;Health related
"Liu, T; Vietri, G; Wu, ZS";Iterative Methods for Private Synthetic Data: Unifying Framework and New Methods;We study private synthetic data generation for query release, where the goal is to construct a sanitized version of a sensitive dataset, subject to differential privacy, that approximately preserves the answers to a large collection of statistical queries. We first present an algorithmic framework that unifies a long line of iterative algorithms in the literature. Under this framework, we propose two new methods. Our first method, generative networks with the exponential mechanism (GEM), circumvents computational bottlenecks in algorithms such as MWEM by optimizing over generative models parameterized by neural networks, which capture a rich family of distributions while enabling fast gradient-based optimization. The second method, private entropy projection (PEP), can be viewed as an advanced variant of MWEM that adaptively reuses past query measurements to boost accuracy. We demonstrate that GEM and PEP empirically outperform existing algorithms. Furthermore, we show that GEM nicely incorporates prior information from public data while overcoming limitations of PMWPub, the existing state-of-the-art method that also leverages public data.;2021;Not health related;Not health related
"Yang, HY; Staib, LH";DUAL ADVERSARIAL AUTOENCODER FOR DERMOSCOPIC IMAGE GENERATIVE MODELING;Skin cancer is a severe public health issue in the United States and worldwide, While Computer Aided Diagnosis (CAD) of dermoscopic images shows potential in accelerating diagnosis and improving accuracy, numerous issues remain that may be addressed by generative modeling. Major challenges in automated skin lesion classification include manual efforts required to label new training data and a relatively limited amount of data compared to more generalized computer vision tasks. We propose a novel generative model based on a dual discrimination training algorithm for autoencoders. At each training iteration, the encoder and decoder undergo two stages of adversarial training by two individual discriminator networks, The algorithm is end-to-end trainable with standard hack-propagation. In contrast with traditional autoencoders, our method incorporates extra constraints via adversarial training, which results in visually realistic synthetic data, We demonstrate the versatility of the proposed method and applications on numerous tasks including latent space visualization, data augmentation, and image denoising.;2019;Health related;Health related
"Delgado, A; Hamilton, KE";Unsupervised quantum circuit learning in high energy physics;Unsupervised training of generative models is a machine learning task that has many applications in scientific computing. In this work we evaluate the efficacy of using quantum circuit-based generative models to generate synthetic data of high energy physics processes. We use nonadversarial, gradient-based training of quantum circuit Born machines to generate joint distributions over two and three variables.;2022;Not health related;Not health related
"Yao, YC; Li, GZ; Chen, YJ; Li, RQ; Zhou, YZ; Zhang, XD; Hu, HY; Xu, YH";LB-CGM: Latent Based Conditional Generative Model with Reliable Distribution Prediction;Randomness exists either due to the inherent noise of the problem or lack of important input features, which could lead to multimodality of the data distribution. Therefore, in more and more scenarios, it is required not only to predict a single point-value, but also the distribution of the prediction. However, well-studied prediction models usually focus on point prediction that minimizes the mean squared error or the mean absolute error. These approaches could miss important knowledge when their outputs are applied to the downstream decision process. In this paper, we combine the advantages of both GANs (Generative Adversarial Nets) and VAEs (Variational Auto-Encoders), and introduce a latent-based conditional generative model (LB-CGM) to handle the distribution regression problems. The VAE framework is adopted, and the adversarial network is applied to estimate the validity of the generated sample. Besides, the latent-based reconstruction loss is introduced to mitigate mode collapse, in which the direct pairwise comparison between the original and generated samples ensures the correctness and completeness of the generated mode pattern. In this work, we explore a path for the generative model to be used in probabilistic prediction problems. This method can produce conditional prediction distribution close to the actual distribution and is verified on both the synthetic dataset and benchmark dataset.;2020;Not health related;Not health related
"Elfeki, M; Couprie, C; Rivière, M; Elhoseiny, M";GDPP: Learning Diverse Generations using Determinantal Point Processes;Generative models have proven to be an outstanding tool for representing high-dimensional probability distributions and generating realistic looking images. An essential characteristic of generative models is their ability to produce multimodal outputs. However, while training, they are often susceptible to mode collapse, that is models are limited in mapping input noise to only a few modes of the true data distribution. In this work, we draw inspiration from Determinantal Point Process (DPP) to propose an unsupervised penalty loss that alleviates mode collapse while producing higher quality samples. DPP is an elegant probabilistic measure used to model negative correlations within a subset and hence quantify its diversity. We use DPP kernel to model the diversity in real data as well as in synthetic data. Then, we devise an objective term that encourages generator to synthesize data with a similar diversity to real data. In contrast to previous state-of-the-art generative models that tend to use additional trainable parameters or complex training paradigms, our method does not change the original training scheme. Embedded in an adversarial training and variational autoencoder, our Generative DPP approach shows a consistent resistance to mode-collapse on a wide-variety of synthetic data and natural image datasets including MNIST, CIFAR10, and CelebA, while outperforming state-of-the-art methods for data-efficiency, generation quality, and convergence-time whereas being 5.8x faster than its closest competitor.(1);2019;Not health related;Not health related
[Anonymous];Into the latent space;Generative deep learning can produce artificial, natural-looking images and other data, which has many promising applications in research - and in art. But the wide availability of generative models poses a challenge for society, which needs tools and best practices to distinguish between real and synthetic data.;2020;Not health related;Not health related
"Aznan, NKN; Atapour-Abarghouei, A; Bonner, S; Connolly, JD; Al Moubayed, N; Breckon, TP";Simulating Brain Signals: Creating Synthetic EEG Data via Neural-Based Generative Models for Improved SSVEP Classification;Despite significant recent progress in the area of Brain-Computer Interface (BCI), there are numerous shortcomings associated with collecting Electroencephalography (EEG) signals in real-world environments. These include, but are not limited to, subject and session data variance, long and arduous calibration processes and predictive generalisation issues across different subjects or sessions. This implies that many downstream applications, including Steady State Visual Evoked Potential (SSVEP) based classification systems, can suffer from a shortage of reliable data. Generating meaningful and realistic synthetic data can therefore be of significant value in circumventing this problem. We explore the use of modern neural-based generative models trained on a limited quantity of EEG data collected from different subjects to generate supplementary synthetic EEG signal vectors, subsequently utilised to train an SSVEP classifier. Extensive experimental analysis demonstrates the efficacy of our generated data, leading to improvements across a variety of evaluations, with the crucial task of cross-subject generalisation improving by over 35% with the use of such synthetic data.;2019;Not health related;Not health related
"Carrle, FP; Hollenbenders, Y; Reichenbach, A";Generation of synthetic EEG data for training algorithms supporting the diagnosis of major depressive disorder;Introduction: Major depressive disorder (MDD) is the most common mental disorder worldwide, leading to impairment in quality and independence of life. Electroencephalography (EEG) biomarkers processed with machine learning (ML) algorithms have been explored for objective diagnoses with promising results. However, the generalizability of those models, a prerequisite for clinical application, is restricted by small datasets. One approach to train ML models with good generalizability is complementing the original with synthetic data produced by generative algorithms. Another advantage of synthetic data is the possibility of publishing the data for other researchers without risking patient data privacy. Synthetic EEG time-series have not yet been generated for two clinical populations like MDD patients and healthy controls.Methods: We first reviewed 27 studies presenting EEG data augmentation with generative algorithms for classification tasks, like diagnosis, for the possibilities and shortcomings of recent methods. The subsequent empirical study generated EEG time-series based on two public datasets with 30/28 and 24/29 subjects (MDD/controls). To obtain baseline diagnostic accuracies, convolutional neural networks (CNN) were trained with time-series from each dataset. The data were synthesized with generative adversarial networks (GAN) consisting of CNNs. We evaluated the synthetic data qualitatively and quantitatively and finally used it for re-training the diagnostic model.Results: The reviewed studies improved their classification accuracies by between 1 and 40% with the synthetic data. Our own diagnostic accuracy improved up to 10% for one dataset but not significantly for the other. We found a rich repertoire of generative models in the reviewed literature, solving various technical issues. A major shortcoming in the field is the lack of meaningful evaluation metrics for synthetic data. The few studies analyzing the data in the frequency domain, including our own, show that only some features can be produced truthfully.Discussion: The systematic review combined with our own investigation provides an overview of the available methods for generating EEG data for a classification task, their possibilities, and shortcomings. The approach is promising and the technical basis is set. For a broad application of these techniques in neuroscience research or clinical application, the methods need fine-tuning facilitated by domain expertise in (clinical) EEG research.;2023;Health related;Health related
"Zhao, GN; Magoulianitis, V; You, SY; Kuo, CCJ";LGSQE: LIGHTWEIGHT GENERATED SAMPLE QUALITY EVALUATION;"Despite prolific work on evaluating generative models, little research has been done on the quality evaluation of an individual generated sample. To address this problem, a lightweight generated sample quality evaluation (LGSQE) method is proposed in this work. In the training stage of LGSQE, a binary classifier is trained on real and synthetic samples, where real and synthetic data are labeled by 0 and 1, respectively. In the inference stage, the classifier assigns soft labels (ranging from 0 to 1) to each generated sample. The value of the soft label indicates the quality level; namely, the quality is better if its soft label is closer to 0. LGSQE can serve as a post-processing module for quality control. Furthermore, LGSQE can be used to evaluate the performance of generative models, such as accuracy, AUC, precision, and recall, by aggregating sample-level quality. Experiments are conducted on several datasets and generative models to demonstrate that LGSQE can preserve the same performance rank order as that predicted by the Frechet Inception Distance (FID) but with significantly lower complexity.";2023;Not health related;Not health related
"Ma, XB; Yang, R; Zheng, MB";RDP-WGAN: Image Data Privacy Protection based on Renyi Differential Privacy;In recent years, artificial intelligence technology based on image data has been widely used in various industries. Rational analysis and mining of image data can not only promote the development of the technology field but also become a new engine to drive economic development. However, the privacy leakage problem has become more and more serious. To solve the privacy leakage problem of image data, this paper proposes the RDP-WGAN privacy protection framework, which deploys the Renyi differential privacy (RDP) protection techniques in the training process of generative adversarial networks to obtain a generative model with differential privacy. This generative model is used to generate an unlimited number of synthetic datasets to complete various data analysis tasks instead of sensitive datasets. Experimental results demonstrate that the RDP-WGAN privacy protection framework provides privacy protection for sensitive image datasets while ensuring the usefulness of the synthetic datasets.;2022;Not health related;Not health related
"Catrambone, V; Greco, A; Vanello, N; Scilingo, EP; Valenza, G";Time-Resolved Directional Brain-Heart Interplay Measurement Through Synthetic Data Generation Models;Although a plethora of synthetic data generation models have been proposed to validate biomarkers of brain and cardiovascular dynamics separately, a limited number of computational methods estimating directed brain-heart information flow are currently available in the scientific literature. This study introduces a computational framework exploiting existing generative models for a novel time-resolved quantification of causal brain-heart interplay. Exemplarily, having electroencephalographic signals and heart rate variability series as inputs, respective synthetic data models are coupled through parametrised functions defined in accordance with current central autonomic network (CAN) knowledge. We validate this concept using data from 30 healthy volunteers undergoing notable sympathetic elicitation through a cold-pressor test, and further compare the obtained results with a state-of-the-art method as maximal information coefficient. Although our findings are in agreement with previous CAN findings, we report new insights into the role of fronto-parietal region activity and lateralisation mechanisms over the temporal cortices during prolonged peripheral elicitation, which occur with specific time delays. Additionally, the afferent autonomic outflow maps to brain oscillations in the and bands, whereas complementary cortical dynamics in the , , and bands act on efferent autonomic control. The proposed framework paves the way towards novel biomarker definitions for the assessment of complex physiological networks using existing data generation models for brain and peripheral dynamics.;2019;Health related;Health related
"Biswas, S; Riba, P; Lladós, J; Pal, U";Graph-Based Deep Generative Modelling for Document Layout Generation;One of the major prerequisites for any deep learning approach is the availability of large-scale training data. When dealing with scanned document images in real world scenarios, the principal information of its content is stored in the layout itself. In this work, we have proposed an automated deep generative model using Graph Neural Networks (GNNs) to generate synthetic data with highly variable and plausible document layouts that can be used to train document interpretation systems, in this case, specially in digital mailroom applications. It is also the first graph-based approach for document layout generation task experimented on administrative document images, in this case, invoices.;2021;Not health related;Not health related
"Castelli, M; Manzoni, L; Espindola, T; Popovic, A; De Lorenzo, A";Generative adversarial networks for generating synthetic features for Wi-Fi signal quality;Wireless networks are among the fundamental technologies used to connect people. Considering the constant advancements in the field, telecommunication operators must guarantee a high-quality service to keep their customer portfolio. To ensure this high-quality service, it is common to establish partnerships with specialized technology companies that deliver software services in order to monitor the networks and identify faults and respective solutions. A common barrier faced by these specialized companies is the lack of data to develop and test their products. This paper investigates the use of generative adversarial networks (GANs), which are state-of-the-art generative models, for generating synthetic telecommunication data related to Wi-Fi signal quality. We developed, trained, and compared two of the most used GAN architectures: the Vanilla GAN and the Wasserstein GAN (WGAN). Both models presented satisfactory results and were able to generate synthetic data similar to the real ones. In particular, the distribution of the synthetic data overlaps the distribution of the real data for all of the considered features. Moreover, the considered generative models can reproduce the same associations observed for the synthetic features. We chose the WGAN as the final model, but both models are suitable for addressing the problem at hand.;2021;Not health related;Not health related
"Zhou, XL; Hasan, M; Deschaintre, V; Guerrero, P; Hold-Geoffroy, Y; Sunkavalli, K; Kalantari, NK";PhotoMat: A Material Generator Learned from Single Flash Photos;"Authoring high-quality digital materials is key to realism in 3D rendering. Previous generative models for materials have been trained exclusively on synthetic data; such data is limited in availability and has a visual gap to real materials. We circumvent this limitation by proposing PhotoMat: the first material generator trained exclusively on real photos of material samples captured using a cell phone camera with flash. Supervision on individual material maps is not available in this setting. Instead, we train a generator for a neural material representation that is rendered with a learned relighting module to create arbitrarily lit RGB images; these are compared against real photos using a discriminator. We train PhotoMat with a new dataset of 12,000 material photos captured with handheld phone cameras under flash lighting. We demonstrate that our generated materials have better visual quality than previous material generators trained on synthetic data. Moreover, we can fit analytical material models to closely match these generated neural materials, thus allowing for further editing and use in 3D rendering.";2023;Not health related;Not health related
"Zamir, B; Campos, JR; Vieira, M";Advanced Machine Learning for Runtime Data Generation;Given the ubiquity of software in everyday critical tasks, ensuring its dependability is of utmost importance. Software faults, which can lead to errors and vulnerabilities, can significantly comprise the target system. Various techniques have been developed to improve the dependability of software-intensive systems, from fault avoidance to fault tolerance. Machine Learning (ML) techniques have been playing a vital role in improving the dependability of systems. Nonetheless, such techniques require significant amounts of data, which are not typically available. To overcome this, various techniques, such as fault injection or intrusion injection, have been proposed to generate realistic data. Still, they are computationally expensive and require considerable expertise. At the same time, a recent growing sub-field of ML is generative models. Generative models offer an innovative solution by creating synthetic data that closely resemble real-world samples. If such models could be used to generate realistic synthetic failure or intrusion data on demand, their value would be significant. Notwithstanding, the feasibility of such an approach has not yet been researched. Generative models have only mostly been used for sequential data (e.g., text or music) or data with high spatial dependency (e.g., images). On the other hand, dependability problems often have high dimensional tabular data, for which generative models are yet to excel, and for which it is also considerably more difficult to assess the representativeness of the generated data. This research will focus on determining the feasibility of using generative techniques to generate runtime data to support dependability research.;2023;Not health related;Not health related
"Noguer, J; Contreras, I; Mujahid, O; Beneyto, A; Vehi, J";Generation of Individualized Synthetic Data for Augmentation of the Type 1 Diabetes Data Sets Using Deep Learning Models;In this paper, we present a methodology based on generative adversarial network architecture to generate synthetic data sets with the intention of augmenting continuous glucose monitor data from individual patients. We use these synthetic data with the aim of improving the overall performance of prediction models based on machine learning techniques. Experiments were performed on two cohorts of patients suffering from type 1 diabetes mellitus with significant differences in their clinical outcomes. In the first contribution, we have demonstrated that the chosen methodology is able to replicate the intrinsic characteristics of individual patients following the statistical distributions of the original data. Next, a second contribution demonstrates the potential of synthetic data to improve the performance of machine learning approaches by testing and comparing different prediction models for the problem of predicting nocturnal hypoglycemic events in type 1 diabetic patients. The results obtained for both generative and predictive models are quite encouraging and set a precedent in the use of generative techniques to train new machine learning models.;2022;Health related;Health related
"Treppner, M; Salas-Bastos, A; Hess, M; Lenz, S; Vogel, T; Binder, H";Synthetic single cell RNA sequencing data from small pilot studies using deep generative models;Deep generative models, such as variational autoencoders (VAEs) or deep Boltzmann machines (DBMs), can generate an arbitrary number of synthetic observations after being trained on an initial set of samples. This has mainly been investigated for imaging data but could also be useful for single-cell transcriptomics (scRNA-seq). A small pilot study could be used for planning a full-scale experiment by investigating planned analysis strategies on synthetic data with different sample sizes. It is unclear whether synthetic observations generated based on a small scRNA-seq dataset reflect the properties relevant for subsequent data analysis steps. We specifically investigated two deep generative modeling approaches, VAEs and DBMs. First, we considered single-cell variational inference (scVI) in two variants, generating samples from the posterior distribution, the standard approach, or the prior distribution. Second, we propose single-cell deep Boltzmann machines (scDBMs). When considering the similarity of clustering results on synthetic data to ground-truth clustering, we find that the scVIposterior variant resulted in high variability, most likely due to amplifying artifacts of small datasets. All approaches showed mixed results for cell types with different abundance by overrepresenting highly abundant cell types and missing less abundant cell types. With increasing pilot dataset sizes, the proportions of the cells in each cluster became more similar to that of ground-truth data. We also showed that all approaches learn the univariate distribution of most genes, but problems occurred with bimodality. Across all analyses, in comparing 10x Genomics and Smart-seq2 technologies, we could show that for 10x datasets, which have higher sparsity, it is more challenging to make inference from small to larger datasets. Overall, the results show that generative deep learning approaches might be valuable for supporting the design of scRNA-seq experiments.;2021;Not health related;Not health related
"Chen, NT; Klushyn, A; Kurle, R; Jiang, XY; Bayer, J; van der Smagt, P";Metrics for Deep Generative Models;"Neural samplers such as variational autoencoders (VAEs) or generative adversarial networks (GANs) approximate distributions by transforming samples from a simple random source-the latent space-to samples from a more complex distribution represented by a dataset. While the manifold hypothesis implies that a dataset contains large regions of low density, the training criterions of VAEs and GANs will make the latent space densely covered. Consequently points that are separated by low-density regions in observation space will be pushed together in latent space, making stationary distances poor proxies for similarity. We transfer ideas from Riemannian geometry to this setting, letting the distance between two points be the shortest path on a Riemannian manifold induced by the transformation. The method yields a principled distance measure, provides a tool for visual inspection of deep generative models, and an alternative to linear interpolation in latent space. In addition, it can be applied for robot movement generalization using previously learned skills. The method is evaluated on a synthetic dataset with known ground truth; on a simulated robot arm dataset; on human motion capture data; and on a generative model of handwritten digits.";2018;Not health related;Not health related
"Zaballa, O; Pérez, A; Inhiesto, EG; Ayesta, TA; Lozano, JA";Learning the progression patterns of treatments using a probabilistic generative model;"Modeling a disease or the treatment of a patient has drawn much attention in recent years due to the vast amount of information that Electronic Health Records contain. This paper presents a probabilistic generative model of treatments that are described in terms of sequences of medical activities of variable length. The main objective is to identify distinct subtypes of treatments for a given disease, and discover their development and progression. To this end, the model considers that a sequence of actions has an associated hierarchical structure of latent variables that both classifies the sequences based on their evolution over time, and segments the sequences into different progression stages. The learning procedure of the model is performed with the Expectation-Maximization algorithm which considers the exponential number of configurations of the latent variables and is efficiently solved with a method based on dynamic programming. The evaluation of the model is twofold: first, we use synthetic data to demonstrate that the learning procedure allows the generative model underlying the data to be recovered; we then further assess the potential of our model to provide treatment classification and staging information in real-world data. Our model can be seen as a tool for classification, simulation, data augmentation and missing data imputation.";2023;Health related;Health related
"Allen, C; Aryal, S; Do, T; Gautum, R; Hasan, MM; Jasthi, BK; Gnimpieba, E; Gadhamshetty, V";Deep learning strategies for addressing issues with small datasets in 2D materials research: Microbial Corrosion;Protective coatings based on two dimensional materials such as graphene have gained traction for diverse applications. Their impermeability, inertness, excellent bonding with metals, and amenability to functionalization renders them as promising coatings for both abiotic and microbiologically influenced corrosion (MIC). Owing to the success of graphene coatings, the whole family of 2D materials, including hexagonal boron nitride and molybdenum disulphide are being screened to obtain other promising coatings. AI-based data-driven models can accelerate virtual screening of 2D coatings with desirable physical and chemical properties. However, lack of large experimental datasets renders training of classifiers difficult and often results in over-fitting. Generate large datasets for MIC resistance of 2D coatings is both complex and laborious. Deep learning data augmentation methods can alleviate this issue by generating synthetic electrochemical data that resembles the training data classes. Here, we investigated two different deep generative models, namely variation autoencoder (VAE) and generative adversarial network (GAN) for generating synthetic data for expanding small experimental datasets. Our model experimental system included few layered graphene over copper surfaces. The synthetic data generated using GAN displayed a greater neural network system performance (83-85% accuracy) than VAE generated synthetic data (78-80% accuracy). However, VAE data performed better (90% accuracy) than GAN data (84%-85% accuracy) when using XGBoost. Finally, we show that synthetic data based on VAE and GAN models can drive machine learning models for developing MIC resistant 2D coatings.;2022;Not health related;Not health related
"Shodamola, J; Qureshi, H; Masood, U; Imran, A";Towards Addressing the Spatial Sparsity of MDT Reports to Enable Zero Touch Network Automation;Minimization of Drive Test (MDT) reports are a key enabler for Machine Learning (ML)-based zero-touch automation envisioned for emerging cellular networks. However, due to numerous factors, the MDT reports are spatially sparse in nature. This sparsity undermines the performance of ML models that are built on the MDT data to estimate and optimize network KPIs. In this paper, we present and evaluate a framework to address this challenge. We leverage generative models, specifically, Generative Adversarial Networks (GAN) and Variational Autoencoders (VAE) to augment the sparse multi-dimensional MDT data. Unlike image data where the quality of synthetic images produced by the generative models can be evaluated visually, establishing the authenticity of tabular synthetic data is a more complex problem. We address this problem by leveraging a tripartite approach: 1) We use several statistical measures to quantify the resemblance of synthetic data with original data. 2) We compare the performance of an ensemble learning model trained on augmented data, with that of trained on original data only 3) We benchmark the performance of the generative models with several classical ML models. This analysis is carried out for varying levels of sparsity and reveals insights about robustness of generative models against training data sparsity as well as on suitability of various methods for evaluating the quality of the generated synthetic tabular data. Results show GAN performs considerably better compared to other approaches. The presented solution thus can be used to overcome the sparsity problem in MDT reports thereby enabling ML-based automation use cases.;2021;Not health related;Not health related
"Trampert, P; Rubinstein, D; Boughorbel, F; Schlinkmann, C; Luschkova, M; Slusallek, P; Dahmen, T; Sandfeld, S";Deep Neural Networks for Analysis of Microscopy Images-Synthetic Data Generation and Adaptive Sampling;The analysis of microscopy images has always been an important yet time consuming process in materials science. Convolutional Neural Networks (CNNs) have been very successfully used for a number of tasks, such as image segmentation. However, training a CNN requires a large amount of hand annotated data, which can be a problem for material science data. We present a procedure to generate synthetic data based on ad hoc parametric data modelling for enhancing generalization of trained neural network models. Especially for situations where it is not possible to gather a lot of data, such an approach is beneficial and may enable to train a neural network reasonably. Furthermore, we show that targeted data generation by adaptively sampling the parameter space of the generative models gives superior results compared to generating random data points.;2021;Not health related;Not health related
"Lenz, S; Hess, M; Binder, H";Deep generative models in DataSHIELD;BackgroundThe best way to calculate statistics from medical data is to use the data of individual patients. In some settings, this data is difficult to obtain due to privacy restrictions. In Germany, for example, it is not possible to pool routine data from different hospitals for research purposes without the consent of the patients.MethodsThe DataSHIELD software provides an infrastructure and a set of statistical methods for joint, privacy-preserving analyses of distributed data. The contained algorithms are reformulated to work with aggregated data from the participating sites instead of the individual data. If a desired algorithm is not implemented in DataSHIELD or cannot be reformulated in such a way, using artificial data is an alternative. Generating artificial data is possible using so-called generative models, which are able to capture the distribution of given data. Here, we employ deep Boltzmann machines (DBMs) as generative models. For the implementation, we use the package BoltzmannMachines from the Julia programming language and wrap it for use with DataSHIELD, which is based on R.ResultsWe present a methodology together with a software implementation that builds on DataSHIELD to create artificial data that preserve complex patterns from distributed individual patient data. Such data sets of artificial patients, which are not linked to real patients, can then be used for joint analyses. As an exemplary application, we conduct a distributed analysis with DBMs on a synthetic data set, which simulates genetic variant data. Patterns from the original data can be recovered in the artificial data using hierarchical clustering of the virtual patients, demonstrating the feasibility of the approach. Additionally, we compare DBMs, variational autoencoders, generative adversarial networks, and multivariate imputation as generative approaches by assessing the utility and disclosure of synthetic data generated from real genetic variant data in a distributed setting with data of a small sample size.ConclusionsOur implementation adds to DataSHIELD the ability to generate artificial data that can be used for various analyses, e.g., for pattern recognition with deep learning. This also demonstrates more generally how DataSHIELD can be flexibly extended with advanced algorithms from languages other than R.;2021;Health related;Health related
"Ghanadian, H; Nejadgholi, I; Al Osman, H";Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models;Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.;2024;Health related;Health related
"Elhabian, SY; Agrawal, P; Whitaker, RT";OPTIMAL PARAMETER MAP ESTIMATION FOR SHAPE REPRESENTATION: A GENERATIVE APPROACH;Probabilistic label maps are a useful tool for important medical image analysis tasks such as segmentation, shape analysis, and atlas building. Existing methods typically rely on blurred signed distance maps or smoothed label maps to model uncertainties and shape variabilities, which do not conform to any generative model or estimation process, and are therefore suboptimal. In this paper, we propose to learn probabilistic label maps using a generative model on given set of binary label maps. The proposed approach generalizes well on unseen data while simultaneously capturing the variability in the training samples. Efficiency of the proposed approach is demonstrated for consensus generation and shape-based clustering using synthetic datasets as well as left atrial segmentations from late-gadolinium enhancement MRI.;2016;Health related;Health related
"Cheng, V; Suriyakumar, VM; Dullerud, N; Joshi, S; Ghassemi, M";Can You Fake It Until You Make It?: Impacts of Differentially Private Synthetic Data on Downstream Classification Fairness;The recent adoption of machine learning models in high-risk settings such as medicine has increased demand for developments in privacy and fairness. Rebalancing skewed datasets using synthetic data created by generative adversarial networks (GANs) has shown potential to mitigate disparate impact on minoritized subgroups. However, such generative models are subject to privacy attacks that can expose sensitive data from the training dataset. Differential privacy (DP) is the current leading solution for privacy-preserving machine learning. Differentially private GANs (DP GANs) are often considered a potential solution for improving model fairness while maintaining privacy of sensitive training data. We investigate the impact of using synthetic images from DP GANs on downstream classification model utility and fairness. We demonstrate that existing DP GANs cannot simultaneously maintain model utility, privacy, and fairness. The images generated from GAN models trained with DP exhibit extreme decreases in image quality and utility which leads to poor downstream classification model performance. Our evaluation highlights the friction between privacy, fairness, and utility and how this directly translates into real loss of performance and representation in common machine learning settings. Our results show that additional work improving the utility and fairness of DP generative models is required before they can be utilized as a potential solution to privacy and fairness issues stemming from lack of diversity in the training dataset.;2021;Not health related;Not health related
"Tepelyan, R; Gopal, A";Generative Machine Learning for Multivariate Equity Returns;The use of machine learning to generate synthetic data has grown in popularity with the proliferation of text-to-image models and especially large language models. The core methodology these models use is to learn the distribution of the underlying data, similar to the classical methods common in finance of fitting statistical models to data. In this work, we explore the efficacy of using modern machine learning methods, specifically conditional importance weighted autoencoders (a variant of variational autoencoders) and conditional normalizing flows, for the task of modeling the returns of equities. The main problem we work to address is modeling the joint distribution of all the members of the S&P 500, or, in other words, learning a 500-dimensional joint distribution. We show that this generative model has a broad range of applications in finance, including generating realistic synthetic data, volatility and correlation estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization.;2023;Not health related;Not health related
"Barrere, K; Soullard, Y; Lemaitre, A; Coueasnon, B";Training transformer architectures on few annotated data: an application to historical handwritten text recognition;Transformer-based architectures show excellent results on the task of handwritten text recognition, becoming the standard architecture for modern datasets. However, they require a significant amount of annotated data to achieve competitive results. They typically rely on synthetic data to solve this problem. Historical handwritten text recognition represents a challenging task due to degradations, specific handwritings for which few examples are available and ancient languages that vary over time. These limitations also make it difficult to generate realistic synthetic data. Given sufficient and appropriate data, Transformer-based architectures could alleviate these concerns, thanks to their ability to have a global view of textual images and their language modeling capabilities. In this paper, we propose the use of a lightweight Transformer model to tackle the task of historical handwritten text recognition. To train the architecture, we introduce realistic looking synthetic data reproducing the style of historical handwritings. We present a specific strategy, both for training and prediction, to deal with historical documents, where only a limited amount of training data are available. We evaluate our approach on the ICFHR 2018 READ dataset which is dedicated to handwriting recognition in specific historical documents. The results show that our Transformer-based approach is able to outperform existing methods.;2024;Not health related;Not health related
"Kafunah, J; Verma, P; Ali, MI; Breslin, JG";Out-of-Distribution Data Generation for Fault Detection and Diagnosis in Industrial Systems;The emergence of Industry 4.0 has transformed modern-day factories into high-tech industrial sites through rapid automation and increased access to real-time data. Deep learning approaches possessing superior capabilities for intelligent, data-driven fault diagnosis have become critical in ensuring process safety and reliability in these industrial sites. However, such applications trained exclusively on in-distribution process data face challenges in the wake of previously unseen out-of-distribution (OOD) data in the real world. This paper addresses the challenge of out-of-distribution data detection for deep learning-based fault diagnosis models by generating synthetic data to simulate real-world anomalies not present in the training set. We propose Manifold Guided Sampling (MGS), a data-driven method for generating synthetic OOD samples from the in-distribution data-supporting manifold estimated through a deep generative model. Synthetic data from MGS enhances the model capacity for prediction uncertainty quantification, resulting in safe and reliable models for real-world industrial process monitoring. Furthermore, the MGS algorithm maintains the in-distribution data feature space as a reference point during data generation to ensure the resulting synthetic OOD data is realistic. We analyze the effectiveness of MGS through experiments conducted on the steel plates faults dataset and demonstrate that augmenting training data with synthetic data from MGS enhances the model performance in OOD detection tasks and provides robustness against dataset distributional shifts. The findings underscore the effectiveness of utilizing synthetic MGS-generated OOD data in scenarios where real-world OOD data is limited, enabling better generalization and more reliable fault detection in practical applications.;2023;Not health related;Not health related
"Charlier, J; State, R; Hilger, J";PHom-GeM: Persistent Homology for Generative Models;Generative neural network models, including Generative Adversarial Network (GAN) and Auto-Encoders (AE), are among the most popular neural network models to generate adversarial data. The GAN model is composed of a generator that produces synthetic data and of a discriminator that discriminates between the generator's output and the true data. AE consist of an encoder which maps the model distribution to a latent manifold and of a decoder which maps the latent manifold to a reconstructed distribution. However, generative models are known to provoke chaotically scattered reconstructed distribution during their training, and consequently, incomplete generated adversarial distributions. Current distance measures fail to address this problem because they are not able to acknowledge the shape of the data manifold, i.e. its topological features, and the scale at which the manifold should be analyzed. We propose Persistent Homology for Generative Models, PHom-GeM, a new methodology to assess and measure the distribution of a generative model. PHom-GeM minimizes an objective function between the true and the reconstructed distributions and uses persistent homology, the study of the topological features of a space at different spatial resolutions, to compare the nature of the true and the generated distributions. Our experiments underline the potential of persistent homology for Wasserstein GAN in comparison to Wasserstein AE and Variational AE. The experiments are conducted on a real-world data set particularly challenging for traditional distance measures and generative neural network models. PHom-GeM is the first methodology to propose a topological distance measure, the bottleneck distance, for generative models used to compare adversarial samples in the context of credit card transactions.;2019;Not health related;Not health related
"Elkano, M; Bustince, H; Paplinski, A";A Preliminary Approach to Semi-supervised Learning in Convolutional Neural Networks Applying Sleep-Wake Cycles;The scarcity of labeled data has limited the capacity of convolutional neural networks (CNNs) until not long ago and still represents a serious problem in a number of image processing applications. Unsupervised methods have been shown to perform well in feature extraction and clustering tasks, but further investigation on unsupervised solutions for CNNs is needed. In this work, we propose a bio-inspired methodology that applies a deep generative model to help the CNN take advantage of unlabeled data and improve its classification performance. Inspired by the human sleep-wake cycles, the proposed method divides the learning process into sleep and waking periods. During the waking period, both the generative model and the CNN learn from real training data simultaneously. When sleep begins, none of the networks receive real data and the generative model creates a synthetic dataset from which the CNN learns. The experimental results showed that the generative model was able to teach the CNN and improve its classification performance.;2017;Not health related;Not health related
"Ravuri, S; Vinyals, O";Classification Accuracy Score for Conditional Generative Models;"Deep generative models (DGMs) of images are now sufficiently mature that they produce nearly photorealistic samples and obtain scores similar to the data distribution on heuristics such as Frechet Inception Distance (FID). These results, especially on large-scale datasets such as ImageNet, suggest that DGMs are learning the data distribution in a perceptually meaningful space and can be used in downstream tasks. To test this latter hypothesis, we use class-conditional generative models from a number of model classes-variational autoencoders, autoregressive models, and generative adversarial networks (GANs)-to infer the class labels of real data. We perform this inference by training an image classifier using only synthetic data and using the classifier to predict labels on real data. The performance on this task, which we call Classification Accuracy Score (CAS), reveals some surprising results not identified by traditional metrics and constitute our contributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1 and Top-5 accuracy decrease by 27.9% and 41.6%, respectively, compared to the original data; and conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on this benchmark. Second, CAS automatically surfaces particular classes for which generative models failed to capture the data distribution, and were previously unknown in the literature. Third, we find traditional GAN metrics such as Inception Score (IS) and FID neither predictive of CAS nor useful when evaluating non-GAN models. Furthermore, in order to facilitate better diagnoses of generative models, we open-source the proposed metric.";2019;Not health related;Not health related
"Papagiannis, T; Alexandridis, G; Stafylopatis, A";Boosting Deep Reinforcement Learning Agents with Generative Data Augmentation;Data augmentation is a promising technique in improving exploration and convergence speed in deep reinforcement learning methodologies. In this work, we propose a data augmentation framework based on generative models for creating completely novel states and increasing diversity. For this purpose, a diffusion model is used to generate artificial states (learning the distribution of original, collected states), while an additional model is trained to predict the action executed between two consecutive states. These models are combined to create synthetic data for cases of high and low immediate rewards, which are encountered less frequently during the agent's interaction with the environment. During the training process, the synthetic samples are mixed with the actually observed data in order to speed up agent learning. The proposed methodology is tested on the Atari 2600 framework, producing realistic and diverse synthetic data which improve training in most cases. Specifically, the agent is evaluated on three heterogeneous games, achieving a reward increase of up to 31%, although the results indicate performance variance among the different environments. The augmentation models are independent of the learning process and can be integrated to different algorithms, as well as different environments, with slight adaptations.;2024;Not health related;Not health related
"Kuo, NIH; Perez-Concha, O; Hanly, M; Mnatzaganian, E; Hao, BD; Di Sipio, M; Yu, GL; Vanjara, J; Valerie, IC; Costa, JD; Churches, T; Lujic, S; Hegarty, J; Jorm, L; Barbieri, S";Enriching Data Science and Health Care Education: Application and Impact of Synthetic Data Sets Through the Health Gym Project;Large-scale medical data sets are vital for hands-on education in health data science but are often inaccessible due to privacy concerns. Addressing this gap, we developed the Health Gym project, a free and open-source platform designed to generate synthetic health data sets applicable to various areas of data science education, including machine learning, data visualization, and traditional statistical models. Initially, we generated 3 synthetic data sets for sepsis, acute hypotension, and antiretroviral therapy for HIV infection. This paper discusses the educational applications of Health Gym's synthetic data sets. We illustrate this through their use in postgraduate health data science courses delivered by the University of New South Wales, Australia, and a Datathon event, involving academics, students, clinicians, and local health district professionals. We also include adaptable worked examples using our synthetic data sets, designed to enrich hands-on tutorial and workshop experiences. Although we highlight the potential of these data sets in advancing data science education and health care artificial intelligence, we also emphasize the need for continued research into the inherent limitations of synthetic data.;2024;Health related;Health related
"Alsafadi, F; Wu, X";Deep generative modeling-based data augmentation with demonstration using the BFBT benchmark void fraction datasets;Deep learning (DL) has achieved remarkable successes in many disciplines such as computer vision and natural language processing due to the availability of big data. However, such success cannot be easily replicated in many nuclear engineering problems because of the limited amount of training data, especially when the data comes from high-cost experiments. To overcome such a data scarcity issue, this paper explores the applications of deep generative models (DGMs) that have been widely used for image data generation to scientific data augmentation. DGMs, such as generative adversarial networks (GANs), normalizing flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can be trained to learn the underlying probabilistic distribution of the training dataset. Once trained, they can be used to generate synthetic data that are similar to the training data and significantly expand the dataset size. By employing DGMs to augment TRACE simulated data of the steady-state void fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have comparable generative performance with similar errors in the synthetic data, with CVAEs achieving the smallest errors. The findings shows that DGMs have a great potential to augment scientific data in nuclear engineering, which proves effective for expanding the training dataset and enabling other DL models to be trained more accurately.;2023;Not health related;Not health related
"Debnath, A; Gupta, N; Waghmare, G; Wadhwa, H; Asthana, S; Arora, A";Adversarial Generation of Temporal Data: A Critique on Fidelity of Synthetic Data;Generative modelling for temporal data has seen a paradigm shift from autoregressive to adversarial models. Adversarial generation algorithms have proven to be more efficient in capturing the complex temporal correlations that the simplistic autoregressive model could not. Albeit, high-fidelity remains a concern even for adversarial modelling. The generation of high-fidelity data requires the model to have three strengths: capture feature correlations, model long-term dependencies, and scalability in dimensions. This paper analyzes these strengths on the existing methods of adversarial temporal generation regarding the fidelity of synthetic data. Towards this, we evaluate different algorithms for adversarial temporal generation on five different datasets of varying dynamics (long-term vs. short-term dependency) and dimensionality. We conclude by discussing gaps in the literature and future directions for high fidelity temporal data generation through adversarial methods.;2021;Not health related;Not health related
"Li, CS; Cheung, WK; Ye, YM; Zhang, XF; Chu, DH; Li, X";The Author-Topic-Community model for author interest profiling and community discovery;In this paper, we propose a generative model named the author-topic-community (ATC) model for representing a corpus of linked documents. The ATC model allows each author to be associated with a topic distribution and a community distribution as its model parameters. A learning algorithm based on variational inference is derived for the model parameter estimation where the two distributions are essentially reinforcing each other during the estimation. We compare the performance of the ATC model with two related generative models using first synthetic data sets and then real data sets, which include a research community data set, a blog data set, a news-sharing data set, and a microblogging data set. The empirical results obtained confirm that the proposed ATC model outperforms the existing models for tasks such as author interest profiling and author community discovery. We also demonstrate how the inferred ATC model can be used to characterize the roles of users/authors in online communities.;2015;Not health related;Not health related
"Zaballa, O; Pérez, A; Gómez-Inhiesto, E; Acaiturri-Ayesta, T; Lozano, JA";A probabilistic generative model to discover the treatments of coexisting diseases with missing data;"Background and Objective: Comorbidities, defined as the presence of co-existing diseases, progress through complex temporal patterns among patients. Learning such dynamics from electronic health records is crucial for understanding the coevolution of diseases. In general, medical records are represented through temporal sequences of clinical variables together with their diagnosis. However, we consider the specific problem where most of the diagnoses are missing. We present a novel probabilistic generative model with a three-foldobjective: (i) identify and segment the medical history of patients into treatments associated with comorbidities; (ii) learn the model associated with each identified disease treatment; and (iii) discover subtypes of patients with similar coevolution of comorbidities. Methods: To this end, the model considers a latent structure for the sequences, where patients are modeled by a latent class defined by the evolution of their comorbidities, and each observed medical event of their clinical history is associated with a latent disease. The learning process is performed using an Expectation-Maximization algorithm that considers the exponential number of configurations of the latent variables and is efficiently solved with dynamic programming.Results: The evaluation of the method is carried out both on synthetic and real world data: the experiments on synthetic data show that the learning procedure allows the generative model underlying the data to be recovered; the experiments on real medical data show accurate results in the segmentation of sequences into different treatments, subtyping of patients and diagnosis imputation.Conclusion: We present an interpretable generative model that handles the incompleteness of EHRs and describes the different joint evolution of coexisting diseases depending on the active comorbidities of the patient at each moment.";2024;Health related;Health related
"Barbosa, D; Mendelzon, AO";Declarative generation of synthetic XML data;Synthetic data can be extremely useful in testing and evaluating algorithms, tools and systems. Most synthetic data generators available today are the result of individual benchmarking efforts. Typicallly, these are complex programs in which the specifications of both the structure and the contents of the data are hard-coded. As a result, it is often difficult to customize these tools for producing synthetic data tailored for specific needs. In this article, we describe the ToXgene synthetic data generator, which is a declarative tool for generating realistic XML data for benchmarking as well as testing purposes. We present our template specification language, which consists of augmenting XML Schema with probabilistic models that guide the data-generation process. We discuss the architecture of our current implementation and we argue about ToXgene's usefulness by discussing experimental results as well as describing two projects that use our tool. Copyright (C) 2006 John Wiley & Sons, Ltd.;2006;Not health related;Not health related
"Alshantti, A; Varagnolo, D; Rasheed, A; Rahmati, A; Westad, F";CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis;Generative adversarial networks (GANs) have drawn considerable attention in recent years for their proven capability in generating synthetic data which can be utilised for multiple purposes. While GANs have demonstrated tremendous successes in producing synthetic data samples that replicate the dynamics of the original datasets, the validity of the synthetic data and the underlying privacy concerns represent major challenges which are not sufficiently addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN) for generating realistic tabular data with a specific focus on the validity of the output. In this context, validity refers to the the dependency between features that can be found in the real data, but is typically misrepresented by traditional generative models. Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data. Our experimental results demonstrate that our model is capable of generating synthetic tabular data that can be used for fitting machine learning models, as CasTGAN's classification performance only falls under the real training data's PR-AUC score by 4.88% on average for classification datasets, and exhibits an average reduction of the real training data's R(2 )score by 0.139 for regression datasets. In addition, our model captures well the constraints and the correlations between the features of the real data, especially the high dimensional datasets. Assessing the generation of invalid records demonstrates that CasTGAN reduces the number of invalid data observations by up to 622% in comparison to the second best performing baseline tabular GAN model. Furthermore, we evaluate the risk of white-box privacy attacks on our model and subsequently show that applying some perturbations to the auxiliary learners in CasTGAN increases the overall robustness of our model against targeted attacks.;2024;Not health related;Not health related
"Nadjahi, K; Durmus, A; Simsekli, U; Badeau, R";Asymptotic Guarantees for Learning Generative Models with the Sliced-Wasserstein Distance;Minimum expected distance estimation (MEDE) algorithms have been widely used for probabilistic models with intractable likelihood functions and they have become increasingly popular due to their use in implicit generative modeling (e.g. Wasserstein generative adversarial networks, Wasserstein autoencoders). Emerging from computational optimal transport, the Sliced-Wasserstein (SW) distance has become a popular choice in MEDE thanks to its simplicity and computational benefits. While several studies have reported empirical success on generative modeling with SW, the theoretical properties of such estimators have not yet been established. In this study, we investigate the asymptotic properties of estimators that are obtained by minimizing SW. We first show that convergence in SW implies weak convergence of probability measures in general Wasserstein spaces. Then we show that estimators obtained by minimizing SW (and also an approximate version of SW) are asymptotically consistent. We finally prove a central limit theorem, which characterizes the asymptotic distribution of the estimators and establish a convergence rate of root n, where n denotes the number of observed data points. We illustrate the validity of our theory on both synthetic data and neural networks.;2019;Not health related;Not health related
"Lin, F; Yuan, X; Peng, L; Tzeng, NF";Cascade Variational Auto-Encoder for Hierarchical Disentanglement;While deep generative models pave the way for many emerging applications, decreased interpretability for larger model sizes and complexities hinders their generalizability to wide domains such as economy, security, healthcare, etc. Considering this obstacle, a common practice is to learn interpretable representations through latent feature disentanglement, aiming for exposing a set of mutually independent factors of data variations. However, existing methods either fail to catch the trade-off between the synthetic data quality and model interpretability, or consider the first-order feature disentangling only, overlooking the fact that a subset of salient features can carry decomposable semantic meanings and hence be of high-order in nature. Hence, we in this paper propose a novel generative modeling paradigm by introducing a Bayesian network-based regularizer on a cascade Variational Auto-Encoder (VAE). Specifically, this regularizer guides the learner to discover a representation space that comprises both first-order disentangled features and high-order salient features, with the feature interplay captured by the Bayesian structure. Experiments demonstrate that this regularizer gives us free control over the representation space and can guide the learner to discover decomposable semantic meanings by capturing the interplay among independent factors. Meanwhile, we benchmark extensive experiments on six widely-used vision datasets, and the results exhibit that our approach outperforms the state-of-the-art VAE competitors in terms of the trade-off between the synthetic data quality and model interpretability. Although our design is framed in the VAE regime, it in effect is generic and can be better amenable to both GANs and VAEs in terms of letting them concurrently enjoy both high model interpretability and high synthesis quality.;2022;Health related;Health related
"Agrawal, G; Kaur, A; Myneni, S";A Review of Generative Models in Generating Synthetic Attack Data for Cybersecurity;The ability of deep learning to process vast data and uncover concealed malicious patterns has spurred the adoption of deep learning methods within the cybersecurity domain. Nonetheless, a notable hurdle confronting cybersecurity researchers today is the acquisition of a sufficiently large dataset to effectively train deep learning models. Privacy and security concerns associated with using real-world organization data have made cybersecurity researchers seek alternative strategies, notably focusing on generating synthetic data. Generative adversarial networks (GANs) have emerged as a prominent solution, lauded for their capacity to generate synthetic data spanning diverse domains. Despite their widespread use, the efficacy of GANs in generating realistic cyberattack data remains a subject requiring thorough investigation. Moreover, the proficiency of deep learning models trained on such synthetic data to accurately discern real-world attacks and anomalies poses an additional challenge that demands exploration. This paper delves into the essential aspects of generative learning, scrutinizing their data generation capabilities, and conducts a comprehensive review to address the above questions. Through this exploration, we aim to shed light on the potential of synthetic data in fortifying deep learning models for robust cybersecurity applications.;2024;Not health related;Not health related
"Harder, F; Adamczewski, K; Park, M";DP-MERF: Differentially Private Mean Embeddings with Random Features for Practical Privacy-Preserving Data Generation;We propose a differentially private data generation paradigm using random feature representations of kernel mean embeddings when comparing the distribution of true data with that of synthetic data. We exploit the random feature representations for two important benefits. First, we require a minimal privacy cost for training deep generative models. This is because unlike kernel-based distance metrics that require computing the kernel matrix on all pairs of true and synthetic data points, we can detach the data-dependent term from the term solely dependent on synthetic data. Hence, we need to perturb the data-dependent term only once and then use it repeatedly during the generator training. Second, we can obtain an analytic sensitivity of the kernel mean embedding as the random features are norm bounded by construction. This removes the necessity of hyper-parameter search for a clipping norm to handle the unknown sensitivity of a generator network. We provide several variants of our algorithm, differentially-private mean embeddings with random features (DP-MERF) to jointly generate labels and input features for datasets such as heterogeneous tabular data and image data. Our algorithm achieves drastically better privacy-utility trade-offs than existing methods when tested on several datasets.;2021;Not health related;Not health related
"Ho, S; Qu, YY; Gu, B; Gao, LX; Li, JX; Xiang, Y";DP-GAN: Differentially private consecutive data publishing using generative adversarial nets;In the era of big data, increasingly massive volumes of data is generated and published consecutively for both research and commercial purposes. The potential value of sensitive information also attracts interest from adversaries and thereby arises public concern. Current research mostly focuses on privacy-preserving data publishing in a statistic manner rather than taking the dynamics and correlation of context into consideration. Motivated by this, we propose a novel idea that combining differential privacy and generative adversarial nets. Generative adversarial nets and its extensions are used to generate a synthetic dataset with indistinguishable statistic features while differential privacy guarantees a trade-off between privacy protection and data utility. By employing a min-max game with three players, we devise a deep generative model, namely DP-GAN model, for synthetic data generation while fulfilling the privacy constraints in a differentially private manner. Extensive simulation results on a real-world dataset testify the superiority of the proposed model in terms of privacy protection, data utility, and efficiency.;2021;Not health related;Not health related
"Liu, C; Wang, DL; Zhang, H; Wu, W; Sun, WZ; Zhao, T; Zheng, NG";Using Simulated Training Data of Voxel-Level Generative Models to Improve 3D Neuron Reconstruction;Reconstructing neuron morphologies from fluorescence microscope images plays a critical role in neuroscience studies. It relies on image segmentation to produce initial masks either for further processing or final results to represent neuronal morphologies. This has been a challenging step due to the variation and complexity of noisy intensity patterns in neuron images acquired from microscopes. Whereas progresses in deep learning have brought the goal of accurate segmentation much closer to reality, creating training data for producing powerful neural networks is often laborious. To overcome the difficulty of obtaining a vast number of annotated data, we propose a novel strategy of using two-stage generative models to simulate training data with voxel-level labels. Trained upon unlabeled data by optimizing a novel objective function of preserving predefined labels, the models are able to synthesize realistic 3D images with underlying voxel labels. We showed that these synthetic images could train segmentation networks to obtain even better performance than manually labeled data. To demonstrate an immediate impact of our work, we further showed that segmentation results produced by networks trained upon synthetic data could be used to improve existing neuron reconstruction methods.;2022;Health related;Health related
"Cazenavette, G; Wang, TZ; Torralba, A; Efros, AA; Zhu, JY";Generalizing Dataset Distillation via Deep Generative Prior;Dataset Distillation aims to distill an entire dataset's knowledge into a few synthetic images. The idea is to synthesize a small number of synthetic data points that, when given to a learning algorithm as training data, result in a model approximating one trained on the original data. Despite a recent upsurge of progress in the field, existing dataset distillation methods fail to generalize to new architectures and scale to high-resolution datasets. To overcome the above issues, we propose to use the learned prior from pre-trained deep generative models to synthesize the distilled data. To achieve this, we present a new optimization algorithm that distills a large number of images into a few intermediate feature vectors in the generative model's latent space. Our method augments existing techniques, significantly improving cross-architecture generalization in all settings.;2023;Not health related;Not health related
"Pinceti, A; Sankar, L; Kosut, O";Synthetic Time-Series Load Data via Conditional Generative Adversarial Networks;A framework for the generation of synthetic time-series transmission-level load data is presented. Conditional generative adversarial networks are used to learn the patterns of a real dataset of hourly-sampled week-long load profiles and generate unique synthetic profiles on demand, based on the season and type of load required. Extensive testing of the generative model is performed to verify that the synthetic data fully captures the characteristics of real loads and that it can be used for downstream power system and/or machine learning applications.;2021;Not health related;Not health related
"von Kügelgen, J; Mey, A; Loog, M";Semi-Generative Modelling: Covariate-Shift Adaptation with Cause and Effect Features;Current methods for covariate-shift adaptation use unlabelled data to compute importance weights or domain-invariant features, while the final model is trained on labelled data only. Here, we consider a particular case of covariate shift which allows us also to learn from unlabelled data, that is, combining adaptation with semi-supervised learning. Using ideas from causality, we argue that this requires learning with both causes, X-C, and effects, X-E, of a target variable, Y, and show how this setting leads to what we call a semi-generative model, P(Y, X-E vertical bar X-C, theta). Our approach is robust to domain shifts in the distribution of causal features and leverages unlabelled data by learning a direct map from causes to effects. Experiments on synthetic data demonstrate significant improvements in classification over purely-supervised and importance-weighting baselines.;2019;Not health related;Not health related
"Xu, K; Singh, R; Bilen, H; Fiore, M; Marina, MK; Wang, Y";CartaGenie: Context-Driven Synthesis of City-Scale Mobile Network Traffic Snapshots;Mobile network traffic data offers unprecedented opportunities for innovative studies within and beyond networking. However, progress is hindered by the very limited access that the research community at large has to the real-world mobile network data that is needed to develop and dependably test mobile traffic data-driven solutions. As a contribution to overcome this barrier, we propose CartaGenie, a generator of realistic mobile traffic snapshots at city scale. Taking a deep generative modeling approach and through a tailored conditional generator design, CartaGenie can synthesize high-fidelity and artifact-free spatial traffic snapshots using only contextual information about the target geographical region that is easily found in public repositories. Hence, CartaGenie allows researchers to create their own realistic datasets of spatial traffic from open data about their region of interest. Experiments with real-world mobile traffic measurements collected in multiple metropolitan areas show that CartaGenie can produce dependable network traffic loads for areas where no prior traffic information is available, significantly outperforming a comprehensive set of benchmarks. Moreover, tests with practical case studies demonstrate that the synthetic data generated by CartaGenie is as good as real data in supporting diverse research-oriented mobile traffic data-driven applications.;2022;Not health related;Not health related
"Flanagan, AR; Glavin, FG";A Comparative Analysis of Data Synthesis Techniques to Improve Classification Accuracy of Raman Spectroscopy Data;"Raman spectra are examples of high dimensional data that can often be limited in the number of samples. This is a primary concern when Deep Learning frameworks are developed for tasks such as chemical species identification, quantification, and diagnostics. Open-source data are difficult to obtain and often sparse; furthermore, the collecting and curating of new spectra require expertise and resources. Deep generative modeling utilizes Deep Learning architectures to approximate high dimensional distributions and aims to generate realistic synthetic data. The evaluation of the data and the performance of the deep models is usually conducted on a per-task basis and provides no indication of an increase to robustness, or generalization, on a wider scale. In this study, we compare the benefits and limitations of a standard statistical approach to data synthesis (weighted blending) with a popular deep generative model, the Variational Autoencoder. Two binary data sets are divided into 3-fold to simulate small, limited samples. Synthetic data distributions are created per fold using the two methods and then augmented into the training of two Deep Learning algorithms, a Convolutional Neural Network and a Fully-Connected Neural Network. The goal of this study is to observe the trends in learning as synthetic data are continually augmented to the training data in increasing batches. To determine the impact of each synthetic method, Principal Component Analysis and the discrete Frechet distance are implemented to visualize and measure the distance between the source and synthetic distributions along with the Machine Learning metric balanced accuracy for evaluating performance on imbalanced data.";2023;Not health related;Not health related
"Gwon, H; Ahn, I; Kim, Y; Kang, HJ; Seo, H; Choi, H; Cho, HN; Kim, M; Han, JY; Kee, G; Park, S; Lee, KH; Jun, TJ; Kim, YH";LDP-GAN : Generative adversarial networks with local differential privacy for patient medical records synthesis;Electronic medical records(EMR) have considerable potential to advance healthcare technologies, including medical AI. Nevertheless, due to the privacy issues associated with the sharing of patient's personal information, it is difficult to sufficiently utilize them. Generative models based on deep learning can solve this problem by creating synthetic data similar to real patient data. However, the data used for training these deep learning models run into the risk of getting leaked because of malicious attacks. This means that traditional deep learning-based generative models cannot completely solve the privacy issues. Therefore, we suggested a method to prevent the leakage of training data by protecting the model from malicious attacks using local differential privacy(LDP). Our method was evaluated in terms of utility and privacy. Experimental results demonstrated that the proposed method can generate medical data with reasonable performance while protecting training data from malicious attacks.;2024;Health related;Health related
"Li, HL; Stueckler, J";Tracking 6-DoF Object Motion from Events and Frames;Event cameras are promising devices for low latency tracking and high-dynamic range imaging. In this paper, we propose a novel approach for 6 degree-of-freedom (6-DoF) object motion tracking that combines measurements of event and frame-based cameras. We formulate tracking from high rate events with a probabilistic generative model of the event measurement process of the object. On a second layer, we refine the object trajectory in slower rate image frames through direct image alignment. We evaluate the accuracy of our approach in several object tracking scenarios with synthetic data, and also perform experiments with real data.;2021;Not health related;Not health related
"Ojeda, C; Cvejoski, K; Georgiev, B; Bauckhage, C; Schuecker, J; Sanchez, RJ";Learning Deep Generative Models for Queuing Systems;Modern society is heavily dependent on large scale client-server systems with applications ranging from Internet and Communication Services to sophisticated logistics and deployment of goods. To maintain and improve such a system, a careful study of client and server dynamics is needed - e.g. response/service times, average number of clients at given times, etc. To this end, one traditionally relies, within the queuing theory formalism, on parametric analysis and explicit distribution forms. However, parametric forms limit the model's expressiveness and could struggle on extensively large datasets. We propose a novel data-driven approach towards queuing systems: the Deep Generative Service Times. Our methodology delivers a flexible and scalable model for service and response times. We leverage the representation capabilities of Recurrent Marked Point Processes for the temporal dynamics of clients, as well as Wasser-stein Generative Adversarial Network techniques, to learn deep generative models which are able to represent complex conditional service time distributions. We provide extensive experimental analysis on both empirical and synthetic datasets, showing the effectiveness of the proposed models.;2021;Not health related;Not health related
"Yang, K; Chen, KJ; Zhang, WM; Yu, NH";Provably Secure Generative Steganography Based on Autoregressive Model;Synthetic data and generative models have been more and more popular with the rapid development of machine learning and artificial intelligence (AI). Consequently, generative steganography, a novel steganographic method finishing the operation of steganography directly in the process of image generation, tends to get more attention. However, most of the existing generative steganographic methods have more or less shortcomings, such as low security, small capacity or limited to certain images. In this paper, we propose a novel framework for generative steganography based on autoregressive model, or rather, PixelCNN. Theoretical derivation has been taken to prove the security of the framework. A simplified version is also proposed for binary embedding with lower complexity, for which the experiments show that the proposed method can resist the existing steganalytic methods.;2019;Not health related;Not health related
"Ribeiro, RA; Marques, JS; Lemos, JM";A Multiple Velocity Fields Approach to the Detection of Pedestrians Interactions Using HMM and Data Association Filters;This paper addresses the diagnosis of interactions between pairs of pedestrians in outdoor scenes, using a generative model for the trajectories. It is assumed that pedestrians' motions are driven by a set of velocity fields, learned from the video signal. This model is extended to account for the interaction among pedestrians, using attractive/repulsive velocity components. An inference algorithm is provided to estimate the attraction/repulsion velocity from the pedestrian trajectory and characterize pedestrians' interaction. Since we consider multiple motion models switched according to space-varying probabilities, inference is performed by combining a data association filter with a HMM-like forward algorithm. The proposed algorithm is denoted I-PDAF and is tested with synthetic data and pedestrians trajectories.;2013;Not health related;Not health related
"Smtith, MR; Verzi, SJ; Johnson, NT; Zhou, X; Khanna, K; Quynn, S; Krishnakumar, R";Malware Generation with Specific Behaviors to Improve Machine Learning-based Detection;We describe efforts in generating synthetic malware samples that have specified behaviors that can then be used to train a machine learning (ML) algorithm to detect behaviors in malware. The idea behind detecting behaviors is that a set of core behaviors exists that are often shared in many malware variants and that being able to detect behaviors will improve the detection of novel malware. However, empirically the multi-label task of detecting behaviors is significantly more difficult than malware classification, only achieving on average 84% accuracy across all behaviors as opposed to the greater than 95% multi-class or binary accuracy reported in many malware detection studies. One of the difficulties in identifying behaviors is that while there are ample malware samples, most data sources do not include behavioral labels, which means that generally there is insufficient training data for behavior identification. Inspired by the success of generative models in improving image processing techniques, we examine and extend a 1) conditional variational auto-encoder and 2) a flow-based generative model for malware generation with behavior labels. Initial experiments indicate that synthetic data is able to capture behavioral information and increase the recall of behaviors in novel malware from 32% to 45% without increasing false positives and to 52% with increased false positives.;2021;Not health related;Not health related
Wang, ZH;TABNET WITH DATA AUGMENTATION APPORACH IN STOCK RETURN PREDICTION TASK;Despite the advent of deep learning, stock return prediction task still has many challenges. Due to the scarcity of stock data, we adopt a GAN-based deep generative model to create synthetic data samples. To deal with the intrinsic low signal-to-noise ratio property of stock price time series, we formulate the return prediction as a supervised learning problem with tabular dataset, where we do feature engineering before training with a TabNet model. We conduct extensive experiments on real Chinese stock market with 6 different models, which proves that our proposed model makes larger profit and remains stability.;2022;Not health related;Not health related
"Sun, C; van Soest, J; Dumontier, M";Generating synthetic personal health data using conditional generative adversarial networks combining with differential privacy;A large amount of personal health data that is highly valuable to the scientific community is still not accessible or requires a lengthy request process due to privacy concerns and legal restrictions. As a solution, synthetic data has been studied and proposed to be a promising alternative to this issue. However, generating realistic and privacy-preserving synthetic personal health data retains challenges such as simulating the characteristics of the patients' data that are in the minority classes, capturing the relations among variables in imbalanced data and transferring them to the synthetic data, and preserving individual patients' privacy. In this paper, we propose a differentially private conditional Generative Adversarial Network model (DP-CGANS) consisting of data transformation, sampling, conditioning, and network training to generate realistic and privacy-preserving personal data. Our model distinguishes categorical and continuous variables and transforms them into latent space separately for better training performance. We tackle the unique challenges of generating synthetic patient data due to the special data characteristics of personal health data. For example, patients with a certain disease are typically the minority in the dataset and the relations among variables are crucial to be observed. Our model is structured with a conditional vector as an additional input to present the minority class in the imbalanced data and maximally capture the dependency between variables. Moreover, we inject statistical noise into the gradients in the networking training process of DP-CGANS to provide a differential privacy guarantee. We extensively evaluate our model with state-of-the-art generative models on personal socio-economic datasets and real-world personal health datasets in terms of statistical similarity, machine learning performance, and privacy measurement. We demonstrate that our model outperforms other comparable models, especially in capturing the dependence between variables. Finally, we present the balance between data utility and privacy in synthetic data generation considering the different data structures and characteristics of real-world personal health data such as imbalanced classes, abnormal distributions, and data sparsity.;2023;Health related;Health related
"Monachino, G; Zanchi, B; Fiorillo, L; Conte, G; Auricchio, A; Tzovara, A; Faraci, FD";Deep Generative Models: The winning key for large and easily accessible ECG datasets?;Large high-quality datasets are essential for building powerful artificial intelligence (AI) algorithms capable of supporting advancement in cardiac clinical research. However, researchers working with electrocardiogram (ECG) signals struggle to get access and/or to build one. The aim of the present work is to shed light on a potential solution to address the lack of large and easily accessible ECG datasets. Firstly, the main causes of such a lack are identified and examined. Afterward, the potentials and limitations of cardiac data generation via deep generative models (DGMs) are deeply analyzed. These very promising algorithms have been found capable not only of generating large quantities of ECG signals but also of supporting data anonymization processes, to simplify data sharing while respecting patients' privacy. Their application could help research progress and cooperation in the name of open science. However several aspects, such as a standardized synthetic data quality evaluation and algorithm stability, need to be further explored.;2023;Health related;Health related
"Ikeuchi, R; Ikeda, K";An Automatic Music Transcription Based on Translation of Spectrum and Sound Path Estimation;An automatic music transcription method is proposed. The method is based on a generative model that takes into account the translation of spectrum for an instrument and the sound path from the instrument to a microphone. The fundamental frequency (note), the spectrum of the instrument (basis pattern) and the sound path are estimated simultaneously using an extended complex nonnegative matrix factorization. The effectiveness of the proposed method is confirmed by synthetic data.;2011;Not health related;Not health related
"Atapour-Abarghouei, A; Akcay, S; de La Garanderie, GP; Breckon, TP";Generative adversarial framework for depth filling via Wasserstein metric, cosine transform and domain transfer;In this work, the issue of depth filling is addressed using a self-supervised feature learning model that predicts missing depth pixel values based on the context and structure of the scene. A fully-convolutional generative model is conditioned on the available depth information and full RGB colour information from the scene and trained in an adversarial fashion to complete scene depth. Since ground truth depth is not readily available, synthetic data is instead used with a separate model developed to predict where holes would appear in a sensed (non-synthetic) depth image based on the contents of the RGB image. The resulting synthetic data with realistic holes is utilized in training the depth filling model which makes joint use of a reconstruction loss which employs the Discrete Cosine Transform for more realistic outputs, an adversarial loss which measures the distribution distances via the Wasserstein metric and a bottleneck feature loss that aids in better contextual feature execration. Additionally, the model is adversarially adapted to perform well on naturally-obtained data with no available ground truth. Qualitative and quantitative evaluations demonstrate the efficacy of the approach compared to contemporary depth filling techniques. The strength of the feature learning capabilities of the resulting deep network model is also demonstrated by performing the task of monocular depth estimation using our pre-trained depth hole filling model as the initialization for subsequent transfer learning. (C) 2019 Elsevier Ltd. All rights reserved.;2019;Not health related;Not health related
van Laarhoven, T;Generative models for local network community detection;Local network community detection aims to find a single community in a large network, while inspecting only a small part of that network around a given seed node. This is much cheaper than finding all communities in a network. Most methods for local community detection are formulated as ad hoc optimization problems. In this paper, we instead start from a generative model for networks with a community structure. By assuming that the network is uniform, we can approximate the structure of the unobserved parts of the network to obtain a method for local community detection. We apply this local approximation technique to two variants of the stochastic block model. This results in local community detection methods based on probabilistic models. Interestingly, in the limit, one of the proposed approximations corresponds to conductance, a popular metric in this field. Experiments on real and synthetic data sets show comparable or improved results compared to state-of-the-art local community detection algorithms.;2018;Not health related;Not health related
"Louppe, G; Hermans, J; Cranmer, K";Adversarial Variational Optimization of Non-Differentiable Simulators;Complex computer simulators are increasingly used across fields of science as generative models tying parameters of an underlying theory to experimental observations. Inference in this setup is often difficult, as simulators rarely admit a tractable density or likelihood function. We introduce Adversarial Variational Optimization (AVO), a likelihood-free inference algorithm for fitting a non-differentiable generative model incorporating ideas from generative adversarial networks, variational optimization and empirical Bayes. We adapt the training procedure of generative adversarial networks by replacing the differentiable generative network with a domain-specific simulator. We solve the resulting non-differentiable minimax problem by minimizing variational upper bounds of the two adversarial objectives. Effectively, the procedure results in learning a proposal distribution over simulator parameters, such that the JS divergence between the marginal distribution of the synthetic data and the empirical distribution of observed data is minimized. We evaluate and compare the method with simulators producing both discrete and continuous data.;2019;Not health related;Not health related
"Yu, LT; Zhang, WN; Wang, J; Yu, Y";SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient;As a new way of training generative models, Generative Adversarial Net (GAN) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real-valued data. However, it has limitations when the goal is for generating sequences of discrete tokens. A major reason lies in that the discrete outputs from the generative model make it difficult to pass the gradient update from the discriminative model to the generative model. Also, the discriminative model can only assess a complete sequence, while for a partially generated sequence, it is non-trivial to balance its current score and the future one once the entire sequence has been generated. In this paper, we propose a sequence generation framework, called SeqGAN, to solve the problems. Modeling the data generator as a stochastic policy in reinforcement learning (RL), SeqGAN bypasses the generator differentiation problem by directly performing gradient policy update. The RL reward signal comes from the GAN discriminator judged on a complete sequence, and is passed back to the intermediate state-action steps using Monte Carlo search. Extensive experiments on synthetic data and real-world tasks demonstrate significant improvements over strong baselines.;2017;Not health related;Not health related
"Xu, K; Singh, R; Fiore, M; Marina, MK; Bilen, H; Usama, M; Benn, H; Ziemlicki, C";SpectraGAN: Spectrum based Generation of City Scale Spatiotemporal Mobile Network Traffic Data;City-scale spatiotemporal mobile network traffic data can support numerous applications in and beyond networking. However, operators are very reluctant to share their data, which is curbing innovation and research reproducibility. To remedy this status quo, we propose SpectraGAN, a novel deep generative model that, upon training with real-world network traffic measurements, can produce high-fidelity synthetic mobile traffic data for new, arbitrary sized geographical regions over long periods. To this end, the model only requires publicly available context information about the target region, such as population census data. SpectraGAN is an original conditional GAN design with the defining feature of generating spectra of mobile traffic at all locations of the target region based on their contextual features. Evaluations with mobile traffic measurement datasets collected by different operators in 13 cities across two European countries demonstrate that SpectraGAN can synthesize more dependable traffic than a range of representative baselines from the literature. We also show that synthetic data generated with SpectraGAN yield similar results to that with real data when used in applications like radio access network infrastructure power savings and resource allocation, or dynamic population mapping.;2021;Not health related;Not health related
"Fernandes, TT; Direito, B; Sayal, A; Pereira, J; Andrade, A; Castelo-Branco, M";The boundaries of state-space Granger causality analysis applied to BOLD simulated data: A comparative modelling and simulation approach;Background: The analysis of connectivity has become a fundamental tool in human neuroscience. Granger Causality Mapping is a data-driven method that uses Granger Causality (GC) to assess the existence and direction of influence between signals, based on temporal precedence of information. More recently, a theory of Granger causality has been developed for state-space (SS-GC) processes, but little is known about its statistical validation and application on functional magnetic resonance imaging (fMRI) data. New method: We explored different multivariate computational frameworks to define the optimal combination for GC estimation. We hypothesized a new heuristic, combining SS-GC with a distinct statistical validation technique, Time Reversed Testing, validating it on synthetic data. We test its performance with a number of experimental parameters, including block structure, sampling frequency, noise and system mean pairwise correlation, using a statistical framework of binary classification. Results: We found that SS-GC with time reversed testing outperforms other frameworks. The results validate the application of SS-GC to generative models. When estimating reliable causal relations, SS-GC returns promising results, especially when considering synthetic data with a high impact of noise and sampling rate. Conclusions: In this study, we empirically explored the boundaries of SS-GC with time reversed testing, a data-driven causality analysis framework with potential applicability to fMRI data.;2020;Health related;Health related
"Dabrowski, JJ; de Villiers, JP";Maritime piracy situation modelling with dynamic Bayesian networks;A generative model for modelling maritime vessel behaviour is proposed. The model is a novel variant of the dynamic Bayesian network (DBN). The proposed DBN is in the form of a switching linear dynamic system (SLDS) that has been extended into a larger DBN. The application of synthetic data fabrication of maritime vessel behaviour is considered. Behaviour of various vessels in a maritime piracy situation is simulated. A means to integrate information from context based external factors that influence behaviour is provided. Simulated observations of the vessels kinematic states are generated. The generated data may be used for the purpose of developing and evaluating counter-piracy methods and algorithms. A novel methodology for evaluating and optimising behavioural models such as the proposed model is presented. The log-likelihood, cross entropy, Bayes factor and the Bhattacharyya distance measures are applied for evaluation. The results demonstrate that the generative model is able to model both spatial and temporal datasets. (C) 2014 Elsevier B.V. All rights reserved.;2015;Not health related;Not health related
"Kawashima, T; Hino, H";Gaussian Process Koopman Mode Decomposition;We propose a nonlinear probabilistic generative model of Koopman mode decomposition based on an unsupervised gaussian process. Existing data-driven methods for Koopman mode decomposition have focused on estimating the quantities specified by Koopman mode decomposition: eigenvalues, eigenfunctions, and modes. Our model enables the simultaneous estimation of these quantities and latent variables governed by an unknown dynamical system. Furthermore, we introduce an efficient strategy to estimate the parameters of our model by low-rank approximations of covariance matrices. Applying the proposed model to both synthetic data and a real-world epidemiological data set, we show that various analyses are available using the estimated parameters.;2022;Not health related;Not health related
"Dixit, V; Selvarajan, R; Aldwairi, T; Koshka, Y; Novotny, MA; Humble, TS; Alam, MA; Kais, S";Training a Quantum Annealing Based Restricted Boltzmann Machine on Cybersecurity Data;A restricted Boltzmann machine (RBM) is a generative model that could be used in effectively balancing a cybersecurity dataset because the synthetic data a RBM generates follows the probability distribution of the training data. RBM training can be performed using contrastive divergence (CD) and quantum annealing (QA). QA-based RBM training is fundamentally different from CD and requires samples from a quantum computer. We present a real-world application that uses a quantum computer. Specifically, we train a RBM using QA for cybersecurity applications. The D-Wave 2000Q has been used to implement QA. RBMs are trained on the ISCX data, which is a benchmark dataset for cybersecurity. For comparison, RBMs are also trained using CD. CD is a commonly used method for RBM training. Our analysis of the ISCX data shows that the dataset is imbalanced. We present two different schemes to balance the training dataset before feeding it to a classifier. The first scheme is based on the undersampling of benign instances. The imbalanced training dataset is divided into five sub-datasets that are trained separately. A majority voting is then performed to get the result. Our results show the majority vote increases the classification accuracy up from 90.24% to 95.68%, in the case of CD. For the case of QA, the classification accuracy increases from 74.14% to 80.04%. In the second scheme, a RBM is used to generate synthetic data to balance the training dataset. We show that both QA and CD-trained RBM can be used to generate useful synthetic data. Balanced training data is used to evaluate several classifiers. Among the classifiers investigated, K-Nearest Neighbor (KNN) and Neural Network (NN) perform better than other classifiers. They both show an accuracy of 93%. Our results show a proof-of-concept that a QA-based RBM can be trained on a 64-bit binary dataset. The illustrative example suggests the possibility to migrate many practical classification problems to QA-based techniques. Further, we show that synthetic data generated from a RBM can be used to balance the original dataset.;2022;Not health related;Not health related
"Perez-Bueno, F; Garcia, L; Macia-Fernandez, G; Molina, R";Leveraging a Probabilistic PCA Model to Understand the Multivariate Statistical Network Monitoring Framework for Network Security Anomaly Detection;Network anomaly detection is a very relevant research area nowadays, especially due to its multiple applications in the field of network security. The boost of new models based on variational autoencoders and generative adversarial networks has motivated a reevaluation of traditional techniques for anomaly detection. It is, however, essential to be able to understand these new models from the perspective of the experience attained from years of evaluating network security data for anomaly detection. In this paper, we revisit anomaly detection techniques based on PCA from a probabilistic generative model point of view, and contribute a mathematical model that relates them. Specifically, we start with the probabilistic PCA model and explain its connection to the Multivariate Statistical Network Monitoring (MSNM) framework. MSNM was recently successfully proposed as a means of incorporating industrial process anomaly detection experience into the field of networking. We have evaluated the mathematical model using two different datasets. The first, a synthetic dataset created to better understand the analysis proposed, and the second, UGR'16, is a specifically designed real-traffic dataset for network security anomaly detection. We have drawn conclusions that we consider to be useful when applying generative models to network security detection.;2022;Not health related;Not health related
"Gu, Z; Zhang, GY; Yang, C";Horizontally Partitioned Data Publication with Differential Privacy;"In this paper, we study the privacy-preserving data publishing problem in a distributed environment. The data contain sensitive information; hence, directly pooling and publishing the local data will lead to privacy leaks. To solve this problem, we propose a multiparty horizontally partitioned data publishing method under differential privacy (HPDP-DP). First, in order to make the noise level of the published data in the distributed scenario the same as in the centralized scenario, we use the infinite divisibility of the Laplace distribution to design a distributed noise addition scheme to perturb the locally shared data and use Paillier encryption to transmit the locally shared data to the semitrusted curator. Then, the semitrusted curator obtains the estimator of the covariance matrix of the aggregated data with Laplace noise and then obtains the principal components of the aggregated data and returns them to each data owner. Finally, the data owner utilizes the generative model of probabilistic principal component analysis to generate a synthetic data set for publication. We conducted experiments on different real data sets; the experimental results demonstrate that the synthetic data set released by the HPDP-DP method can maintain high utility.";2022;Not health related;Not health related
"Yang, AX; Lu, CD; Yu, WK; Hu, J; Nakanishi, Y; Wu, M";Data Augmentation Considering Distribution Discrepancy for Fault Diagnosis of Drilling Process With Limited Samples;The fault diagnosis during drilling is necessary to prevent the accidents develop to more serious status. Data-driven diagnosis methods have great advantages in nonlinear industrial process, however, the problem of limited samples restricts its further application. This article proposes a data augmentation method based on synthetic data generation and updating for drilling fault diagnosis with limited samples. First, the generator is trained with generative adversarial nets (GAN), and the GAN is improved by the design of parameter selection module, and loss function in generative model. Then, sufficient samples are obtained, and a balanced dataset is constructed for modeling. Meanwhile, by considering the distribution discrepancy, the self-organizing incremental neural network-based synthetic data updating is realized to track the changes of data distribution when the data drift appears. Finally, the actual data acquired from two wells are employed for the method validation. The experimental results illustrate that the proposed method is helpful for improving the performance of diagnosis model with limited samples, and the negative impact to diagnosis model due to the distribution discrepancy also can be overcome.;2023;Not health related;Not health related
"Nyczka, P; Hütt, MT";Generative network model of transcriptome patterns in disease cohorts with tunable signal strength;Algorithmic methods for interpreting the collective transcriptome (gene expression) patterns of disease cohorts in the context of biological networks are a cornerstone of systems medicine. The calibration of these algorithms using synthetic data with predefined statistical properties can be a relevant benchmarking procedure, facilitating the choice of the appropriate algorithm and the detailed mechanistic interpretation of the results. Here we present a generative model producing patterns of significantly up- and down-regulated genes for synthetic disease cohorts, in which the statistical agreement between the given biological network and the transcriptome patterns can be tuned. Parameters of this generative model are, among others, the size of the cohort, the number of disease-associated genes, the clustering of differentially expressed genes in the network and the network size. Several properties of the model can be analyzed analytically. In a first application of this generative model to produce test instances, we show that considering the subset of significant expression changes occurring in more than one patient of the cohort as an additional filtering step serves as an efficient noise suppression mechanism to enhance the recall of the signal contained in the data by the network connectivity.;2020;Health related;Health related
"Babu, EK; Bashir, I; Pillai, G; Jyothi, KC";Generation of synthetic datasets for transformer's dissolved gas analysis using Monte-Carlo Simulation;The fault diagnosis in power transformers is carried out using Dissolved Gas Analysis (DGA). Although DGA does provide key information for fault detection, the method is inherently complex. Several methods have been developed for DGA, but still possess challenges in accurately detecting the fault. A method has been developed to generate synthetic data using Monte-Carlo simulation. The generated synthetic data is feed into DGA excel tool to investigate the accuracy of fault detection. The synthetic data can be used to further enhance the DGA tool, improve its accuracy and investigate the inclusive faults. A model has been proposed for the integration of synthetic data generator with DGA tool for machine learning and to obtain an automated and improved DGA tool for fault diagnoses in power transformers.;2021;Not health related;Not health related
"Gayathri, RG; Sajjanhar, A; Xiang, Y";Adversarial Training for Robust Insider Threat Detection;Insider threat analysis techniques based on machine learning provide convenient and effective automated detection of internally generated cyberattacks. When data are manipulated by adding slight perturbations, the threat intelligence models result in misclassifications of highly skewed class distribution with rare occurrences of events in insider threats. This paper proposes a generative model WGAN-GP conditioned by the class labels, referred to as CWGAN-GP, for insider threat analysis to create synthetic data samples for the rare malicious activities and shows that it generalizes well across different learning algorithms. Further, the robustness of the supervised algorithms to unknown inputs have not been investigated in any other works. This study explores how the synthetically created adversarial samples can increase the robustness of supervised models using adversarial training. We use a target classifier as threat model to generate one-step and iterative adversarial samples and perform a non-targeted test-time attack on the classifiers. We evaluate the robustness of various learning models against synthetic data from other data generation methods and demonstrate that the adversarial training using data generated from CWGAN-GP is less susceptible to adversarial attacks on insider threat classifiers using multiple versions of benchmark CMU CERT data set.;2022;Not health related;Not health related
"Caffagni, D; Barraco, M; Cornia, M; Baraldi, L; Cucchiara, R";SynthCap: Augmenting Transformers with Synthetic Data for Image Captioning;Image captioning is a challenging task that combines Computer Vision and Natural Language Processing to generate descriptive and accurate textual descriptions for input images. Research efforts in this field mainly focus on developing novel architectural components to extend image captioning models and using large-scale image-text datasets crawled from the web to boost final performance. In this work, we explore an alternative to web-crawled data and augment the training dataset with synthetic images generated by a latent diffusion model. In particular, we propose a simple yet effective synthetic data augmentation framework that is capable of significantly improving the quality of captions generated by a standard Transformer-based model, leading to competitive results on the COCO dataset.;2023;Not health related;Not health related
"Asiaee, TA; Goel, H; Ghosh, S; Yegneswaran, V; Banerjee, A";Time Series Deinterleaving of DNS Traffic;Stream deinterleaving is an important problem with various applications in the cybersecurity domain. In this paper, we consider the specific problem of deinterleaving DNS data streams using machine-learning techniques, with the objective of automating the extraction of malware domain sequences. We first develop a generative model for user request generation and DNS stream interleaving. Based on these we evaluate various inference strategies for deinterleaving including augmented HMMs and LSTMs on synthetic datasets. Our results demonstrate that state-of-the-art LSTMs outperform more traditional augmented HMMs in this application domain.;2018;Not health related;Not health related
"Chiesa, S; Taraglio, S";Traffic Request Generation through a Variational Auto Encoder Approach;Traffic and transportation forecasting is a key issue in urban planning aimed to provide a greener and more sustainable environment to residents. Their privacy is a second key issue that requires synthetic travel data. A possible solution is offered by generative models. Here, a variational autoencoder architecture has been trained on a floating car dataset in order to grasp the statistical features of the traffic demand in the city of Rome. The architecture is based on multilayer dense neural networks for encoding and decoding parts. A brief analysis of parameter influence is conducted. The generated trajectories are compared with those in the dataset. The resulting reconstructed synthetic data are employed to compute the traffic fluxes and geographic distribution of parked cars. Further work directions are provided.;2022;Not health related;Not health related
"Goncalves, A; Ray, P; Soper, B; Stevens, J; Coyle, L; Sales, AP";Generation and evaluation of synthetic patient data;"BackgroundMachine learning (ML) has made a significant impact in medicine and cancer research; however, its impact in these areas has been undeniably slower and more limited than in other application domains. A major reason for this has been the lack of availability of patient data to the broader ML research community, in large part due to patient privacy protection concerns. High-quality, realistic, synthetic datasets can be leveraged to accelerate methodological developments in medicine. By and large, medical data is high dimensional and often categorical. These characteristics pose multiple modeling challenges.MethodsIn this paper, we evaluate three classes of synthetic data generation approaches; probabilistic models, classification-based imputation models, and generative adversarial neural networks. Metrics for evaluating the quality of the generated synthetic datasets are presented and discussed.ResultsWhile the results and discussions are broadly applicable to medical data, for demonstration purposes we generate synthetic datasets for cancer based on the publicly available cancer registry data from the Surveillance Epidemiology and End Results (SEER) program. Specifically, our cohort consists of breast, respiratory, and non-solid cancer cases diagnosed between 2010 and 2015, which includes over 360,000 individual cases.ConclusionsWe discuss the trade-offs of the different methods and metrics, providing guidance on considerations for the generation and usage of medical synthetic data.";2020;Health related;Health related
"Zheleva, E; Sharara, H; Getoor, L";Co-evolution of Social and Affiliation Networks;In our work, we address the problem of modeling social network generation which explains both link and group formation. Recent studies on social network evolution propose generative models which capture the statistical properties of real-world networks related only to node-to-node link formation. We propose a novel model which captures the co-evolution of social and affiliation networks. We provide surprising insights into group formation based on observations in several real-world networks, showing that users often join groups for reasons other than their friends. Our experiments show that the model is able to capture both the newly observed and previously studied network properties. This work is the first to propose a generative model which captures the statistical properties of these complex networks. The proposed model facilitates controlled experiments which study the effect of actors' behavior oil the network evolution, and it allows the generation of realistic synthetic datasets.;2009;Not health related;Not health related
"Hubschneider, C; Roesler, S; Zöllner, JM";Unsupervised Evaluation of Lidar Domain Adaptation;In this work, we investigate the potential of latent representations generated by Variational Autoencoders (VAE) to analyze and distinguish between real and synthetic data. Although the details of the domain adaptation task are not the focus of this work, we use the example of simulated lidar data adapted by a generative model to match real lidar data. To assess the resulting adapted data, we evaluate the potential of latent representations learned by a VAE. During training, the VAE aims to reduce the input data to a fixed-dimensional feature vector, while also enforcing stochastic independence between the latent variables. These properties can be used to define pseudometrics to make statements about generative models that perform domain adaptation tasks. The variational autoencoder is trained on real target data only and is subsequently used to generate distributions of feature vectors for data coming from different data sources such as simulations or the output of Generative Adversarial Networks.;2020;Not health related;Not health related
"Eikema, B; Aziz, W";Auto-Encoding Variational Neural Machine Translation;We present a deep generative model of bilingual sentence pairs for machine translation. The model generates source and target sentences jointly from a shared latent representation and is parameterised by neural networks. We perform efficient training using amortised variational inference and reparameterised gradients. Additionally, we discuss the statistical implications of joint modelling and propose an efficient approximation to maximum a posteriori decoding for fast test-time predictions. We demonstrate the effectiveness of our model in three machine translation scenarios: in-domain training, mixed-domain training, and learning from a mix of gold-standard and synthetic data. Our experiments show consistently that our joint formulation outperforms conditional modelling (i.e. standard neural machine translation) in all such scenarios.;2019;Not health related;Not health related
"García-García, D; Parrado-Hernández, E; Diaz-de-Maria, F";Sequence Segmentation via Clustering of Subsequences;We propose a new algorithm for sequence segmentation based on recent advances in semi-parametric sequence clustering. This approach implies the use of model-based distance measures between sequences, as well as a variant of spectral clustering specially tailored for segmentation. The method is highly flexible since it allows for the use of any probabilistic generative model for the individual segments. The performance of the proposed algorithm is demonstrated using both a synthetic dataset and a speaker segmentation task.;2009;Not health related;Not health related
"Ergün, O; Sahillioglu, Y";3D point cloud classification with ACGAN-3D and VACWGAN-GP;Machine learning and deep learning techniques are widely used to make sense of 3D point cloud data which became ubiquitous and important due to the recent advances in 3D scanning technologies and other sensors. In this work, we propose two networks to predict the class of the input 3D point cloud: 3D Auxiliary Classifier Generative Adversarial Network (ACGAN-3D) and Versatile Auxiliary Conditional Wasserstein Generative Adversarial Network with Gradient Penalty (VACWGAN-GP). Unlike other classifiers, we are able to enlarge the limited data set with the data produced by generative models. We consequently aim to increase the success of the model by training it with more data.As suggested by the conventional ACGAN models, in addition to the real dataset, we train the Discriminator with synthetic data generated by the Generator using the class label. By doing so, we ensure that Discriminator can discriminate between the real data and the synthetic data. Thus, as the training evolves, the Generator is trained to produce more realistic synthetic data, which in turn forces Discriminator to classify or discriminate better. Defined originally on 2D images, our ACGAN-3D modifies this conventional ACGAN model in order to classify 3D point clouds by updating the neural network layers.Our second model VACWGAN-GP, on the other hand, demonstrates similar abilities with more stable training by replacing its Discriminator with Critic and by modifying its loss function. In this model, we managed to merge Wasserstein GAN-GP with conditional GAN in order to improve the classifier's performance.The proposed models ACGAN-3D and VACWGAN-GP were tested extensively on 3D datasets and comparisons with the other state-of-the-art studies have revealed our clear advantages on various aspects. While ACGAN-3D can be preferred with its compact design, our second method VACWGAN-GP stands out for higher performance.;2023;Not health related;Not health related
"Liu, SY; Yao, J; Motani, M";Early Prediction of Vital Signs Using Generative Boosting via LSTM Networks;Vital signs including heart rate, respiratory rate, body temperature and blood pressure, are critical in the clinical decision making process. Abnormal vital signs help to alert medical practitioners to potential health problems. Effective and long-range early prediction of vital signs may prevent adverse health outcomes and reduce cost. In this paper, we suggest a new approach called generative boosting, in order to effectively perform long-range early prediction of vital signs. Generative boosting consists of a generative model, to generate synthetic data for the next few time steps, and a predictive model, to directly make long-range predictions based on observed and generated data. We explore generative boosting via long short-term memory (LSTM) for both the predictive and generative models, leading to a scheme called generative LSTM (GLSTM). Our experiments indicate that GLSTM outperforms a diverse range of strong benchmark models, with and without generative boosting. As expected, the results also indicate that more accurately generated data leads to more accurate long-range predictions. In light of this, we use a mutual information based clustering algorithm to select a more representative dataset to train the generative model. This leads to significantly improved accuracy of the long-range prediction of high variation vital signs such as heart rate and systolic blood pressure. Overall, our best results indicate that the proposed method is able to predict heart rate and systolic blood pressure 20 minutes in advance, with a mean absolute percentage error of 7.41% and 6.17%, respectively.;2019;Health related;Health related
"Moreu, E; Arazo, E; McGuinness, K; O'Connor, NE";Joint one-sided synthetic unpaired image translation and segmentation for colorectal cancer prevention;Deep learning has shown excellent performance in analysing medical images. However, datasets are difficult to obtain due privacy issues, standardization problems, and lack of annotations. We address these problems by producing realistic synthetic images using a combination of 3D technologies and generative adversarial networks. We propose CUT-seg, a joint training where a segmentation model and a generative model are jointly trained to produce realistic images while learning to segment polyps. We take advantage of recent one-sided translation models because they use significantly less memory, allowing us to add a segmentation model in the training loop. CUT-seg performs better, is computationally less expensive, and requires less real images than other memory-intensive image translation approaches that require two stage training. Promising results are achieved on five real polyp segmentation datasets using only one real image and zero real annotations. As a part of this study we release Synth-Colon, an entirely synthetic dataset that includes 20,000 realistic colon images and additional details about depth and 3D geometry:;2023;Health related;Health related
"Sehwag, V; Hazirbas, C; Gordo, A; Ozgenel, F; Ferrer, CC";Generating High Fidelity Data from Low-density Regions using Diffusion Models;Our work focuses on addressing sample deficiency from low-density regions of data manifold in common image datasets. We leverage diffusion process based generative models to synthesize novel images from low-density regions. We observe that uniform sampling from diffusion models predominantly samples from high-density regions of the data manifold. Therefore, we modify the sampling process to guide it towards low-density regions while simultaneously maintaining the fidelity of synthetic data. We rigorously demonstrate that our process successfully generates novel high fidelity samples from low-density regions. We further examine generated samples and show that the model does not memorize low-density data and indeed learns to generate novel samples from low-density regions.;2022;Not health related;Not health related
"Misra, R; Mishra, SS; Gandhi, TK";Assistive Completion of Agrammatic Aphasic Sentences: Amalgamation of NLP and Neurolinguistics-based Synthetic Dataset;Damage to the inferior frontal gyrus (Broca's area) can cause agrammatic aphasia wherein patients, although able to comprehend, lack the ability to form complete sentences. This inability leads to communication gaps which cause difficulties in their daily lives. The usage of assistive devices can help in mitigating these issues and enable the patients to communicate effectively. However, due to lack of large scale studies of linguistic deficits in aphasia, research on such assistive technology is relatively limited. In this work, we present two contributions that aim to re-initiate research and development in this field. Firstly, we propose a model that uses linguistic features from small scale studies on aphasia patients and generates large scale datasets of synthetic aphasic utterances from grammatically correct datasets. We show that the mean length of utterance, the noun/verb ratio, and the simple/complex sentence ratio of our synthetic datasets correspond to the reported features of aphasic speech. Further, we demonstrate how the synthetic datasets may be utilized to develop assistive devices for aphasia patients. The pre-trained T5 transformer is fine-tuned using the generated dataset to suggest 5 corrected sentences given an aphasic utterance as input. We evaluate the efficacy of the T5 model using the BLEU and cosine semantic similarity scores. Affirming results with BLEU score of 0.827/1.00 and semantic similarity of 0.904/1.00 were obtained. These results provide a strong foundation for the concept that a synthetic dataset based on small scale studies on aphasia can be used to develop effective assistive technology.;2023;Health related;Health related
"Wang, R; Fung, JCH; Lau, AKH";Physical-Dynamic-Driven AI-Synthetic Precipitation Nowcasting Using Task-Segmented Generative Model;Precise and timely rainfall nowcasting plays a critical role in ensuring public safety amid disasters triggered by heavy precipitation. While deep-learning models have exhibited superior performance over traditional nowcasting methods in recent years, their efficacy is still hampered by limited forecasting skill, insufficient training data, and escalating blurriness in forecasts. To address these challenges, we present the Synthetic-data Task-segmented Generative Model (STGM), an innovative physical-dynamic-driven heavy rainfall nowcasting model. The STGM encompasses three key components: the Long Video Generation (LVG) model generating synthetic radar data from observed radar images and data provided by the Weather Research and Forecasting (WRF) model, MaskPredNet predicting the spatial coverage of various rainfall intensities, and SPADE determining rainfall intensity based on the coverage provided by MaskPredNet. The STGM has demonstrated promising skill for precipitation forecasts for up to six hours, and significantly reduce the blurriness of predicted images, thus showcasing advances in rainfall nowcasting. Deep-learning methods have proven superior to traditional techniques in rainfall nowcasting, but current models still face limitations such as low accuracy, insufficient training data, and a brief effective forecast period. To address these challenges, we've developed the STGM, a novel deep-learning-based architecture for predicting heavy rainfall. The STGM shows excellent performance by using a new design that breaks tasks into smaller parts and relies on AI-generated data. Our results indicate that it excels in predicting heavy rainfall for up to 6 hr, accurately tracking the spatial and temporal evolution of storm cells over extended periods. Moreover, it significantly improves the clarity of the produced images compared to commonly used baseline models. Our novel STGM model outperforms common baseline models, showcasing high proficiency in predicting precipitation up to 6 hr aheadBy integrating physical data from numerical weather prediction models, the performance of the STGM model is significantly enhancedThe use of synthetic data provides a substantial boost to the predictive capabilities of the STGM model;2023;Not health related;Not health related
"Deja, K; Trzcinski, T; Graczykowski, L";Generative Models for Fast Cluster Simulations in the TPC for the ALICE Experiment;Simulating the possible detector response is a key component of every high-energy physics experiment. The methods used currently for this purpose provide high-fidelity results. However, this precision comes at a price of a high computational cost, which renders those methods infeasible to be used in other applications, e.g. data quality assurance. In this work, we present a proof-of-concept solution for generating the possible responses of detector clusters to particle collisions, using the real-life example of the Time Projection Chamber (TPC) in the ALICE experiment at CERN. We introduce this solution as a first step towards a semi-real-time anomaly detection tool. It's essential component is a generative model that allows to simulate synthetic data points that bear high similarity to the real data. Leveraging recent advancements in machine learning, we propose to use state-of-the-art generative models, namely Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN), that prove their usefulness and efficiency in the context of computer vision and image processing. The main advantage offered by those methods is a significant speedup in the execution time, reaching up to the factor of 103 with respect to the GEANT3, a currently used cluster simulation tool. Nevertheless, this computational speedup comes at a price of a lower simulation quality. In this work we show quantitative and qualitative limitations of currently available generative models. We also propose several further steps that will allow to improve the accuracy of the models and lead to the deployment of anomaly detection mechanism based on generative models in a production environment of the TPC detector.;2020;Not health related;Not health related
"Krishnamurthy, V; Bhatt, S; Pedersen, T";Tracking Infection Diffusion in Social Networks: Filtering Algorithms and Threshold Bounds;This paper deals with the statistical signal processing over graphs for tracking infection diffusion in social networks. Infection (or Information) diffusion is modeled using the susceptible-infected-susceptible (SIS) model. Mean field approximation is employed to approximate the discrete valued infection dynamics by a deterministic difference equation, thereby yielding a generative model for the infection diffusion. The infection is shown to follow polynomial dynamics and is estimated using an exact nonlinear Bayesian filter. We compute posterior Cramer-Rao bounds to obtain the fundamental limits of the filter that depend on the structure of the network. The SIS model is extended to include homophily, and filtering on these networks is illustrated. Considering the randomly evolving nature of realworld networks, a filtering algorithm for estimating the underlying degree distribution is also investigated using generative models for the time evolution of the network. We validate the efficacy of the proposed models and algorithms with synthetic data and Twitter datasets. We find that the SIS model is a satisfactory fit for the information diffusion, and the nonlinear filter effectively tracks the information diffusion.;2017;Not health related;Health related
"Li, LY; Yan, JC; Wang, HY; Jin, YH";Anomaly Detection of Time Series With Smoothness-Inducing Sequential Variational Auto-Encoder;Deep generative models have demonstrated their effectiveness in learning latent representation and modeling complex dependencies of time series. In this article, we present a smoothness-inducing sequential variational auto-encoder (VAE) (SISVAE) model for the robust estimation and anomaly detection of multidimensional time series. Our model is based on VAE, and its backbone is fulfilled by a recurrent neural network to capture latent temporal structures of time series for both the generative model and the inference model. Specifically, our model parameterizes mean and variance for each time-stamp with flexible neural networks, resulting in a nonstationary model that can work without the assumption of constant noise as commonly made by existing Markov models. However, such flexibility may cause the model fragile to anomalies. To achieve robust density estimation which can also benefit detection tasks, we propose a smoothness-inducing prior over possible estimations. The proposed prior works as a regularizer that places penalty at nonsmooth reconstructions. Our model is learned efficiently with a novel stochastic gradient variational Bayes estimator. In particular, we study two decision criteria for anomaly detection: reconstruction probability and reconstruction error. We show the effectiveness of our model on both synthetic data sets and public real-world benchmarks.;2021;Not health related;Not health related
"Zeraati, R; Engel, TA; Levina, A";A flexible Bayesian framework for unbiased estimation of timescales;Timescales characterize the pace of change for many dynamic processes in nature. They are usually estimated by fitting the exponential decay of data autocorrelation in the time or frequency domain. Here we show that this standard procedure often fails to recover the correct timescales due to a statistical bias arising from the finite sample size. We develop an alternative approach to estimate timescales by fitting the sample autocorrelation or power spectrum with a generative model based on a mixture of Ornstein-Uhlenbeck processes using adaptive approximate Bayesian computations. Our method accounts for finite sample size and noise in data and returns a posterior distribution of timescales that quantifies the estimation uncertainty and can be used for model selection. We demonstrate the accuracy of our method on synthetic data and illustrate its application to recordings from the primate cortex. We provide a customizable Python package that implements our framework via different generative models suitable for diverse applications.;2022;Not health related;Not health related
"Pinaya, WHL; Tudosiu, PD; Dafflon, J; Da Costa, PF; Fernandez, V; Nachev, P; Ourselin, S; Cardoso, MJ";Brain Imaging Generation with Latent Diffusion Models;Deep neural networks have brought remarkable breakthroughs in medical image analysis. However, due to their data-hungry nature, the modest dataset sizes in medical imaging projects might be hindering their full potential. Generating synthetic data provides a promising alternative, allowing to complement training datasets and conducting medical image research at a larger scale. Diffusion models recently have caught the attention of the computer vision community by producing photorealistic synthetic images. In this study, we explore using Latent Diffusion Models to generate synthetic images from high-resolution 3D brain images. We used T1w MRI images from the UK Biobank dataset (N = 31,740) to train our models to learn about the probabilistic distribution of brain images, conditioned on covariates, such as age, sex, and brain structure volumes. We found that our models created realistic data, and we could use the conditioning variables to control the data generation effectively. Besides that, we created a synthetic dataset with 100,000 brain images and made it openly available to the scientific community.;2022;Health related;Health related
"Wang, BX; Wu, F; Long, YH; Rimanic, L; Zhang, C; Li, B";DataLens: Scalable Privacy Preserving Training via Gradient Compression and Aggregation;"Recent success of deep neural networks (DNNs) hinges on the availability of large-scale dataset; however, training on such dataset often poses privacy risks for sensitive training information. In this paper, we aim to explore the power of generative models and gradient sparsity, and propose a scalable privacy-preserving generative model DATALENS, which is able to generate synthetic data in a differentially private (DP) way given sensitive input data. Thus, it is possible to train models for different down-stream tasks with the generated data while protecting the private information. In particular, we leverage the generative adversarial networks (GAN) and PATE framework to train multiple discriminators as teacher models, allowing them to vote with their gradient vectors to guarantee privacy. Comparing with the standard PATE privacy preserving framework which allows teachers to vote on one-dimensional predictions, voting on the high dimensional gradient vectors is challenging in terms of privacy preservation. As dimension reduction techniques are required, we need to navigate a delicate tradeoff space between (1) the improvement of privacy preservation and (2) the slowdown of SGD convergence. To tackle this, we propose a novel dimension compression and aggregation approach ToPAGG, which combines top-k dimension compression with a corresponding noise injection mechanism. We theoretically prove that the DATALENS framework guarantees differential privacy for its generated data, and provide a novel analysis on its convergence to illustrate such a tradeoff on privacy and convergence rate, which requires nontrivial analysis as it requires a joint analysis on gradient compression, coordinate-wise gradient clipping, and DP mechanism. To demonstrate the practical usage of DATALENS, we conduct extensive experiments on diverse datasets including MNIST, Fashion-MNIST, and high dimensional CelebA and Place365 datasets. We show that DATALENS significantly outperforms other baseline differentially private data generative models. Our code is publicly available at https://github.com/AI-secure/DataLens.";2021;Not health related;Not health related
"Burt, JB; Helmer, M; Shinn, M; Anticevic, A; Murray, JD";Generative modeling of brain maps with spatial autocorrelation;Studies of large-scale brain organization have revealed interesting relationships between spatial gradients in brain maps across multiple modalities. Evaluating the significance of these findings requires establishing statistical expectations under a null hypothesis of interest. Through generative modeling of synthetic data that instantiate a specific null hypothesis, quantitative benchmarks can be derived for arbitrarily complex statistical measures. Here, we present a generative null model, provided as an open-access software platform, that generates surrogate maps with spatial autocorrelation (SA) matched to SA of a target brain map. SA is a prominent and ubiquitous property of brain maps that violates assumptions of independence in conventional statistical tests. Our method can simulate surrogate brain maps, constrained by empirical data, that preserve the SA of cortical, subcortical, parcellated, and dense brain maps. We characterize how SA impacts p-values in pairwise brain map comparisons. Furthermore, we demonstrate how SA-preserving surrogate maps can be used in gene set enrichment analyses to test hypotheses of interest related to brain map topography. Our findings demonstrate the utility of SA-preserving surrogate maps for hypothesis testing in complex statistical analyses, and underscore the need to disambiguate meaningful relationships from chance associations in studies of large-scale brain organization.;2020;Health related;Not health related
"Achddou, R; Gousseau, Y; Ladjal, S";Fully synthetic training for image restoration tasks;In this work, we show that neural networks aimed at solving various image restoration tasks can be successfully trained on fully synthetic data. In order to do so, we rely on a generative model of images, the scaling dead leaves model, which is obtained by superimposing disks whose size distribution is scale-invariant. Pairs of clean , corrupted synthetic images can then be obtained by a careful simulation of the degradation process. We show on various restoration tasks that such a synthetic training yields results that are only slightly inferior to those obtained when the training is performed on large natural image databases. This implies that, for restoration tasks, the geometric contents of natural images can be nailed down to only a simple generative model and a few parameters. This prior can then be used to train neural networks for specific modality, without having to rely on demanding campaigns of natural images acquisition. We demonstrate the feasibility of this approach on difficult restoration tasks, including the denoising of smartphone RAW images and the full development of low-light images.;2023;Not health related;Not health related
"Li, D; Zhang, YF; Yang, Z; Jin, YH; Xu, YY";Sensing anomaly of photovoltaic systems with sequential conditional variational autoencoder;The market for urban distributed photovoltaics (DPV) is expected to take off in the next decade. However, these systems are often subject to complex urban contexts and sub-optimal conditions, requiring scalable and comprehensive solutions to detect their underperformances. In recent years, deep generative models (DGMs) have exhibited outstanding performance in the anomaly detection domain, dealing with generic high-dimensional time series data. Nevertheless, the existing applications of DGMs in the photovoltaic (PV) sector are still unable to account for environmental information, limiting their performance under various environmental conditions. This study proposes the Sequential Conditional Variational Autoencoder (SCVAE), which can cope with the sequential impacts of the environment on PV power generation. Using real-world data collected from 30 rooftop PV sites located across China, a data processing pipeline is developed to construct the training datasets which contain mostly normal samples for unsupervised SCVAE model training. This work also constructs a synthetic dataset with a wide variety of artificial anomalies in reference to the domain insights and engineering practice of DPV systems. After checking and refining by experts, the synthetic dataset can finally be used to validate the anomaly detection models. The results demonstrate that the SCVAE model outperforms existing state-of-the-art unsupervised anomaly detection models and can be effectively generalized to unseen PV sites. Moreover, the latent variables of SCVAE could be used to identify the type of DPV failure, thereby enabling more targeted diagnostics of anomaly mechanisms.;2024;Not health related;Not health related
"Jaureguiberry, X; Vincent, E; Richard, G";VARIATIONAL BAYESIAN MODEL AVERAGING FOR AUDIO SOURCE SEPARATION;Non-negative Matrix Factorization (NMF) has become popular in audio source separation in order to design source-specific models. The number of components of the NMF is known to have a noticeable influence on separation quality. Many methods have thus been proposed to select the best order for a given task. To go further, we propose here to use model averaging. As existing techniques do not allow an effective averaging, we introduce a generative model in which the number of components is a random variable and we propose a modification to conventional variational Bayesian (VB) inference. Experimental results on synthetic data show promising results as our model leads to better separation results and is less computationally demanding than conventional VB model selection.;2014;Not health related;Not health related
"Wang, DL; Zhao, T; Zheng, NG; Gong, ZF";Two-Stage Generative Models of Simulating Training Data at The Voxel Level for Large-Scale Microscopy Bioimage Segmentation;Bioimage Informatics is a growing area that aims to extract biological knowledge from microscope images of biomedical samples automatically. Its mission is vastly challenging, however, due to the complexity of diverse imaging modalities and big scales of multi-dimensional images One major challenge is automatic image segmentation, an essential step towards high-level modeling and analysis. While progresses in deep learning have brought the goal of automation much closer to reality, creating training data for producing powerful neural networks is often laborious. To provide a shortcut for this costly step, we propose a novel two-stage generative model for simulating voxel level training data based on a specially designed objective function of preserving foreground labels. Using segmenting neurons from LM (Light Microscopy) image stacks as a testing example, we showed that segmentation networks trained by our synthetic data were able to produce satisfactory results. Unlike other simulation methods available in the field, our method can be easily extended to many other applications because it does not involve sophisticated cell models and imaging mechanisms.;2019;Health related;Health related
"Shin, Y; Chun, C";Sound Event Localization and Detection Using Imbalanced Real and Synthetic Data via Multi-Generator;This study proposes a sound event localization and detection (SELD) method using imbalanced real and synthetic data via a multi-generator. The proposed method is based on a residual convolutional neural network (RCNN) and a transformer encoder for real spatial sound scenes. SELD aims to classify the sound event, detect the onset and offset of the classified event, and estimate the direction of the sound event. In Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Task 3, SELD is performed with a few real spatial sound scene data and a relatively large number of synthetic data. When a model is trained using imbalanced data, it can proceed by focusing only on a larger number of data. Thus, a multi-generator that samples real and synthetic data at a specific rate in one batch is proposed to prevent this problem. We applied the data augmentation technique SpecAugment and used time-frequency masking to the dataset. Furthermore, we propose a neural network architecture to apply the RCNN and transformer encoder. Several models were trained with various structures and hyperparameters, and several ensemble models were obtained by cherry-picking specific models. Based on the experiment, the single model of the proposed method and the model applied with the ensemble exhibited improved performance compared with the baseline model.;2023;Not health related;Not health related
"Bano, S; Cassara, P; Tonellotto, N; Gotta, A";A Federated Channel Modeling System using Generative Neural Networks;The paper proposes a data-driven approach to air-to-ground channel estimation in a millimeter-wave wireless network on an unmanned aerial vehicle. Unlike traditional centralized learning methods that are specific to certain geographical areas and inappropriate for others, we propose a generalized model that uses Federated Learning (FL) for channel estimation and can predict the air-to-ground path loss between a low-altitude platform and a terrestrial terminal. To this end, our proposed FL-based Generative Adversarial Network (FL-GAN) is designed to function as a generative data model that can learn different types of data distributions and generate realistic patterns from the same distributions without requiring prior data analysis before the training phase. To evaluate the effectiveness of the proposed model, we evaluate its performance using Kullback-Leibler divergence (KL), and Wasserstein distance between the synthetic data distribution generated by the model and the actual data distribution. We also compare the proposed technique with other generative models, such as FL-Variational Autoencoder (FL-VAE) and stand-alone VAE and GAN models. The results of the study show that the synthetic data generated by FL-GAN has the highest similarity in distribution with the real data. This shows the effectiveness of the proposed approach in generating data-driven channel models that can be used in different regions.;2023;Not health related;Not health related
"Gelencsér-Horváth, A; Kopácsi, L; Varga, V; Keller, D; Dobolyi, A; Karacs, K; Lorincz, A";Tracking Highly Similar Rat Instances under Heavy Occlusions: An Unsupervised Deep Generative Pipeline;"Identity tracking and instance segmentation are crucial in several areas of biological research. Behavior analysis of individuals in groups of similar animals is a task that emerges frequently in agriculture or pharmaceutical studies, among others. Automated annotation of many hours of surveillance videos can facilitate a large number of biological studies/experiments, which otherwise would not be feasible. Solutions based on machine learning generally perform well in tracking and instance segmentation; however, in the case of identical, unmarked instances (e.g., white rats or mice), even state-of-the-art approaches can frequently fail. We propose a pipeline of deep generative models for identity tracking and instance segmentation of highly similar instances, which, in contrast to most region-based approaches, exploits edge information and consequently helps to resolve ambiguity in heavily occluded cases. Our method is trained by synthetic data generation techniques, not requiring prior human annotation. We show that our approach greatly outperforms other state-of-the-art unsupervised methods in identity tracking and instance segmentation of unmarked rats in real-world laboratory video recordings.";2022;Not health related;Not health related
"Sattarzadeh, S; Shalmani, SM; Azad, S";Mitigating Paucity of Data in Sinusoid Characterization Using Generative Synthetic Noise;Although the remarkable breakthrough offered by Deep Learning (DL) models in numerous computer vision tasks, the need to acquire large amounts of high-quality natural data and fine-grained annotations is a shortcoming that fundamentally increases the cost and time devoted to training these models in real-world applications. Hence, synthetic datasets are considered reliable alternatives that can reduce the data acquisition by replacing or merging with natural data or effective pre-training of the models. To this end, in this work, we propose a novel approach to integrate structural data structures with the synthetic noise structures learned by unsupervised models that mimic the noise structures in natural data. Based on the proposed approach, we introduce the Sinusoid Feature Recognition (SFR) dataset, which contains hard-to-detect fixed-period sinusoid waves. While the previous works in this regard use generative models to sample synthetic data to inflate the training set, we instead apply unsupervised learning models to generate deep synthetic noise which makes training models in the proposed dataset more challenging. We evaluate the segmentation, image reconstruction, and sinusoid characterization models pre-trained or fully trained on the synthetic SFR dataset on a private dataset of grayscale Acoustic Tele-Viewer (ATV) images. Experimental results show that supervision on our proposed synthetic dataset can improve the accuracy of the models by 3-4% via pre-training, and by 17-27% via ad-hoc training while dealing with challenging, realistic real-world images.;2022;Not health related;Not health related
"Chan, ER; Monteiro, M; Kellnhofer, P; Wu, JJ; Wetzstein, G";pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis;"We have witnessed rapid progress on 3D-aware image synthesis, leveraging recent advances in generative visual models and neural rendering. Existing approaches however fall short in two ways: first, they may lack an underlying 3D representation or rely on view-inconsistent rendering, hence synthesizing images that are not multi-view consistent; second, they often depend upon representation network architectures that are not expressive enough, and their results thus lack in image quality. We propose a novel generative model, named Periodic Implicit Generative Adversarial Networks (pi-GAN or pi-GAN), for high-quality 3D-aware image synthesis. pi-GAN leverages neural representations with periodic activation functions and volumetric rendering to represent scenes as view-consistent radiance fields. The proposed approach obtains state-of-the-art results for 3D-aware image synthesis with multiple real and synthetic datasets.";2021;Not health related;Not health related
"Song, YX; Miao, N; Zhou, H; Yu, LT; Wang, MX; Li, L";Improving Maximum Likelihood Training for Text Generation with Density Ratio Estimation;"Autoregressive sequence generative models trained by Maximum Likelihood Estimation suffer the exposure bias problem in practical finite sample scenarios. The crux is that the number of training samples for Maximum Likelihood Estimation is usually limited and the input data distributions are different at training and inference stages. Many methods have been proposed to solve the above problem (Yu et al., 2017; Lu et al., 2018), which relies on sampling from the non-stationary model distribution and suffers from high variance or biased estimations. In this paper, we propose psi-MLE, a new training scheme for autoregressive sequence generative models, which is effective and stable when operating at large sample space encountered in text generation. We derive our algorithm from a new perspective of self-augmentation and introduce bias correction with density ratio estimation. Extensive experimental results on synthetic data and real-world text generation tasks demonstrate that our method stably outperforms Maximum Likelihood Estimation and other state-of-the-art sequence generative models in terms of both quality and diversity.";2020;Not health related;Not health related
"Hu, HY; Liu, JR; Chen, GY; Zhao, YT; Gao, ZH; Zheng, RC";Driver Identification Using Deep Generative Model With Limited Data;"The scarcity of driving data constrains the accuracy of deep learning (DL)-based driver identification methods in practical application scenarios. To address this issue, this study proposes a novel unsupervised deep generative model called the convolution condition variant autoencoder (CCVAE) for driving data augmentation. In CCVAE, aided by driver identification information, the condition variant autoencoder can learn the real driving data distribution of each driver through an unsupervised learning paradigm; and aiming for better feature representation ability, convolutional neural network and deconvolution are leveraged, respectively. Therefore, a large number of synthetic samples can be generated by the generative part of the CCVAE. We demonstrate the effectiveness of the CCVAE through extensive experimental analysis using a real dataset collected from a vehicular CAN bus; the improvement of the DL-based driver identification results is demonstrated using synthetic samples. For instance, when only using 2% of the original data, approximately 20% improvement is achieved in terms of four evaluation indicators for two commonly used DL-based driver identification methods, namely, 1-D CNN and LSTM. Furthermore, several comparable experiments with state-of-the-art deep generative methods reveal the superior performance of the proposed CCVAE with respect to identification results, synthetic data quality, and model computation time. Therefore, the proposed model accomplishes a breakthrough in driver identification with limited data and shows great potential in data-driven applications of intelligent vehicles.";2023;Not health related;Not health related
"Zia, M; Frazier, S; Nazaripouya, H";Synthetic Agricultural Load Data Generation Using TimeGANs;In power system applications, accessing real data is one of the main challenges. Load modeling is an example that can be hampered by a lack of real data. This paper proposes synthetic data generation as a solution to deal with insufficient datasets. To this end, Timeseries Generative Adversarial Networks (TimeGANs) are proposed to create synthetic electricity data for an agricultural load. Center pivot irrigation system data is targeted, which does not exhibit the same trends as residential or commercial utility data, and information is presented in the lower dimensions. Obtained results show that TimeGANs can leverage the lower dimensional information to produce synthetic data with the same characteristics as the actual data. The proposed method can be utilized for modeling different electric loads.;2023;Not health related;Not health related
"Balaji, Y; Min, MR; Bai, B; Chellappa, R; Graf, HP";Conditional GAN with Discriminative Filter Generation for Text-to-Video Synthesis;Developing conditional generative models for textto-video synthesis is an extremely challenging yet an important topic of research in machine learning. In this work, we address this problem by introducing Text-Filter conditioning Generative Adversarial Network (TFGAN), a conditional GAN model with a novel multi-scale text-conditioning scheme that improves text-video associations. By combining the proposed conditioning scheme with a deep GAN architecture, TFGAN generates high quality videos from text on challenging real-world video datasets. In addition, we construct a synthetic dataset of text-conditioned moving shapes to systematically evaluate our conditioning scheme. Extensive experiments demonstrate that TFGAN significantly outperforms existing approaches, and can also generate videos of novel categories not seen during training;2019;Not health related;Not health related
"Veretennikov, S; Minartz, K; Menkovski, V; Gumuscu, B; de Boer, J";Simulation of Scientific Experiments with Generative Models;Lab experiments are a crucial part of research in natural sciences. High-throughput screening is leveraged to generate hypotheses, by evaluating a wide range of experimental parameter values and accumulating a wealth of data on the corresponding experimental outcomes. The data is subsequently analyzed to design new rounds of experiments. While discriminative models have previously proven useful for screening data analytics, they do not account for randomness inherent to lab experiments, and do not have the capacity to capture the potentially high-dimensional relationship between the experiment input parameters and outcomes. Instead, we take a data-driven simulation perspective on the problem. Inspired by biomaterials research experiments, we consider a case where both the input parameter space and the outcome space have a high-dimensional (image) representation. We propose a deep generative model that serves simultaneously as a simulation model of the experiment, i.e. allows to generate potential outcomes conditioned on the experiment input, and as a tool for inverse design, i.e. generating instances of inputs that could lead to a given experiment outcome. A proof-of-concept evaluation on a synthetic dataset shows that the model is able to learn the embedded relationship between the properties of the input and of the output in a probabilistic manner and allows for experiment simulation and design application scenarios.;2022;Not health related;Not health related
"Fang, ML; Dhami, DS; Kersting, K";DP-CTGAN: Differentially Private Medical Data Generation Using CTGANs;Generative Adversarial Networks (GANs) are an important tool to generate synthetic medical data, in order to combat the limited and difficult access to the real data sets and accelerate the innovation in the healthcare domain. Despite their promising capability, they are vulnerable to various privacy attacks that might reveal information of individuals from the training data. Preserving privacy while keeping the quality of the generated data still remains a challenging problem. We propose DP-CTGAN, which incorporates differential privacy into a conditional tabular generative model. Our experiments demonstrate that our model outperforms existing state-of-the-art models under the same privacy budget on several benchmark data sets. In addition, we combine our method with federated learning, enabling a more secure way of synthetic data generation without the need of uploading locally collected data to a central repository.;2022;Health related;Health related
"Ke, WJ; Gao, JH; Shen, HW; Cheng, XQ";ConsistSum: Unsupervised Opinion Summarization with the Consistency of Aspect, Sentiment and Semantic;Unsupervised opinion summarization techniques are designed to condense the review data and summarize informative and salient opinions in the absence of golden references. Existing dominant methods generally follow a two-stage framework: first creating the synthetic review-summary paired datasets and then feeding them into the generative summary model for supervised training. However, these methods mainly focus on semantic similarity in synthetic dataset creation, ignoring the consistency of aspects and sentiments in synthetic pairs. Such inconsistency also brings a gap to the training and inference of the summarization model. To alleviate this problem, we propose ConsistSum, an unsupervised opinion summarization method devoting to capture the consistency of aspects and sentiment between reviews and summaries. Specifically, ConsistSum first extracts the preliminary review-summary pairs from the raw corpus by evaluating the distance of aspect distribution and sentiment distribution. Then, we refine the preliminary summary with the constrained Metropolis-Hastings sampling to produce highly consistent synthetic datasets. In the summarization phase, we adopt the generative model T5 as the summarization model. T5 is fine-tuned for the opinion summarization task by incorporating the loss of predicting aspect and opinion distribution. Experimental results on two benchmark datasets, i.e.., Yelp and Amazon, demonstrate the superior performance of ConsistSum over the state-of-the-art baselines.;2022;Not health related;Not health related
"Wang, ZY; Deng, Y; Yang, JL; Yu, JY; Tong, X";Generative Deformable Radiance Fields for Disentangled Image Synthesis of Topology-Varying Objects;3D-aware generative models have demonstrated their superb performance to generate 3D neural radiance fields (NeRF) from a collection of monocular 2D images even for topology-varying object categories. However, these methods still lack the capability to separately control the shape and appearance of the objects in the generated radiance fields. In this paper, we propose a generative model for synthesizing radiance fields of topology-varying objects with disentangled shape and appearance variations. Our method generates deformable radiance fields, which builds the dense correspondence between the density fields of the objects and encodes their appearances in a shared template field. Our disentanglement is achieved in an unsupervised manner without introducing extra labels to previous 3D-aware GAN training. We also develop an effective image inversion scheme for reconstructing the radiance field of an object in a real monocular image and manipulating its shape and appearance. Experiments show that our method can successfully learn the generative model from unstructured monocular images and well disentangle the shape and appearance for objects (e.g., chairs) with large topological variance. The model trained on synthetic data can faithfully reconstruct the real object in a given single image and achieve high-quality texture and shape editing results.;2022;Not health related;Not health related
"Leonardi, G; Portinale, L";Applying Machine Learning to High-Quality Wine Identification;This paper discusses a machine learning approach, aimed at the definition of methods for authenticity assessment of some of the highest valued Nebbiolo-based wines from Piedmont (Italy). This issue is one of the most relevant in the wine market, where commercial frauds related to such a kind of products are estimated to be worth millions of Euros. The main objective of the work is to demonstrate the effectiveness of classification algorithms in exploiting simple features about the chemical profile of a wine, obtained from inexpensive standard bio-chemical analyses. We report on experiments performed with datasets of real samples and with synthetic datasets which have been artificially generated from real data through the learning of a Bayesian network generative model.;2017;Not health related;Not health related
"Nadjahi, K; Durmus, A; Jacob, PE; Badeau, R; Simsekli, U";Fast Approximation of the Sliced-Wasserstein Distance Using Concentration of Random Projections;The Sliced-Wasserstein distance (SW) is being increasingly used in machine learning applications as an alternative to the Wasserstein distance and offers significant computational and statistical benefits. Since it is defined as an expectation over random projections, SW is commonly approximated by Monte Carlo. We adopt a new perspective to approximate SW by making use of the concentration of measure phenomenon: under mild assumptions, one-dimensional projections of a high-dimensional random vector are approximately Gaussian. Based on this observation, we develop a simple deterministic approximation for SW. Our method does not require sampling a number of random projections, and is therefore both accurate and easy to use compared to the usual Monte Carlo approximation. We derive nonasymptotical guarantees for our approach, and show that the approximation error goes to zero as the dimension increases, under a weak dependence condition on the data distribution. We validate our theoretical findings on synthetic datasets, and illustrate the proposed approximation on a generative modeling problem.;2021;Not health related;Not health related
"Ngxande, M; Tapamo, JR; Burke, M";DepthwiseGANs: Fast Training Generative Adversarial Networks for Realistic Image Synthesis;Recent work has shown significant progress in the direction of synthetic data generation using Generative Adversarial Networks (GANs). GANs have been applied in many fields of computer vision including text-to-image conversion, domain transfer, super-resolution, and image-to-video applications. In computer vision, traditional GANs are based on deep convolutional neural networks. However, deep convolutional neural networks can require extensive computational resources because they are based on multiple operations performed by convolutional layers, which can consist of millions of trainable parameters. Training a GAN model can be difficult and it takes a significant amount of time to reach an equilibrium point. In this paper, we investigate the use of depthwise separable convolutions to reduce training time while maintaining data generation performance. Our results show that a DepthwiseGAN architecture can generate realistic images in shorter training periods when compared to a StarGan architecture, but that model capacity still plays a significant role in generative modelling. In addition, we show that depthwise separable convolutions perform best when only applied to the generator. For quality evaluation of generated images, we use the Frechet Inception Distance (FID), which compares the similarity between the generated image distribution and that of the training dataset.;2019;Not health related;Not health related
"Wu, JJ; Lu, E; Kohli, P; Freeman, WT; Tenenbaum, JB";Learning to See Physics via Visual De-animation;"We introduce a paradigm for understanding physical scenes without human annotations. At the core of our system is a physical world representation that is first recovered by a perception module and then utilized by physics and graphics engines. During training, the perception module and the generative models learn by visual de-animation - interpreting and reconstructing the visual information stream. During testing, the system first recovers the physical world state, and then uses the generative models for reasoning and future prediction. Even more so than forward simulation, inverting a physics or graphics engine is a computationally hard problem; we overcome this challenge by using a convolutional inversion network. Our system quickly recognizes the physical world state from appearance and motion cues, and has the flexibility to incorporate both differentiable and non-differentiable physics and graphics engines. We evaluate our system on both synthetic and real datasets involving multiple physical scenes, and demonstrate that our system performs well on both physical state estimation and reasoning problems. We further show that the knowledge learned on the synthetic dataset generalizes to constrained real images.";2017;Not health related;Not health related
"Schmidt, MN; Herlau, T; Morup, M";DISCOVERING HIERARCHICAL STRUCTURE IN NORMAL RELATIONAL DATA;Index Terms- Hierarchical clustering is a widely used tool for structuring and visualizing complex data using similarity. Traditionally, hierarchical clustering is based on local heuristics that do not explicitly provide assessment of the statistical saliency of the extracted hierarchy. We propose a non-parametric generative model for hierarchical clustering of similarity based on multifurcating Gibbs fragmentation trees. This allows us to infer and display the posterior distribution of hierarchical structures that comply with the data. We demonstrate the utility of our method on synthetic data and data of functional brain connectivity.;2014;Not health related;Not health related
"Sapai, S; Loo, JY; Ding, ZY; Tan, CP; Baskaran, VM; Nurzaman, SG";A Deep Learning Framework for Soft Robots with Synthetic Data;Data-driven methods with deep neural networks demonstrate promising results for accurate modeling in soft robots. However, deep neural network models rely on voluminous data in discovering the complex and nonlinear representations inherent in soft robots. Consequently, while it is not always possible, a substantial amount of effort is required for data acquisition, labeling, and annotation. This article introduces a data-driven learning framework based on synthetic data to circumvent the exhaustive data collection process. More specifically, we propose a novel time series generative adversarial network with a self-attention mechanism, Transformer TimeGAN (TTGAN) to precisely learn the complex dynamics of a soft robot. On top of that, the TTGAN is incorporated with a conditioning network that enables it to produce synthetic data for specific soft robot behaviors. The proposed framework is verified on a widely used pneumatic-based soft gripper as an exemplary experimental setup. Experimental results demonstrate that the TTGAN generates synthetic time series data with realistic soft robot dynamics. Critically, a combination of the synthetic and only partially available original data produces a data-driven model with estimation accuracy comparable to models obtained from using complete original data.;2023;Not health related;Not health related
"Helmsen, J; Baracat-Donovan, B; White, R; McCullough, T";Swiss Army VAE: Comprehensive Sensor Data Analysis via Explainable AI;An integrated system for processing sensor data has been developed based on novel variational autoencoder (VAE) algorithms with explainability that significantly eases analysis of sensor data. By continuously updating a generative model of the data, the system assists users with minimal artificial intelligence (AI) training or experience to perform data analysis. The system performs an extensive range of integrated machine learning (ML) tasks: anomaly detection, active learning, model-drift detection, synthetic data generation, semi-supervised classification, and counterfactual explanation generation. When the system is provided a data schema (map of Booleans, integers, reals, categories, time series, etc.) and data set, it automatically forms a preliminary generative model of the data. The construction of the system is modular, so new data types can be added as necessary. Counterfactually explainable anomaly detection is immediately performed via sparse gradient search. This informs the user how to interactively remove or repair bad records and/or begin labeling records of interest. The addition of labels to the data allows multi-class, semi-supervised, counterfactually explainable classification via the support vector machine embedded hyperplane algorithm (SVM-EH). Once some labels are added, active learning is used to assist further labeling by suggesting data elements that are highly likely to improve classification accuracy, significantly accelerating the labeling process by trading human effort for computational cycles. In production, the system detects when its training is becoming stale and requests retraining. Classification accuracy is demonstrated to be comparable to other deep learning systems on benchmark data sets.;2023;Not health related;Not health related
"Park, H; Li, B; Liu, YM; Nelson, MS; Wilson, HM; Sifakis, E; Eliceiri, KW";Collagen fiber centerline tracking in fibrotic tissue via deep neural networks with variational autoencoder-based synthetic training data generation;The role of fibrillar collagen in the tissue microenvironment is critical in disease contexts ranging from cancers to chronic inflammations, as evidenced by many studies. Quantifying fibrillar collagen organization has become a powerful approach for characterizing the topology of collagen fibers and studying the role of collagen fibers in disease progression. We present a deep learning-based pipeline to quantify collagen fibers' topological properties in microscopy-based collagen images from pathological tissue samples. Our method leverages deep neural networks to extract collagen fiber centerlines and deep generative models to create synthetic training data, addressing the current shortage of large-scale annotations. As a part of this effort, we have created and annotated a collagen fiber centerline dataset, with the hope of facilitating further research in this field. Quantitative measurements such as fiber orientation, alignment, density, and length can be derived based on the centerline extraction results. Our pipeline comprises three stages. Initially, a variational autoencoder is trained to generate synthetic centerlines possessing controllable topological properties. Subsequently, a conditional generative adversarial network synthesizes realistic collagen fiber images from the synthetic centerlines, yielding a synthetic training set of image-centerline pairs. Finally, we train a collagen fiber centerline extraction network using both the original and synthetic data. Evaluation using collagen fiber images from pancreas, liver, and breast cancer samples collected via second-harmonic generation microscopy demonstrates our pipeline's superiority over several popular fiber centerline extraction tools. Incorporating synthetic data into training further enhances the network's generalizability. Our code is available at https://github.com/uw-loci/collagen-fiber-metrics.;2023;Health related;Health related
Pulkkinen, S;Ridge-based method for finding curvilinear structures from noisy data;Extraction of curvilinear structures from noisy data is an essential task in many application fields such as data analysis, pattern recognition and machine vision. The proposed approach assumes a random process in which the samples are obtained from a generative model. The model specifies a set of generating functions describing curvilinear structures as well as sampling noise and background clutter. It is shown that ridge curves of the marginal density induced by the model can be used to estimate the generating functions. Given a Gaussian kernel density estimate for the marginal density, ridge curves of the density estimate are parametrized as the solution to a differential equation. Finally, a predictor corrector algorithm for tracing the ridge curve set of such a density estimate is developed. Efficiency and robustness of the algorithm are demonstrated by numerical experiments on synthetic datasets as well as observational datasets from seismology and cosmology. (C) 2014 Elsevier B.V. All rights reserved.;2015;Not health related;Not health related
"Xing, XD; Nan, Y; Felder, F; Walsh, S; Yang, G";The Beauty or the Beast: Which Aspect of Synthetic Medical Images Deserves Our Focus?;Training medical AI algorithms requires large volumes of accurately labeled datasets, which are difficult to obtain in the real world. Synthetic images generated from deep generative models can help alleviate the data scarcity problem, but their effectiveness relies on their fidelity to real-world images. Typically, researchers select synthesis models based on image quality measurements, prioritizing synthetic images that appear realistic. However, our empirical analysis shows that high-fidelity and visually appealing synthetic images are not necessarily superior. In fact, we present a case where low-fidelity synthetic images outperformed their high-fidelity counterparts in downstream tasks. Our findings highlight the importance of comprehensive analysis before incorporating synthetic data into real-world applications. We hope our results will raise awareness among the research community of the value of low-fidelity synthetic images in medical AI algorithm training.;2023;Health related;Health related
"Kaada, S; Hamideche, SA; Daems, C; Morel, MLA";Classification with Synthetic Radio Data for Real-life Environment Sensing;In sensing-enabled mobile infrastructure, the network itself acts as a whole sensor by leveraging radio data or signals collected within Base Stations (BSs). This data is exploited for the development of data-driven machine learning solutions to augment network's capabilities. Nevertheless, large-scale qualitative data is required for achieving high accuracy learning. However, their training phase leads to prohibitive cost and heavy constraints on data collection and storage that are not desirable for network. To overcome this problem, we propose to use synthetic data instead of real data for training machine learning models to avoid high cost data sharing/storage. In this paper, we are interested in real-life Environment Sensing Network in a context of limited data amount sharing. We focus on Indoor-Outdoor Detection (IOD) using unsupervised machine learning classification models. For this purpose, experiments are conducted following the paradigm of Training on Synthetic data and Testing on Real Data (TSTR). We conduct a comparative study of four well-known generative models, that are able to generate synthetic 3GPP radio data with similar distribution than the source data. We investigate the quality of these synthetic generated radio data according to three dimensions: distribution similarity, data variability and detection capability. The classification models trained with synthetic generated data are tested in real-life context to infer whether a user connected to the network is inside or outside a building. The study shows convincing results with an Indoor/Outdoor unsupervised classification performance up to 80% of F1 - score like in real-life data training scenarios.;2023;Not health related;Not health related
Piatkowski, N;Hyper-Parameter-Free Generative Modelling with Deep Boltzmann Trees;Deep neural networks achieve state-of-the-art results in various classification and synthetic data generation tasks. However, only little is known about why depth improves a model. We investigate the structure of stochastic deep neural works, also known as Deep Boltzmann Machines, to shed some light on this issue. While the best known results postulate an exponential dependence between the number of visible units and the depth of the model, we show that the required depth is upper bounded by the longest path in the underlying junction tree, which is at most linear in the number of visible units. Moreover, we show that the conditional independence structure of any categorical Deep Boltzmann Machine contains a sub-tree that allows the consistent estimation of the full joint probability mass function of all visible units. We connect our results to l(1)-regularized maximum-likelihood estimation and Chow-Liu trees. Based on our theoretical findings, we present a new tractable version of Deep Boltzmann Machines, namely the Deep Boltzmann Tree (DBT). We provide a hyper-parameter-free algorithm for learning the DBT from data, and propose a new initialization method to enforce convergence to good solutions. Our findings provide some theoretical evidence for why a deep model might be beneficial. Experimental results on benchmark data show, that the DBT is a theoretical sound alternative to likelihood-free generative models.;2020;Not health related;Not health related
"Zhao, ZL; Kunar, A; Birke, R; van der Scheer, H; Chen, LY";CTAB-GAN plus : enhancing tabular data synthesis;"The usage of synthetic data is gaining momentum in part due to the unavailability of original data due to privacy and legal considerations and in part due to its utility as an augmentation to the authentic data. Generative adversarial networks (GANs), a paragon of generative models, initially for images and subsequently for tabular data, has contributed many of the state-of-the-art synthesizers. As GANs improve, the synthesized data increasingly resemble the real data risking to leak privacy. Differential privacy (DP) provides theoretical guarantees on privacy loss but degrades data utility. Striking the best trade-off remains yet a challenging research question. In this study, we propose CTAB-GAN+ a novel conditional tabular GAN. CTAB-GAN+ improves upon state-of-the-art by (i) adding downstream losses to conditional GAN for higher utility synthetic data in both classification and regression domains; (ii) using Wasserstein loss with gradient penalty for better training convergence; (iii) introducing novel encoders targeting mixed continuous-categorical variables and variables with unbalanced or skewed data; and (iv) training with DP stochastic gradient descent to impose strict privacy guarantees. We extensively evaluate CTAB-GAN+ on statistical similarity and machine learning utility against state-of-the-art tabular GANs. The results show that CTAB-GAN+ synthesizes privacy-preserving data with at least 21.9% higher machine learning utility (i.e., F1-Score) across multiple datasets and learning tasks under given privacy budget.";2024;Not health related;Not health related
"Schultz, K; Bej, S; Hahn, W; Wolfien, M; Srivastava, P; Wolkenhauer, O";ConvGeN: A convex space learning approach for deep-generative oversampling and imbalanced classification of small tabular datasets;Oversampling is commonly used to improve classifier performance for small tabular imbalanced datasets. Stateof-the-art linear interpolation approaches can be used to generate synthetic samples from the convex space of the minority class. Generative networks are common deep learning approaches for synthetic sample generation. However, their scope on synthetic tabular data generation in the context of imbalanced classification is not adequately explored. In this article, we show that existing deep generative models perform poorly compared to linear interpolation-based approaches for imbalanced classification problems on small tabular datasets. To overcome this, we propose a deep generative model, ConvGeN that combines the idea of convex space learning with deep generative models. ConvGeN learns coefficients for the convex combinations of the minority class samples, such that the synthetic data is distinct enough from the majority class. Our benchmarking experiments demonstrate that our proposed model ConvGeN improves imbalanced classification on such small datasets, as compared to existing deep generative models, while being on par with the existing linear interpolation approaches. Moreover, we discuss how our model can be used for synthetic tabular data generation in general, even outside the scope of data imbalance, and thus improves the overall applicability of convex space learning.;2024;Not health related;Not health related
"Yu, MH; Kulhare, S; Mehanian, C; Delahunt, CB; Shea, DE; Laverriere, Z; Shah, I; Horning, MP";How Good Are Synthetic Medical Images? An Empirical Study with Lung Ultrasound;"Acquiring large quantities of data and annotations is effective for developing high-performing deep learning models, but is difficult and expensive to do in the healthcare context. Adding synthetic training data using generative models offers a low-cost method to deal effectively with the data scarcity challenge, and can also address data imbalance and patient privacy issues. In this study, we propose a comprehensive framework that fits seamlessly into model development workflows for medical image analysis. We demonstrate, with datasets of varying size, (i) the benefits of generative models as a data augmentation method; (ii) how adversarial methods can protect patient privacy via data substitution; (iii) novel performance metrics for these use cases by testing models on real holdout data. We show that training with both synthetic and real data outperforms training with real data alone, and that models trained solely with synthetic data approach their real-only counterparts. Code is available at https://github.com/Global-Health- Labs/US-DCGAN.";2023;Health related;Health related
"Li, B; Luo, SL; Qin, XN; Pan, LM";Improving GAN with inverse cumulative distribution function for tabular data synthesis;Designing a generative model to synthesize realistic tabular data is of great significance in data science. Existing tabular data generative models have difficulty in handling complicated and diverse marginal dis-tribution types due to the gradient vanishing problem, and these models pay little attention to the cor-relation between attributes. We propose a method that improves the generative adversarial network (GAN) with inverse cumulative distribution function for tabular data synthesis. This method first trans -forms continuous columns into uniform distribution data by using the cumulative distribution function, which can alleviate the gradient vanishing problem in model training. Then the method trains GAN with the transformed data, where the discriminator with label reconstruction function is presented to model the correlation among attributes accurately by introducing an auxiliary supervised task to help the cor-relations extraction. After that, we train a neural network for each continuous column to perform the inverse transformation of generated data into the target distribution, thereby the synthetic data is obtained. Experiments on simulated and real-world datasets show that our method compares favorably against the state-of-the-art methods in modeling tabular data. (c) 2021 Elsevier B.V. All rights reserved.;2021;Not health related;Not health related
"Wang, YD; Deng, WH";Generative Model With Coordinate Metric Learning for Object Recognition Based on 3D Models;One of the bottlenecks in acquiring a perfect database for deep learning is the tedious process of collecting and labeling data. In this paper, we propose a generative model trained with synthetic images rendered from 3D models which can reduce the burden on collecting real training data and make the background conditions more realistic. Our architecture is composed of two sub-networks: a semantic foreground object reconstruction network based on Bayesian inference and a classification network based on multi-triplet cost training for avoiding overfitting on the monotone synthetic object surface and utilizing accurate information of synthetic images like object poses and lighting conditions which are helpful for recognizing regular photos. First, our generative model with metric learning utilizes additional foreground object channels generated from semantic foreground object reconstruction sub-network for recognizing the original input images. Multi-triplet cost function based on poses is used for metric learning which makes it possible to train an effective categorical classifier purely based on synthetic data. Second, we design a coordinate training strategy with the help of adaptive noise applied on the inputs of both of the concatenated sub-networks to make them benefit from each other and avoid inharmonious parameter tuning due to different convergence speeds of two sub-networks. Our architecture achieves the state-of-the-art accuracy of 50.5% on the ShapeNet database with data migration obstacle from synthetic images to real images. This pipeline makes it applicable to do recognition on real images only based on 3D models. Our codes are available at https://github.com/wangyida/gm-cml.;2018;Not health related;Not health related
"Zuo, ZW; Zhao, L; Li, AL; Wang, ZZ; Chen, HB; Xing, W; Lu, DM";Dual distribution matching GAN;Generative Adversarial Network (GAN) has become the dominant generative model in recent years. Although GAN is capable of generating sharp and realistic images, it faces several problems such as training instability and mode collapse. To address these issues, aside from the usual distribution matching via GAN's adversarial training in a high-dimensional data space, we propose to perform distribution matching within a low-dimensional latent representation space as well. Such a low-dimensional latent representation space is obtained through training an Autoencoder (AE), which not only captures salient features and modes of the data distribution but can also be regularized to learn a nice latent manifold structure of the data. Based on that, we develop a novel hybrid generative model that combines AE and GAN, namely Dual Distribution Matching GAN (DM2GAN), that performs distribution matching in both data and latent space simultaneously. We theoretically show that the optimum of the proposed distribution matching constraint in the latent space is attained if and only if the generated and the real data distribution match exactly. The empirical evaluations on the 2D synthetic data, MNIST-1K, and several real-world datasets demonstrate the effectiveness of the proposed method to stabilize the training and increase mode coverage for GAN. (C) 2021 Elsevier B.V. All rights reserved.;2022;Not health related;Not health related
"Taherkhani, F; Rai, A; Gao, QK; Srivastava, S; Chen, XB; de la Torre, F; Song, S; Prakash, A; Kim, D";Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance;"3D face modeling has been an active area of research in computer vision and computer graphics, fueling applications ranging from facial expression transfer in virtual avatars to synthetic data generation. Existing 3D deep learning generative models (e.g., VAE, GANs) allow generating compact face representations (both shape and texture) that can model non-linearities in the shape and appearance space (e.g., scatter effects, specularities,..). However, they lack the capability to control the generation of subtle expressions. This paper proposes a new 3D face generative model that can decouple identity and expression and provides granular control over expressions. In particular, we propose using a pair of supervised auto-encoder and generative adversarial networks to produce high-quality 3D faces, both in terms of appearance and shape. Experimental results in the generation of 3D faces learned with holistic expression labels, or Action Unit (AU) labels, show how we can decouple identity and expression; gaining fine-control over expressions while preserving identity. (1)";2023;Not health related;Not health related
"Moreno, P; Williams, CKI; Nash, C; Kohli, P";Overcoming Occlusion with Inverse Graphics;Scene understanding tasks such as the prediction of object pose, shape, appearance and illumination are hampered by the occlusions often found in images. We propose a vision-as-inverse-graphics approach to handle these occlusions by making use of a graphics renderer in combination with a robust generative model (GM). Since searching over scene factors to obtain the best match for an image is very inefficient, we make use of a recognition model (RM) trained on synthetic data to initialize the search. This paper addresses two issues: (i) We study how the inferences are affected by the degree of occlusion of the foreground object, and show that a robust GM which includes an outlier model to account for occlusions works significantly better than a non-robust model. (ii) We characterize the performance of the RM and the gains that can be made by refining the search using the GM, using a new dataset that includes background clutter and occlusions. We find that pose and shape are predicted very well by the RM, but appearance and especially illumination less so. However, accuracy on these latter two factors can be clearly improved with the generative model.;2016;Not health related;Not health related
"Sokolovska, N; Artières, T";A Probabilistic Prior Knowledge Integration Method: Application to Generative and Discriminative Models;Prior knowledge integration aims at taking advantage of cheap plentiful data to improve the efficiency of supervised learning procedures. For parametric models, however, it is a challenging task. In this contribution, we introduce a novel simple methodology to incorporate prior knowledge into a supervised objective function. We propose to introduce the prior knowledge in the form of joint probability of observations and labels. We discuss the nature of features in discriminative and generative models and hence, differences in priors integration. We illustrate the efficiency of the proposed method both by synthetic data sets and by our results on a realistic large-scale sequence labeling task.;2016;Not health related;Not health related
"Kar, P; Tiruvadi-Krishnan, S; Männik, J; Männik, J; Amir, A";Distinguishing different modes of growth using single-cell data;eLife digest All cells - from bacteria to humans - tightly control their size as they grow and divide. Cells can also change the speed at which they grow, and the pattern of how fast a cell grows with time is called 'mode of growth'. Mode of growth can be 'linear', when cells increase their size at a constant rate, or 'exponential', when cells increase their size at a rate proportional to their current size. A cell's mode of growth influences its inner workings, so identifying how a cell grows can reveal information about how a cell will behave. Scientists can measure the size of cells as they age and identify their mode of growth using single cell imaging techniques. Unfortunately, the statistical methods available to analyze the large amounts of data generated in these experiments can lead to incorrect conclusions. Specifically, Kar et al. found that scientists had been using specific types of plots to analyze growth data that were prone to these errors, and may lead to misinterpreting exponential growth as linear and vice versa. This discrepancy can be resolved by ensuring that the plots used to determine the mode of growth are adequate for this analysis. But how can the adequacy of a plot be tested? One way to do this is to generate synthetic data from a known model, which can have a specific and known mode of growth, and using this data to test the different plots. Kar et al. developed such a 'generative model' to produce synthetic data similar to the experimental data, and used these data to determine which plots are best suited to determine growth mode. Once they had validated the best statistical methods for studying mode of growth, Kar et al. applied these methods to growth data from the bacterium Escherichia coli. This showed that these cells have a form of growth called 'super-exponential growth'. These findings identify a strategy to validate statistical methods used to analyze cell growth data. Furthermore, this strategy - the use of generative models to produce synthetic data to test the accuracy of statistical methods - could be used in other areas of biology to validate statistical approaches. Collection of high-throughput data has become prevalent in biology. Large datasets allow the use of statistical constructs such as binning and linear regression to quantify relationships between variables and hypothesize underlying biological mechanisms based on it. We discuss several such examples in relation to single-cell data and cellular growth. In particular, we show instances where what appears to be ordinary use of these statistical methods leads to incorrect conclusions such as growth being non-exponential as opposed to exponential and vice versa. We propose that the data analysis and its interpretation should be done in the context of a generative model, if possible. In this way, the statistical methods can be validated either analytically or against synthetic data generated via the use of the model, leading to a consistent method for inferring biological mechanisms from data. On applying the validated methods of data analysis to infer cellular growth on our experimental data, we find the growth of length in E. coli to be non-exponential. Our analysis shows that in the later stages of the cell cycle the growth rate is faster than exponential.;2021;Not health related;Not health related
"Makrushin, A; Kauba, C; Kirchgasser, S; Seidlitz, S; Kraetzer, C; Uhl, A; Dittmann, J";General Requirements on Synthetic Fingerprint Images for Biometric Authentication and Forensic Investigations;Generation of synthetic biometric samples such as, for instance, fingerprint images gains more and more importance especially in view of recent cross-border regulations on security of private data. The reason is that biometric data is designated in recent regulations such as the EU GDPR as a special category of private data, making sharing datasets of biometric samples hardly possible even for research purposes. The usage of fingerprint images in forensic research faces the same challenge. The replacement of real datasets by synthetic datasets is the most advantageous straightforward solution which bears, however, the risk of generating unrealistic samples or unrealistic distributions of samples which may visually appear realistic. Despite numerous efforts to generate high-quality fingerprints, there is still no common agreement on how to define high-quality and how to validate that generated samples are realistic enough. Here, we propose general requirements on synthetic biometric samples (that are also applicable for fingerprint images used in forensic application scenarios) together with formal metrics to validate whether the requirements are fulfilled. Validation of our proposed requirements enables establishing the quality of a generative model (informed evaluation) or even the quality of a dataset of generated samples (blind evaluation). Moreover, we demonstrate in an example how our proposed evaluation concept can be applied to a comparison of real and synthetic datasets aiming at revealing if the synthetic samples exhibit significantly different properties as compared to real ones.;2021;Not health related;Not health related
"Tian, RZ; Mao, YY; Zhang, R";Learning VAE-LDA Models with Rounded Reparameterization Trick;The introduction of VAE provides an efficient framework for the learning of generative models, including generative topic models. However, when the topic model is a Latent Dirichlet Allocation (LDA) model, a central technique of VAE, the reparameterization trick, fails to be applicable. This is because no reparameterization form of Dirichlet distributions is known to date that allows the use of the reparameterization trick. In this work, we propose a new method, which we call Rounded Reparameterization Trick (RRT), to reparameterize Dirichlet distributions for the learning of VAE-LDA models. This method, when applied to a VAE-LDA model, is shown experimentally to outperform the existing neural topic models on several benchmark datasets and on a synthetic dataset.;2020;Not health related;Not health related
"Campbell, E; Cameron, JAD; Scheme, E";Feasibility of Data-driven EMG Signal Generation using a Deep Generative Model;"Despite recent advancements in the field of pattern recognition-based myoelectric control, the collection of a high quality training set remains a challenge limiting its adoption. This paper proposes a framework for a possible solution by augmenting short training protocols with subject-specific synthetic electromyography (EMG) data generated using a deep generative network, known as SinGAN. The aim of this work is to produce high quality synthetic data that could improve classification accuracy when combined with a limited training protocol. SinGAN was used to generate 1000 synthetic windows of EMG data from a single window of six different motions, and results were evaluated qualitatively, quantitatively, and in a classification task. Qualitative assessment of synthetic data was conducted via visual inspection of principal component analysis projections of real and synthetic feature space. Quantitative assessment of synthetic data revealed 11 of 32 synthetic features had similar location and scale to real features (using univariate two-sample Lepage tests); whereas multivariate distributions were found to be statistically different (p < 0.05). Finally, the addition of these synthetic data to a brief training set of real data significantly improved classification accuracy in a crossvalidation testing scheme by 5.4% (p < 0.001).";2020;Not health related;Not health related
"Silva, WN; Bandória, LHT; Dias, BH; de Almeida, MC; de Oliveira, LW";Generating realistic load profiles in smart grids: An approach based on nonlinear independent component estimation (NICE) and convolutional layers;The utilization of energy consumption data is crucial for efficient operation and planning in smart grids. Nonetheless, certain obstacles need to be addressed, such as high computational costs, data security and privacy concerns, and significant expenses associated with installing smart meters across the electrical grid. To address these challenges, generating synthetic data has emerged as a promising approach, providing an opportunity to enhance energy efficiency, demand flexibility, and power grid operation. Therefore, this study proposes a nonlinear model of independent component estimation (NICE) with convolutional layers to produce realistic load profiles. This research aims to evaluate the potential of deep generative models (DGMs) through the characterization and quantification of electricity consumption profiles obtained from an actual smart grid on a university campus. The Kullback-Leibler divergence is used to evaluate the performance of the proposed model. Simulation results show that the proposed model can accurately capture the spatiotemporal correlation of actual samples, leading to synthetic load profiles that closely resemble actual profiles. The performance of the proposed NICE model is compared with a NICE model with dense layers, as well as with Generative Adversarial Networks (GAN) with dense layers, and GAN with convolutional layers (cGAN), all methods previously used in the literature to generate synthetic load profiles. It was observed that the proposed NICE model with convolutional layers leads to better results. This model produces more significant similarity between the probability distributions of actual and synthetic data, in addition to a more extraordinary ability to reproduce more realistic load variability curves.;2023;Not health related;Not health related
"de Souza, CR; Gaidon, A; Cabon, Y; Murray, N; López, AM";Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models;Deep video action recognition models have been highly successful in recent years but require large quantities of manually-annotated data, which are expensive and laborious to obtain. In this work, we investigate the generation of synthetic training data for video action recognition, as synthetic data have been successfully used to supervise models for a variety of other computer vision tasks. We propose an interpretable parametric generative model of human action videos that relies on procedural generation, physics models and other components of modern game engines. With this model we generate a diverse, realistic, and physically plausible dataset of human action videos, called PHAV for Procedural Human Action Videos. PHAV contains a total of 39,982 videos, with more than 1000 examples for each of 35 action categories. Our video generation approach is not limited to existing motion capture sequences: 14 of these 35 categories are procedurally-defined synthetic actions. In addition, each video is represented with 6 different data modalities, including RGB, optical flow and pixel-level semantic labels. These modalities are generated almost simultaneously using the Multiple Render Targets feature of modern GPUs. In order to leverage PHAV, we introduce a deep multi-task (i.e. that considers action classes from multiple datasets) representation learning architecture that is able to simultaneously learn from synthetic and real video datasets, even when their action categories differ. Our experiments on the UCF-101 and HMDB-51 benchmarks suggest that combining our large set of synthetic videos with small real-world datasets can boost recognition performance. Our approach also significantly outperforms video representations produced by fine-tuning state-of-the-art unsupervised generative models of videos.;2020;Not health related;Not health related
"Luessi, M; Babacan, SD; Molina, R; Booth, JR; Katsaggelos, AK";Bayesian symmetrical EEG/fMRI fusion with spatially adaptive priors;In this paper, we propose a novel symmetrical EEG/fMRI fusion method which combines EEG and fMRI by means of a common generative model. We use a total variation (TV) prior to model the spatial distribution of the cortical current responses and hemodynamic response functions, and utilize spatially adaptive temporal priors to model their temporal shapes. The spatial adaptivity of the prior model allows for adaptation to the local characteristics of the estimated responses and leads to high estimation performance for the cortical current distribution and the hemodynamic response functions. We utilize a Bayesian formulation with a variational Bayesian framework and obtain a fully automatic fusion algorithm. Simulations with synthetic data and experiments with real data from a multimodal study on face perception demonstrate the performance of the proposed method. (c) 2010 Elsevier Inc. All rights reserved.;2011;Health related;Not health related
"Fan, C; Chen, ML; Tang, R; Wang, JY";A novel deep generative modeling-based data augmentation strategy for improving short-term building energy predictions;Short-term building energy predictions serve as one of the fundamental tasks in building operation management. While large numbers of studies have explored the value of various supervised machine learning techniques in energy predictions, few studies have addressed the potential data shortage problem in developing data-driven models. One promising solution is data augmentation, which aims to enrich existing building data resources for reliable predictive modeling. This study proposes a deep generative modeling-based data augmentation strategy for improving short-term building energy predictions. Two types of conditional variational autoencoders have been designed for synthetic energy data generation using fully connected and one-dimensional convolutional layers respectively. Data experiments have been designed to evaluate the value of data augmentation using actual measurements from 52 buildings. The results indicate that conditional variational autoencoders are capable of generating high-quality synthetic data samples, which in turns helps to enhance the accuracy in short-term building energy predictions. The average performance enhancement ratios in terms of CV-RMSE range between 12% and 18%. Practical guidelines have been obtained to ensure the validity and quality of synthetic building energy data. The research outcomes are valuable for enhancing the robustness and reliability of data-driven models for smart building operation management.;2022;Not health related;Not health related
"Domingo-Enrich, C; Bietti, A; Vanden-Eijnden, E; Bruna, J";On Energy-Based Models with Overparametrized Shallow Neural Networks;Energy-based models (EBMs) are a simple yet powerful framework for generative modeling. They are based on a trainable energy function which defines an associated Gibbs measure, and they can be trained and sampled from via well-established statistical tools, such as MCMC. Neural networks may be used as energy function approximators, providing both a rich class of expressive models as well as a flexible device to incorporate data structure. In this work we focus on shallow neural networks. Building from the incipient theory of overparametrized neural networks, we show that models trained in the so-called 'active' regime provide a statistical advantage over their associated 'lazy' or kernel regime, leading to improved adaptivity to hidden low-dimensional structure in the data distribution, as already observed in supervised learning. Our study covers both maximum likelihood and Stein Discrepancy estimators, and we validate our theoretical results with numerical experiments on synthetic data.;2021;Not health related;Not health related
"Lezcano, C; Arias, M";Synthetic Dataset Generation with Itemset-Based Generative Models;This paper proposes three different data generators, tailored to transactional datasets, based on existing itemset-based generative models. All these generators are intuitive and easy to implement and show satisfactory performance. The quality of each generator is assessed by means of three different methods that capture how well the original dataset structure is preserved.;2019;Not health related;Not health related
"Gallucci, A; Pezzotti, N; Znamenskiy, D; Petkovic, M";A latent space exploration for microscopic skin lesion augmentations with VQ-VAE-2 and PixelSNAIL;Skin cancer affects more than 3 million people only in the U.S. Comprehensive microscopic databases include around 30 thousand samples, limiting the richness of patterns that can be presented to machine learning. To this end, generative models such as GANs have been proposed for creating realistic synthetic images but, despite their popularity, they are often difficult to train and control. Recently an autoregressive approach based on a quantized autoencoder showed state of the art performances while being simple to train and provide synthetic data generation opportunities. In the first part of this paper we evaluate the training of VQ-VAE-2 with different latent space configuration. In the second part, we show how to use a learned prior over the latent space with PixelSNAIL to generate and modify skin lesions. We show how this process can be used for powerful data augmentation and visualization for skin health, evaluating it on a downstream application that classifies malignant lesions.;2021;Health related;Health related
"Gauvin, L; Panisson, A; Cattuto, C; Barrat, A";Activity clocks: spreading dynamics on temporal networks of human contact;Dynamical processes on time-varying complex networks are key to understanding and modeling a broad variety of processes in socio-technical systems. Here we focus on empirical temporal networks of human proximity and we aim at understanding the factors that, in simulation, shape the arrival time distribution of simple spreading processes. Abandoning the notion of wall-clock time in favour of node-specific clocks based on activity exposes robust statistical patterns in the arrival times across different social contexts. Using randomization strategies and generative models constrained by data, we show that these patterns can be understood in terms of heterogeneous inter-event time distributions coupled with heterogeneous numbers of events per edge. We also show, both empirically and by using a synthetic dataset, that significant deviations from the above behavior can be caused by the presence of edge classes with strong activity correlations.;2013;Not health related;Not health related
"Nader, CA; Ayache, N; Robert, P; Lorenzi, M";Monotonic Gaussian Process for spatio-temporal disease progression modeling in brain imaging data;We introduce a probabilistic generative model for disentangling spatio-temporal disease trajectories from collections of high-dimensional brain images. The model is based on spatio-temporal matrix factorization, where inference on the sources is constrained by anatomically plausible statistical priors. To model realistic trajectories, the temporal sources are defined as monotonic and time-reparameterized Gaussian Processes. To account for the non-stationarity of brain images, we model the spatial sources as sparse codes convolved at multiple scales. The method was tested on synthetic data favourably comparing with standard blind source separation approaches. The application on large-scale imaging data from a clinical study allows to disentangle differential temporal progression patterns mapping brain regions key to neurodegeneration, while revealing a disease-specific time scale associated to the clinical diagnosis.;2020;Health related;Health related
"Tao, CY; Chen, LQ; Henao, R; Feng, JF; Carin, L";_2 Generative Adversarial Network;To assess the difference between real and synthetic data, Generative Adversarial Networks (GANs) are trained using a distribution discrepancy measure. Three widely employed measures are information-theoretic divergences, integral probability metrics, and Hilbert space discrepancy metrics. We elucidate the theoretical connections between these three popular GAN training criteria and propose a novel procedure, called chi(2)-GAN, that is conceptually simple, stable at training and resistant to mode collapse. Our procedure naturally generalizes to address the problem of simultaneous matching of multiple distributions. Further, we propose a resampling strategy that significantly improves sample quality, by repurposing the trained critic function via an importance weighting mechanism. Experiments show that the proposed procedure improves stability and convergence, and yields state-of-art results on a wide range of generative modeling tasks.;2018;Not health related;Not health related
"Ramakrishna, A; Gupta, R; Narayanan, S";Joint Multi-Dimensional Model for Global and Time-Series Annotations;Crowdsourcing is a popular approach to collect annotations for unlabeled data instances. It involves collecting a large number of annotations from several, often naive untrained annotators for each data instance which are then combined to estimate the ground truth. Further, annotations for constructs such as affect are often multi-dimensional with annotators rating multiple dimensions, such as valence and arousal, for each instance. Most annotation fusion schemes however ignore this aspect and model each dimension separately. In this article we address this by proposing a generative model for multi-dimensional annotation fusion, which models the dimensions jointly leading to more accurate ground truth estimates. The model we propose is applicable to both global and time series annotation fusion problems and treats the ground truth as a latent variable distorted by the annotators. The model parameters are estimated using the Expectation-Maximization algorithm and we evaluate its performance using synthetic data and real emotion corpora as well as on an artificial task with human annotations.;2022;Not health related;Not health related
"Iwata, T; Yamada, T; Ueda, N";Modeling Noisy Annotated Data with Application to Social Annotation;We propose a probabilistic topic model for analyzing and extracting content-related annotations from noisy annotated discrete data such as webpages stored using social bookmarking services. With these services, because users can attach annotations freely, some annotations do not describe the semantics of the content, thus they are noisy, i.e., not content related. The extraction of content-related annotations can be used as a prepossessing step in machine learning tasks such as text classification and image recognition, or can improve information retrieval performance. The proposed model is a generative model for content and annotations, in which the annotations are assumed to originate either from topics that generated the content or from a general distribution unrelated to the content. We demonstrate the effectiveness of the proposed method by using synthetic data and real social annotation data for text and images.;2013;Not health related;Not health related
"Xu, CG; Ren, J; Zhang, DY; Zhang, YX; Qin, Z; Ren, K";GANobfuscator: Mitigating Information Leakage Under GAN via Differential Privacy;By learning generative models of semantic-rich data distributions from samples, generative adversarial network (GAN) has recently attracted intensive research interests due to its excellent empirical performance as a generative model. The model is used to estimate the underlying distribution of a dataset and randomly generate realistic samples according to their estimated distribution. However, GANs can easily remember training samples due to the high model complexity of deep networks. When GANs are applied to private or sensitive data, the concentration of distribution may divulge some critical information. It consequently requires new technological advances to mitigate the information leakage under GANs. To address this issue, we propose GANobfuscator, a differentially private GAN, which can achieve differential privacy under GANs by adding carefully designed noise to gradients during the learning procedure. With GANobfuscator, analysts are able to generate an unlimited amount of synthetic data for arbitrary analysis tasks without disclosing the privacy of training data. Moreover, we theoretically prove that GANobfuscator can provide strict privacy guarantee with differential privacy. In addition, we develop a gradient-pruning strategy for GANobfuscator to improve the scalability and stability of data training. Through extensive experimental evaluation on benchmark datasets, we demonstrate that GANobfuscator can produce high-quality generated data and retain desirable utility under practical privacy budgets.;2019;Not health related;Not health related
"Shin, HC; Tenenholtz, NA; Rogers, JK; Schwarz, CG; Senjem, ML; Gunter, JL; Andriole, KP; Michalski, M";Medical Image Synthesis for Data Augmentation and Anonymization Using Generative Adversarial Networks;Data diversity is critical to success when training deep learning models. Medical imaging data sets are often imbalanced as pathologic findings are generally rare, which introduces significant challenges when training deep learning models. In this work, we propose a method to generate synthetic abnormal MRI images with brain tumors by training a generative adversarial network using two publicly available data sets of brain MRI. We demonstrate two unique benefits that the synthetic images provide. First, we illustrate improved performance on tumor segmentation by leveraging the synthetic images as a form of data augmentation. Second, we demonstrate the value of generative models as an anonymization tool, achieving comparable tumor segmentation results when trained on the synthetic data versus when trained on real subject data. Together, these results offer a potential solution to two of the largest challenges facing machine learning in medical imaging, namely the small incidence of pathological findings, and the restrictions around sharing of patient data.;2018;Health related;Health related
"Andersen, KW; Morup, M; Siebner, H; Madsen, KH; Hansen, LK";IDENTIFYING MODULAR RELATIONS IN COMPLEX BRAIN NETWORKS;We evaluate the infinite relational model (IRM) against two simpler alternative nonparametric Bayesian models for identifying structures in multi subject brain networks. The models are evaluated for their ability to predict new data and infer reproducible structures. Prediction and reproducibility are measured within the data driven NPAIRS split-half framework. Using synthetic data drawn from each of the generative models we show that the IRM model outperforms the two competing models when data contain relational structure. For data drawn from the other two simpler models the IRM does not overfit and obtains comparable reproducibility and predictability. For resting state functional magnetic resonance imaging data from 30 healthy controls the IRM model is also superior to the two simpler alternatives, suggesting that brain networks indeed exhibit universal complex relational structure in the population.;2012;Health related;Health related
"Nadjahi, K; De Bortoli, V; Durmus, A; Badeau, R; Simsekli, U";APPROXIMATE BAYESIAN COMPUTATION WITH THE SLICED-WASSERSTEIN DISTANCE;Approximate Bayesian Computation (ABC) is a popular method for approximate inference in generative models with intractable but easy-to-sample likelihood. It constructs an approximate posterior distribution by finding parameters for which the simulated data are close to the observations in terms of summary statistics. These statistics are defined beforehand and might induce a loss of information, which has been shown to deteriorate the quality of the approximation. To overcome this problem, Wasserstein-ABC has been recently proposed, and compares the datasets via the Wasserstein distance between their empirical distributions, but does not scale well to the dimension or the number of samples. We propose a new ABC technique, called Sliced-Wasserstein ABC and based on the Sliced-Wasserstein distance, which has better computational and statistical properties. We derive two theoretical results showing the asymptotical consistency of our approach, and we illustrate its advantages on synthetic data and an image denoising task.;2020;Not health related;Not health related
"Wang, GF; Jiao, YL; Xu, Q; Wang, Y; Yang, C";Deep Generative Learning via Schrodinger Bridge;We propose to learn a generative model via entropy interpolation with a Schrodinger Bridge. The generative learning task can be formulated as interpolating between a reference distribution and a target distribution based on the Kullback-Leibler divergence. At the population level, this entropy interpolation is characterized via an SDE on [0, 1] with a time-varying drift term. At the sample level, we derive our Schrodinger Bridge algorithm by plugging the drift term estimated by a deep score estimator and a deep density ratio estimator into the Euler-Maruyama method. Under some mild smoothness assumptions of the target distribution, we prove the consistency of both the score estimator and the density ratio estimator, and then establish the consistency of the proposed Schrodinger Bridge approach. Our theoretical results guarantee that the distribution learned by our approach converges to the target distribution. Experimental results on multimodal synthetic data and benchmark data support our theoretical findings and indicate that the generative model via Schrodinger Bridge is comparable with state-of-the-art GANs, suggesting a new formulation of generative learning. We demonstrate its usefulness in image interpolation and image inpainting.;2021;Not health related;Not health related
"Zhu, DL; Fu, L; Kazei, V; Li, WC";Diffusion Model for DAS-VSP Data Denoising;Distributed acoustic sensing (DAS) has emerged as a transformational technology for seismic data acquisition. However, noise remains a major impediment, necessitating advanced denoising techniques. This study pioneers the application of diffusion models, a type of generative model, for DAS vertical seismic profile (VSP) data denoising. The diffusion network is trained on a new generated synthetic dataset that accommodates variations in the acquisition parameters. The trained model is applied to suppress noise in synthetic and field DAS-VSP data. The results demonstrate the model's effectiveness in removing various noise types with minimal signal leakage, outperforming conventional methods. This research signifies diffusion models' potential for DAS processing.;2023;Not health related;Not health related
"Lopez-Martin, M; Carro, B; Sanchez-Esguevillas, A";Variational data generative model for intrusion detection;A Network Intrusion Detection System is a system which detects intrusive, malicious activities or policy violations in a host or hosts network. The ability to access balanced and diversified data to train the system is very important for any detection system. Intrusion data rarely have these characteristics, since samples of network traffic are strongly biased to normal traffic, being difficult to access traffic associated with intrusion events. Therefore, it is important to have a method to synthesize intrusion data with a probabilistic and behavioral structure similar to the original one. In this work, we provide such a method. Intrusion data have continuous and categorical features, with a strongly unbalanced distribution of intrusion labels. That is the reason why we generate synthetic samples conditioned to the distribution of labels. That is, from a particular set of labels, we generate training samples associated with that set of labels, replicating the probabilistic structure of the original data that comes from those labels. We use a generative model based on a customized variational autoencoder, using the labels of the intrusion class as an additional input to the network. This modification provides an advantage, as we can readily generate new data using only the labels, without having to rely on training samples as canonical representatives for each label, which makes the generation process more reliable, less complex and faster. We show that the synthetic data are similar to the real data, and that the new synthesized data can be used to improve the performance scores of common machine learning classifiers.;2019;Not health related;Not health related
"Zhong, PL; Mo, YC; Xiao, C; Chen, PY; Zheng, CX";Rethinking Generative Mode Coverage: A Pointwise Guaranteed Approach;Many generative models have to combat missing modes. The conventional wisdom to this end is by reducing through training a statistical distance (such as f-divergence) between the generated distribution and provided data distribution. But this is more of a heuristic than a guarantee. The statistical distance measures a global, but not local, similarity between two distributions. Even if it is small, it does not imply a plausible mode coverage. Rethinking this problem from a game-theoretic perspective, we show that a complete mode coverage is firmly attainable. If a generative model can approximate a data distribution moderately well under a global statistical distance measure, then we will be able to find a mixture of generators that collectively covers every data point and thus every mode, with a lower-bounded generation probability. Constructing the generator mixture has a connection to the multiplicative weights update rule, upon which we propose our algorithm. We prove that our algorithm guarantees complete mode coverage. And our experiments on real and synthetic datasets confirm better mode coverage over recent approaches, ones that also use generator mixtures but rely on global statistical distances.;2019;Not health related;Not health related
"Vo, TV; Soh, H";Generation Meets Recommendation: Proposing Novel Items for Groups of Users;Consider a movie studio aiming to produce a set of new movies for summer release: What types of movies it should produce? Who would the movies appeal to? How many movies should it make? Similar issues are encountered by a variety of organizations, e.g., mobile-phone manufacturers and online magazines, who have to create new (non-existent) items to satisfy groups of users with different preferences. In this paper, we present a joint problem formalization of these interrelated issues, and propose generative methods that address these questions simultaneously. Specifically, we leverage on the latent space obtained by training a deep generative model-the Variational Autoencoder (VAE)-via a loss function that incorporates both rating performance and item reconstruction terms. We use a greedy search algorithm that utilize this learned latent space to jointly obtain K plausible new items, and user groups that would find the items appealing. An evaluation of our methods on a synthetic dataset indicates that our approach is able to generate novel items similar to highly-desirable unobserved items. As case studies on real-world data, we applied our method on the MART abstract art and Movielens Tag Genome datasets, which resulted in promising results: small and diverse sets of novel items.;2018;Not health related;Not health related
"He, B; Armaghani, DJ; Lai, SH; Samui, P; Mohamad, ET";Applying data augmentation technique on blast-induced overbreak prediction: Resolving the problem of data shortage and data imbalance;"Blast-induced overbreak in tunnels can cause severe damage and has therefore been a main concern in tunnel blasting. Researchers have developed many machine learning-based models to predict overbreak. Collecting overbreak data manually, however, can be challenging and might obtain insufficient or poorly structured data. Thus, this study aims to utilise a deep generative model, namely the Conditional Tabular Generative Adversarial Network (CTGAN), to establish an acceptable dataset for overbreak prediction. The CTGAN model was applied to overbreak data collected from paired tunnels: a left-line tunnel and a right-line tunnel. The overbreak dataset collected from the left-line tunnel-nominated as the true dataset-served to train the CTGAN model. Then the well-trained CTGAN model generated a synthetic overbreak dataset. Statistical-based approaches verified the similarity between the true and synthetic datasets; machine learning-based approaches verified the feasibility of using the synthetic dataset to train overbreak prediction model. Lastly, this study clarified how to resolve the problem of data shortage and data imbalance by leveraging the CTGAN model. The results evidence that the CTGAN model can effectively generate a high-quality synthetic overbreak dataset. The synthetic overbreak dataset not only greatly retains the properties of the true dataset but also effectively enhances its diversity. The way, integrating the true and synthetic overbreak datasets, can dramatically resolve the problem of data shortage and data imbalance in overbreak prediction. The findings in this study, therefore, highlight it as a promising perspective to resolve such a particular engineering problem.";2024;Not health related;Not health related
"Budhwani, A; Lin, TN; Feng, D; Bachmann, C";Assessing and Comparing Data Imputation Techniques for Item Nonresponse in Household Travel Surveys;This research provides a comparative assessment of data imputation techniques for item nonresponse in household travel surveys. Using the Transportation Tomorrow Survey (TTS) data for the Region of Waterloo in Ontario, Canada, a series of synthetic datasets are generated with varying amounts of missing data, while preserving the respective proportions of missing items and missing item combinations in the original survey data. Then, the performances of six different imputation techniques are compared. The six different imputation techniques include two simple imputation techniques (mode and hot-deck), three discriminative models (logistic regression, multi-layered perceptron, support vector machines) and one generative model (autoencoder). This assessment compares these techniques, as well as the impact of the proportion of item nonresponse in the dataset through their repeated application to multiple synthetic datasets. Results show that the machine/deep learning techniques (both generative and discriminative) not previously applied to household travel survey data outperform their simple imputation counterparts. Overall, the accuracy of travel household survey data imputation is shown to depend on many factors, including the technique employed, the dimensionality of the missing item, and the hypertuning of the technique (if applicable), but not on the amount of missing data in these experiments. This research should prove beneficial to practitioners who often confront item nonresponse in their household travel survey data by providing evidence and recommendations to support the selection and implementation of a data imputation technique. The research methodology also provides a repeatable procedure for future researchers to test data imputation techniques on their own datasets.;2022;Not health related;Not health related
"Song, WJ; Dong, WY; Kang, LL";Group anomaly detection based on Bayesian framework with genetic algorithm;Anomaly detection is an important application field of evolutionary algorithm. Unlike traditionly anomaly detection, group anomaly detection aims to discover the anomalous aggregate behaviors in data points. Over past decades, a large number of promising methods have been successfully applied for group anomaly detection. However, they inherently neglect the correlations among groups in data points, limiting their abilities. This paper presents a correlated hierarchical generative model, which can model the intricate correlations hidden in groups by introducing a logistic normal distribution to capture the correlations among groups. With the proposed model, we construct a full variational Bayesian framework, which can data-adaptively optimize the model parameters of the proposed model. The model is designed and trained using Genetic Algorithm (GA), which helps automating the use of generative model. Further, a new score function is proposed as an anomaly criterion to estimate final anomaly groups in data points. Several experiments on synthetic data and real astronomical star data from Sloan Digital Sky Survey demonstrate the effectiveness of proposed method compared with the-state-of-art methods, in terms of average accurac (AP) and area under the Receiver Operating Characteristic(ROC) curve(AUC). (C) 2020 Published by Elsevier Inc.;2020;Not health related;Not health related
"Joshi, B; Li, XW; Plan, Y; Yilmaz, Ö";PLUGIn: A simple algorithm for inverting generative models with recovery guarantees;We consider the problem of recovering an unknown latent code vector under a known generative model. For a d-layer deep generative network G : R-n0 -> R-nd with ReLU activation functions, let the observation be G(x) + epsilon where epsilon is noise. We introduce a simple novel algorithm, Partially Linearized Update for Generative Inversion (PLUGIn), to estimate x (and thus G(x)). We prove that, when weights are Gaussian and layer widths ni greater than or similar to 5(i)n(0) (up to log factors), the algorithm converges geometrically to a neighbourhood of x with high probability. Note the inequality on layer widths allows n(i) > n(i)+1 when i >= 1. To our knowledge, this is the first such result for networks with some contractive layers. After a sufficient number of iterations, the estimation errors for both x and G(x) are at most in the order of root 4(d)n(0)/nd vertical bar vertical bar epsilon vertical bar vertical bar. Thus, the algorithm can denoise when the expansion ratio n(d)/n(0) is large. Numerical experiments on synthetic data and real data are provided to validate our theoretical results and to illustrate that the algorithm can effectively remove artifacts in an image.;2021;Not health related;Not health related
"Gurevich, A; Bamani, E; Sintov, A";Learning a data-efficient model for a single agent in homogeneous multi-agent systems;Training Reinforcement Learning (RL) policies for a robot requires an extensive amount of data recorded while interacting with the environment. Acquiring such a policy on a real robot is a tedious and time-consuming task. This is more challenging in a multi-agent system where individual data may be required from each agent. While training in simulations is the common approach due to efficiency and low-cost, they rarely describe the real world. Consequently, policies trained in simulations and transferred to the real robot usually perform poorly. In this paper, we present a novel real-to-sim-to-real framework to bridge the reality gap for an agent in collective motion of a homogeneous multi-agent system. First, we propose a novel deep neural-network architecture termed Convolutional-Recurrent Network (CR-Net) to capture the complex state transition of an agent and simulate its motion. Once trained with data from one agent, we show that the CR-Net can accurately predict motion of all agents in the group. Second, we propose to invest a limited amount of real data from the agent in a generative model. Then, training the CR-Net with synthetic data sampled from the generative model is shown to be at least equivalent to real data. Hence, the proposed approach provides a sufficiently accurate model with significantly less real data. The generative model can also be disseminated along with open-source hardware for easier usage. We show experiments on ground and underwater vehicles in which multi-agent RL policies are trained in the simulation for collective motion and successfully transferred to the real-world.;2023;Not health related;Not health related
"Taghia, J; Ryali, S; Chen, TW; Supekar, K; Cai, WD; Menon, V";Bayesian switching factor analysis for estimating time-varying functional connectivity in fMRI;There is growing interest in understanding the dynamical properties of functional interactions between distributed brain regions. However, robust estimation of temporal dynamics from functional magnetic resonance imaging (fMRI) data remains challenging due to limitations in extant multivariate methods for modeling time-varying functional interactions between multiple brain areas. Here, we develop a Bayesian generative model for fMRI time-series within the framework of hidden Markov models (HMMs). The model is a dynamic variant of the static factor analysis model (Ghahramani and Beal, 2000). We refer to this model as Bayesian switching factor analysis (BSFA) as it integrates factor analysis into a generative HMM in a unified Bayesian framework. In BSFA, brain dynamic functional networks are represented by latent states which are learnt from the data. Crucially, BSFA is a generative model which estimates the temporal evolution of brain states and transition probabilities between states as a function of time. An attractive feature of BSFA is the automatic determination of the number of latent states via Bayesian model selection arising from penalization of excessively complex models. Key features of BSFA are validated using extensive simulations on carefully designed synthetic data. We further validate BSFA using fingerprint analysis of multisession resting-state fMRI data from the Human Connectome Project (HCP). Our results show that modeling temporal dependencies in the generative model of BSFA results in improved fingerprinting of individual participants. Finally, we apply BSFA to elucidate the dynamic functional organization of the salience, central-executive, and default mode networks-three core neurocognitive systems with central role in cognitive and affective information processing (Menon, 2011). Across two HCP sessions, we demonstrate a high level of dynamic interactions between these networks and determine that the salience network has the highest temporal flexibility among the three networks. Our proposed methods provide a novel and powerful generative model for investigating dynamic brain connectivity.;2017;Health related;Health related
Bykov, NY;RECONSTRUCTING THE THERMAL PROCESS MODEL USING THE TIME-SPACE DISTRIBUTIONS OF TEMPERATURE;The method of generative model design (GMD) has been applied to reconstruct the structure and coefficients of a partial differential equation describing the target's heating and its evaporation by laser radiation. The initial synthetic data includes heating scenarios corresponding to surface energy absorption or to volume one. It was shown that reconstructing the model correctly required the use of a preprocessing technique providing the exclusion of a part of the initial data if the volume absorption took place. A modification of the method that made it possible to take into account the temperature dependence of the coefficients of the reconstructed equation was put forward. The influence of various statistical criteria used in selecting the optimal subset of elements on the accuracy of reconstructing the equation structure was discussed. The efficiency of the GMD was demonstrated for a wide range of target heating parameters and different options for setting the energy input. The possibility of model generating by noisy data was shown.;2022;Not health related;Not health related
"Harada, S; Hayashi, H; Uchida, S";Biosignal Data Augmentation Based on Generative Adversarial Networks;In this paper, we propose a synthetic generation method for time-series data based on generative adversarial networks (GANs) and apply it to data augmentation for biosignal classification. GANs are a recently proposed framework for learning a generative model, where two neural networks, one generating synthetic data and the other discriminating synthetic and real data, are trained while competing with each other. In the proposed method, each neural network in GANs is developed based on a recurrent neural network using long short-term memories, thereby allowing the adaptation of the GANs framework to time-series data generation. In the experiments, we confirmed the capability of the proposed method for generating synthetic biosignals using the electrocardiogram and electroencephalogram datasets. We also showed the effectiveness of the proposed method for data augmentation in the biosignal classification problem.;2018;Health related;Health related
"Deja, K; Trzcinski, T; Graczykowski, L";Generative models for fast cluster simulations in the TPC for the ALICE experiment;Simulating the detector response is a key component of every high-energy physics experiment. The methods used currently for this purpose provide high-fidelity results. However, this precision comes at a price of a high computational cost. In this work, we introduce our research aiming at fast generation of the possible responses of detector clusters to particle collisions. We present the results for the real-life example of the Time Projection Chamber in the ALICE experiment at CERN. The essential component of our solution is a generative model that allows to simulate synthetic data points that bear high similarity to the real data. Leveraging recent advancements in machine learning, we propose to use conditional Generative Adversarial Networks. In this work we present a method to simulate data samples possible to record in the detector based on the initial information about particles. We propose and evaluate several models based on convolutional or recursive networks. The main advantage offered by the proposed method is a significant speed-up in the execution time, reaching up to the factor of 10(2) with respect to the currently used simulation tool. Nevertheless, this speed-up comes at a price of a lower simulation quality. In this work we adapt available methods and show their quantitative and qualitative limitations.;2019;Not health related;Not health related
"Gabrié, M; Manoel, A; Luneau, C; Barbier, J; Macris, N; Krzakala, F; Zdeborová, L";Entropy and mutual information in models of deep neural networks;We examine a class of stochastic deep learning models with a tractable method to compute information-theoretic quantities. Our contributions are three-fold: (i) we show how entropies and mutual informations can be derived from heuristic statistical physics methods, under the assumption that weight matrices are independent and orthogonally-invariant. (ii) We extend particular cases in which this result is known to be rigorously exact by providing a proof for two-layers networks with Gaussian random weights, using the recently introduced adaptive interpolation method. (iii) We propose an experiment framework with generative models of synthetic datasets, on which we train deep neural networks with a weight constraint designed so that the assumption in (i) is verified during learning. We study the behavior of entropies and mutual informations throughout learning and conclude that, in the proposed setting, the relationship between compression and generalization remains elusive.;2019;Not health related;Not health related
"Gutiérrez-Becker, B; Sarasua, I; Wachinger, C";Discriminative and generative models for anatomical shape analysis on point clouds with deep neural networks;We introduce deep neural networks for the analysis of anatomical shapes that learn a low-dimensional shape representation from the given task, instead of relying on hand-engineered representations. Our framework is modular and consists of several computing blocks that perform fundamental shape processing tasks. The networks operate on unordered point clouds and provide invariance to similarity transformations, avoiding the need to identify point correspondences between shapes. Based on the framework, we assemble a discriminative model for disease classification and age regression, as well as a generative model for the accruate reconstruction of shapes. In particular, we propose a conditional generative model, where the condition vector provides a mechanism to control the generative process. For instance, it enables to assess shape variations specific to a particular diagnosis, when passing it as side information. Next to working on single shapes, we introduce an extension for the joint analysis of multiple anatomical structures, where the simultaneous modeling of multiple structures can lead to a more compact encoding and a better understanding of disorders. We demonstrate the advantages of our framework in comprehensive experiments on real and synthetic data. The key insights are that (i) learning a shape representation specific to the given task yields higher performance than alternative shape descriptors, (ii) multi-structure analysis is both more efficient and more accurate than single-structure analysis, and (iii) point clouds generated by our model capture morphological differences associated to Alzheimer's disease, to the point that they can be used to train a discriminative model for disease classification. Our framework naturally scales to the analysis of large datasets, giving it the potential to learn characteristic variations in large populations. (C) 2020 Elsevier B.V. All rights reserved.;2021;Health related;Health related
"Santos, T; Schrunner, S; Geiger, BC; Pfeiler, O; Zernig, A; Kaestner, A; Kern, R";Feature Extraction From Analog Wafermaps: A Comparison of Classical Image Processing and a Deep Generative Model;Semiconductor manufacturing is a highly innovative branch of industry, where a high degree of automation has already been achieved. For example, devices tested to be outside of their specifications in electrical wafer test are automatically scrapped. In this paper, we go one step further and analyze test data of devices still within the limits of the specification, by exploiting the information contained in the analog wafermaps. To that end, we propose two feature extraction approaches with the aim to detect patterns in the wafer test dataset. Such patterns might indicate the onset of critical deviations in the production process. The studied approaches are: 1) classical image processing and restoration techniques in combination with sophisticated feature engineering and 2) a data-driven deep generative model. The two approaches are evaluated on both a synthetic and a real-world dataset. The synthetic dataset has been modeled based on real-world patterns and characteristics. We found both approaches to provide similar overall evaluation metrics. Our in-depth analysis helps to choose one approach over the other depending on data availability as a major aspect, as well as on available computing power and required interpretability of the results.;2019;Not health related;Not health related
"Klemmer, K; Xu, TL; Acciaio, B; Neill, DB";SPATE-GAN: Improved Generative Modeling of Dynamic Spatio-Temporal Patterns with an Autoregressive Embedding Loss;From ecology to atmospheric sciences, many academic disciplines deal with data characterized by intricate spatiotemporal complexities, the modeling of which often requires specialized approaches. Generative models of these data are of particular interest, as they enable a range of impactful downstream applications like simulation or creating synthetic training data. Recently, COT-GAN, a new GAN algorithm inspired by the theory of causal optimal transport (COT), was proposed in an attempt to improve generation of sequential data. However, the task of learning complex patterns over time and space requires additional knowledge of the specific data structures. In this study, we propose a novel loss objective combined with COT-GAN based on an autoregressive embedding to reinforce the learning of spatio-temporal dynamics. We devise SPATE (spatio-temporal association), a new metric measuring spatio-temporal autocorrelation. We compute SPATE for real and synthetic data samples and use it to compute an embedding loss that considers space-time interactions, nudging the GAN to learn outputs that are faithful to the observed dynamics. We test our new SPATE-GAN on a diverse set of spatio-temporal patterns: turbulent flows, log-Gaussian Cox processes and global weather data. We show that our novel embedding loss improves performance without any changes to the architecture of the GAN backbone, highlighting our model's increased capacity for capturing autoregressive structures.;2022;Not health related;Not health related
"Simpson, IJA; Örzsik, B; Harrison, N; Asllani, I; Cercignani, M";Motion Correction in Low SNR MRI Using an Approximate Rician Log-Likelihood;Certain MRI acquisitions, such as Sodium imaging, produce data with very low signal-to-noise ratio (SNR). One approach to improve SNR is to acquire several images, each of which takes may take more than a minute, and then average these measurements. A consequence of such a lengthy acquisition procedure is subject motion between each image. This work investigates a solution for retrospective motion correction in this scenario, where the high level of Rician noise renders standard registration tools less effective. We employ a simple generative model for the data based on tissue segmentation maps, and provide a differentiable approximation of the Rician log-likelihood to fit the model to the observations. We find that this approach substantially outperforms a Gaussian log-likelihood baseline on synthetic data that has been corrupted by Rician noise of varying degrees. We also provide results of our approach on real Sodium MRI data, and demonstrate that we can reduce the effects of substantial motion compared to a general purpose registration tool.;2022;Not health related;Not health related
"Li, J; Cairns, BJ; Li, JS; Zhu, TT";Generating synthetic mixed-type longitudinal electronic health records for artificial intelligent applications;The recent availability of electronic health records (EHRs) have provided enormous opportunities to develop artificial intelligence (AI) algorithms. However, patient privacy has become a major concern that limits data sharing across hospital settings and subsequently hinders the advances in AI. Synthetic data, which benefits from the development and proliferation of generative models, has served as a promising substitute for real patient EHR data. However, the current generative models are limited as they only generate singletype of clinical data for a synthetic patient, i.e., either continuous-valued or discrete-valued. To mimic the nature of clinical decision-making which encompasses various data types/sources, in this study, we propose a generative adversarial network (GAN) entitled EHR-M-GAN that simultaneously synthesizes mixed-type timeseries EHR data. EHR-M-GAN is capable of capturing the multidimensional, heterogeneous, and correlated temporal dynamics in patient trajectories. We have validated EHR-M-GAN on three publicly-available intensive care unit databases with records from a total of 141,488 unique patients, and performed privacy risk evaluation of the proposed model. EHR-M-GAN has demonstrated its superiority over state-of-the-art benchmarks for synthesizing clinical timeseries with high fidelity, while addressing the limitations regarding data types and dimensionality in the current generative models. Notably, prediction models for outcomes of intensive care performed significantly better when training data was augmented with the addition of EHR-M-GAN-generated timeseries. EHR-M-GAN may have use in developing AI algorithms in resource-limited settings, lowering the barrier for data acquisition while preserving patient privacy.;2023;Health related;Health related
"Svensson, CM; Bondoc, KG; Pohnert, G; Figge, MT";Segmentation of clusters by template rotation expectation maximization;To solve the task of segmenting clusters of nearly identical objects we here present the template rotation expectation maximization (TREM) approach which is based on a generative model. We explore both a general purpose optimization approach for maximizing the log-likelihood and a modification of the standard expectation maximization (EM) algorithm. The general purpose approach is strict template matching, while TREM allows for a more deformable model. As benchmarking we compare TREM with standard EM for a two dimensional Gaussian mixture model (GMM) as well as direct maximization of the log-likelihood using general purpose optimization. We find that the EM based algorithms, TREM and standard GMM, are faster than the general purpose optimizer algorithms without any loss of segmentation accuracy. When applying TREM and GMM to a synthetic data set consisting of pairs of almost parallel objects we find that the TREM is better at segmenting those than an unconstrained GMM. Finally we demonstrate that this advantage for TREM over GMM gives significant improvement in segmentation of microscopy images of the motile unicellular alga Seminavis robusta. (C) 2016 Elsevier Inc. All rights reserved.;2017;Not health related;Not health related
"Das Bhattacharjee, S; Tolone, WJ; Mahabal, A; Elshambakey, M; Cho, I; Nayeem, AAR; Yuan, JS; Djorgovski, G";Multi-View, Generative, Transfer Learning for Distributed Time Series Classification;In this paper, we propose an effective, multi-view, generative, transfer learning framework for multivariate time series data. While generative models are demonstrated effective for several machine learning tasks, their application to time-series classification problems is underexplored. The need for additional exploration is motivated when data are large, annotations are unbalanced or scarce, or data are distributed and fragmented. Recent advances in computer vision attempt to use synthesized samples with system generated annotations to overcome the lack or imbalance of annotated data. However, in multi-view problem settings, view mismatches between the synthetic data and real data pose additional challenges against harnessing new annotated data collections. The proposed method offers important contributions to facilitate knowledge sharing, while simultaneously ensuring an effective solution for domain-specific, fine level categorizations. We propose a principled way to perform view adaptation in a cross-view learning environment, wherein pairwise view similarity is identified by a smaller subset of source samples that closely resemble the target data patterns. This approach integrates generative models within a deep classification framework to minimize the gap between source and target data. More precisely, we design category specific conditional, generative models to update the source generator in order for transforming source features so that they appear as target features and simultaneously tune the associated discriminative model to distinguish these features. During each learning iteration, the source generator is conditioned by a source training set represented as some target-like features. This transformation in appearance was performed via a target generator specifically learned for target-specific customization per category. Afterward, a smaller source training set, indicating close target pattern resemblance in terms of the corresponding generative and discriminative loss, is used to fine-tune the source classification model parameters. Experiments show that compared to existing approaches, our proposed multi-view, generative, transfer learning framework improves time series classification performance by around 4% in the UCI multi view activity recognition dataset, while also showing a robust, generalized representation capacity in classifying several large-scale multi-view light curve collections.;2019;Not health related;Not health related
"Lin, W; Gao, JY; Wang, Q; Li, XL";Learning to detect anomaly events in crowd scenes from synthetic data;Recently, due to its widespread applications in public safety, anomaly detection in crowd scenes has become a hot topic. Some deep-learning-based methods attain significant achievements in this field. Nevertheless, most of them suffer from over-fitting to some extent because of scarce data, which are usually abrupt and low-frequency in the real world. To remedy the above problem, this paper firstly develops a synthetic anomaly event generating system, which could simulate typical specific abnormal events. By utilizing this system, a large synthetic, diverse anomaly event dataset is built, which contains 2,149 video sequences. After getting the dataset, a 3D CNN is designed to detect the abnormal types at the video level. However, we find that there are obvious domain differences (also named as ?domain gap/shifts?) between synthetic videos and real-world data, which results in performance degradation when applying the model to the real world. Thus, this paper further proposes a cyclic 3D GAN for domain adaption to reduce the domain gap, which translates the synthetic data to the photorealistic video sequences. Then the detection model is trained on the translated data and it can perform well in the real data. Experimental results illustrate that the proposed method outperforms these baselines for the domain adaptation anomaly detection. Recently, due to its widespread applications in public safety, anomaly detection in crowd scenes has become a hot topic. Some deep-learning-based methods attain significant achievements in this field. Nevertheless, most of them suffer from over-fitting to some extent because of scarce data, which are usually abrupt and low-frequency in the real world. To remedy the above problem, this paper firstly develops a synthetic anomaly event generating system, which could simulate typical specific abnormal events. By utilizing this system, a large synthetic, diverse anomaly event dataset is built, which contains 2,149 video sequences. After getting the dataset, a 3D CNN is designed to detect the abnormal types at the video level. However, we find that there are obvious domain differences (also named as ?domain gap/shifts?) between synthetic videos and real-world data, which results in performance degradation when applying the model to the real world. Thus, this paper further proposes a cyclic 3D GAN for domain adaption to reduce the domain gap, which translates the synthetic data to the photorealistic video sequences. Then the detection model is trained on the translated data and it can perform well in the real data. Experimental results illustrate that the proposed method outperforms these baselines for the domain adaptation anomaly detection. ? 2021 Elsevier B.V. All rights reserved.;2021;Not health related;Not health related
"Arroyo, DM; Postels, J; Tombari, F";Variational Transformer Networks for Layout Generation;Generative models able to synthesize layouts of different kinds (e.g. documents, user interfaces or furniture arrangements) are a useful tool to aid design processes and as a first step in the generation of synthetic data, among other tasks. We exploit the properties of self-attention layers to capture high level relationships between elements in a layout, and use these as the building blocks of the well-known Variational Autoencoder (VAE) formulation. Our proposed Variational Transformer Network (VTN) is capable of learning margins, alignments and other global design rules without explicit supervision. Layouts sampled from our model have a high degree of resemblance to the training data, while demonstrating appealing diversity. In an extensive evaluation on publicly available benchmarks for different layout types VTNs achieve state-of-the-art diversity and perceptual quality. Additionally, we show the capabilities of this method as part of a document layout detection pipeline.;2021;Not health related;Not health related
"Streich, AP; Buhmann, JM";Classification of Multi-labeled Data: A Generative Approach;Multi-label classification assigns a data item to one or several classes. This problem of multiple labels arises in fields like acoustic and visual scene analysis, news reports and medical diagnosis. In a generative framework, data with multiple labels can be interpreted as additive mixtures of emissions of the individual sources. We propose a deconvolution approach to estimate the individual contributions of each source to a given data item. Similarly, the distributions of multi-label data are computed based on the source distributions. In experiments with synthetic data, the novel approach is compared to existing models and yields more accurate parameter estimates, higher classification accuracy and ameliorated generalization to previously unseen label sets. These improvements are most pronounced on small training data sets. Also on real world acoustic data, the algorithm outperforms other generative models, in particular on small training data sets.;2008;Health related;Health related
"Li, Q; Bian, W; Xu, RYD; You, J; Tao, DC";Random Mixed Field Model for Mixed-Attribute Data Restoration;"Noisy and incomplete data restoration is a critical preprocessing step in developing effective learning algorithms, which targets to reduce the effect of noise and missing values in data. By utilizing attribute correlations and/or instance similarities, various techniques have been developed for data denoising and imputation tasks. However, current existing data restoration methods are either specifically designed for a particular task, or incapable of dealing with mixed-attribute data. In this paper, we develop a new probabilistic model to provide a general and principled method for restoring mixed-attribute data. The main contributions of this study are twofold: a) a unified generative model, utilizing a generic random mixed field (RMF) prior, is designed to exploit mixed-attribute correlations; and b) a structured mean-field variational approach is proposed to solve the challenging inference problem of simultaneous denoising and imputation. We evaluate our method by classification experiments on both synthetic data and real benchmark datasets. Experiments demonstrate, our approach can effectively improve the classification accuracy of noisy and incomplete data by comparing with other data restoration methods.";2016;Not health related;Not health related
"Feldman, S; Bates, S; Romano, Y";Calibrated Multiple-Output Quantile Regression with Representation Learning;We develop a method to generate predictive regions that cover a multivariate response variable with a user-specified probability. Our work is composed of two components. First, we use a deep generative model to learn a representation of the response that has a unimodal distribution. Existing multiple-output quantile regression approaches are effective in such cases, so we apply them on the learned representation, and then transform the solution to the original space of the response. This process results in a flexible and informative region that can have an arbitrary shape, a property that existing methods lack. Second, we propose an extension of conformal prediction to the multivariate response setting that modifies any method to return sets with a pre-specified coverage level. The desired coverage is theoretically guaranteed in the finite-sample case for any distribution. Experiments conducted on both real and synthetic data show that our method constructs regions that are significantly smaller compared to existing techniques.;2023;Not health related;Not health related
"Peng, XC; Saenko, K";Synthetic to Real Adaptation with Generative Correlation Alignment Networks;Synthetic images rendered from 3D CAD models are useful for augmenting training data for object recognition algorithms. However, the generated images are non-photorealistic and do not match real image statistics. This leads to a large domain discrepancy, causing models trained on synthetic data to perform poorly on real domains. Recent work has shown the great potential of deep convolutional neural networks to generate realistic images, but has not utilized generative models to address synthetic-to-real domain adaptation. In this work, we propose a Deep Generative Correlation Alignment Network (DGCAN) to synthesize images using a novel domain adaption algorithm. DGCAN leverages a shape preserving loss and a low level statistic matching loss to minimize the domain discrepancy between synthetic and real images in deep feature space. Experimentally, we show training off-the-shelf classifiers on the newly generated data can significantly boost performance when testing on the real image domains (PASCAL VOC 2007 benchmark and Office dataset), improving upon several existing methods.;2018;Not health related;Not health related
"Wang, L; Zhang, W; He, XF";Continuous Patient-Centric Sequence Generation via Sequentially Coupled Adversarial Learning;Analyzing massive patient-centric Electronic Health Records (EHRs) becomes a key to success for improving health care and treatment. However, the amount of these data is limited and the access to EHRs is difficult due to the issue of patient privacy. Thus high quality synthetic EHRs data is necessary to alleviate these issues. In this paper, we propose a Sequentially Coupled Generative Adversarial Network (SC-GAN) to generate continuous patient-centric data, including patient state and medication dosage data. SC-GAN consists of two generators which coordinate the generation of patient state and medication dosage in a unified model, revealing the clinical fact that the generation of patient state and medication dosage data have noticeable mutual influence on each other. To verify the quality of the synthetic data, we conduct comprehensive experiments to employ these data on real medical tasks, showing that data generated from SC-GAN leads to better performance than the data from other generative models.;2019;Health related;Health related
"Yu, Y; Chen, J; Gao, T; Yu, M";DAG-GNN: DAG Structure Learning with Graph Neural Networks;"Learning a faithful directed acyclic graph (DAG) from samples of a joint distribution is a challenging combinatorial problem, owing to the intractable search space superexponential in the number of graph nodes. A recent breakthrough formulates the problem as a continuous optimization with a structural constraint that ensures acyclicity (Zheng et al., 2018). The authors apply the approach to the linear structural equation model (SEM) and the least-squares loss function that are statistically well justified but nevertheless limited. Motivated by the widespread success of deep learning that is capable of capturing complex nonlinear mappings, in this work we propose a deep generative model and apply a variant of the structural constraint to learn the DAG. At the heart of the generative model is a variational autoencoder parameterized by a novel graph neural network architecture, which we coin DAG-GNN. In addition to the richer capacity, an advantage of the proposed model is that it naturally handles discrete variables as well as vector-valued ones. We demonstrate that on synthetic data sets, the proposed method learns more accurate graphs for nonlinearly generated samples; and on benchmark data sets with discrete variables, the learned graphs are reasonably close to the global optima. The code is available at https:// github.com/fishmoon1234/DAG-GNN.";2019;Not health related;Not health related
"Gabrié, M; Manoel, A; Luneau, C; Barbier, J; Macris, N; Krzakala, F; Zdeborová, L";Entropy and mutual information in models of deep neural networks;We examine a class of stochastic deep learning models with a tractable method to compute information-theoretic quantities. Our contributions are three-fold: (i) We show how entropies and mutual informations can be derived from heuristic statistical physics methods, under the assumption that weight matrices are independent and orthogonally-invariant. (ii) We extend particular cases in which this result is known to be rigorously exact by providing a proof for two-layers networks with Gaussian random weights, using the recently introduced adaptive interpolation method. (iii) We propose an experiment framework with generative models of synthetic datasets, on which we train deep neural networks with a weight constraint designed so that the assumption in (i) is verified during learning. We study the behavior of entropies and mutual informations throughout learning and conclude that, in the proposed setting, the relationship between compression and generalization remains elusive.;2018;Not health related;Not health related
"Yoon, J; Mizrahi, M; Ghalaty, NF; Jarvinen, T; Ravi, AS; Brune, P; Kong, FY; Anderson, D; Lee, G; Meir, A; Bandukwala, F; Kanal, E; Arik, SÖ; Pfister, T";EHR-Safe: generating high-fidelity and privacy-preserving synthetic electronic health records;Privacy concerns often arise as the key bottleneck for the sharing of data between consumers and data holders, particularly for sensitive data such as Electronic Health Records (EHR). This impedes the application of data analytics and ML-based innovations with tremendous potential. One promising approach for such privacy concerns is to instead use synthetic data. We propose a generative modeling framework, EHR-Safe, for generating highly realistic and privacy-preserving synthetic EHR data. EHR-Safe is based on a two-stage model that consists of sequential encoder-decoder networks and generative adversarial networks. Our innovations focus on the key challenging aspects of real-world EHR data: heterogeneity, sparsity, coexistence of numerical and categorical features with distinct characteristics, and time-varying features with highly-varying sequence lengths. Under numerous evaluations, we demonstrate that the fidelity of EHR-Safe is almost-identical with real data (<3% accuracy difference for the models trained on them) while yielding almost-ideal performance in practical privacy metrics.;2023;Health related;Health related
"Rodrigues, J; Andrade, A";Synthetic neuronal datasets for benchmarking directed functional connectivity metrics;Background. Datasets consisting of synthetic neural data generated with quantifiable and controlled parameters are a valuable asset in the process of testing and validating directed functional connectivity metrics. Considering the recent debate in the neuroimaging community concerning the use of these metrics for fMRI data, synthetic datasets that emulate the BOLD signal dynamics have played a central role by supporting claims that argue in favor or against certain choices. Generative models often used in studies that simulate neuronal activity, with the aim of gaining insight into specific brain regions and functions, have different requirements from the generative models for benchmarking datasets. Even though the latter must be realistic, there is a tradeoff between realism and computational demand that needs to be contemplated and simulations that efficiently mimic the real behavior of single neurons or neuronal populations are preferred, instead of more cumbersome and marginally precise ones. Methods. This work explores how simple generative models are able to produce neuronal datasets, for benchmarking purposes, that reflect the simulated effective connectivity and, how these can be used to obtain synthetic recordings of EEG and fMRI BOLD signals. The generative models covered here are AR processes, neural mass models consisting of linear and nonlinear stochastic differential equations and populations with thousands of spiking units. Forward models for EEG consist in the simple three-shell head model while the fMRI BOLD signal is modeled with the Balloon-Windkessel model or by convolution with a hemodynamic response function. Results. The simulated datasets are tested for causality with the original spectral formulation for Granger causality. Modeled effective connectivity can be detected in the generated data for varying connection strengths and interaction delays. Discussion. All generative models produce synthetic neuronal data with detectable causal effects although the relation between modeled and detected causality varies and less biophysically realistic models offer more control in causal relations such as modeled strength and frequency location.;2015;Health related;Health related
"Paepae, T; Bokoro, PN; Kyamakya, K";Data Augmentation for a Virtual-Sensor-Based Nitrogen and Phosphorus Monitoring;To better control eutrophication, reliable and accurate information on phosphorus and nitrogen loading is desired. However, the high-frequency monitoring of these variables is economically impractical. This necessitates using virtual sensing to predict them by utilizing easily measurable variables as inputs. While the predictive performance of these data-driven, virtual-sensor models depends on the use of adequate training samples (in quality and quantity), the procurement and operational cost of nitrogen and phosphorus sensors make it impractical to acquire sufficient samples. For this reason, the variational autoencoder, which is one of the most prominent methods in generative models, was utilized in the present work for generating synthetic data. The generation capacity of the model was verified using water-quality data from two tributaries of the River Thames in the United Kingdom. Compared to the current state of the art, our novel data augmentation-including proper experimental settings or hyperparameter optimization-improved the root mean squared errors by 23-63%, with the most significant improvements observed when up to three predictors were used. In comparing the predictive algorithms' performances (in terms of the predictive accuracy and computational cost), k-nearest neighbors and extremely randomized trees were the best-performing algorithms on average.;2023;Not health related;Not health related
"Navidan, H; Moshiri, PF; Nabati, M; Shahbazian, R; Ghorashi, SA; Shah-Mansouri, V; Windridge, D";Generative Adversarial Networks (GANs) in networking: A comprehensive survey & evaluation;Despite the recency of their conception, Generative Adversarial Networks (GANs) constitute an extensively researched machine learning sub-field for the creation of synthetic data through deep generative modeling. GANs have consequently been applied in a number of domains, most notably computer vision, in which they are typically used to generate or transform synthetic images. Given their relative ease of use, it is therefore natural that researchers in the field of networking (which has seen extensive application of deep learning methods) should take an interest in GAN-based approaches. The need for a comprehensive survey of such activity is therefore urgent. In this paper, we demonstrate how this branch of machine learning can benefit multiple aspects of computer and communication networks, including mobile networks, network analysis, internet of things, physical layer, and cybersecurity. In doing so, we shall provide a novel evaluation framework for comparing the performance of different models in non-image applications, applying this to a number of reference network datasets.;2021;Not health related;Not health related
"Chen, JW; Yu, CM; Kao, CC; Pang, TW; Lu, CS";DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis;Despite an increased demand for valuable data, the privacy concerns associated with sensitive datasets present a barrier to data sharing. One may use differentially private generative models to generate synthetic data. Unfortunately, generators are typically restricted to generating images of low-resolutions due to the limitation of noisy gradients. Here, we propose DPGEN, a network model designed to synthesize high-resolution natural images while satisfying differential privacy. In particular, we propose an energy-guided network trained on sanitized data to indicate the direction of the true data distribution via Langevin Markov chain Monte Carlo (MCMC) sampling method. In contrast to the state-of-the-art methods that can process only low-resolution images (e.g., MNIST and Fashion-MNIST), DPGEN can generate differentially private synthetic images with resolutions up to 128 x 128 with superior visual quality and data utility.;2022;Not health related;Not health related
"Haleem, MS; Ekuban, A; Antonini, A; Pagliara, S; Pecchia, L; Allocca, C";Deep-Learning-Driven Techniques for Real-Time Multimodal Health and Physical Data Synthesis;With the advent of Artificial Intelligence for healthcare, data synthesis methods present crucial benefits in facilitating the fast development of AI models while protecting data subjects and bypassing the need to engage with the complexity of data sharing and processing agreements. Existing technologies focus on synthesising real-time physiological and physical records based on regular time intervals. Real health data are, however, characterised by irregularities and multimodal variables that are still hard to reproduce, preserving the correlation across time and different dimensions. This paper presents two novel techniques for synthetic data generation of real-time multimodal electronic health and physical records, (a) the Temporally Correlated Multimodal Generative Adversarial Network and (b) the Document Sequence Generator. The paper illustrates the need and use of these techniques through a real use case, the H2020 GATEKEEPER project of AI for healthcare. Furthermore, the paper presents the evaluation for both individual cases and a discussion about the comparability between techniques and their potential applications of synthetic data at the different stages of the software development life-cycle.;2023;Health related;Health related
"Iglesias, G; Talavera, E; González-Prieto, A; Mozo, A; Gómez-Canaval, S";Data Augmentation techniques in time series domain: a survey and taxonomy;With the latest advances in deep learning-based generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using data augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state of the art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will be analysed. The ultimate aim of this study is to provide a summary of the evolution and performance of areas that produce better results to guide future researchers in this field.;2023;Not health related;Not health related
"Tu, LY; Talbot, A; Gallagher, NM; Carlson, DE";Supervising the Decoder of Variational Autoencoders to Improve Scientific Utility;Probabilistic generative models are attractive for scientific modeling because their inferred parameters can be used to generate hypotheses and design experiments. This requires that the learned model accurately represents the input data and yields a latent space that effectively predicts outcomes relevant to the scientific question. Supervised Variational Autoencoders (SVAEs) have previously been used for this purpose, as a carefully designed decoder can be used as an interpretable generative model of the data, while the supervised objective ensures a predictive latent representation. Unfortunately, the supervised objective forces the encoder to learn a biased approximation to the generative posterior distribution, which renders the generative parameters unreliable. This issue has remained undetected as reconstruction losses commonly used to evaluate model performance do not detect bias in the encoder. We address this previously-unreported issue by developing a new framework (SOS-VAE) that updates the decoder parameters, rather than the encoder, to induce a predictive latent representation. This ensures that the encoder maintains a reliable posterior approximation and the decoder parameters can be effectively interpreted. We extend this technique to allow the user to trade-off the bias in the generative parameters for improved predictive performance, acting as an intermediate option between SVAEs and SOS-VAE. We also use this methodology to address missing data issues that often arise when combining recordings from multiple scientific experiments. We demonstrate the effectiveness of these developments using synthetic data and electrophysiological recordings with an emphasis on how our learned representations can be used to design scientific experiments.;2022;Not health related;Not health related
"Sasada, T; Kawai, M; Taenaka, Y; Fall, D; Kadobayashi, Y";Differentially-Private Text Generation via Text Preprocessing to Reduce Utility Loss;To provide user-generated texts to third parties, various anonymization used to process the texts. Since this anonymization assume the knowledge possessed by the adversary, sensitive information may he leaked depending on the adversary's knowledge even after this anonymization. Moreover, setting the strongest assumptions about the adversary's knowledge leads to the degradation of the utility as the data by removing any quasi-identifiers. Therefore, instead of providing original data, a method to generate differentially-private synthetic data has been proposed. Differential privacy is more flexible than anonymization technologies because it does not require the assumption of the adversary's knowledge. However, if a large noise is added to the gradient in text generative model to satisfy differential privacy, the utility of the synthetic text is degraded. Since differential privacy can he satisfied with a small noise in data containing duplicates, it is possible to reduce utility loss as text by creating duplicates before adding noise. In this study, we reduce the amount of noise added by creating duplicates through generalization, thereby minimizing text utility loss. By constructing a differentiaity-private text generation model, we can provide synthetic text and promote text utilization while protecting privacy information in the text.;2021;Not health related;Not health related
"Boelts, J; Harth, P; Gao, RC; Udvary, D; Yanez, F; Baum, D; Hege, HC; Oberlaender, M; Macke, JH";Simulation-based inference for efficient identification of generative models in computational connectomics;Recent advances in connectomics research enable the acquisition of increasing amounts of data about the connectivity patterns of neurons. How can we use this wealth of data to efficiently derive and test hypotheses about the principles underlying these patterns? A common approach is to simulate neuronal networks using a hypothesized wiring rule in a generative model and to compare the resulting synthetic data with empirical data. However, most wiring rules have at least some free parameters, and identifying parameters that reproduce empirical data can be challenging as it often requires manual parameter tuning. Here, we propose to use simulation-based Bayesian inference (SBI) to address this challenge. Rather than optimizing a fixed wiring rule to fit the empirical data, SBI considers many parametrizations of a rule and performs Bayesian inference to identify the parameters that are compatible with the data. It uses simulated data from multiple candidate wiring rule parameters and relies on machine learning methods to estimate a probability distribution (the 'posterior distribution over parameters conditioned on the data') that characterizes all data-compatible parameters. We demonstrate how to apply SBI in computational connectomics by inferring the parameters of wiring rules in an in silico model of the rat barrel cortex, given in vivo connectivity measurements. SBI identifies a wide range of wiring rule parameters that reproduce the measurements. We show how access to the posterior distribution over all data-compatible parameters allows us to analyze their relationship, revealing biologically plausible parameter interactions and enabling experimentally testable predictions. We further show how SBI can be applied to wiring rules at different spatial scales to quantitatively rule out invalid wiring hypotheses. Our approach is applicable to a wide range of generative models used in connectomics, providing a quantitative and efficient way to constrain model parameters with empirical connectivity data. The brain is composed of an intricately connected network of cells-what are the principles that contribute to constructing these patterns of connectivity, and how? To answer these questions, amassing connectivity data alone is not enough. We must also be able to efficiently develop and test our ideas about the underlying connectivity principles. For example, we could simulate a hypothetical wiring rule like neurons near each other are more likely to form connections in a computational model and generate corresponding synthetic data. If the synthetic, simulated data resembles the real, measured data, then we have some confidence that our hypotheses might be correct. However, the proposed wiring rules usually have unknown parameters that we need to tune such that simulated data matches the measurements. The central challenge thus lies in finding all the potential parametrizations of a wiring rule that can reproduce the measured data, as this process is often idiosyncratic and labor-intensive. To tackle this challenge, we introduce an approach combining computational modeling in connectomics, deep learning, and Bayesian statistical inference to automatically infer a probability distribution over the model parameters likely to explain the data. We demonstrate our approach by inferring the parameters of a wiring rule in a detailed model of the rat barrel cortex and find that the inferred distribution identifies multiple data-compatible model parameters, reveals biologically plausible parameter interactions, and allows us to make experimentally testable predictions.;2023;Not health related;Health related
"Tekin, SF; Kozat, SS";Crime prediction with graph neural networks and multivariate normal distributions;We study high-resolution crime prediction and introduce a new generative model applicable to any spatiotemporal data with graph convolutional gated recurrent units (Graph-ConvGRU) and multivariate Gaussian distributions. We introduce a subdivision algorithm and create a graph representation to tackle the sparsity and complexity problem in high-resolution spatiotemporal data. By leveraging the flexible structure of graph representation, we model the spatial, temporal, and categorical relations of crime events and produce state vectors for each region. We create a multivariate probability distribution from the state vectors and train the distributions by minimizing the KL divergence between the generated and the actual distribution of the crime events. After creating the distributions, crime can be predicted in any resolution as the first time in the literature. In our experiments on real-life and synthetic datasets, our model obtains the best score with respect to the state-of-the-art models with statistically significant improvements. Hence, our model is not only generative but also precise. We also provide the source code of our algorithm for reproducibility.;2023;Not health related;Not health related
"Yunus, F; Dandekar, A; Bressan, S";Data Driven Generation of Synthetic Data with Support Vector Data Description;We propose a method to generate synthetic data by Support Vector Data Description. Support Vector Data Description is a variant of Support Vector Machine for one-class classification problem. Our method assumes that an observed data is a sample of a random variable which satisfies an unknown membership decision function. The unknown membership decision function is to be learned by Support Vector Data Description based on the training data. By using the learned membership decision function, we perform rejection sampling. Firstly, we generate a random data point. Secondly, we test the data point against the membership decision function. Lastly, if the data point fails the test, we repeat from the first step. However, in some cases, the rejection sampling approach runs slowly. Therefore, we also propose another approach. The approach works by using a heuristic to find a good starting point and then performs gradient descent to gradually move the data point into inside the positive region boundary while maintaining randomness of the generated data. This approach runs noticeably faster than rejection sampling when rejection sampling runs slowly.;2017;Not health related;Not health related
"Rozumnyi, D; Oswald, MR; Ferrari, V; Matas, J; Pollefeys, M";DeFMO: Deblurring and Shape Recovery of Fast Moving Objects;Objects moving at high speed appear significantly blurred when captured with cameras. The blurry appearance is especially ambiguous when the object has complex shape or texture. In such cases, classical methods, or even humans, are unable to recover the object's appearance and motion. We propose a method that, given a single image with its estimated background, outputs the object's appearance and position in a series of sub frames as if captured by a high-speed camera (i.e. temporal super-resolution). The proposed generative model embeds an image of the blurred object into a latent space representation, disentangles the background, and renders the sharp appearance. Inspired by the image formation model, we design novel self-supervised loss function terms that boost performance and show good generalization capabilities. The proposed DeFMO method is trained on a complex synthetic dataset, yet it performs well on real-world data from several datasets. DeFMO outperforms the state of the art and generates high-quality temporal super-resolution frames.;2021;Not health related;Not health related
"Bae, J; Lee, C";Easy Data Augmentation for Improved Malware Detection: A Comparative Study;Artificial data generation is important for improving research outcomes when using deep learning. As one of the most popular and promising generative models, the variational autoencoder (VAE) model generates synthetic data for training classifiers more accurately. Artificial data can be generated also via easy data augmentation (EDA) techniques. EDA is a simple method used to boost the performance of text classification tasks, and unlike generative models such as VAE, it does not require model training. Malware detection is a task of determining whether there is malicious software in the host system and diagnosing the type of attack. Without an appropriate amount of training data, the detection efficiency of malicious programs decreases. In this study, EDA was applied to malware detection, and two artificial data generation methods were compared. Using both methods, artificial training data to be used for malware detection were generated, and the long short-term memory recurrent neural network (LSTM RNN) based malware detection classifier was boosted. Experiment results show that when the synthetic malware sample generated by EDA was added to the training data, the accuracy of LSTM RNN classifier improved by 1.76% as compared to the 0.98% improvement by VAE. In addition, EDA could generate malware training data, without requiring a separate training process, 10 times faster than VAE. Further, we performed extensive ablation studies conducted and suggested parameters for practical use.;2021;Not health related;Not health related
"Contisciani, M; Safdari, H; De Bacco, C";Community detection and reciprocity in networks by jointly modelling pairs of edges;To unravel the driving patterns of networks, the most popular models rely on community detection algorithms. However, these approaches are generally unable to reproduce the structural features of the network. Therefore, attempts are always made to develop models that incorporate these network properties beside the community structure. In this article, we present a probabilistic generative model and an efficient algorithm to both perform community detection and capture reciprocity in networks. Our approach jointly models pairs of edges with exact two-edge joint distributions. In addition, it provides closed-form analytical expressions for both marginal and conditional distributions. We validate our model on synthetic data in recovering communities, edge prediction tasks and generating synthetic networks that replicate the reciprocity values observed in real networks. We also highlight these findings on two real datasets that are relevant for social scientists and behavioural ecologists. Our method overcomes the limitations of both standard algorithms and recent models that incorporate reciprocity through a pseudo-likelihood approximation. The inference of the model parameters is implemented by the efficient and scalable expectation-maximization algorithm, as it exploits the sparsity of the dataset. We provide an open-source implementation of the code online.;2022;Not health related;Not health related
"Kariyappa, S; Prakash, A; Qureshi, MK";MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient Estimation;High quality Machine Learning (ML) models are often considered valuable intellectual property by companies. Model Stealing (MS) attacks allow an adversary with black-box access to a ML model to replicate its functionality by training a clone model using the predictions of the target model for different inputs. However, best available existing MS attacks fail to produce a high-accuracy clone without access to the target dataset or a representative dataset necessary to query the target model. In this paper, we show that preventing access to the target dataset is not an adequate defense to protect a model. We propose MAZE - a data-free model stealing attack using zeroth-order gradient estimation that produces high-accuracy clones. In contrast to prior works, MAZE uses only synthetic data created using a generative model to perform MS. Our evaluation with four image classification models shows that MAZE provides a normalized clone accuracy in the range of 0.90x to 0.99x, and outperforms even the recent attacks that rely on partial data (JBDA, clone accuracy 0.13x to 0.69x) and on surrogate data (KnockoffNets, clone accuracy 0.52x to 0.97x). We also study an extension of MAZE in the partial-data setting, and develop MAZE-PD, which generates synthetic data closer to the target distribution. MAZE-PD further improves the clone accuracy (0.97x to 1.0x) and reduces the query budget required for the attack by 2x-24x.;2021;Not health related;Not health related
"Cencer, MM; Suslick, BA; Moore, JS";From skeptic to believer: The power of models;"Complex systems that contain a chemical component benefit from clever application of computational and cheminformatics tools. As classically trained synthetic experimentalists, we initially viewed in silico methods with skepticism, in large part due to our own ignorance. Over time, we were each exposed to enlightening projects that completely altered our opinions on computation; we now firmly believe that better science occurs when experiments and models exist in harmony. The goal of our perspective is three-fold. We first provide historical context for the explosive growth of modern simulation-based techniques, with interesting parallels to the development of modern scientific thought. We next discuss the three short vignettes from our own research that illuminated us into appreciating computation. Finally, we propose several calls to action for the scientific community to better advocate for computation. Science education must better prepare learners of chemistry for an increasingly digital world that not only includes experimental data but also synthetic data from generative models. As scientists, we must make raw data (experimental and synthetic) accessible to the broader community. (c) 2022 Elsevier Ltd. All rights reserved.";2022;Not health related;Not health related
"Sterling, A; Rewkowski, N; Klatzky, RL; Lin, MC";Audio-Material Reconstruction for Virtualized Reality Using a Probabilistic Damping Model;Modal sound synthesis has been used to create realistic sounds from rigid-body objects. but requires accurate real-world material parameters. These material parameters can be estimated from recorded sounds of an impacted object, but external factors can interfere with accurate parameter estimation. We present a novel technique for estimating the damping parameters of materials from recorded impact sounds that probabilistically models these external factors. We represent the combined effects of material damping. support damping. and sampling inaccuracies with a probabilistic generative model, then use maximum likelihood estimation to fit a damping model to recorded data. This technique greatly reduces the human effort needed and does not require the precise object geometry or the exact hit location. We validate the effectiveness of this technique with a comprehensive analysis of a synthetic dataset and a perceptual study on object identification. We also present a study establishing human performance on the same parameter estimation task for comparison.;2019;Not health related;Not health related
"Azadmanesh, M; Ghahfarokhi, BS; Talouki, MA";An Auto-Encoder based Membership Inference Attack against Generative Adversarial Network;Using generative models to produce unlimited synthetic samples is a popular replacement for database sharing. Generative Adversarial Network (GAN) is a popular class of generative models which generates synthetic data samples very similar to real training datasets. However, GAN models do not necessarily guarantee training privacy as these models may memorize details of training data samples. When these models are built using sensitive data, the developers should ensure that the training dataset is appropriately protected against privacy leakage. Hence, quantifying the privacy risk of these models is essential. To this end, this paper focuses on evaluating the privacy risk of publishing the generator network of GAN models. Specially, we conduct a novel generator white-box membership inference attack against GAN models that exploits accessible information about the victim model, i.e., the generator's weights and synthetic samples, to conduct the attack. In the proposed attack, an auto-encoder is trained to determine member and non-member training records. This attack is applied to various kinds of GANs. We evaluate our attack accuracy with respect to various model types and training configurations. The results demonstrate the superior performance of the proposed attack on non-private GANs compared to previous attacks in white-box generator access. The accuracy of the proposed attack is 19% higher on average than similar work. The proposed attack, like previous attacks, has better performance for victim models that are trained with small training sets.(c) 2023 ISC. All rights reserved.;2023;Not health related;Not health related
"González-Prieto, A; Mozo, A; Gómez-Canaval, S; Talavera, E";Improving the quality of generative models through Smirnov transformation;Solving the convergence issues of Generative Adversarial Networks (GANs) is one of the most outstanding problems in generative models. In this work, we propose a novel activa-tion function to be used as output of the generator agent. This activation function is based on the Smirnov probabilistic transformation and it is specifically designed to improve the quality of the generated data. In sharp contrast to previous works, our activation function provides a more general approach that deals not only with the replication of categorical variables but with any type of data distribution (continuous or discrete). Moreover, our activation function is derivable and therefore, it can be seamlessly integrated in the back -propagation computations during the GAN training processes. To validate this approach, we firstly evaluate our proposal on two different data sets: a) an artificially rendered data set containing a mixture of discrete and continuous variables, and b) a real data set of flow -based network traffic data containing both normal connections and cryptomining attacks. In addition, three publicly available data sets were added to the evaluation to generalize the obtained results. To evaluate the fidelity of the generated data, we analyze their results both in terms of quality measures of statistical nature and regarding the use of these syn-thetic data to feed a nested machine learning-based classifier.The experimental results evince a clear outperformance of a Wasserstein GAN network (WGAN) tuned with this new activation function with respect to both a naive mean -based generator and a standard WGAN. The quality of the generated data allows to fully substitute real data with synthetic data for training the nested classifier without a signif-icant fall in the obtained accuracy.(c) 2022 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).;2022;Not health related;Not health related
"Huang, JQ; Wu, CY";Privacy Leakage in GAN Enabled Load Profile Synthesis;Load profile synthesis is a commonly used technique for preserving smart meter data privacy. Recent efforts have successfully integrated advanced generative models, such as the Generative Adversarial Networks (GAN), to synthesize highquality load profiles. Such methods are becoming increasingly popular for conducting privacy-preserving load data analytics. It is commonly believed that performing analyses on synthetic data can ensure certain privacy. In this paper, we examine this common belief. Specifically, we reveal the privacy leakage issue in load profile synthesis enabled by GAN. We first point out that the synthesis process cannot provide any provable privacy guarantee, highlighting that directly conducting load data analytics based on such data is extremely dangerous. The sample re-appearance risk is then presented under different volumes of training data, which indicates that the original load data could be directly leaked by GAN without any intentional effort from adversaries. Furthermore, we discuss potential approaches that might address this privacy leakage issue.;2022;Not health related;Not health related
"Saito, K; Ohara, K; Kimura, M; Motoda, H";Detecting Changes in Content and Posting Time Distributions in Social Media;We address a problem of detecting changes in information posted to social media taking both content and posting time distributions into account. To this end, we introduce a generative model consisting of two components, one for a content distribution and the other for a timing distribution, approximating the shape of the parameter change by a series of step functions. We then propose an efficient algorithm to detect change points by maximizing the likelihood of generating the observed sequence data, which has time complexity almost proportional to the length of observed sequence (possible change points). We experimentally evaluate the method on synthetic data streams and demonstrate the importance of considering both distributions to improve the accuracy. We, further, apply our method to real scoring stream data extracted from a Japanese word-of-mouth communication site for cosmetics and show that it can detect change points and the detected parameter change patterns are interpretable through an in-depth investigation of actual reviews.;2013;Not health related;Not health related
"Bonifacio, L; Abonizio, H; Fadaee, M; Nogueira, R";InPars: Unsupervised Dataset Generation for Information Retrieval;The Information Retrieval (IR) community has recently witnessed a revolution due to large pretrained transformer models. Another key ingredient for this revolution was the MS MARCO dataset, whose scale and diversity has enabled zero-shot transfer learning to various tasks. However, not all IR tasks and domains can benefit from one single dataset equally. Extensive research in various NLP tasks has shown that using domain-specific training data, as opposed to a general-purpose one, improves the performance of neural models [45, 56]. In this work, we harness the few-shot capabilities of large pretrained language models as synthetic data generators for IR tasks. We show that models fine-tuned solely on our synthetic datasets outperform strong base-lines such as BM25 as well as recently proposed self-supervised dense retrieval methods. Code, models, and data are available at https://github.com/zetaalphavector/inpars.;2022;Not health related;Not health related
"Mohammadjafari, S; Cevik, M; Basar, A";VARGAN: variance enforcing network enhanced GAN;Generative adversarial networks (GANs) are one of the most widely used generative models. GANs can learn complex multi-modal distributions, and generate real-like samples. Despite the major success of GANs in generating synthetic data, they might suffer from unstable training process, and mode collapse. In this paper, we propose a new GAN architecture called variance enforcing GAN (VARGAN), which incorporates a third network to introduce diversity in the generated samples. The third network measures the diversity of the generated samples, which is used to penalize the generator's loss for low diversity samples. The network is trained on the available training data and undesired distributions with limited modality. On a set of synthetic and real-world image data, VARGAN generates a more diverse set of samples compared to the recent state-of-the-art models. High diversity and low computational complexity, as well as fast convergence, make VARGAN a promising model to alleviate mode collapse.;2023;Not health related;Not health related
"Ishiwatari, T; Saito, S; Nakahara, Y; Iikubo, Y; Matsushima, T";Bayes optimal estimation and its approximation algorithm for difference with and without treatment under IRSLC model;We consider verifying the effect of the treatment under the situation in which a response is given when a treatment is applied to units with features. In estimating the effect, there are problems such as the treatment can be given only once to the unit and the features of the unit cannot be controlled. For such problems, conventional studies have some mathematical models. However, in this paper, we propose the different data generative model in which there are latent classes of units with the same response, each latent class contains units with similar features. We call this model the identical response structure latent class model (IRSLC model). Under the proposed model, we calculate the Bayes optimal decision and its approximation algorithm for the difference with and without the treatment for the entire population. We conducted experiments using the synthetic data of the model assumed by the proposed method or the conventional method. Then, we compared our method with previous studies to confirm the characteristics of the proposed model.;2023;Not health related;Health related
"Platscher, M; Zopes, J; Federau, C";Image translation for medical image generation: Ischemic stroke lesion segmentation;Deep learning based disease detection and segmentation algorithms promise to improve many clinical processes. However, such algorithms require vast amounts of annotated training data, which are typically not available in the medical context due to data privacy, legal obstructions, and non-uniform data acquisition protocols. Synthetic databases with annotated pathologies could provide the required amounts of training data. We demonstrate with the example of ischemic stroke that an improvement in lesion segmentation is feasible using deep learning based augmentation. To this end, we train different image-to-image translation models to synthesize magnetic resonance images of brain volumes with and without stroke lesions from semantic segmentation maps. In addition, we train a generative adversarial network to generate synthetic lesion masks. Subsequently, we combine these two components to build a large database of synthetic stroke images. The performance of the various models is evaluated using a U-Net which is trained to segment stroke lesions on a clinical test set. We report a Dice score of 72.8% [70.8 +/- 1.0%] for the model with the best performance, which outperforms the model trained on the clinical images alone 67.3% [63.2 +/- 1.9%], and is close to the human inter-reader Dice score of 76.9%. Moreover, we show that for a small database of only 10 or 50 clinical cases, synthetic data augmentation yields significant improvement compared to a setting where no synthetic data is used. To the best of our knowledge, this presents the first comparative analysis of synthetic data augmentation based on image-to-image translation, and first application to ischemic stroke.;2022;Health related;Health related
"Liang, YP; Han, ZY; Nie, XT; Ohkura, K";Improving generative adversarial network with multiple generators by evolutionary algorithms;Generative Adversarial Network (GAN) is a novel class of deep generative models that has recently gained significant attention. However, the original GAN with one generator can easily get trapped into the mode collapsing problem, which could cause the generator only to produce similar images. This paper proposed a combination of GAN and an evolutionary algorithm to overcome the mode collapsing problem. In our approach, multiple generator networks are trained with the evolutionary strategy (ES), an evolution algorithm. The discriminator network distinguishes if the image comes from the real dataset or not. An additional classifier network is implemented to distinguish different generators. The mutations in the evolutionary strategy and the additional classifier network keep the diversity among generators. We term our approach the Evolution-GAN. In this paper, we conduct experiments on 2D synthetic data to verify that the Evolution-GAN overcomes the mode collapsing problem. Furthermore, experiments on MNIST datasets are implemented to compare the performance of Evolution-GAN, the original GAN, and Deep Convolutional GAN(DCGAN) and Evolutionary GAN.;2022;Not health related;Not health related
"Semenoglou, AA; Spiliotis, E; Assimakopoulos, V";Data augmentation for univariate time series forecasting with neural networks;Neural networks have been proven particularly accurate in univariate time series forecasting settings, re-quiring however a significant number of training samples to be effectively trained. In machine learning applications where available data are limited, data augmentation techniques have been successfully used to generate synthetic data that resemble and complement the original train set. Since the potential of data augmentation has been largely neglected in univariate time series forecasting, in this study we in-vestigate nine data augmentation techniques, ranging from simple transformations and adjustments to sophisticated generative models and a novel upsampling approach. We empirically evaluate the impact of data augmentation on forecasting accuracy considering both shallow and deep feed-forward neural networks and time series data sets of different sizes from the M4 and the Tourism competitions. Our results suggest that certain data augmentation techniques that build on upsampling and time series com-binations can improve forecasting performance, especially when deep networks are used. However, these improvements become less significant as the initial size of the train set increases. (c) 2022 Elsevier Ltd. All rights reserved.;2022;Not health related;Not health related
"Gong, JL; Fan, GL; Yu, LJ; Havlicek, JP; Chen, DR; Fan, NJ";Joint view-identity manifold for infrared target tracking and recognition;We propose a new joint view-identity manifold (JVIM) for multi-view and multi-target shape modeling that is well-suited for automated target tracking and recognition (ATR) in infrared imagery. As a shape generative model, JVIM features a novel manifold structure that imposes a conditional dependency between the two shape-related factors, view and identity, in a unified latent space, which is embedded with one view-independent identity manifold and infinite identity-dependent view manifolds. A modified local linear Gaussian process latent variable model (LL-GPLVM) is proposed for JVIM learning where a stochastic gradient descent method is used to improve the learning efficiency. We also develop a local inference technique to speed up JVIM-based shape interpolation. Due to its probabilistic and continuous nature, JVIM provides effective shape synthesis and supports robust ATR inference for both known and unknown target types under arbitrary views. Experiments on both synthetic data and the SENSIAC infrared ATR database demonstrate the advantages of the proposed method over several existing techniques both qualitatively and quantitatively. (C) 2013 Elsevier Inc. All rights reserved.;2014;Not health related;Not health related
"Zhang, H; Zhang, ST; Li, K; Metaxas, DN";ROBUST SHAPE PRIOR MODELING BASED ON GAUSSIAN-BERNOULLI RESTRICTED BOLTZMANN MACHINE;Shape information is essential in medical image analysis as the anatomical structures usually have strong shape characteristics. Shape priors can resolve ambiguities when the low level appearance is weak or misleading due to imaging artifacts and diseases. In this paper, we propose a shape prior model based on the Gaussian-Bernoulli Restricted Boltzmann Machine (GB-RBM). This powerful generative model is effective in capturing complex shape variations and handling nonlinear shape transformations. The model also shows great robustness, which is able to handle both outliers and Gaussian noise with large variance. We validate our model on synthetic data and a real clinical problem, i.e., lung segmentation in chest X-ray. Experiments show that our shape modeling method is qualitatively and quantitatively better than other widely-used shape prior methods.;2014;Health related;Health related
"Kahlen, JN; Andres, M; Moser, A";Improving Machine-Learning Diagnostics with Model-Based Data Augmentation Showcased for a Transformer Fault;Machine-learning diagnostic systems are widely used to detect abnormal conditions in electrical equipment. Training robust and accurate diagnostic systems is challenging because only small databases of abnormal-condition data are available. However, the performance of the diagnostic systems depends on the quantity and quality of the data. The training database can be augmented utilizing data augmentation techniques that generate synthetic data to improve diagnostic performance. However, existing data augmentation techniques are generic methods that do not include additional information in the synthetic data. In this paper, we develop a model-based data augmentation technique integrating computer-implementable electromechanical models. Synthetic normal- and abnormal-condition data are generated with an electromechanical model and a stochastic parameter value sampling method. The model-based data augmentation is showcased to detect an abnormal condition of a distribution transformer. First, the synthetic data are compared with the measurements to verify the synthetic data. Then, ML-based diagnostic systems are created using model-based data augmentation and are compared with state-of-the-art diagnostic systems. It is shown that using the model-based data augmentation results in an improved accuracy compared to state-of-the-art diagnostic systems. This holds especially true when only a small abnormal-condition database is available.;2021;Not health related;Not health related
"Janssen, A; Smalbil, L; Bennis, FC; Cnossen, MH; Mathôt, RAA";A Generative and Causal Pharmacokinetic Model for Factor VIII in Hemophilia A: A Machine Learning Framework for Continuous Model Refinement;In rare diseases, such as hemophilia A, the development of accurate population pharmacokinetic (PK) models is often hindered by the limited availability of data. Most PK models are specific to a single recombinant factor VIII (rFVIII) concentrate or measurement assay, and are generally unsuited for answering counterfactual (what-if) queries. Ideally, data from multiple hemophilia treatment centers are combined but this is generally difficult as patient data are kept private. In this work, we utilize causal inference techniques to produce a hybrid machine learning (ML) PK model that corrects for differences between rFVIII concentrates and measurement assays. Next, we augment this model with a generative model that can simulate realistic virtual patients as well as impute missing data. This model can be shared instead of actual patient data, resolving privacy issues. The hybrid ML-PK model was trained on chromogenic assay data of lonoctocog alfa and predictive performance was then evaluated on an external data set of patients who received octocog alfa with FVIII levels measured using the one-stage assay. The model presented higher accuracy compared with three previous PK models developed on data similar to the external data set (root mean squared error = 14.6 IU/dL vs. mean of 17.7 IU/dL). Finally, we show that the generative model can be used to accurately impute missing data (< 18% error). In conclusion, the proposed approach introduces interesting new possibilities for model development. In the context of rare disease, the introduction of generative models facilitates sharing of synthetic data, enabling the iterative improvement of population PK models.;2024;Health related;Health related
"Rasheed, K; Qadir, J; O'Brien, TJ; Kuhlmann, L; Razi, A";A Generative Model to Synthesize EEG Data for Epileptic Seizure Prediction;Objective: Scarcity of good quality electroencephalography (EEG) data is one of the roadblocks for accurate seizure prediction. This work proposes a deep convolutional generative adversarial network (DCGAN) to generate synthetic EEG data. Another objective of our study is to use transfer-learning (TL) for evaluating the performance of four well-known deep-learning (DL) models to predict epileptic seizure. Methods: We proposed an algorithm that generate synthetic data using DCGAN trained on real EEG data in a patient-specific manner. We validate quality of generated data using one-class SVM and a new proposal namely convolutional epileptic seizure predictor (CESP). We evaluate performance of VGG16, VGG19, ResNet50, and Inceptionv3 trained on augmented data using TL with average time of 10 min between true prediction and seizure onset samples. Results: The CESP model achieves sensitivity of 78.11% and 88.21%, and false prediction rate of 0.27/h and 0.14/h for training on synthesized and testing on real Epilepsyecosystem and CHB-MIT datasets, respectively. Using TL and augmented data, Inceptionv3 achieved highest accuracy with sensitivity of 90.03% and 0.03 FPR/h. With the proposed data augmentation method prediction results of CESP model and Inceptionv3 increased by 4-5% as compared to state-of-the-art augmentation techniques. Conclusion: The performance of CESP shows that synthetic data acquired association between features and labels very well and by using the augmented data CESP predicted better than chance level for both datasets. Significance: The proposed DCGAN can be used to generate synthetic data to increase the prediction performance and to overcome good quality data scarcity issue.;2021;Health related;Health related
"Cabezas, R; Straub, J; Fisher, JW";Semantically-Aware Aerial Reconstruction from Multi-Modal Data;We consider a methodology for integrating multiple sensors along with semantic information to enhance scene representations. We propose a probabilistic generative model for inferring semantically-informed aerial reconstructions from multi-modal data within a consistent mathematical framework. The approach, called Semantically-Aware Aerial Reconstruction (SAAR), not only exploits inferred scene geometry, appearance, and semantic observations to obtain a meaningful categorization of the data, but also extends previously proposed methods by imposing structure on the prior over geometry, appearance, and semantic labels. This leads to more accurate reconstructions and the ability to fill in missing contextual labels via joint sensor and semantic information. We introduce a new multi-modal synthetic dataset in order to provide quantitative performance analysis. Additionally, we apply the model to real-world data and exploit OpenStreetMap as a source of semantic observations. We show quantitative improvements in reconstruction accuracy of large-scale urban scenes from the combination of LiDAR, aerial photography, and semantic data. Furthermore, we demonstrate the model's ability to fill in for missing sensed data, leading to more interpretable reconstructions.;2015;Not health related;Not health related
"Thambawita, V; Hammer, HL; Riegler, M; Halvorsen, P";GANEx: A complete pipeline of training, inference and benchmarking GAN experiments;Deep learning (DL) is one of the standard methods in the field of multimedia research to perform data classification, detection, segmentation and generation. Within DL, generative adversarial networks (GANs) represents a new and highly popular branch of methods. GANs have the capability to generate, from random noise or conditional input, new data realizations within the dataset population. While generation is popular and highly useful in itself, GANs can also be useful to improve supervised DL. GAN-based approaches can, for example, perform segmentation or create synthetic data for training other DL models. The latter one is especially interesting in domains where not much training data exists such as medical multimedia. In this respect, performing a series of experiments involving GANs can be very time consuming due to the lack of tools that support the whole pipeline such as structured training, testing and tracking of different architectures and configurations. Moreover, the success of generative models is highly dependent on hyper-parameter optimization and statistical analysis in the design and fine-tuning stages. In this paper, we present a new tool called GANEx for making the whole pipeline of training, inference and benchmarking GANs faster, more efficient and more structured. The tool consists of a special library called FastGAN which allows designing generative models very fast. Moreover, GANEx has a graphical user interface to support structured experimenting, quick hyperparameter configurations and output analysis. The presented tool is not limited to a specific DL framework and can be therefore even used to compare the performance of cross frameworks.;2019;Not health related;Health related
"Liu, R; Azabou, M; Dabagia, M; Lin, CH; Azar, MG; Hengen, KB; Valko, M; Dyer, EL";Drop, Swap, and Generate: A Self-Supervised Approach for Generating Neural Activity;Meaningful and simplified representations of neural activity can yield insights into how and what information is being processed within a neural circuit. However, without labels, finding representations that reveal the link between the brain and behavior can be challenging. Here, we introduce a novel unsupervised approach for learning disentangled representations of neural activity called Swap-VAE. Our approach combines a generative modeling framework with an instance-specific alignment loss that tries to maximize the representational similarity between transformed views of the input (brain state). These transformed (or augmented) views are created by dropping out neurons and jittering samples in time, which intuitively should lead the network to a representation that maintains both temporal consistency and invariance to the specific neurons used to represent the neural state. Through evaluations on both synthetic data and neural recordings from hundreds of neurons in different primate brains, we show that it is possible to build representations that disentangle neural datasets along relevant latent dimensions linked to behavior.;2021;Health related;Health related
"Albers, KJ; Morup, M; Schmidt, MN";THE INFLUENCE OF HYPER-PARAMETERS IN THE INFINITE RELATIONAL MODEL;"The infinite relational model (IRM) is a Bayesian nonparametric stochastic block model; a generative model for random networks parameterized for unipartite undirected networks by a partition of the node set and symmetric matrix of inter- partion link probabilities. The prior for the node clusters is the Chinese restaurant process, and the link probabilities are, in the most simple setting, modeled as iid. with a common symmetric Beta prior. More advanced priors such as separate asymmetric Beta priors for links within and between clusters have also been proposed. In this paper we investigate the importance of these priors for discovering latent clusters and for predicting links. We compare fixed symmetric priors and fixed asymmetric priors based on the empirical distribution of links with a Bayesian hierarchical approach where the parameters of the priors are inferred from data. On synthetic data, we show that the hierarchical Bayesian approach can infer the prior distributions used to generate the data. On real network data we demonstrate that using asymmetric priors significantly improves predictive performance and heavily influences the number of extracted partitions.";2016;Not health related;Not health related
"Suematsu, N; Hayashi, A";Time Series Alignment with Gaussian Processes;We propose a nonparametric Bayesian approach to time series alignment. Time series alignment is a technique often required when we analyze a set of time series in which there exists a typical structural pattern common to all the time series. Such a set of time series is typically obtained by repeated measurements of a biological, chemical or physical process. In time series alignment, we are required to estimate a common shape function, which describes a common structural patter shared among a set of time series, and time transformation functions, each of which represents time shifts involved in individual time series. In this paper, we introduce a generative model for time series data in which the common shape function and the time transformation functions are modeled nonparametrically using Gaussian processes and we develop an effective Markov Chain Monte Carlo algorithm, which realizes a nonparametric Bayesian approach to time series alignment. The effectiveness of our method is demonstrated in an experiment with synthetic data and an experiment with real time series data is also presented.;2012;Not health related;Not health related
"Zhang, L; Zhao, JY; Ye, XL; Chen, Y";Cooperation: A new force for boosting generative adversarial nets with dual-network structure;The principle of generative adversarial net is to fit the given data distribution by combining a generative model and discriminative model. There are two major challenges to conventional systems - they are difficult to train and they easily fall into 'mode collapse'. To improve it, this study describes a novel network structure with dual generators. A 'cooperation' mechanism is introduced to help the generators work together. During training, generators not only learn from discriminative feedback but also from each other (like a study group). Compared with a single-generator network, a dual-generator network could capture many more 'modes' and eventually reduce the impact of 'mode collapse.' Dual networks also require extra computational resources. However, our experiment shows that even with network parameters of similar size, dual networks still achieved better results. Additionally, a dual-generator structure could be extended to multiple generators. The proposed network structure is also very robust and flexible. It can be adapted to various application scenarios, such as high-resolution image generation, domain adaptation and 3D model generation. The experimental results showed that with the same computing resources, multiple generators can generate better quality synthetic data, including 2D images, 3D objects, style transferring etc.;2020;Not health related;Not health related
"Reynaud, H; Vlontzos, A; Dombrowski, M; Lee, CG; Beqiri, A; Leeson, P; Kainz, B";D'ARTAGNAN: Counterfactual Video Generation;Causally-enabled machine learning frameworks could help clinicians to identify the best course of treatments by answering counterfactual questions. We explore this path for the case of echocardiograms by looking into the variation of the Left Ventricle Ejection Fraction, the most essential clinical metric gained from these examinations. We combine deep neural networks, twin causal networks and generative adversarial methods for the first time to build D'ARTAGNAN (Deep ARtificial Twin-Architecture GeNerAtive Networks), a novel causal generative model. We demonstrate the soundness of our approach on a synthetic dataset before applying it to cardiac ultrasound videos to answer the question: What would this echocardiogram look like if the patient had a different ejection fraction?. To do so, we generate new ultrasound videos, retaining the video style and anatomy of the original patient, while modifying the Ejection Fraction conditioned on a given input. We achieve an SSIM score of 0.79 and an R2 score of 0.51 on the counterfactual videos. Code and models are available at: https://github.com/HReynaud/dartagnan.;2022;Health related;Health related
"Manukian, H; Pei, YR; Bearden, SRB; Di Ventra, M";Mode-assisted unsupervised learning of restricted Boltzmann machines;Restricted Boltzmann machines (RBMs) are a powerful class of generative models, but their training requires computing a gradient that, unlike supervised backpropagation on typical loss functions, is notoriously difficult even to approximate. Here, we show that properly combining standard gradient updates with an off-gradient direction, constructed from samples of the RBM ground state (mode), improves training dramatically over traditional gradient methods. This approach, which we call 'mode-assisted training', promotes faster training and stability, in addition to lower converged relative entropy (KL divergence). We demonstrate its efficacy on synthetic datasets where we can compute KL divergences exactly, as well as on a larger machine learning standard (MNIST). The proposed mode-assisted training can be applied in conjunction with any given gradient method, and is easily extended to more general energy-based neural network structures such as deep, convolutional and unrestricted Boltzmann machines. While widely adopted, contrastive divergence methods for Restricted Boltzmann Machines typically result in poor representations of the data distribution. Here, the authors propose an unsupervised training where gradient-descent is combined with the Machine's mode samples, significantly improving the final model quality.;2020;Not health related;Not health related
"Kahlen, JN; Würde, A; Andres, M; Moser, A";Improving Machine Learning Diagnostic Systems with Model-Based Data Augmentation - Part B: Application;Data augmentation can be used to train more robust machine-learning classifiers. Classically, synthetic data from a data augmentation are used to augment measurement datasets and use them for training of machine learning (ML) algorithms. However, the synthetic data often do not represent the measurements perfectly. This leads to insufficiently trained ML-models for real world application. In this paper, ML models are trained using only synthetic data. These ML models are then transferred to the available measurements utilizing transfer learning. This approach is showcased for the detection of a power and distribution transformer fault and benchmarked with state-of-the-art diagnostic systems. The performance of all diagnostic systems is analyzed by limiting the amount of fault-condition measurements available for the training process and by comparison of learning curves. It is shown that the model-based data augmentation combined with fine tuning is capable of improving the accuracy for the analyzed diagnostic task.;2021;Not health related;Not health related
"Long, NMH; Chung, WY";Reconstruction of Corrupted Photoplethysmography Signals Using Recursive Generative Adversarial Networks;This article explores how motion artifacts (MAs) affect photoplethysmography (PPG) signals measured from the radial artery of the wrist through our wearable system called WrisTee. We propose a recursive generative adversarial network (GAN) model that reconstructs corrupted PPG signals across a wide range of signal-to-noise ratios (SNRs) from -33 to 25 dB. To train and evaluate the model's performance, we constructed a dataset of PPG signals obtained from 15 subjects and developed an algorithm for generating synthetic noisy data. The proposed GAN model enables the measurement of heart rate (HR) from synthetic data with a mean absolute error (MAE) of 1.7 bpm. Finally, our model successfully processed 77% of PPG segments from real noisy data. This method provides a foundation for developing generative models aimed at reconstructing noisy PPG data affected by MAs, therefore enhancing the accuracy of personal health monitoring devices.;2024;Health related;Health related
"Lee, CS; Elgammal, A";Simultaneous inference of view and body pose using torus manifolds;Inferring 3D body pose as well as viewpoint from a single silhouette image is a challenging problem. We present a new generative model to represent shape deformations according to view and body configuration changes on a two dimensional manifold. We model the two continuous states by a product space (different configurations x different views) embedded on a conceptual two dimensional torus manifold. We learn a nonlinear mapping between torus manifold embedding and visual input (silhouettes) using empirical kernel mapping. Since every view and body pose has a corresponding embedding point on the torus manifold, inferring view and body pose from a given image becomes estimating the embedding point from a given input. As the shape varies in different people even in the same view and body pose, we extend our model to be adaptive to different people by decomposing person dependent style factors. Experimental results with real data as well as synthetic data show simultaneous estimation of view and body configuration from given silhouettes from unknown people.;2006;Not health related;Not health related
"Chu, ZG; He, JS; Peng, DD; Zhang, X; Zhu, NF";Differentially Private Denoise Diffusion Probability Models;Diffusion models and their variants have achieved high-quality image generation without adversarial training. These algorithms provide new ideas for data shortages in some fields. But the diffusion model also faces the same problem as other generative models: the learned probability density function will retain the characteristics of the training samples, which means that the high complexity of the deep network will make the model easily remember the training samples. When a diffusion model is applied to sensitive datasets, the distribution the model focuses on may reveal private information, and the security concerns described above become more pronounced. To address this challenge, this paper proposes a privacy diffusion model named DPDM (Differentially Private Denoise Diffusion Probability Models) that satisfies differential privacy by adding appropriate noise to the gradient during the training. Besides, this paper adopts a series of optimization strategies to improve model performance and training speed such as adaptive gradient clipping threshold and dynamic decay learning rate. Through the evaluation and analysis of the benchmark dataset, it is found that the attempt in this paper has promising usability, and the synthetic data has better performance.;2023;Not health related;Not health related
"Ni, H; Szpruch, L; Sabate-Vidales, M; Xiao, BR; Wiese, M; Liao, SJ";Sig-Wasserstein GANs for Time Series Generation;Synthetic data is an emerging technology that can significantly accelerate the development and deployment of AI machine learning pipelines. In this work, we develop high-fidelity time-series generators, the SigWGAN, by combining continuous-time stochastic models with the newly proposed signature W-1 metric. The former are the Logsig-RNN models based on the stochastic differential equations, whereas the latter originates from the universal and principled mathematical features to characterize the measure induced by time series. SigWGAN allows turning computationally challenging GAN min-max problem into supervised learning while generating high fidelity samples. We validate the proposed model on both synthetic data generated by popular quantitative risk models and empirical financial data. Codes are available at https://github.com/SigCGANs/Sig-Wasserstein-GANs.git;2021;Not health related;Not health related
"Zhao, QB; Zhou, GX; Zhang, LQ; Cichocki, A";TENSOR-VARIATE GAUSSIAN PROCESSES REGRESSION AND ITS APPLICATION TO VIDEO SURVEILLANCE;We present a novel framework for tensor valued Gaussian processes (GP) regression, which exploits a covariance function defined on tensor representation of data inputs. In this way, we bring together the powerful GP methods supported by Bayesian inference and higher-order tensor analysis techniques into one framework. This enables us to account for the underlying structure of data within the model, providing a powerful framework for structural data analysis, such as 3D video sequences. To this end, we propose a new kernel function with tensor arguments under the assumption of generative models, in the form of product kernels where a symmetrical Kullback-Leibler divergence measure is exploited to define the covariance function for tensorial data. A fully Bayesian treatment is employed to estimate the hyperparameters and infer the predictive distributions. Simulation results on both the synthetic data and a real world application of estimating the crowd size from 3D videos demonstrate the effectiveness of the proposed framework.;2014;Not health related;Health related
"Mei, HY; Eisner, J";The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process;Many events occur in the world. Some event types are stochastically excited or inhibited-in the sense of having their probabilities elevated or decreased-by patterns in the sequence of previous events. Discovering such patterns can help us predict which type of event will happen next and when. We model streams of discrete events in continuous time, by constructing a neurally self-modulating multivariate point process in which the intensities of multiple event types evolve according to a novel continuous-time LSTM. This generative model allows past events to influence the future in complex and realistic ways, by conditioning future event intensities on the hidden state of a recurrent neural network that has consumed the stream of past events. Our model has desirable qualitative properties. It achieves competitive likelihood and predictive accuracy on real and synthetic datasets, including under missing-data conditions.;2017;Not health related;Not health related
"Miao, JB; Liu, YW; Wang, K; Liu, JX; Xu, Z";VARIATIONAL DEPTH ESTIMATION ON HYPERSPHERE FOR PANORAMA;Depth estimation for panorama is a key part of 3D scene understanding, and adopting discriminative models is the most common solution. However, due to the rectangular convolution kernel, these existing learning methods cannot efficiently extract the distorted features in panoramas. To this end, we propose OmniVAE, a generative model based on Conditional Variational Auto-Encoder (CVAE) and von Mises-Fisher (vMF) distribution, to strengthen the exclusive generative ability for spherical signals by mapping panoramas to hypersphere space. Further, to alleviate the side effects of manifold-mismatching caused by non-planar distribution, we put forward the Atypical Receptive Field (ARF) module to slightly shift the receptive field of the network and even take the distribution difference into account in the reconstruction loss. The quantitative and qualitative evaluations are performed on real-world and synthetic datasets, and the results show that OmniVAE outperforms the state-of-the-art methods.;2022;Not health related;Not health related
"Aetesam, H; Maji, SK";Perceptually Motivated Generative Model for Magnetic Resonance Image Denoising;Image denoising is an important preprocessing step in low-level vision problems involving biomedical images. Noise removal techniques can greatly benefit raw corrupted magnetic resonance images (MRI). It has been discovered that the MR data is corrupted by a mixture of Gaussian-impulse noise caused by detector flaws and transmission errors. This paper proposes a deep generative model (GenMRIDenoiser) for dealing with this mixed noise scenario. This work makes four contributions. To begin, Wasserstein generative adversarial network (WGAN) is used in model training to mitigate the problem of vanishing gradient, mode collapse, and convergence issues encountered while training a vanilla GAN. Second, a perceptually motivated loss function is used to guide the training process in order to preserve the low-level details in the form of high-frequency components in the image. Third, batch renormalization is used between the convolutional and activation layers to prevent performance degradation under the assumption of non-independent and identically distributed (non-iid) data. Fourth, global feature attention module (GFAM) is appended at the beginning and end of the parallel ensemble blocks to capture the long-range dependencies that are often lost due to the small receptive field of convolutional filters. The experimental results over synthetic data and MRI stack obtained from real MR scanners indicate the potential utility of the proposed technique across a wide range of degradation scenarios.;2023;Health related;Health related
"Yu, S; Zhai, DH; Guan, YY; Xia, YQ";Category-Level 6-D Object Pose Estimation With Shape Deformation for Robotic Grasp Detection;Category-level 6-D object pose estimation plays a crucial role in achieving reliable robotic grasp detection. However, the disparity between synthetic and real datasets hinders the direct transfer of models trained on synthetic data to real-world scenarios, leading to ineffective results. Additionally, creating large-scale real datasets is a time-consuming and labor-intensive task. To overcome these challenges, we propose CatDeform, a novel category-level object pose estimation network trained on synthetic data but capable of delivering good performance on real datasets. In our approach, we introduce a transformer-based fusion module that enables the network to leverage multiple sources of information and enhance prediction accuracy through feature fusion. To ensure proper deformation of the prior point cloud to align with scene objects, we propose a transformer-based attention module that deforms the prior point cloud from both geometric and feature perspectives. Building upon CatDeform, we design a two-branch network for supervised learning, bridging the gap between synthetic and real datasets and achieving high-precision pose estimation in real-world scenes using predominantly synthetic data supplemented with a small amount of real data. To minimize reliance on large-scale real datasets, we train the network in a self-supervised manner by estimating object poses in real scenes based on the synthetic dataset without manual annotation. We conduct training and testing on CAMERA25 and REAL275 datasets, and our experimental results demonstrate that the proposed method outperforms state-of-the-art (SOTA) techniques in both self-supervised and supervised training paradigms. Finally, we apply CatDeform to object pose estimation and robotic grasp experiments in real-world scenarios, showcasing a higher grasp success rate.;2023;Not health related;Not health related
"Zhu, XG; Yin, ZC; Shi, JP; Li, HS; Lin, DH";Generative Adversarial Frontal View to Bird View Synthesis;Environment perception is an important task with great practical value and bird view is an essential part for creating panoramas of surrounding environment. Due to the large gap and severe deformation between the frontal view and bird view, generating a bird view image from a single frontal view is challenging. To tackle this problem, we propose the BridgeGAN, i.e., a novel generative model for bird view synthesis. First, an intermediate view, i.e., homography view, is introduced to bridge the large gap. Next, conditioned on the three views (frontal view, homography view and bird view) in our task, a multi-GAN based model is proposed to learn the challenging cross-view translation. Extensive experiments conducted on a synthetic dataset have demonstrated that the images generated by our model are much better than those generated by existing methods, with more consistent global appearance and sharper details. Ablation studies and discussions show its reliability and robustness in some challenging cases.;2018;Not health related;Not health related
"Yu, QC; Yu, ZW; Wang, Z; Wang, XF; Wang, YZ";Estimating posterior inference quality of the relational infinite latent feature model for overlapping community detection;Overlapping community detection has become a very hot research topic in recent decades, and a plethora of methods have been proposed. But, a common challenge in many existing overlapping community detection approaches is that the number of communities K must be predefined manually. We propose a flexible nonparametric Bayesian generative model for count-value networks, which can allow K to increase as more and more data are encountered instead of to be fixed in advance. The Indian buffet process was used to model the community assignment matrix Z, and an uncollapsed Gibbs sampler has been derived. However, as the community assignment matrix Z is a structured multi-variable parameter, how to summarize the posterior inference results and estimate the inference quality about Z, is still a considerable challenge in the literature. In this paper, a graph convolutional neural network based graph classifier was utilized to help to summarize the results and to estimate the inference quality about Z. We conduct extensive experiments on synthetic data and real data, and find that empirically, the traditional posterior summarization strategy is reliable.;2020;Not health related;Not health related
"Li, CE; Feng, GW; Li, YA; Liu, RY; Miao, QG; Chang, L";DiffTAD: Denoising diffusion probabilistic models for vehicle trajectory anomaly detection;Vehicle trajectory anomaly detection plays an essential role in the fields of traffic video surveillance, autonomous driving navigation, and taxi fraud detection. Deep generative models have been shown to be promising solutions for anomaly detection, avoiding the costs involved in manual labeling. However, existing popular generative models such as Generative Adversarial Networks (GANs) and Variational AutoEncoders (VAEs) are often plagued by training instability, mode collapse, and poor sample quality. To resolve the dilemma, we present DiffTAD, a novel vehicle trajectory anomaly detection framework based on the emerging diffusion models. DiffTAD formalizes anomaly detection as a noisy -to -normal process that progressively adds noise to the vehicle trajectory until the path is corrupted to pure Gaussian noise. The core idea of our framework is to devise deep neural networks to learn the reverse of the diffusion process and to detect anomalies by comparing the difference between a query trajectory and its reconstruction. DiffTAD is a parameterized Markov chain trained with variational inference and allows the mean square error to optimize the reweighted variational lower bound. In addition, DiffTAD integrates decoupled Transformer -based temporal and spatial encoders to model the temporal dependencies and spatial interactions among vehicles in the diffusion models. Experiments on the real -world trajectory dataset TRAFFIC demonstrate that our DiffTAD achieves significant improvements over existing state-of-the-art methods, with the maximum enhancements reaching 25.87% and 35.59% in terms of AUC and F1. While on the synthetic datasets CROSS, SynTra, and MAAD, the maximum improvements in AUC/F1 are 27.47%/38.56%, 25.38%/31.42%, and 58.22%/50.04%, respectively.;2024;Not health related;Not health related
"Chen, P; Liu, HY; Xin, RY; Carval, T; Zhao, JL; Xia, YN; Zhao, ZM";Effectively Detecting Operational Anomalies In Large-Scale IoT Data Infrastructures By Using A GAN-Based Predictive Model;Quality of data services is crucial for operational large-scale internet-of-things (IoT) research data infrastructure, in particular when serving large amounts of distributed users. Effectively detecting runtime anomalies and diagnosing their root cause helps to defend against adversarial attacks, thereby essentially boosting system security and robustness of the IoT infrastructure services. However, conventional anomaly detection methods are inadequate when facing the dynamic complexities of these systems. In contrast, supervised machine learning methods are unable to exploit large amounts of data due to the unavailability of labeled data. This paper leverages popular GAN-based generative models and end-to-end one-class classification to improve unsupervised anomaly detection. A novel heterogeneous BiGAN-based anomaly detection model Heterogeneous Temporal Anomaly-reconstruction GAN (HTA-GAN) is proposed to make better use of a one-class classifier and a novel anomaly scoring function. The Generator-Encoder-Discriminator BiGAN structure can lead to practical anomaly score computation and temporal feature capturing. We empirically compare the proposed approach with several state-of-the-art anomaly detection methods on real-world datasets, anomaly benchmarks and synthetic datasets. The results show that HTA-GAN outperforms its competitors and demonstrates better robustness.;2022;Not health related;Not health related
"Antelmi, L; Ayache, N; Robert, P; Lorenzi, M";Sparse Multi-Channel Variational Autoencoder for the Joint Analysis of Heterogeneous Data;Interpretable modeling of heterogeneous data channels is essential in medical applications, for example when jointly analyzing clinical scores and medical images. Variational Autoencoders (VAE) are powerful generative models that learn representations of complex data. The flexibility of VAE may come at the expense of lack of interpretability in describing the joint relationship between heterogeneous data. To tackle this problem, in this work we extend the variational framework of VAE to bring parsimony and interpretability when jointly account for latent relationships across multiple channels. In the latent space, this is achieved by constraining the variational distribution of each channel to a common target prior. Parsimonious latent representations are enforced by variational dropout. Experiments on synthetic data show that our model correctly identifies the prescribed latent dimensions and data relationships across multiple testing scenarios. When applied to imaging and clinical data, our method allows to identify the joint effect of age and pathology in describing clinical condition in a large scale clinical cohort.;2019;Health related;Health related
"Salazar, A; Vergara, L; Serrano, A; Igual, J";A general procedure for learning mixtures of independent component analyzers;This paper presents a new procedure for learning mixtures of independent component analyzers. The procedure includes non-parametric estimation of the source densities, supervised-unsupervised learning of the model parameters, incorporation of any independent component analysis (ICA) algorithm into the learning of the ICA mixtures, and estimation of residual dependencies after training for correction of the posterior probability of every class to the testing observation vector. We demonstrate the performance of the procedure in the classification of ICA mixtures of two, three, and four classes of synthetic data, and in the classification of defective materials, consisting of 3D finite element models and lab specimens, in non-destructive testing using the impact-echo technique. The application of the proposed posterior probability correction demonstrates an improvement in the classification accuracy. Semi-supervised learning shows that unlabeled data can degrade the performance of the classifier when they do not fit the generative model. Comparative results of the proposed method and standard ICA algorithms for blind source separation in one and multiple ICA data mixtures show the suitability of the non-parametric ICA mixture-based method for data modeling. (C) 2009 Elsevier Ltd. All rights reserved.;2010;Not health related;Not health related
"Sánchez-Gutiérrez, ME; González-Pérez, PP";Addressing the class imbalance in tabular datasets from a generative adversarial network approach in supervised machine learning;One common issue with datasets used for supervised classification tasks is data imbalance or the unequal distribution of classes within a dataset. The class imbalance may cause biased machine learning models to favor the dominant class, misclassifying the minority class. Specific techniques can be employed to deal with the issue of class imbalance, including resampling by oversampling or undersampling and ensemble approaches. Besides, generative adversarial networks, a deep learning technique for building generative models, offer an alternative machine learning technique that is particularly well suited to address the class imbalance problem. This work introduces a machine learning-based approach to deal with the class imbalance in a cancer intracellular signaling dataset produced by a verified and validated computer simulation. Specifically, we use synthetic data generation to increase and balance the dataset generated by the computational simulation. The used approach simulates the oversampling method by employing a generative adversarial network to produce new examples for the minority class. Subsequently, we applied supervised machine learning methods, such as the K-NN algorithm, to assess whether or not the classification accuracy improved relative to the unbalanced dataset. The results presented in this work have shown an accuracy increase in the classification of patterns belonging to the minority class, with an improvement of 24.5%.;2023;Not health related;Health related
"Lucas, T; Tallec, C; Verbeek, J; Ollivier, Y";Mixed batches and symmetric discriminators for GAN training;Generative adversarial networks (GANs) are powerful generative models based on providing feedback to a generative network via a discriminator network. However, the discriminator usually assesses individual samples. This prevents the discriminator from accessing global distributional statistics of generated samples, and often leads to mode dropping: the generator models only part of the target distribution. We propose to feed the discriminator with mixed batches of true and fake samples, and train it to predict the ratio of true samples in the batch. The latter score does not depend on the order of samples in a batch. Rather than learning this invariance, we introduce a generic permutation-invariant discriminator architecture. This architecture is provably a universal approximator of all symmetric functions. Experimentally, our approach reduces mode collapse in GANs on two synthetic datasets, and obtains good results on the CIFAR10 and CelebA datasets, both qualitatively and quantitatively.;2018;Not health related;Not health related
"Ramesh, L; Murthy, CR; Tyagi, H";Multiple Support Recovery Using Very Few Measurements Per Sample;In the problem of multiple support recovery, we are given access to linear measurements of multiple sparse samples in R-d. These samples can be partitioned into l groups, with samples having the same support belonging to the same group. For a given budget of m measurements per sample, the goal is to recover the l underlying supports, in the absence of the knowledge of group labels. We study this problem with a focus on the measurement-constrained regime where m is smaller than the support size k of each sample. We design a two-step procedure that estimates the union of the underlying supports first, and then uses a spectral algorithm to estimate the individual supports. Our proposed estimator can recover the supports with m < k measurements per sample, from <(O)over tilde> (k(4) l(4)/m(4)) samples. Our guarantees hold for a general, generative model assumption on the samples and measurement matrices. We also provide results from experiments conducted on synthetic data and on the MNIST dataset.;2022;Not health related;Not health related
"Grande, RC; Walsh, TJ; Chowdhary, G; Ferguson, S; How, JP";Online Regression for Data With Changepoints Using Gaussian Processes and Reusable Models;Many prediction, decision-making, and control architectures rely on online learned Gaussian process (GP) models. However, most existing GP regression algorithms assume a single generative model, leading to poor predictive performance when the data are nonstationary, i.e., generated from multiple switching processes. Furthermore, existing methods for GP regression over nonstationary data require significant computation, do not come with provable guarantees on correctness and speed, and many only work in batch settings, making them ill-suited for real-time prediction. We present an efficient online GP framework, GP-non-Bayesian clustering (GP-NBC), which addresses these computational and theoretical issues, allowing for real-time changepoint detection and regression using GPs. Our empirical results on two real-world data sets and two synthetic data set show that GP-NBC outperforms state-of-the-art methods for nonstationary regression in terms of both regression error and computation. For example, it outperforms Dirichlet process GP clustering with Gibbs sampling by 98% in computation time reduction while the mean absolute error is comparable.;2017;Not health related;Not health related
"Frisch, Y; Fuchs, M; Sanner, A; Ucar, FA; Frenzel, M; Wasielica-Poslednik, J; Gericke, A; Wagner, FM; Dratsch, T; Mukhopadhyay, A";Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models;Cataract surgery is a frequently performed procedure that demands automation and advanced assistance systems. However, gathering and annotating data for training such systems is resource intensive. The publicly available data also comprises severe imbalances inherent to the surgical process. Motivated by this, we analyse cataract surgery video data for the worst-performing phases of a pre-trained downstream tool classifier. The analysis demonstrates that imbalances deteriorate the classifier's performance on underrepresented cases. To address this challenge, we utilise a conditional generative model based on Denoising Diffusion Implicit Models (DDIM) and Classifier-Free Guidance (CFG). Our model can synthesise diverse, high-quality examples based on complex multi-class multi-label conditions, such as surgical phases and combinations of surgical tools. We affirm that the synthesised samples display tools that the classifier recognises. These samples are hard to differentiate from real images, even for clinical experts with more than five years of experience. Further, our synthetically extended data can improve the data sparsity problem for the downstream task of tool classification. The evaluations demonstrate that the model can generate valuable unseen examples, allowing the tool classifier to improve by up to 10% for rare cases. Overall, our approach can facilitate the development of automated assistance systems for cataract surgery by providing a reliable source of realistic synthetic data, which we make available for everyone.;2023;Health related;Health related
"Katrolia, JS; Krämer, L; Rambach, J; Mirbach, B; Stricker, D";An Adversarial Training based Framework for Depth Domain Adaptation;In absence of sufficient labeled training data, it is common practice to resort to synthetic data with readily available annotations. However, some performance gap still exists between deep learning models trained on synthetic versus on real data. Using adversarial training based generative models, it is possible to translate images from synthetic to real domain and train on them easily generalizable models for real-world datasets, but the efficiency of this method is limited in the presence of large domain shifts such as between synthetic and real depth images characterized by depth sensor and scene dependent artifacts in the image. In this paper, we present an adversarial training based framework for adapting depth images from synthetic to real domain. We use a cyclic loss together with an adversarial loss to bring the two domains of synthetic and real depth images closer by translating synthetic images to real domain, and demonstrate the usefulness of synthetic images modified this way for training deep neural networks that can perform well on real images. We demonstrate our method for the application of person detection and segmentation in real-depth images captured in a car for in-cabin person monitoring. We also show through experiments the effect of using target domain image sets captured using different types of depth sensors on this domain adaptation approach.;2021;Not health related;Not health related
"Bird, JJ; Faria, DR; Premebida, C; Ekárt, A; Ayrosa, PPS";Overcoming Data Scarcity in Speaker Identification: Dataset Augmentation with Synthetic MFCCs via Character-level RNN;Autonomous speaker identification suffers issues of data scarcity due to it being unrealistic to gather hours of speaker audio to form a dataset, which inevitably leads to class imbalance in comparison to the large data availability from non-speakers since large-scale speech datasets are available online. In this study, we explore the possibility of improving speaker recognition by augmenting the dataset with synthetic data produced by training a Character-level Recurrent Neural Network on a short clip of five spoken sentences. A deep neural network is trained on a selection of the Flickr8k dataset as well as the real and synthetic speaker data (all in the form of MFCCs) as a binary classification problem in order to discern the speaker from the Flickr speakers. Ranging from 2,500 to 10,000 synthetic data objects, the network weights are then transferred to the original dataset of only Flickr8k and the real speaker data, in order to discern whether useful rules can be learnt from the synthetic data. Results for all three subjects show that fine-tune learning from datasets augmented with synthetic speech improve the classification accuracy, F1 score, precision, and the recall when applied to the scarce real data vs non-speaker data. We conclude that even with just five spoken short sentences, data augmentation via synthetic speech data generated by a Char-RNN can improve the speaker classification process. Accuracy and related metrics are shown to improve from around 93% to 99% for three subjects classified from thousands of others when fine-tuning from exposure to 2500-1000 synthetic data points. High F1 scores, precision and recall also show that issues due to class imbalance are also solved.;2020;Not health related;Not health related
"Adenle, OA; Fitzgerald, WJ";A Gibbs sampling approach to independent factor analysis;We present a Gibbs sampler for estimating parameters of the Independent Factor model. Independent Factor Analysis (IFA) is a generalization of Mixtures of Factor Analyzers, where instead we learn nonlinear subspaces in data. IFA can also be considered a method for blind source separation. The IFA generative model is hierarchical, with each factor modeled as an independent Mixture of Gaussians, each mixture component representing a factor state. Computing expectations over factors quickly becomes intractable with increasing number of factors as this requires summation over exponentially many state configurations, making parameter estimation via Expectation Maximization (EM) with an exact E-step infeasible. Unlike the Variational method that has been proposed, we take a simulation based approach to obtain exact parameter estimates. We define prior distributions and use a Gibbs sampler to obtain samples from the parameter posterior. Application to synthetic data demonstrates effectiveness of the method in estimating model parameters and robustness to model permutation invariance.;2006;Not health related;Not health related
"Jang, TE; Zheng, F; Wang, XQ";Constructing a Fair Classifier with the Generated Fair Data;Fairness in machine learning is getting rising attention as it is directly related to real-world applications and social problems. Recent methods have been explored to alleviate the discrimination between certain demographic groups that are characterized by sensitive attributes (such as race, age, or gender). Some studies have found that the data itself is biased, so training directly on the data causes unfair decision making. Models directly trained on raw data can replicate or even exacerbate bias in the prediction between demographic groups. This leads to vastly different prediction performance in different demographic groups. In order to address this issue, we propose a new approach to improve machine learning fairness by generating fair data. We introduce a generative model to generate cross-domain samples w.r.t. multiple sensitive attributes. This ensures that we can generate infinite number of samples that are balanced w.r.t. both target label and sensitive attributes to enhance fair prediction. By training the classifier solely with the synthetic data and then transfer the model to real data, we can overcome the under-representation problem which is non-trivial since collecting real data is extremely time and resource consuming. We provide empirical evidence to demonstrate the benefit of our model with respect to both fairness and accuracy.;2021;Not health related;Not health related
"Tai, CY; Wang, WJ; Huang, YM";Using Time-Series Generative Adversarial Networks to Synthesize Sensing Data for Pest Incidence Forecasting on Sustainable Agriculture;"A sufficient amount of data is crucial for high-performance and accurate trend prediction. However, it is difficult and time-consuming to collect agricultural data over long periods of time; the consequence of such difficulty is datasets that are characterized by missing data. In this study we use a time-series generative adversarial network (TimeGAN) to synthesize multivariate agricultural sensing data and train RNN (Recurrent Neural Network), LSTM (Long Short-Term Memory), and GRU (Gated Recurrent Unit) neural network prediction models on the original and generated data to predict future pest populations. After our experiment, the data generated using TimeGAN and the original data have the smallest EC value in the GRU model, which is 9.86. The results show that the generative model effectively synthesizes multivariate agricultural sensing data and can be used to make up for the lack of actual data. The pest prediction model trained on synthetic data using time-series data generation yields results that are similar to that of the model trained on actual data. Accurate prediction of pest populations would represent a breakthrough in allowing for accurate and timely pest control.";2023;Not health related;Not health related
"Bao, JW; Tang, DY; Duan, N; Yan, Z; Lv, YH; Zhou, M; Zhao, TJ";Table-to-Text: Describing Table Region with Natural Language;In this paper, we present a generative model to generate a natural language sentence describing a table region, e.g., a row. The model maps a row from a table to a continuous vector and then generates a natural language sentence by leveraging the semantics of a table. To deal with rare words appearing in a table, we develop a flexible copying mechanism that selectively replicates contents from the table in the output sequence. Extensive experiments demonstrate the accuracy of the model and the power of the copying mechanism. On two synthetic datasets, WIKIBIO and SIMPLEQUESTIONS, our model improves the current state-of-the-art BLEU-4 score from 34.70 to 40.26 and from 33.32 to 39.12, respectively. Furthermore, we introduce an open-domain dataset WIKITABLETEXT including 13,318 explanatory sentences for 4,962 tables. Our model achieves a BLEU-4 score of 38.23, which outperforms template based and language model based approaches.;2018;Not health related;Not health related
"Lu, C; Zheng, KW; Bao, F; Chen, JF; Li, CX; Zhu, J";Maximum Likelihood Training for Score-Based Diffusion ODEs by High-Order Denoising Score Matching;"Score-based generative models have excellent performance in terms of generation quality and likelihood. They model the data distribution by matching a parameterized score network with first-order data score functions. The score network can be used to define an ODE (score-based diffusion ODE) for exact likelihood evaluation. However, the relationship between the likelihood of the ODE and the score matching objective is unclear. In this work, we prove that matching the first-order score is not sufficient to maximize the likelihood of the ODE, by showing a gap between the maximum likelihood and score matching objectives. To fill up this gap, we show that the negative likelihood of the ODE can be bounded by controlling the first, second, and third-order score matching errors; and we further present a novel highorder denoising score matching method to enable maximum likelihood training of score-based diffusion ODEs. Our algorithm guarantees that the higher-order matching error is bounded by the training error and the lower-order errors. We empirically observe that by high-order score matching, score-based diffusion ODEs achieve better likelihood on both synthetic data and CIFAR-10, while retaining the high generation quality.";2022;Not health related;Not health related
"Kang, ZW; Mukhopadhyay, A; Gokhale, A; Wen, SJ; Dubey, A";Traffic Anomaly Detection Via Conditional Normalizing Flow;Traffic congestion anomaly detection is of paramount importance in intelligent traffic systems. The goals of transportation agencies are two-fold: to monitor the general traffic conditions in the area of interest and to locate road segments under abnormal congestion states. Modeling congestion patterns can achieve these goals for citywide roadways, which amounts to learning the distribution of multivariate time series (MTS). However, existing works are either not scalable or unable to capture the spatial-temporal information in MTS simultaneously. To this end, we propose a principled and comprehensive framework consisting of a data-driven generative approach that can perform tractable density estimation for detecting traffic anomalies. Our approach first clusters segments in the feature space and then uses conditional normalizing flow to identify anomalous temporal snapshots at the cluster level in an unsupervised setting. Then, we identify anomalies at the segment level by using a kernel density estimator on the anomalous cluster. Extensive experiments on synthetic datasets show that our approach significantly outperforms several stateof-the-art congestion anomaly detection and diagnosis methods in terms of Recall and F1-Score. We also use the generative model to sample labeled data, which can train classifiers in a supervised setting, alleviating the lack of labeled data for anomaly detection in sparse settings.;2022;Not health related;Not health related
"Pineau, E; Razakarivony, S; Bonald, T";Seq2VAR: Multivariate Time Series Representation with Relational Neural Networks and Linear Autoregressive Model;Finding understandable and meaningful feature representation of multivariate time series (MTS) is a difficult task, since information is entangled both in temporal and spatial dimensions. In particular, MTS can be seen as the observation of simultaneous causal interactions between dynamical variables. Standard way to model these interactions is the vector linear autoregression (VAR). The parameters of VAR models can be used as MTS feature representation. Yet, VAR cannot generalize on new samples, hence independent VAR models must be trained to represent different MTS. In this paper, we propose to use the inference capacity of neural networks to overpass this limit. We propose to associate a relational neural network to a VAR generative model to form an encoder-decoder of MTS. The model is denoted Seq2VAR for Sequence-to-VAR. We use recent advances in relational neural network to build our MTS encoder by explicitly modeling interactions between variables of MTS samples. We also propose to leverage reparametrization tricks for binomial sampling in neural networks in order to build a sparse version of Seq2VAR and find back the notion of Granger causality defined in sparse VAR models. We illustrate the interest of our approach through experiments on synthetic datasets.;2020;Not health related;Not health related
"Ickin, S; Vandikas, K; Moradi, F; Taghia, J; Hu, WF";Ensemble-based Synthetic Data Synthesis for Federated QoE Modeling;Quality of Experience (QoE) models need good generalization that necessitates sufficient amount of user-labeled datasets associated with measurements related to underlying QoE factors. However, obtaining QoE datasets is often costly, since they are preferably collected from many subjects with diverse background, and eventually dataset sizes and representations are limited. Models can be improved by sharing and merging those collected local datasets, however regulations such as GDPR make data sharing difficult, as those local user datasets might contain sensitive information about the subjects. A privacy-preserving machine learning approach such as Federated Learning (FL) is a potential candidate that enables sharing of QoE data models between collaborators without exposing ground truth, but only by means of sharing the securely aggregated form of extracted model parameters. While FL can enable a seamless QoE model management, if collaborators do not have the same level of data quality, more iterations of information sharing over a communication channel might be necessary for models to reach an acceptable accuracy. In this paper, we present an ensemble based Bayesian synthetic data generation method for FL, LOO (Leave-One-Out), which reduces the training time by 30% and the network footprint in the communication channel by 60%.;2020;Not health related;Not health related
"Chen, QL; Ye, AY; Zhang, YX; Chen, JW; Huang, C";An intra-class distribution-focused generative adversarial network approach for imbalanced tabular data learning;Data imbalance is a critical factor that adversely affects the performance of machine learning algorithms. It leads to deviations in decision boundaries, resulting in biased predictions towards the majority class and inaccurate classification of the minority class. Although oversampling the minority class using deep generative models is a popular strategy, many existing methods focus solely on enhancing data for the minority class while overlooking the distribution relationship within and between classes. Therefore, we propose an oversampling method that merges unsupervised clustering and generative adversarial network (GAN) to facilitate the imbalanced tabular data learning. First, we perform preprocessing (clustering) on the original data, remove clusters that do not require sampling and generate more samples for sparsely distributed minority class clusters to achieve sample balance within the minority class. Moreover, we design a CTGAN-based auxiliary classifier GAN (ACCTGAN) to generate the minority class. It enhances the semantic integrity of the synthetic data and avoids generating noisy samples. We conducted validation experiments comparing our approach to 7 typical methods on 12 real tabular datasets. Our method shows excellent performance in F1-measure and area under the curve (AUC), obtaining 19 and 20 best results on the three classifiers, respectively. It significantly enhances classification results and demonstrates good robustness and stability.;2024;Not health related;Not health related
"Taniguchi, T; Nagasaka, S; Nakashima, R";Nonparametric Bayesian Double Articulation Analyzer for Direct Language Acquisition From Continuous Speech Signals;"Human infants can discover words directly from unsegmented speech signals without any explicitly labeled data. Current machine learning methods cannot efficiently estimate language model (LM) and acoustic model (AM) and discover words directly from continuous human speech signals in an unsupervised manner. To solve this problem, we propose an integrative generative model that combines an LM and an AM into a single generative model called the hierarchical Dirichlet process hidden LM (HDP-HLM). The HDP-HLM is obtained by extending the hierarchical Dirichlet process hidden semi-Markov model (HDP-HSMM) proposed by Johnson et al. An inference procedure for the HDP-HLM is derived using the blocked Gibbs sampler originally proposed for the HDP-HSMM. This procedure enables the simultaneous and direct inference of LM and AM from continuous speech signals. Based on the HDP-HLM and its inference procedure, we develop a novel machine learning method called nonparametric Bayesian double articulation analyzer (NPB-DAA) that can directly acquire LM and AM from observed continuous speech signals. By assuming HDP-HLM as a generative model of observed time series data, and by inferring latent variables of the model, the method can analyze latent double articulation structure, i.e., hierarchically organized latent words and phonemes, of the data in an unsupervised manner. We also carried out two evaluation experiments using synthetic data and actual human continuous speech signals representing Japanese vowel sequences. In the word acquisition and phoneme categorization tasks, the NPB-DAA outperformed a conventional double articulation analyzer and baseline automatic speech recognition system whose AM was trained in a supervised manner. The main contributions of this paper are as follows: 1) we develop a probabilistic generative model that integrates LM and AM, i.e., HDP-HLM; 2) we derive an inference method for this, and propose the NPB-DAA; and 3) we show that the NPB-DAA can discover words directly from continuous human speech signals in an unsupervised manner.";2016;Not health related;Not health related
"Kim, M; Pavlovic, V";Conditional state space models for discriminative motion estimation;We consider the problem of predicting a sequence of real-valued multivariate states from a given measurement sequence. Its typical application in computer vision is the task of motion estimation. State Space Models are widely used generative probabilistic models for the problem. Instead of jointly modeling states and measurements, we propose a novel discriminative undirected graphical model which conditions the states on the measurements while exploiting the sequential structure of the problem. The major benefits of this approach are: (1) It focuses on the ultimate prediction task while avoiding probably unnecessary effort in modeling the measurement density, (2) It relaxes generative models' assumption that the measurements are independent given the states, and (3) The proposed inference algorithm takes linear time in the measurement dimension as opposed to the cubic time for Kalman filtering, which allows us to incorporate large numbers of measurement features. We show that the parameter learning can be cast as an instance of convex optimization. We also provide efficient convex optimization methods based on theorems from linear algebra. The performance of the proposed model is evaluated on both synthetic data and the human body pose estimation from silhouette videos.;2007;Not health related;Not health related
"Theisen, R; Wang, H; Varshney, LR; Xiong, CM; Socher, R";Evaluating State-of-the-Art Classification Models Against Bayes Optimality;Evaluating the inherent difficulty of a given data-driven classification problem is important for establishing absolute benchmarks and evaluating progress in the field. To this end, a natural quantity to consider is the Bayes error, which measures the optimal classification error theoretically achievable for a given data distribution. While generally an intractable quantity, we show that we can compute the exact Bayes error of generative models learned using normalizing flows. Our technique relies on a fundamental result, which states that the Bayes error is invariant under invertible transformation. Therefore, we can compute the exact Bayes error of the learned flow models by computing it for Gaussian base distributions, which can be done efficiently using Holmes-Diaconis-Ross integration. Moreover, we show that by varying the temperature of the learned flow models, we can generate synthetic datasets that closely resemble standard benchmark datasets, but with almost any desired Bayes error. We use our approach to conduct a thorough investigation of state-of-the-art classification models, and find that in some - but not all - cases, these models are capable of obtaining accuracy very near optimal. Finally, we use our method to evaluate the intrinsic hardness of standard benchmark datasets.;2021;Not health related;Not health related
"Daunizeau, J; Grova, C; Marrelec, G; Mattout, J; Jbabdi, S; Pélégrini-Issac, M; Lina, JM; Benali, H";Symmetrical event-related EEG/fMRI information fusion in a variational Bayesian framework;In this work, we propose a symmetrical multimodal EEG/fMRI information fusion approach dedicated to the identification of event-related bioelectric and hemodynamic responses. Unlike existing, asymmetrical EEG/fMRI data fusion algorithms, we build a joint EEG/fMRI generative model that explicitly accounts for local coupling/uncoupling of bioelectric and hemodynamic activities, which are supposed to share a common substrate. Under a dedicated assumption of spatio-temporal separability, the spatial profile of the common EEG/fMRI sources is introduced as an unknown hierarchical prior on both markers of cerebral activity. Thereby, a devoted Variational Bayesian (VB) learning scheme is derived to infer common EEG/fMRI sources from a joint EEG/fMRI dataset. This yields an estimate of the common spatial profile, which is built as a trade-off between information extracted from EEG and fMRI datasets. Furthermore, the spatial structure of the EEG/fMRI coupling/uncoupling is learned exclusively from the data. The proposed data generative model and devoted VBEM learning scheme thus provide an un-supervised well-balanced approach for the fusion of EEG/fMRI information. We first demonstrate our approach on synthetic data. Results show that, in contrast to classical EEG/fMRI fusion approach, the method proved efficient and robust regardless of the EEG/fMRI discordance level. We apply the method on EEG/fMRI recordings from a patient with epilepsy, in order to identify brain areas involved during the generation of epileptic spikes. The results are validated using intracranial EEG measurements. (C) 2007 Elsevier Inc. All rights reserved.;2007;Health related;Health related
"García-Jara, G; Protopapas, P; Estévez, PA";Improving Astronomical Time-series Classification via Data Augmentation with Generative Adversarial Networks;Due to the latest advances in technology, telescopes with significant sky coverage will produce millions of astronomical alerts per night that must be classified both rapidly and automatically. Currently, classification consists of supervised machine-learning algorithms whose performance is limited by the number of existing annotations of astronomical objects and their highly imbalanced class distributions. In this work, we propose a data augmentation methodology based on generative adversarial networks (GANs) to generate a variety of synthetic light curves from variable stars. Our novel contributions, consisting of a resampling technique and an evaluation metric, can assess the quality of generative models in unbalanced data sets and identify GAN-overfitting cases that the Frechet inception distance does not reveal. We applied our proposed model to two data sets taken from the Catalina and Zwicky Transient Facility surveys. The classification accuracy of variable stars is improved significantly when training with synthetic data and testing with real data with respect to the case of using only real data.;2022;Not health related;Not health related
"Davtyan, A; Favaro, P";Controllable Video Generation Through Global and Local Motion Dynamics;We present GLASS, a method for Global and Local Action-driven Sequence Synthesis. GLASS is a generative model that is trained on video sequences in an unsupervised manner and that can animate an input image at test time. The method learns to segment frames into foreground-background layers and to generate transitions of the foregrounds over time through a global and local action representation. Global actions are explicitly related to 2D shifts, while local actions are instead related to (both geometric and photometric) local deformations. GLASS uses a recurrent neural network to transition between frames and is trained through a reconstruction loss. We also introduce W-Sprites (Walking Sprites), a novel synthetic dataset with a predefined action space. We evaluate our method on both W-Sprites and real datasets, and find that GLASS is able to generate realistic video sequences from a single input image and to successfully learn a more advanced action space than in prior work. Further details, the code and example videos are available at https://araachie.github.io/glass/.;2022;Not health related;Not health related
"Joyce, T; Kozerke, S";3D Medical Image Synthesis by Factorised Representation and Deformable Model Learning;In this paper we propose a model for controllable synthesis of 3D (volumetric) medical image data. The model is comprised of three components which are learnt simultaneously from unlabelled data through self-supervision: (i) a multi-tissue anatomical model, (ii) a probability distribution over deformations of this anatomical model, and, (iii) a probability distribution over 'renderings' of the anatomical model (where a rendering defines the relationship between anatomy and resulting pixel intensities). After training, synthetic data can be generated by sampling the deformation and rendering distributions. To encourage meaningful correspondence in the learnt anatomical model the renderer is kept simple during training, however once trained the (deformed) anatomical model provides dense multi-class segmentation masks for all training volumes, which can be used directly for state-of-the-art conditional image synthesis. This factored model based approach to data synthesis has a number of advantages: Firstly, it allows for coherent synthesis of realistic 3D data, as it is only necessary to learn low dimensional generative models (over deformations and renderings) rather than over the high dimensional 3D images themselves. Secondly, as a by-product of the anatomical model we implicitly learn a dense correspondence between all training volumes, which can be used for registration, or one-shot segmentation (through label transfer). Lastly, the factored representation allows for modality transfer (rendering one image in the modality of another), and meaningful interpolation between volumes. We demonstrate the proposed approach on cardiac MR, and multi-modal abdominal MR/CT datasets.;2019;Health related;Health related
"Vasylechko, SD; Warfield, SK; Kurugol, S; Afacan, O";Improved myelin water fraction mapping with deep neural networks using synthetically generated 3D data;We introduce a generative model for synthesis of large scale 3D datasets for quantitative parameter mapping of myelin water fraction (MWF). Our model combines a MR physics signal decay model with an accurate probabilistic multi-component parametric T2 model. We synthetically generate a wide variety of high quality signals and corresponding parameters from a wide range of naturally occurring prior parameter values. To capture spatial variation, the generative signal decay model is combined with a generative spatial model conditioned on generic tissue segmentations. Synthesized 3D datasets can be used to train any convolutional neural network (CNN) based architecture for MWF estimation. Our source code is available at: https://github. com/quin-med-harvard-edu/synthmap Reduction of acquisition time at the expense of lower SNR, as well as accuracy and repeatability of MWF estimation techniques, are key factors that affect the adoption of MWF mapping in clinical practice. We demonstrate that the synthetically trained CNN provides superior accuracy over the competing methods under the constraints of naturally occurring noise levels as well as on the synthetically generated images at low SNR levels. Normalized root mean squared error (nRMSE) is less than 7% on synthetic data, which is significantly lower than competing methods. Additionally, the proposed method yields a coefficient of variation (CoV) that is at least 4x better than the competing method on intra-session test-retest reference dataset.;2024;Health related;Health related
"Piatkowski, N; Lee, S; Morik, K";Integer undirected graphical models for resource-constrained systems;Machine learning on resource-constrained ubiquitous devices suffers from high energy consumption and slow execution. The number of clock cycles that is consumed by arithmetic instructions has an immediate impact on both. In computer systems, the number of consumed cycles depends on particular operations and the types of their operands. We propose a new class of probabilistic graphical models that approximates the full joint probability distribution of discrete multivariate random variables by relying only on integer addition/multiplication and binary bit shift operations. This allows us to sample from high-dimensional generative models and to use structured discriminative classifiers even on computational devices with slow floating point units or in situations where energy has to be saved. While theory and experiments on random synthetic data suggest that hard instances (leading to a large approximation error) exist, experiments on benchmark and real-world data show that the integer models achieve qualitatively the same results as their double-precision counterparts. Moreover, clock cycle consumption on two hardware platforms is regarded, where our results show that resource savings due to integer approximation is even larger on low-end hardware. The integer models consume half of the clock cycles and a small fraction of memory compared to ordinary undirected graphical models. (C) 2015 Elsevier B.V. All rights reserved.;2016;Not health related;Not health related
"Kapp, A; Hansmeyer, J; Mihaljevic, H";Generative Models for Synthetic Urban Mobility Data: A Systematic Literature Review;Although highly valuable for a variety of applications, urban mobility data are rarely made openly available, as it contains sensitive personal information. Synthetic data aims to solve this issue by generating artificial data that resembles an original dataset in structural and statistical characteristics, but omits sensitive information. For mobility data, a large number of corresponding models have been proposed in the past decade. This systematic review provides a structured comparative overview of the current state of this heterogeneous, active field of research. A special focus is put on the applicability of the reviewed models in practice.;2024;Not health related;Not health related
"Saitta, S; Maga, L; Armour, C; Votta, E; O'Regan, DP; Salmasi, MY; Athanasiou, T; Weinsaft, JW; Xu, XY; Pirola, S; Redaelli, A";Data-driven generation of 4D velocity profiles in the aneurysmal ascending aorta;Background and Objective : Numerical simulations of blood flow are a valuable tool to investigate the pathophysiology of ascending thoratic aortic aneurysms (ATAA). To accurately reproduce in vivo hemo-dynamics, computational fluid dynamics (CFD) models must employ realistic inflow boundary conditions (BCs). However, the limited availability of in vivo velocity measurements, still makes researchers resort to idealized BCs. The aim of this study was to generate and thoroughly characterize a large dataset of syn-thetic 4D aortic velocity profiles sampled on a 2D cross-section along the ascending aorta with features similar to clinical cohorts of patients with ATAA.Methods : Time-resolved 3D phase contrast magnetic resonance (4D flow MRI) scans of 30 subjects with ATAA were processed through in-house code to extract anatomically consistent cross-sectional planes along the ascending aorta, ensuring spatial alignment among all planes and interpolating all velocity fields to a reference configuration. Velocity profiles of the clinical cohort were extensively characterized by computing flow morphology descriptors of both spatial and temporal features. By exploiting principal component analysis (PCA), a statistical shape model (SSM) of 4D aortic velocity profiles was built and a dataset of 437 synthetic cases with realistic properties was generated.Results : Comparison between clinical and synthetic datasets showed that the synthetic data presented similar characteristics as the clinical population in terms of key morphological parameters. The average velocity profile qualitatively resembled a parabolic-shaped profile, but was quantitatively characterized by more complex flow patterns which an idealized profile would not replicate. Statistically significant correlations were found between PCA principal modes of variation and flow descriptors.Conclusions : We built a data-driven generative model of 4D aortic inlet velocity profiles, suitable to be used in computational studies of blood flow. The proposed software system also allows to map any of the generated velocity profiles to the inlet plane of any virtual subject given its coordinate set.(c) 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ );2023;Health related;Health related
"Hasegawa, K; Moriwaki, Y; Terada, T; Wei, C; Shimizu, K";Feedback-AVPGAN: Feedback-guided generative adversarial network for generating antiviral peptides;"In this study, we propose Feedback-AVPGAN, a system that aims to computationally generate novel antiviral peptides (AVPs). This system relies on the key premise of the Generative Adversarial Network (GAN) model and the Feedback method. GAN, a generative modeling approach that uses deep learning methods, comprises a generator and a discriminator. The generator is used to generate peptides; the generated proteins are fed to the discriminator to distinguish between the AVPs and non-AVPs. The original GAN design uses actual data to train the discriminator. However, not many AVPs have been experimentally obtained. To solve this problem, we used the Feedback method to allow the discriminator to learn from the existing as well as generated synthetic data. We implemented this method using a classifier module that classifies each peptide sequence generated by the GAN generator as AVP or non-AVP. The classifier uses the transformer network and achieves high classification accuracy. This mechanism enables the efficient generation of peptides with a high probability of exhibiting antiviral activity. Using the Feedback method, we evaluated various algorithms and their performance. Moreover, we modeled the structure of the generated peptides using AlphaFold2 and determined the peptides having similar physicochemical properties and structures to those of known AVPs, although with different sequences.";2022;Not health related;Health related
"Farajtabar, M; Gomez-Rodriguez, M; Wang, YC; Li, S; Zha, HY; Song, L";Co-evolutionary Dynamics of Information Diffusion and Network Structure;Information diffusion in online social networks is obviously affected by the underlying network topology, but it also has the power to change that topology. Online users are constantly creating new links when exposed to new information sources, and in turn these links are alternating the route of information spread. However, these two highly intertwined stochastic processes, information diffusion and network evolution, have been predominantly studied separately, ignoring their co-evolutionary dynamics. In this project, we propose a probabilistic generative model, CO-EVOLVE, for the joint dynamics of these two processes, allowing the intensity of one process to be modulated by that of the other. This model allows us to efficiently' simulate diffusion and network events from the co-evolutionary dynamics, and generate traces obeying common diffusion and network patterns observed in real-world networks. Furthermore, we also develop a convex optimization framework to learn the parameters of the model from historical diffusion and network evolution traces. We experimented with both synthetic data and data gathered from Twitter, and show that our model provides a good fit to the data as well as more accurate predictions than alternatives.;2015;Not health related;Not health related
"Ding, HL; Lu, YH; Sze, NN; Chen, TT; Guo, YY; Lin, QH";A deep generative approach for crash frequency model with heterogeneous imbalanced data;Crash frequency model is often subject to excessive zero observation because of the rare nature of crashes. To address the problem of imbalanced crash data, a deep generative approach - augmented variational autoencoder - was proposed to generate synthetic crash data for the association measure between crash and possible explanatory factors. This approach was characterized by a factorized generative model and refined objective function. For instance, the generative model can handle heterogeneous data including realvalued, nominal and ordinal distributions. On the other hand, the refined objective function can control for the random effect by better recognizing both the zero-crash and non-zero crash cases. In this study, comprehensive traffic and crash data of multiple distribution types in Hong Kong in the period between 2014 and 2016 were used. To assess the data generation performance of the proposed augmented variational autoencoder method, a conventional data synthesis technique (synthetic minority oversampling techniquenominal continuous) was also considered. Performances of crash frequency models of total crashes and fatal and severe injury crashes are assessed. For total crashes, the results of parameter estimation, in terms of statistical fit, prediction accuracy, and explanatory factors identified, of the crash frequency model based on synthetic data using the augmented variational autoencoder method adhered closer to that based on original data, compared to that based on synthetic data using the synthetic minority oversampling technique-nominal continuous method. For fatal and severe injury crashes, zero-crash observations were prevalent, with the ratio of zero-crash to non-zero crash cases of 9 to 1. Crash data was first balanced using the proposed augmented variational autoencoder method. Then, fatal and severe injury crash frequency models using correlated random parameter models based on original data and balanced data were estimated respectively. Results indicate that fatal and severe injury crash frequency model based on balanced data outperforms its counterpart, with the lowest root mean square error, lowest mean absolute error, and highest number of crash explanatory factors identified. More importantly, correlation between the random parameters can be revealed. Findings of this study should shed light to both researchers and practitioners for the development of crash frequency models, with which the problem of excessive zero observations is prevalent when highly disaggregated traffic and crash data by time and space are used.(c) 2022 Elsevier Ltd. All rights reserved.;2022;Not health related;Not health related
"Falcao, J; Baweja, PS; Wang, Y; Sangpetch, A; Noh, HY; Sangpetch, O; Zhang, P";PIWIMS: Physics Informed Warehouse Inventory Monitory via Synthetic Data Generation;State-of-the-art camera-based deep learning methods for inventory monitoring tend to fail to generalize across different domains due to the high variance of scene settings. Large amounts of human labor are required to label and parameterize the models, making a real-world deployment impractical. In a third-party warehouse setting, supervised learning approaches are either too costly and/or inaccurate to deploy due to the need for human labor to address the diverse set of environmental factors (i.e, lighting conditions, product motion, deployment limitations). We introduce PIWIMS, a realistic synthetic dataset generation technique that combines the physical constraints of the scene in real-world deployments, drastically reducing the need for human labeling. In contrast to other generative techniques, where the generative parameters are learned from a large sample of available data, this compositive approach defines the parameters based on physical characteristics of the particular task, which requires minimal human annotation. We demonstrate PIWIMS performance in a 4-month real operating warehouse deployment and show that with only 32 manually labeled images per object, PIWIMS can achieve an accuracy of up to 87% in inventory tracking, which is a 28% increase when compared to traditional data augmentation techniques and 31% error reduction when compared to the third-party warehouse industry average. Furthermore, we demonstrate the ability of PIWIMS to generalize across different camera angles and positions by achieving an accuracy of 85% in inventory tracking while varying the position and angle of the camera.;2021;Not health related;Not health related
"Alaa, AM; van Breugel, B; Saveliev, E; van der Schaar, M";How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models;Devising domain- and model-agnostic evaluation metrics for generative models is an important and as yet unresolved problem. Most existing metrics, which were tailored solely to the image synthesis application, exhibit a limited capacity for diagnosing modes of failure of generative models across broader application domains. In this paper, we introduce a 3-dimensional metric, (alpha-Precision, ss-Recall, Authenticity), that characterizes the fidelity, diversity and generalization performance of any generative model in a wide variety of application domains. Our metric unifies statistical divergence measures with precision-recall analysis, enabling sample- and distribution-level diagnoses of model fidelity and diversity. We introduce generalization as an additional dimension for model performance that quantifies the extent to which a model copies training data-a crucial performance indicator when modeling sensitive and private data. The three metric components are interpretable probabilistic quantities, and can be estimated via sample-level binary classification. The sample-level nature of our metric inspires a novel use case which we call model auditing, wherein we judge the quality of individual samples generated by a (black-box) model, discarding low-quality samples and hence improving the overall model performance in a post-hoc manner.;2022;Not health related;Not health related
"Rubino, R; Marie, B; Dabre, R; Fujita, A; Utiyama, M; Sumita, E";Extremely low-resource neural machine translation for Asian languages;This paper presents a set of effective approaches to handle extremely low-resource language pairs for self-attention based neural machine translation (NMT) focusing on English and four Asian languages. Starting from an initial set of parallel sentences used to train bilingual baseline models, we introduce additional monolingual corpora and data processing techniques to improve translation quality. We describe a series of best practices and empirically validate the methods through an evaluation conducted on eight translation directions, based on state-of-the-art NMT approaches such as hyper-parameter search, data augmentation with forward and backward translation in combination with tags and noise, as well as joint multilingual training. Experiments show that the commonly used default architecture of self-attention NMT models does not reach the best results, validating previous work on the importance of hyper-parameter tuning. Additionally, empirical results indicate the amount of synthetic data required to efficiently increase the parameters of the models leading to the best translation quality measured by automatic metrics. We show that the best NMT models trained on large amount of tagged back-translations outperform three other synthetic data generation approaches. Finally, comparison with statistical machine translation (SMT) indicates that extremely low-resource NMT requires a large amount of synthetic parallel data obtained with back-translation in order to close the performance gap with the preceding SMT approach.;2020;Not health related;Not health related
"Corcoran, P; Javidnia, H; Lemley, JE; Varkarakis, V";Generative Augmented Dataset and Annotation Frameworks for Artificial Intelligence (GADAFAI);Recent Advances in Artificial Intelligence (AI), particularly in the field of compute vision, have been driven by the availability of large public datasets. However, as AI begins to move into embedded devices there will be a growing need for tools to acquire and re-acquire datasets from specific sensing systems to train new device models. In this paper, a roadmap in introduced for a data-acquisition framework that can build the large synthetic datasets required to train AI systems from small seed datasets. A key element to justify such a framework is the validation of the generated dataset and example results are shown from preliminary work on biometric (facial) datasets.;2020;Not health related;Not health related
"Minici, M; Cinus, F; Monti, C; Bonchi, F; Manco, G";Cascade-based Echo Chamber Detection;Despite echo chambers in social media have been under considerable scrutiny, general models for their detection and analysis are missing. In this work, we aim to fill this gap by proposing a probabilistic generative model that explains social media footprints-i.e., social network structure and propagations of information-through a set of latent communities, characterized by a degree of echo-chamber behavior and by an opinion polarity. Specically, echo chambers are modeled as communities that are permeable to pieces of information with similar ideological polarity, and impermeable to information of opposed leaning: this allows discriminating echo chambers from communities that lack a clear ideological alignment. To learn the model parameters we propose a scalable, stochastic adaptation of the Generalized Expectation Maximization algorithm, that optimizes the joint likelihood of observing social connections and information propagation. Experiments on synthetic data show that our algorithm is able to correctly reconstruct ground-truth latent communities with their degree of echo-chamber behavior and opinion polarity. Experiments on real-world data about polarized social and political debates, such as the Brexit referendum or the COVID-19 vaccine campaign, confirm the effectiveness of our proposal in detecting echo chambers. Finally, we show how our model can improve accuracy in auxiliary predictive tasks, such as stance detection and prediction of future propagations.;2022;Not health related;Health related
"Stallmann, D; Göpfert, JP; Schmitz, J; Grünberger, A; Hammer, B";Towards an automatic analysis of CHO-K1 suspension growth in microfluidic single-cell cultivation;"Motivation: Innovative microfluidic systems carry the promise to greatly facilitate spatio-temporal analysis of single cells under well-defined environmental conditions, allowing novel insights into population heterogeneity and opening new opportunities for fundamental and applied biotechnology. Microfluidics experiments, however, are accompanied by vast amounts of data, such as time series of microscopic images, for which manual evaluation is infeasible due to the sheer number of samples. While classical image processing technologies do not lead to satisfactory results in this domain, modern deep-learning technologies, such as convolutional networks can be sufficiently versatile for diverse tasks, including automatic cell counting as well as the extraction of critical parameters, such as growth rate. However, for successful training, current supervised deep learning requires label information, such as the number or positions of cells for each image in a series; obtaining these annotations is very costly in this setting. Results: We propose a novel machine-learning architecture together with a specialized training procedure, which allows us to infuse a deep neural network with human-powered abstraction on the level of data, leading to a high-performing regression model that requires only a very small amount of labeled data. Specifically, we train a generative model simultaneously on natural and synthetic data, so that it learns a shared representation, from which a target variable, such as the cell count, can be reliably estimated.";2021;Not health related;Not health related
"Yan, AL; Hou, RT; Yan, HY; Liu, XZ";Explanation-based data-free model extraction attacks;Deep learning (DL) has dramatically pushed the previous limits of various tasks, ranging from computer vision to natural language processing. Despite its success, the lack of model explanations thwarts the usage of these techniques in life-critical domains, e.g., medical diagnosis and self-driving systems. To date, the core technology to solve the explainable issue is explainable artificial intelligence (XAI). XAI methods have been developed to produce human-understandable explanations by leveraging intermediate results of the DL models, e.g., gradients and model parameters. While the effectiveness of XAI methods has been demonstrated in benign environments, their privacy against model extraction attacks (i.e., attacks at the model confidentially) requires to be studied. To this end, this paper proposes DMEAE, a data-free model extraction attack using explanation-guided, to explore XAI privacy threats. Compared with previous works, DMEAE does not require collecting any data and utilizes model explanation loss. Specifically, DMEAE creates synthetic data using a generative model with model explanation loss items. Extensive evaluations verify the effectiveness and efficiency of the proposed attack strategy on SVHN and CIFAR-10 datasets. We hope that our research can provide insights for the development of practical tools to trade off the relationship between privacy and model explanations.;2023;Not health related;Health related
"Altosaar, J; Ranganath, R; Blei, DM";Proximity Variational Inference;"Variational inference is a powerful approach for approximate posterior inference. However, it is sensitive to initialization and can be subject to poor local optima. In this paper, we develop proximity variational inference (pvi). pvi is a new method for optimizing the variational objective that constrains subsequent iterates of the variational parameters to robustify the optimization path. Consequently, pvi is less sensitive to initialization and optimization quirks and finds better local optima. We demonstrate our method on four proximity statistics. We study pvi on a Bernoulli factor model and sigmoid belief network fit to real and synthetic data and compare to deterministic annealing (Katahira et al., 2008). We highlight the flexibility of pvi by designing a proximity statistic for Bayesian deep learning models such as the variational autoencoder (Kingma and Welling, 2014; Rezende et al., 2014) and show that it gives better performance by reducing overpruning. pvi also yields improved predictions in a deep generative model of text. Empirically, we show that pvi consistently finds better local optima and gives better predictive performance.";2018;Not health related;Not health related
"Fernandez, V; Pinaya, WHL; Borges, P; Tudosiu, PD; Graham, MS; Vercauteren, T; Cardoso, MJ";Can Segmentation Models Be Trained with Fully Synthetically Generated Data?;In order to achieve good performance and generalisability, medical image segmentation models should be trained on sizeable datasets with sufficient variability. Due to ethics and governance restrictions, and the costs associated with labelling data, scientific development is often stifled, with models trained and tested on limited data. Data augmentation is often used to artificially increase the variability in the data distribution and improve model generalisability. Recent works have explored deep generative models for image synthesis, as such an approach would enable the generation of an effectively infinite amount of varied data, addressing the generalisability and data access problems. However, many proposed solutions limit the user's control over what is generated. In this work, we propose brainSPADE, a model which combines a synthetic diffusion-based label generator with a semantic image generator. Our model can produce fully synthetic brain labels on-demand, with or without pathology of interest, and then generate a corresponding MRI image of an arbitrary guided style. Experiments show that brainSPADE synthetic data can be used to train segmentation models with performance comparable to that of models trained on real data.;2022;Health related;Health related
"Morrison, D; Harris-Birtill, D";Anonymising Pathology Data using Generative Adversarial Networks;Anonymising medical data for use in machine learning is important to preserve patient privacy and, in many circumstances, is a requirement before data can be made available. One approach to anonymising image data is to train a generative model to produce data that is statistically similar to the input data and then use the output of the model for downstream tasks, such as image classification, instead of the original sensitive data. In digital pathology, it's not yet well understood how using generative models to anonymise histology slide data impacts the performance of downstream tasks. To begin addressing this, we present an evaluation of a histology image classifier trained using patches extracted from the Camelyon 16 dataset and compare it to a classifier trained on the same number of synthetic images generated with a Deep Convolutional Generative Adversarial Network (DCGAN), from the same data. When predicting the class of an image patch as either cancer or normal it's shown that the accuracy reduces from 0.78 for original alone to 0.59 for synthetic alone, and the recall is significantly reduced from 0.70 to 0.44 when training exclusively on the same amount of synthetic data. If retaining a similar accuracy is required for the downstream task, then either the original data must be used or an improved anonymisation strategy must be devised. We conclude that using this DCGAN to anonymise the dataset, degrades the accuracy of the classifier which implies that it has failed to capture the required variation in the original data to generalise and act as a sufficient anonymisation strategy.;2022;Health related;Health related
"Breaban, ME; Luchian, H; Simovici, D";A Genetic Clustering Algorithm by Monomial Projection Pursuit;This paper proposes a new method to identify interesting structures in data based on the projection pursuit methodology. Past work reported in literature uses projection pursuit methods as means to visualize high-dimensional data, or to identify linear combinations of attributes that reveal grouping tendencies or outliers. The framework of projection pursuit is generally formulated as an optimization problem aiming at finding projection axes that minimize/maximize a projection index. With regard to identifying interesting structure, the existing approaches suffer from obvious limitations: linear models are not able to catch more general structures in data like circular/curved clusters or any structure that is the result of a polynomial/nonlinear generative model. This paper extends linear projection pursuit to nonlinear projections while allowing at the same time for the preservation of the general methodology employed in the search of projections. In addition, an algorithmic framework based on multi-modal genetic algorithms is proposed in order to deal with the large search space and to allow for the use of non-differentiable projection indices. Experiments conducted on synthetic data demonstrate the ability of the new approach to identify clusters of various shapes that otherwise are undetectable with linear projection pursuit or popular clustering methods like k-Means.;2012;Not health related;Not health related
"Corneli, M; Bouveyron, C; Latouche, P";Co-Clustering of Ordinal Data via Latent Continuous Random Variables and Not Missing at Random Entries;This article is about the co-clustering of ordinal data. Such data are very common on e-commerce platforms where customers rank the products/services they bought. In more detail, we focus on arrays of ordinal (possibly missing) data involving two disjoint sets of individuals/objects corresponding to the rows/columns of the arrays. Typically, an observed entry (i, j) in the array is an ordinal score assigned by the individual/row i to the object/column j. A new generative model for arrays of ordinal data is introduced along with an inference algorithm for parameters estimation. The model accounts for not missing at random data and relies on latent continuous random variables. The fitting allows to simultaneously co-cluster the rows and columns of an array. The estimation of the model parameters is performed via a classification expectation maximization algorithm. A model selection criterion is formally obtained to select the number of row and column clusters. To show that our approach reaches and often outperforms the state of the art, we carry out numerical experiments on synthetic data. Finally, applications on real datasets highlight the model capacity to deal with very sparse arrays. for this article are available online.;2020;Not health related;Not health related
"Nikbakht, M; Gazi, AH; Zia, J; An, ST; Lin, DJ; Inan, OT; Kamaleswaran, R";Synthetic seismocardiogram generation using a transformer-based neural network;"Objective: To design and validate a novel deep generative model for seismocardiogram (SCG) dataset augmentation. SCG is a noninvasively acquired cardiomechanical signal used in a wide range of cardivascular monitoring tasks; however, these approaches are limited due to the scarcity of SCG data. Methods: A deep generative model based on transformer neural networks is proposed to enable SCG dataset augmentation with control over features such as aortic opening (AO), aortic closing (AC), and participant-specific morphology. We compared the generated SCG beats to real human beats using various distribution distance metrics, notably Sliced-Wasserstein Distance (SWD). The benefits of dataset augmentation using the proposed model for other machine learning tasks were also explored. Results: Experimental results showed smaller distribution distances for all metrics between the synthetically generated set of SCG and a test set of human SCG, compared to distances from an animal dataset (1.14x SWD), Gaussian noise (2.5x SWD), or other comparison sets of data. The input and output features also showed minimal error (95% limits of agreement for pre-ejection period [PEP] and left ventricular ejection time [LVET] timings are 0.03 +/- 3.81 ms and -0.28 +/- 6.08 ms, respectively). Experimental results for data augmentation for a PEP estimation task showed 3.3% accuracy improvement on an average for every 10% augmentation (ratio of synthetic data to real data). Conclusion: The model is thus able to generate physiologically diverse, realistic SCG signals with precise control over AO and AC features. This will uniquely enable dataset augmentation for SCG processing and machine learning to overcome data scarcity.";2023;Health related;Health related
"Grundkiewicz, R; Junczys-Dowmunt, M; Heafield, K";Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data;Considerable effort has been made to address the data sparsity problem in neural grammatical error correction. In this work, we propose a simple and surprisingly effective unsupervised synthetic error generation method based on confusion sets extracted from a spellchecker to increase the amount of training data. Synthetic data is used to pre-train a Transformer sequence-to-sequence model, which not only improves over a strong baseline trained on authentic error-annotated data, but also enables the development of a practical GEC system in a scenario where little genuine error-annotated data is available. The developed systems placed first in the BEA19 shared task, achieving 69.47 and 64.24 F-0.5 in the restricted and low-resource tracks respectively, both on the W&I+LOCNESS test set. On the popular CoNLL 2014 test set, we report state-of-the-art results of 64.16 M-2 for the submitted system, and 61.30 M-2 for the constrained system trained on the NUCLE and Lang-8 data.;2019;Not health related;Not health related
"Gierjatowicz, P; Sabate-Vidales, M; Siska, D; Szpruch, L; Zuric, Z";Robust pricing and hedging via neural stochastic differential equations;Modern data science techniques are opening the door to data-driven model selection mechanisms. However, most machine learning models are black boxes, as individual parameters do not have a meaningful interpretation. In contrast, classical risk models based on stochastic differential equations (SDEs) with fixed parameterization are well understood. Unfortunately, the risk of using an inadequate model is hard to detect and quantify. In this paper, instead of choosing a fixed parameterization for the model SDE, we aim to learn the drift and diffusion from data using overparameterized neural networks. The resulting model, called neural SDE, allows consistent calibration under both risk-neutral and real-world measures and is an instantiation of generative models closely linked with the theory of causal optimal transport. We demonstrate how neural SDEs make it possible to find robust bounds for the prices of derivatives and the corresponding hedging strategies. Further, the model can simulate the market scenarios needed for assessing risk profiles and hedging strategies. We develop and analyze novel algorithms for the efficient use of neural SDEs and we validate our approach with numerical experiments using both market and synthetic data.;2022;Not health related;Not health related
"Zhang, C; Kjellström, H; Ek, CH";Inter-battery Topic Representation Learning;In this paper, we present the Inter-Battery Topic Model (IBTM). Our approach extends traditional topic models by learning a factorized latent variable representation. The structured representation leads to a model that marries benefits traditionally associated with a discriminative approach, such as feature selection, with those of a generative model, such as principled regularization and ability to handle missing data. The factorization is provided by representing data in terms of aligned pairs of observations as different views. This provides means for selecting a representation that separately models topics that exist in both views from the topics that are unique to a single view. This structured consolidation allows for efficient and robust inference and provides a compact and efficient representation. Learning is performed in a Bayesian fashion by maximizing a rigorous bound on the log-likelihood. Firstly, we illustrate the benefits of the model on a synthetic dataset. The model is then evaluated in both uni- and multi-modality settings on two different classification tasks with off-the-shelf convolutional neural network (CNN) features which generate state-of-the-art results with extremely compact representations.;2016;Not health related;Not health related
"Dionelis, N; Yaghoobi, M; Tsaftaris, SA";BOUNDARY OF DISTRIBUTION SUPPORT GENERATOR (BDSG): SAMPLE GENERATION ON THE BOUNDARY;Generative models, such as Generative Adversarial Networks (GANs), have been used for unsupervised anomaly detection. While performance keeps improving, several limitations exist particularly attributed to difficulties at capturing multimodal supports and to the ability to approximate the underlying distribution closer to the tails, i.e. the boundary of the distribution's support. This paper proposes an approach that attempts to alleviate such shortcomings. We propose an invertible-residual-network-based model, the Boundary of Distribution Support Generator (BDSG). GANs generally do not guarantee the existence of a probability distribution and here, we use the recently developed Invertible Residual Network (IResNet) and Residual Flow (ResFlow), for density estimation. These models have not yet been used for anomaly detection. We leverage IResNet and ResFlow for Out-of-Distribution (OoD) sample detection and for sample generation on the boundary using a compound loss function that forces the samples to lie on the boundary. The BDSG addresses non-convex support, disjoint components, and multimodal distributions. Results on synthetic data and data from multimodal distributions, such as MNIST and CIFAR-10, demonstrate competitive performance compared to methods from the literature.;2020;Not health related;Not health related
"Ding, GD; Zhang, SS; Khan, S; Tang, ZM; Zhang, J; Porikli, F";Feature Affinity-Based Pseudo Labeling for Semi-Supervised Person Re-Identification;Vision-based person re-identification aims to match a persons identity across multiple images, which is a fundamental task in multimedia content analysis and retrieval. Deep neural networks have recently manifested great potential in this task. However, a major bottleneck of existing supervised deep networks is their reliance on a large amount of annotated training data. Manual labeling for person identities in large-scale surveillance camera systems is quite challenging and incurs significant costs. Some recent studies adopt generative model outputs as training data augmentation. To more effectively use these synthetic data for an improved feature learning and re-identification performance, this paper proposes a novel feature affinity-based pseudo labeling method with two possible label encodings. To the best of our knowledge, this is the first study that employs pseudo-labeling by measuring the affinity of unlabeled samples with the underlying clusters of labeled data samples using the intermediate feature representations from deep networks. We propose training the network with the joint supervision of cross-entropy loss together with a center regularization term, which not only ensures discriminative feature representation learning but also simultaneously predicts pseudo-labels for unlabeled data. We show that both label encodings can be learned in a unified manner and help improve the overall performance. Our extensive experiments on three person re-identification datasets: Market-1501, DukeMTMC-reID, and CUHK03, demonstrate significant performance boost over the state-of-the-art person re-identification approaches.;2019;Not health related;Not health related
"Honorio, J; Ortiz, L";Learning the Structure and Parameters of Large-Population Graphical Games from Behavioral Data;"We consider learning, from strictly behavioral data, the structure and parameters of linear influence games (LIGs), a class of parametric graphical games introduced by Irfan and Ortiz (2014). LIGs facilitate causal strategic inference (CSI) : Making inferences from causal interventions on stable behavior in strategic settings. Applications include the identification of the most influential individuals in large (social) networks. Such tasks can also support policy-making analysis. Motivated by the computational work on LIGs, we cast the learning problem as maximum-likelihood estimation (MLE) of a generative model defined by pure-strategy Nash equilibria (PS NE). Our simple formulation uncovers the fundamental interplay between goodness-of-fit and model complexity: good models capture equilibrium behavior within the data while controlling the true number of equilibria, including those unobserved. We provide a generalization bound establishing the sample complexity for MLE in our framework. We propose several algorithms including convex loss minimization (CLM) and sigmoidal approximations. We prove that the number of exact PSNE in LIGs is small, with high probability; thus, CLM is sound. We illustrate our approach on synthetic data and real-world U.S. congressional voting records. We briefly discuss our learning framework's generality and potential applicability to general graphical games.";2015;Not health related;Not health related
"Pippi, V; Cascianelli, S; Cucchiara, R";Handwritten Text Generation from Visual Archetypes;Generating synthetic images of handwritten text in a writer-specific style is a challenging task, especially in the case of unseen styles and new words, and even more when these latter contain characters that are rarely encountered during training. While emulating a writer's style has been recently addressed by generative models, the generalization towards rare characters has been disregarded. In this work, we devise a Transformer-based model for Few-Shot styled handwritten text generation and focus on obtaining a robust and informative representation of both the text and the style. In particular, we propose a novel representation of the textual content as a sequence of dense vectors obtained from images of symbols written as standard GNU Unifont glyphs, which can be considered their visual archetypes. This strategy is more suitable for generating characters that, despite having been seen rarely during training, possibly share visual details with the frequently observed ones. As for the style, we obtain a robust representation of unseen writers' calligraphy by exploiting specific pre-training on a large synthetic dataset. Quantitative and qualitative results demonstrate the effectiveness of our proposal in generating words in unseen styles and with rare characters more faithfully than existing approaches relying on independent one-hot encodings of the characters.;2023;Not health related;Not health related
"Deveshwar, N; Rajagopal, A; Sahin, S; Shimron, E; Larson, PEZ";Synthesizing Complex-Valued Multicoil MRI Data from Magnitude-Only Images;Despite the proliferation of deep learning techniques for accelerated MRI acquisition and enhanced image reconstruction, the construction of large and diverse MRI datasets continues to pose a barrier to effective clinical translation of these technologies. One major challenge is in collecting the MRI raw data (required for image reconstruction) from clinical scanning, as only magnitude images are typically saved and used for clinical assessment and diagnosis. The image phase and multi-channel RF coil information are not retained when magnitude-only images are saved in clinical imaging archives. Additionally, preprocessing used for data in clinical imaging can lead to biased results. While several groups have begun concerted efforts to collect large amounts of MRI raw data, current databases are limited in the diversity of anatomy, pathology, annotations, and acquisition types they contain. To address this, we present a method for synthesizing realistic MR data from magnitude-only data, allowing for the use of diverse data from clinical imaging archives in advanced MRI reconstruction development. Our method uses a conditional GAN-based framework to generate synthetic phase images from input magnitude images. We then applied ESPIRiT to derive RF coil sensitivity maps from fully sampled real data to generate multi-coil data. The synthetic data generation method was evaluated by comparing image reconstruction results from training Variational Networks either with real data or synthetic data. We demonstrate that the Variational Network trained on synthetic MRI data from our method, consisting of GAN-derived synthetic phase and multi-coil information, outperformed Variational Networks trained on data with synthetic phase generated using current state-of-the-art methods. Additionally, we demonstrate that the Variational Networks trained with synthetic k-space data from our method perform comparably to image reconstruction networks trained on undersampled real k-space data.;2023;Health related;Health related
"Li, SC; Tai, BC; Huang, YN";Evaluating Variational Autoencoder as a Private Data Release Mechanism for Tabular Data;Multi-market businesses can collect data from different business entities and aggregate data from various sources to create value. However, due to the restriction of privacy regulation, it could be illegal to exchange data between business entities of the same parent company, unless the users have opted-in to allow it. Regulations such as the EU's GDPR allows data exchange if data is anonymized appropriately. In this study, we use variational autoencoder as a mechanism to generate synthetic data. The privacy and utility of the generated data sets are measured. And its performance is compared with the performance of the plain autoencoder. The primary findings of this study are 1) variational autoencoder can be an option for data exchange with good accuracy even when the number of latent dimensions is low 2) plain autoencoder still provides better accuracy when the number of hidden nodes is high 3) variational autoencoder, as a generative model, can be given to a data user to generate his version of data that closely mimic the original data set.;2019;Not health related;Not health related
"Wang, Y; Wipf, D; Yun, JM; Chen, W; Wassell, I";Clustered Sparse Bayesian Learning;Many machine learning and signal processing tasks involve computing sparse representations using an overcomplete set of features or basis vectors, with compressive sensing-based applications a notable example. While traditionally such problems have been solved individually for different tasks, this strategy ignores strong correlations that may be present in real world data. Consequently there has been a push to exploit these statistical dependencies by jointly solving a series of sparse linear inverse problems. In the majority of the resulting algorithms however, we must a priori decide which tasks can most judiciously be grouped together. In contrast, this paper proposes an integrated Bayesian framework for both clustering tasks together and subsequently learning optimally sparse representations within each cluster. While probabilistic models have been applied previously to solve these types of problems, they typically involve a complex hierarchical Bayesian generative model merged with some type of approximate inference, the combination of which renders rigorous analysis of the underlying behavior virtually impossible. On the other hand, our model subscribes to concrete motivating principles that we carefully evaluate both theoretically and empirically. Importantly, our analyses take into account all approximations that are involved in arriving at the actual cost function to be optimized. Results on synthetic data as well as image recovery from compressive measurements show improved performance over existing methods.;2015;Not health related;Not health related
"Alain, G; Bengio, Y; Yao, L; Yosinski, J; Thibodeau-Laufer, É; Zhang, SZ; Vincent, P";GSNs: generative stochastic networks;"We introduce a novel training principle for generative probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSNs) framework generalizes Denoising Auto-Encoders (DAEs), and is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution is a conditional distribution that generally involves a small move, so it has fewer dominant modes and is unimodal in the limit of small moves. This simplifies the learning problem, making it less like density estimation and more akin to supervised function approximation, with gradients that can be obtained by backprop. The theorems provided here provide a probabilistic interpretation for DAEs and generalize them; seen in the context of this framework, auto-encoders that learn with injected noise are a special case of GSNs and can be interpreted as generative models. The theorems also provide an interesting justification for dependency networks and generalized pseudolikelihood, and define an appropriate joint distribution and sampling mechanism, even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the others. Experiments validating these theoretical results are conducted on both synthetic datasets and image datasets. The experiments employ a particular architecture that mimics the Deep Boltzmann Machine Gibbs sampler, but that allows training to proceed with backprop through a recurrent neural network with noise injected inside and without the need for layerwise pretraining.";2016;Not health related;Not health related
"Wang, MK; Tsai, TH; Di Poto, C; Ferrarini, A; Yu, GQ; Ressom, HW";Topic model-based mass spectrometric data analysis in cancer biomarker discovery studies;Background: A fundamental challenge in quantitation of biomolecules for cancer biomarker discovery is owing to the heterogeneous nature of human biospecimens. Although this issue has been a subject of discussion in cancer genomic studies, it has not yet been rigorously investigated in mass spectrometry based proteomic and metabolomic studies. Purification of mass spectometric data is highly desired prior to subsequent analysis, e.g., quantitative comparison of the abundance of biomolecules in biological samples. Methods: We investigated topic models to computationally analyze mass spectrometric data considering both integrated peak intensities and scan-level features, i.e., extracted ion chromatograms (EICs). Probabilistic generative models enable flexible representation in data structure and infer sample-specific pure resources. Scan-level modeling helps alleviate information loss during data preprocessing. We evaluated the capability of the proposed models in capturing mixture proportions of contaminants and cancer profiles on LC-MS based serum proteomic and GC-MS based tissue metabolomic datasets acquired from patients with hepatocellular carcinoma (HCC) and liver cirrhosis as well as synthetic data we generated based on the serum proteomic data. Results: The results we obtained by analysis of the synthetic data demonstrated that both intensity-level and scan-level purification models can accurately infer the mixture proportions and the underlying true cancerous sources with small average error ratios (< 7 %) between estimation and ground truth. By applying the topic model-based purification to mass spectrometric data, we found more proteins and metabolites with significant changes between HCC cases and cirrhotic controls. Candidate biomarkers selected after purification yielded biologically meaningful pathway analysis results and improved disease discrimination power in terms of the area under ROC curve compared to the results found prior to purification. Conclusions: We investigated topic model-based inference methods to computationally address the heterogeneity issue in samples analyzed by LC/GC-MS. We observed that incorporation of scan-level features have the potential to lead to more accurate purification results by alleviating the loss in information as a result of integrating peaks. We believe cancer biomarker discovery studies that use mass spectrometric analysis of human biospecimens can greatly benefit from topic model-based purification of the data prior to statistical and pathway analyses.;2016;Health related;Health related
"Chien, E; Tulino, AM; Llorca, J";Active Learning in the Geometric Block Model;The geometric block model is a recently proposed generative model for random graphs that is able to capture the inherent geometric properties of many community detection problems, providing more accurate characterizations of practical community structures compared with the popular stochastic block model. Galhotra et al. recently proposed a motif-counting algorithm for unsupervised community detection in the geometric block model that is proved to be near-optimal. They also characterized the regimes of the model parameters for which the proposed algorithm can achieve exact recovery. In this work. we initiate the study of active learning in the geometric block model. That is, we are interested in the problem of exactly recovering the community structure of random graphs following the geometric block model under arbitrary model parameters. by possibly querying the labels of a limited number of chosen nodes. We propose two active learning algorithms that combine the use of motif-counting with two different label query policies. Our main contribution is to show that sampling the labels of a vanishingly small fraction of nodes (sub-linear in the total number of nodes) is sufficient to achieve exact recovery in the regimes under which the state-of-the-art unsupervised method fails. We validate the superior performance of our algorithms via numerical simulations on both real and synthetic datasets.;2020;Not health related;Not health related
"Yuan, JY; Li, B; Xue, XY";Unsupervised Learning of Compositional Scene Representations from Multiple Unspecified Viewpoints;Visual scenes are extremely rich in diversity, not only because there are infinite combinations of objects and background, but also because the observations of the same scene may vary greatly with the change of viewpoints. When observing a visual scene that contains multiple objects from multiple viewpoints, humans are able to perceive the scene in a compositional way from each viewpoint, while achieving the so-called object constancy across different viewpoints, even though the exact viewpoints are untold. This ability is essential for humans to identify the same object while moving and to learn from vision efficiently. It is intriguing to design models that have the similar ability. In this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified viewpoints without using any supervision, and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve this problem. To infer latent representations, the information contained in different viewpoints is iteratively integrated by neural networks. Experiments on several specifically designed synthetic datasets have shown that the proposed method is able to effectively learn from multiple unspecified viewpoints.;2022;Not health related;Not health related
"Yi, HW; Huang, CHP; Tripathi, S; Hering, L; Thies, J; Black, MJ";MIME: Human-Aware 3D Scene Generation;Generating realistic 3D worlds occupied by moving humans has many applications in games, architecture, and synthetic data creation. But generating such scenes is expensive and labor intensive. Recent work generates human poses and motions given a 3D scene. Here, we take the opposite approach and generate 3D indoor scenes given 3D human motion. Such motions can come from archival motion capture or from IMU sensors worn on the body, effectively turning human movement into a scanner of the 3D world. Intuitively, human movement indicates the free-space in a room and human contact indicates surfaces or objects that support activities such as sitting, lying or touching. We propose MIME (Mining Interaction and Movement to infer 3D Environments), which is a generative model of indoor scenes that produces furniture layouts that are consistent with the human movement. MIME uses an auto-regressive transformer architecture that takes the already generated objects in the scene as well as the human motion as input, and outputs the next plausible object. To train MIME, we build a dataset by populating the 3D FRONT scene dataset with 3D humans. Our experiments show that MIME produces more diverse and plausible 3D scenes than a recent generative scene method that does not know about human movement. Code and data are available for research at https://mime.is.tue.mpg.de.;2023;Not health related;Not health related
"Pastorino, J; Biswas, AK";Data Adequacy Bias Impact in a Data-blinded Semi-supervised GAN for Privacy-aware COVID-19 Chest X-Ray Classification;Supervised machine learning models are, by definition, data-sighted, requiring to view all or most parts of the training dataset which are labeled. This paradigm presents two bottlenecks which are intert-wined: risk of exposing sensitive data samples to the third-party site with machine learning engineers, and time-consuming, laborious, bias-prone nature of data annotations by the personnel at the data source site. In this paper we studied learning impact of data adequacy as bias source in a data-blinded semi-supervised learning model for covid chest X-ray classification. Data-blindedness was put in action on a semi-supervised generative adversarial network to generate synthetic data based only on a few labeled data samples and concurrently learn to classify targets. We designed and developed a data-blind COVID-19 patient classifier that classifies whether an individual is suffering from COVID-19 or other type of illness with the ultimate goal of producing a system to assist in labeling large datasets. However, the availability of the labels in the training data had an impact in the model performance, and when a new disease spreads, as it was COVID9-19 in 2019, access to labeled data may be limited. Here, we studied how bias in the labeled sample distribution per class impacted in classification performance for three models: a Convolution Neural Network based classifier (CNN), a semi-supervised GAN using the source data (SGAN), and finally our proposed data-blinded semi-supervised GAN (BSGAN). Data-blind prevents machine learning engineers from directly accessing the source data during training, thereby ensuring data confidentiality. This was achieved by using synthetic data samples, generated by a separate generative model which were then used to train the proposed model. Our model achieved comparable performance, with the trade-off between a privacy-aware model and a traditionally-learnt model of 0.05 AUC-score, and it maintained stable, following the same learning performance as the data distribution was changed.;2022;Health related;Health related
"Li, YH; Aslam, MS; Harfiya, LN; Chang, CC";Conditional Wasserstein Generative Adversarial Networks for Rebalancing Iris Image Datasets;The recent development of deep learning-based generative models has sharply intensified the interest in data synthesis and its applications. Data synthesis takes on an added importance especially for some pattern recognition tasks in which some classes of data are rare and difficult to collect. In an iris dataset, for instance, the minority class samples include images of eyes with glasses, oversized or undersized pupils, misaligned iris locations, and iris occluded or contaminated by eyelids, eyelashes, or lighting reflections. Such class-imbalanced datasets often result in biased classification performance. Generative adversarial networks (GANs) are one of the most promising frameworks that learn to generate synthetic data through a two-player minimax game between a generator and a discriminator. In this paper, we utilized the state-of-the-art conditional Wasserstein generative adversarial network with gradient penalty (CWGAN-GP) for generating the minority class of iris images which saves huge amount of cost of human labors for rare data collection. With our model, the researcher can generate as many iris images of rare cases as they want and it helps to develop any deep learning algorithm whenever large size of dataset is needed.;2021;Not health related;Not health related
"Burlina, PM; Joshi, N; Pacheco, KD; Liu, TYA; Bressler, NM";Assessment of Deep Generative Models for High-Resolution Synthetic Retinal Image Generation of Age-Related Macular Degeneration;IMPORTANCE. Deep learning (DL) used for discriminative tasks in ophthalmology, such as diagnosing diabetic retinopathy or age-related macular degeneration (AMD), requires large image data sets graded by human experts to train deep convolutional neural networks (DCNNs). In contrast, generative DL techniques could synthesize large new data sets of artificial retina images with different stages of AMD. Such images could enhance existing data sets of common and rare ophthalmic diseases without concern for personally identifying information to assist medical education of students, residents, and retinal specialists, as well as for training new DL diagnostic models for which extensive data sets from large clinical trials of expertly graded images may not exist. OBJECTIVE To develop DL techniques for synthesizing high-resolution realistic fundus images serving as proxy data sets for use by retinal specialists and DL machines. DESIGN, SETTING. AND PARTICIPANTS Generative adversarial networks were trained on 133 821 color fundus images from 4613 study participants from the Age-Related Eye Disease Study (AREDS), generating synthetic fundus images with and without AMD. We compared retinal specialists' ability to diagnose AMD on both real and synthetic images, asking them to assess image gradability and testing their ability to discern real from synthetic images. The performance of AMD diagnostic DCNNs (referable vs not referable AMD) trained on either all-real vs all-synthetic data sets was compared. MAIN OUTCOMES AND MEASURES Accuracy of 2 retinal specialists (T.Y.A.L. and K.D.P.) for diagnosing and distinguishing AMD on real vs synthetic images and diagnostic performance (area under the curve) of DL algorithms trained on synthetic vs real images. RESULTS The diagnostic accuracy of 2 retinal specialists on real vs synthetic images was similar. The accuracy of diagnosis as referable vs nonreferable AMD compared with certified human graders for retinal specialist 1 was 84.54% (error margin, 4.06%) on real images vs 84.12% (error margin, 4.16%) on synthetic images and for retinal specialist 2 was 89.47% (error margin, 3.45%) on real images vs 89.19% (error margin, 3.54%) on synthetic images. Retinal specialists could not distinguish real from synthetic images, with an accuracy of 59.50% (error margin, 3.93%) for retinal specialist 1 and 53.67% (error margin, 3.99%) for retinal specialist 2. The DCNNs trained on real data showed an area under the curve of 0.9706 (error margin, 0.0029), and those trained on synthetic data showed an area under the curve of 0.9235 (error margin, 0.0045). CONCLUSIONS AND RELEVANCE Deep learning-synthesized images appeared to be realistic to retinal specialists, and DCNNs achieved diagnostic performance on synthetic data close to that for real images, suggesting that DL generative techniques hold promise for training humans and machines.;2019;Health related;Health related
"Ye, XL; Zhao, JY";Heterogeneous clustering via adversarial deep Bayesian generative model;This paper aims to study the deep clustering problem with heterogeneous features and unknown cluster number. To address this issue, a novel deep Bayesian clustering framework is proposed. In particular, a heterogeneous feature metric is first constructed to measure the similarity between different types of features. Then, a feature metric-restricted hierarchical sample generation process is established, in which sample with heterogeneous features is clustered by generating it from a similarity constraint hidden space. When estimating the model parameters and posterior probability, the corresponding variational inference algorithm is derived and implemented. To verify our model capability, we demonstrate our model on the synthetic dataset and show the superiority of the proposed method on some real datasets Our source code is released on the website: Github.com/yexlwh/Heterogeneousclustering.;2023;Not health related;Not health related
"Xu, K; Srivastava, A; Gutfreund, D; Sosa, FA; Ullman, T; Tenenbaum, JB; Sutton, C";A Bayesian-Symbolic Approach to Reasoning and Learning in Intuitive Physics;Humans can reason about intuitive physics in fully or partially observed environments even after being exposed to a very limited set of observations. This sample-efficient intuitive physical reasoning is considered a core domain of human common sense knowledge. One hypothesis to explain this remarkable capacity, posits that humans quickly learn approximations to the laws of physics that govern the dynamics of the environment. In this paper, we propose a Bayesian-symbolic framework (BSP) for physical reasoning and learning that is close to human-level sample-efficiency and accuracy. In BSP, the environment is represented by a topdown generative model of entities, which are assumed to interact with each other under unknown force laws over their latent and observed properties. BSP models each of these entities as random variables, and uses Bayesian inference to estimate their unknown properties. For learning the unknown forces, BSP leverages symbolic regression on a novel grammar of Newtonian physics in a bilevel optimization setup. These inference and regression steps are performed in an iterative manner using expectation-maximization, allowing BSP to simultaneously learn force laws while maintaining uncertainty over entity properties. We show that BSP is more sample-efficient compared to neural alternatives on controlled synthetic datasets, demonstrate BSP's applicability to real-world common sense scenes and study BSP's performance on tasks previously used to study human physical reasoning.(1);2021;Not health related;Not health related
"Excell, D; Cemgil, AT; Fitzgerald, WJ";Generative model for human motion recognition;This paper describes a generative Bayesian model designed to track an articulated 3D human skeleton in an image sequence. The model infers the subjects appearance, pose, and movement. This technique provides a novel method for implicity modelling depth and self occlusion, two issues that have been identified as drawbacks of existing models. We also employ a switching linear dynamical system to efficiently propose skeleton configurations. The model is verified using synthetic data. A video clip from the Caviar data set is used to demonstrate the potential of the methodology for tracking on real data.;2007;Not health related;Not health related
"Park, C; Lee, J; Kim, Y; Park, JG; Kim, H; Hong, D";An Enhanced AI-Based Network Intrusion Detection System Using Generative Adversarial Networks;As communication technology advances, various and heterogeneous data are communicated in distributed environments through network systems. Meanwhile, along with the development of communication technology, the attack surface has expanded, and concerns regarding network security have increased. Accordingly, to deal with potential threats, research on network intrusion detection systems (NIDSs) has been actively conducted. Among the various NIDS technologies, recent interest is focused on artificial intelligence (AI)-based anomaly detection systems, and various models have been proposed to improve the performance of NIDS. However, there still exists the problem of data imbalance, in which AI models cannot sufficiently learn malicious behavior and thus fail to detect network threats accurately. In this study, we propose a novel AI-based NIDS that can efficiently resolve the data imbalance problem and improve the performance of the previous systems. To address the aforementioned problem, we leveraged a state-of-the-art generative model that could generate plausible synthetic data for minor attack traffic. In particular, we focused on the reconstruction error and Wasserstein distance-based generative adversarial networks, and autoencoder-driven deep learning models. To demonstrate the effectiveness of our system, we performed comprehensive evaluations over various data sets and demonstrated that the proposed systems significantly outperformed the previous AI-based NIDS.;2023;Not health related;Not health related
"Rangamani, A; Mukherjee, A; Basu, A; Arora, A; Ganapathi, T; Chin, S; Tran, TD";Sparse Coding and Autoencoders;In this work we study the landscape of squared loss of an Autoencoder when the data generative model is that of Sparse Coding/ Dictionary Learning. The neural net considered is an R-n -> R-n mapping and has a single ReLU activation layer of size h > n. The net has access to vectors y is an element of R-n obtained as y - A*x* where x* is an element of R-h are sparse high dimensional vectors and A* is an element of R-n x h is an overcomplete incoherent matrix. Under very mild distributional assumptions on x*, we prove that the norm of the expected gradient of the squared loss function is asymptotically (in sparse code dimension) negligible for all points in a small neighborhood of A*. This is supported with experimental evidence using synthetic data. We conduct experiments to suggest that A* sits at the bottom of a well in the landscape and we also give experiments showing that gradient descent on this loss function gets columnwise very close to the original dictionary even with far enough initialization. Along the way we prove that a layer of ReLU gates can be set up to automatically recover the support of the sparse codes. Since this property holds independent of the loss function we believe that it could be of independent interest.;2018;Not health related;Not health related
"Mennella, C; Maniscalco, U; De Pietro, G; Esposito, M";Generating a novel synthetic dataset for rehabilitation exercises using pose-guided conditioned diffusion models: A quantitative and qualitative evaluation;Machine learning has emerged as a promising approach to enhance rehabilitation therapy monitoring and evaluation, providing personalized insights. However, the scarcity of data remains a significant challenge in developing robust machine learning models for rehabilitation.This paper introduces a novel synthetic dataset for rehabilitation exercises, leveraging pose-guided person image generation using conditioned diffusion models. By processing a pre-labeled dataset of class movements for 6 rehabilitation exercises, the described method generates realistic human movement images of elderly subjects engaging in home-based exercises.A total of 22,352 images were generated to accurately capture the spatial consistency of human joint relationships for predefined exercise movements. This novel dataset significantly amplified variability in the physical and demographic attributes of the main subject and the background environment. Quantitative metrics used for image assessment revealed highly favorable results. The generated images successfully maintained intra-class and inter-class consistency in motion data, producing outstanding outcomes with distance correlation values exceeding the 0.90.This innovative approach empowers researchers to enhance the value of existing limited datasets by generating high-fidelity synthetic images that precisely augment the anthropometric and biomechanical attributes of individuals engaged in rehabilitation exercises.;2023;Health related;Health related
"Liang, G; Ji, ZL; Zhong, QH; Huang, Y; Han, K";Vector Quantized Variational Autoencoder-Based Compressive Sampling Method for Time Series in Structural Health Monitoring;The theory of compressive sampling (CS) has revolutionized data compression technology by capitalizing on the inherent sparsity of a signal to enable signal recovery from significantly far fewer samples than what is required by the Nyquist-Shannon sampling theorem. Recent advancement in deep generative models, which can represent high-dimension data in a low-dimension latent space efficiently when trained with big data, has been used to further reduce the sample size for image data compressive sampling. However, compressive sampling for 1D time series data has not significantly benefited from this technological progress. In this study, we investigate the application of different architectures of deep neural networks suitable for time series data compression and propose an efficient method to solve the compressive sampling problem on one-dimensional (1D) structural health monitoring (SHM) data, based on block CS and the vector quantized-variational autoencoder model with a naive multitask paradigm (VQ-VAE-M). The proposed method utilizes VQ-VAE-M to learn the data characteristics of the signal, replaces the hard constraint of sparsity to realize the compressive sampling signal reconstruction and thereby does not need to select the appropriate sparse basis for the signal. A comparative analysis against various CS methods and other deep neural network models was performed in both synthetic data and real-world data from two real bridges in China. The results have demonstrated the superiority of the proposed method, with achieving the smallest reconstruction error of 0.038, 0.034 and 0.021, and the highest reconstruction accuracy of 0.882, 0.892 and 0.936 for compression ratios of 4.0, 2.66, and 2.0, respectively.;2023;Not health related;Health related
"Kahlen, JN; Wurde, A; Andres, M; Moser, A";Improving Machine Learning Diagnostic Systems with Model-Based Data Augmentation - Part A: Data Generation;Various diagnostic systems based on artificial intelligence or machine learning algorithms are already being used today to monitor electrical equipment in power supply systems. The challenge of these data-based diagnostic approaches lies in dealing with the limited fault-condition data available. One possible solution to this problem are data augmentation techniques that generate synthetic data from existing data. In this paper, we develop a model-based data augmentation approach that uses computer-implementable, electromechanical models to generate synthetic data. This approach uses statistical information extracted from the available data to sample model parameters and generate synthetic normal-and fault-condition data. It is shown for vibration measurements of a power and distribution transformer that the proposed model-based data augmentation can generate realistic synthetic normal-and fault-condition data.;2021;Not health related;Not health related
"Hess, M; Hackenberg, M; Binder, H";Exploring generative deep learning for omics data using log-linear models;Motivation: Following many successful applications to image data, deep learning is now also increasingly considered for omics data. In particular, generative deep learning not only provides competitive prediction performance, but also allows for uncovering structure by generating synthetic samples. However, exploration and visualization is not as straightforward as with image applications. Results: We demonstrate how log-linear models, fitted to the generated, synthetic data can be used to extract patterns from omics data, learned by deep generative techniques. Specifically, interactions between latent representations learned by the approaches and generated synthetic data are used to determine sets of joint patterns. Distances of patterns with respect to the distribution of latent representations are then visualized in low-dimensional coordinate systems, e.g. for monitoring training progress. This is illustrated with simulated data and subsequently with cortical single-cell gene expression data. Using different kinds of deep generative techniques, specifically variational autoencoders and deep Boltzmann machines, the proposed approach highlights how the techniques uncover underlying structure. It facilitates the real-world use of such generative deep learning techniques to gain biological insights from omics data.;2020;Not health related;Not health related
"Yang, YX; Zhang, XT; Guan, Q; Lin, YZ";Making Invisible Visible: Data-Driven Seismic Inversion With Spatio-Temporally Constrained Data Augmentation;"Deep learning and data-driven approaches have shown great potential in scientific domains. The promise of data-driven techniques relies on the availability of a large volume of high-quality training datasets. Due to the high cost of obtaining data through expensive physical experiments, instruments, and simulations, data augmentation techniques for scientific applications have emerged as a new direction for obtaining scientific data recently. However, existing data augmentation techniques originating from computer vision yield physically unacceptable data samples that are not helpful for the domain problems that we are interested in. In this article, we develop new data augmentation techniques based on convolutional neural networks. Specifically, our generative models leverage different physics knowledge (such as governing equations, observable perception, and physics phenomena) to improve the quality of the synthetic data. To validate the effectiveness of our data augmentation techniques, we apply them to solve a subsurface seismic full-waveform inversion using simulated CO2 leakage data. Our interest is to invert for subsurface velocity models associated with very small CO2 leakage. We validate the performance of our methods using comprehensive numerical tests. Via comparison and analysis, we show that data-driven seismic imaging can be significantly enhanced by using our data augmentation techniques. Particularly, the imaging quality has been improved by 15 & x0025; in test scenarios of general-sized leakage and 17 & x0025; in small-sized leakage when using an augmented training set obtained with our techniques.";2022;Not health related;Not health related
"Mantini, P; Shah, SK";Camera Tampering Detection using Generative Reference Model and Deep Learned Features;An unauthorized alteration in the viewpoint of a surveillance cameras is called tampering. This involves comparing images from the surveillance camera against a reference model. The reference model represents the features (e.g. background, edges, and interest points) of the image under normal operating conditions. The approach is to identify a tamper by analysing the distance between the features of the image from surveillance camera and from the reference model. If the distance is not within a certain threshold, the image is labeled as a tamper. Most methods have used images from the immediate past of the surveillance camera to construct the reference model. We propose to employ a generative model that learns the distribution of images from the surveillance camera under normal operating conditions, by training a generative adversarial network (GAN). The GAN is capable of sampling images from the probability density function, which are used as reference. We train a Siamese network that transforms the images into a feature space, so as to maximize the distance between the generated images and tampered images (while minimizing the distance between generated and normal images). The distance between the generated and the surveillance camera image is classified as either normal or tampered. The model is trained and tested over a synthetic dataset that is created by inducing artificial tampering (using image processing techniques). We compare the performance of the proposed model against two existing methods. Results show that the proposed model is highly capable of detecting and classifying tampering, and outperforms the existing methods with respect to accuracy and false positive rate.;2019;Not health related;Not health related
"Baptista, ML; Henriques, EMP";1D-DGAN-PHM: A 1-D denoising GAN for Prognostics and Health Management with an application to turbofan;The performance of prognostics is closely related to the quality of condition monitoring signals (e.g., temperature, pressure, or vibration signals), which reveal the degradation of the system of interest. However, typical condition monitoring signals include noise and outliers. Disentangling noise from these signals is essential to obtain the actual degradation trajectories. Different denoising methods have been proposed in prognostics. Conventional denoising methods have low complexity but usually do not preserve edge information and do not involve physical considerations. A promising deep learning approach is denoising generative models. This approach is popular in Computer Vision, which has been shown to outperform other classical techniques but has seldom been used in prognostics on 1-D signals. In this paper, we propose the 1-D Denoising Generative Adversarial Network for Prognostics and Health Management (1D-DGAN-PHM). The 1D-DGAN-PHM is trained on synthetic data generated by a custom data generator that infuses physics-of-failure knowledge in paired samples of noisy and noise-free trajectories. The network consists of two components, a denoising generator and a discriminator. The denoising generator aims to learn to denoise a 1-D input signal. The discriminator guides the learning by comparing noise-free signals with signals from the denoising generator. Advantages of the 1D-DGAN-PHM include the physics-of-failure information in the synthetic data generator and the model sophistication. In this work, we apply the 1D-DGAN-PHM to denoise the raw signals derived from NASA's C-MAPSS simulator of an aircraft turbofan engine. Baseline methods are Moving Average, Median filter, Savitzky-Golay filter, and a denoising autoencoder. The 1D-DGAN-PHM produces smooth trajectories and preserves the initial linear degradation of the signals. The 1D-DGAN-PHM has the most significant improvement in prognosability (on average, 0.73 to 0.81). Data from the 1D-DGAN-PHM resulted in the best MAE (29 to 25 cycles) and RMSE (score of 39 to 36) for a Random Forest.The code is publicly available at 1D-DGAN-PHM.(c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).;2022;Health related;Health related
"Yelmen, B; Decelle, A; Ongaro, L; Marnetto, D; Tallec, C; Montinaro, F; Furtlehner, C; Pagani, L; Jay, F";Creating artificial human genomes using generative neural networks;Generative models have shown breakthroughs in a wide spectrum of domains due to recent advancements in machine learning algorithms and increased computational power. Despite these impressive achievements, the ability of generative models to create realistic synthetic data is still under-exploited in genetics and absent from population genetics. Yet a known limitation in the field is the reduced access to many genetic databases due to concerns about violations of individual privacy, although they would provide a rich resource for data mining and integration towards advancing genetic studies. In this study, we demonstrated that deep generative adversarial networks (GANs) and restricted Boltzmann machines (RBMs) can be trained to learn the complex distributions of real genomic datasets and generate novel high-quality artificial genomes (AGs) with none to little privacy loss. We show that our generated AGs replicate characteristics of the source dataset such as allele frequencies, linkage disequilibrium, pairwise haplotype distances and population structure. Moreover, they can also inherit complex features such as signals of selection. To illustrate the promising outcomes of our method, we showed that imputation quality for low frequency alleles can be improved by data augmentation to reference panels with AGs and that the RBM latent space provides a relevant encoding of the data, hence allowing further exploration of the reference dataset and features for solving supervised tasks. Generative models and AGs have the potential to become valuable assets in genetic studies by providing a rich yet compact representation of existing genomes and high-quality, easy-access and anonymous alternatives for private databases. Author summary Generative neural networks have been effectively used in many different domains in the last decade, including machine dreamt photo-realistic imagery. In our work, we apply a similar concept to genetic data to automatically learn its structure and, for the first time, produce high quality realistic genomes. These novel genomes are distinct from the original ones used for training the generative networks. We show that artificial genomes, as we name them, retain many complex characteristics of real genomes and the heterogeneous relationships between individuals. They can be used in intricate analyses such as imputation of missing data as we demonstrated. We believe they have a high potential to become alternatives for many genome databases which are not publicly available or require long application procedures or collaborations and remove an important accessibility barrier in genomic research in particular for underrepresented populations.;2021;Not health related;Not health related
"Liang, T; Fan, XD; Li, QW; Li, SYR";Detection of dispersed short tandem repeats using reversible jump Markov chain Monte Carlo;Tandem repeats occur frequently in biological sequences. They are important for studying genome evolution and human disease. A number of methods have been designed to detect a single tandem repeat in a sliding window. In this article, we focus on the case that an unknown number of tandem repeat segments of the same pattern are dispersively distributed in a sequence. We construct a probabilistic generative model for the tandem repeats, where the sequence pattern is represented by a motif matrix. A Bayesian approach is adopted to compute this model. Markov chain Monte Carlo (MCMC) algorithms are used to explore the posterior distribution as an effort to infer both the motif matrix of tandem repeats and the location of repeat segments. Reversible jump Markov chain Monte Carlo (RJMCMC) algorithms are used to address the transdimensional model selection problem raised by the variable number of repeat segments. Experiments on both synthetic data and real data show that this new approach is powerful in detecting dispersed short tandem repeats. As far as we know, it is the first work to adopt RJMCMC algorithms in the detection of tandem repeats.;2012;Health related;Health related
"Huang, JK; Sullivan, NP; Zakutayev, A; O'Hayre, R";How reliable is distribution of relaxation times (DRT) analysis? A dual regression-classification perspective on DRT estimation, interpretation, and accuracy;The distribution of relaxation times (DRT) has gained increasing attention and adoption in recent years as a versatile method for analyzing electrochemical impedance spectroscopy (EIS) data obtained from complex devices like fuel cells, electrolyzers, and batteries. The DRT deconvolutes the impedance without a priori specification of a generative model, which is especially useful for interpretation and model selection when the governing principles of the system under study are not fully understood. However, DRT estimation is an ill-posed inversion problem that must be addressed with a subjective choice of regularization and tuning, which leaves substantial risk of misleading interpretations of EIS data. In this work, we suggest a new classification view of the DRT inversion to clarify DRT estimation and interpretation. We introduce a dual regression-classification framework that unifies the classification and regression views of the DRT inversion with wide-reaching implications for DRT analysis. The dual framework is employed to demonstrate a new kind of DRT inversion algorithm and develop novel evaluation metrics that capture previously ignored aspects of DRT accuracy. These approaches are applied to both synthetic data and experimental spectra collected from a protonic ceramic fuel cell and a lithium-ion battery to illustrate their broad utility. The dual inversion algorithm shows promising performance for accurate DRT estimation and autonomous model identification, while the dual evaluation approach produces metrics that meaningfully assess the strengths and risks of DRT algorithms. This work provides valuable insight for both practical application of the DRT to experimental data and further development of EIS analysis methods.;2023;Not health related;Not health related
"Aznan, NKN; Atapour-Abarghouei, A; Bonner, S; Connolly, JD; Breckon, TP";Leveraging Synthetic Subject Invariant EEG Signals for Zero Calibration BCI;Recently, substantial progress has been made in the area of Brain-Computer Interface (BCI) using modern machine learning techniques to decode and interpret brain signals. While Electroencephalography (EEC) has provided a non-invasive method of interfacing with a human brain, the acquired data is often heavily subject and session dependent. This makes the seamless incorporation of such data into realworld applications intractable as the subject and session data variance can lead to long and tedious calibration requirements and cross-subject generalisation issues. Focusing on a Steady State Visual Evoked Potential (SSVEP) classification systems, we propose a novel means of generating highly-realistic synthetic EEG data invariant to any subject, session or other environmental conditions. Our approach, entitled the Subject Invariant SSVEP Generative Adversarial Network (SIS-GAN), produces synthetic EEC data from multiple SSVEP classes using a single network. Additionally, by taking advantage of a fixed-weight pre-trained subject classification network, we ensure that our generative model remains agnostic to subject-specific features and thus produces subject-invariant data that can be applied to new previously unseen subjects. Our extensive experimental evaluation demonstrates the efficacy of our synthetic data, leading to superior performance, with improvements of up to 16 percentage points in zero-calibration classification tasks when trained using our subject-invariant synthetic EEC signals.;2021;Health related;Not health related
"Desai, R; Shah, A; Kothari, S; Surve, A; Shekokar, N";TextBrew: Automated Model Selection and Hyperparameter Optimization for Text Classification;In building a machine learning solution, algorithm selection and hyperparameter tuning is the most time-consuming task. Automated Machine Learning is a solution to fully automate the process of finding the best model for a given task without actually having to try various models. This paper introduces a new AutoML system, TextBrew, explicitly built for the NLP task of text classification. Our system provides an automated method for selecting transformer models, tuning hyperparameters, and combining the best models into one by ensembling. Keeping in mind that new state-of-the-art models are being constantly introduced, TextBrew has been designed to be highly flexible and thus can support additional models easily. In our work, we experiment with multiple transformer models, each with numerous different hyperparameter settings, and select the most robust models. These models are then trained on multiple datasets to obtain accuracy scores, which are then used to build the meta-dataset to train the meta-model. Since text classification datasets are not as abundant, our system generates synthetic data to augment the meta-dataset using CopulaGAN, a deep generative model. The meta-model is an ensemble of five models, which predicts the best candidate model with an accuracy of 78.75%. The final model returned to the user is an ensemble of all the best models that can be trained under the given time constraint. Experiments on various datasets and comparisons with existing systems demonstrate the effectiveness of our system.;2022;Not health related;Not health related
"Dasgupta, S; Osogami, T";Nonlinear Dynamic Boltzmann Machines for Time-Series Prediction;The dynamic Boltzmann machine (DyBM) has been proposed as a stochastic generative model of multi-dimensional time series, with an exact, learning rule that maximizes the log-likelihood of a given time series. The DyBM, however, is defined only for binary valued data, without any nonlinear hidden units. Here, in our first contribution, we extend the DyBM to deal with real valued data. We present a formulation called Gaussian DyBM, that can be seen as an extension of a vector autoregressive (VAR) model. This uses, in addition to standard (explanatory) variables, components that captures long term dependencies in the time series. In our second contribution, we extend the Gaussian DyBM model with a recurrent neural network (RNN) that controls the bias input to the DyBM units. We derive a stochastic gradient update rule such that, the output weights from the RNN can also be trained online along with other DyBM parameters. Furthermore, this acts as nonlinear hidden layer extending the capacity of DyBM and allows it to model nonlinear components in a given time-series. Numerical experiments with synthetic datasets show that the RNN-Gaussian DyBM improves predictive accuracy upon standard VAR by up to approximate to 35%. On real multi-dimensional time-series prediction, consisting of high nonlinearity and non-stationarity, we demonstrate that this nonlinear DyBM model achieves significant improvement upon state of the art baseline methods like VAR and long short-term memory (LSTM) networks at a reduced computational cost.;2017;Not health related;Not health related
"Quinn, CJ; Kiyavash, N; Coleman, TP";Directed Information Graphs;We propose a graphical model for representing networks of stochastic processes, the minimal generative model graph. It is based on reduced factorizations of the joint distribution over time. We show that under appropriate conditions, it is unique and consistent with another type of graphical model, the directed information graph, which is based on a generalization of Granger causality. We demonstrate how directed information quantifies Granger causality in a particular sequential prediction setting. We also develop efficient methods to estimate the topological structure from data that obviate estimating the joint statistics. One algorithm assumes upper bounds on the degrees and uses the minimal dimension statistics necessary. In the event that the upper bounds are not valid, the resulting graph is nonetheless an optimal approximation in terms of Kullback-Leibler (KL) divergence. Another algorithm uses near-minimal dimension statistics when no bounds are known, but the distribution satisfies a certain criterion. Analogous to how structure learning algorithms for undirected graphical models use mutual information estimates, these algorithms use directed information estimates. We characterize the sample-complexity of two plug-in directed information estimators and obtain confidence intervals. For the setting when point estimates are unreliable, we propose an algorithm that uses confidence intervals to identify the best approximation that is robust to estimation error. Last, we demonstrate the effectiveness of the proposed algorithms through the analysis of both synthetic data and real data from the Twitter network. In the latter case, we identify which news sources influence users in the network by merely analyzing tweet times.;2015;Not health related;Not health related
"Helmer, M; Warrington, S; Mohammadi-Nejad, AR; Ji, JL; Howell, A; Rosand, B; Anticevic, A; Sotiropoulos, SN; Murray, JD";On the stability of canonical correlation analysis and partial least squares with application to brain-behavior associations;"Associations between datasets can be discovered through multivariate methods like Canonical Correlation Analysis (CCA) or Partial Least Squares (PLS). A requisite property for interpretability and generalizability of CCA/PLS associations is stability of their feature patterns. However, stability of CCA/PLS in high-dimensional datasets is questionable, as found in empirical characterizations. To study these issues systematically, we developed a generative modeling framework to simulate synthetic datasets. We found that when sample size is relatively small, but comparable to typical studies, CCA/PLS associations are highly unstable and inaccurate; both in their magnitude and importantly in the feature pattern underlying the association. We confirmed these trends across two neuroimaging modalities and in independent datasets with n approximate to 1000 and n = 20,000, and found that only the latter comprised sufficient observations for stable mappings between imaging-derived and behavioral features. We further developed a power calculator to provide sample sizes required for stability and reliability of multivariate analyses. Collectively, we characterize how to limit detrimental effects of overfitting on CCA/PLS stability, and provide recommendations for future studies. Multivariate associations discovered by CCA/PLS can be highly unstable and inaccurate with relatively small but typical sample sizes, inspiring the development of a sample size calculator for stable associations.";2024;Not health related;Not health related
"Turénko, D; Khan, A; Hussain, R; Ali, SI";Oversampling Versus Variational Autoencoders: Employing Synthetic Data for Detection of Heracleum Sosnowskyi in Satellite Images;Detection of growth areas of hazardous invasive plants, such as Heracleum Sosnowskyi (HS), in satellite images, is an important application of machine learning and computer vision methods. There exists extensive literature on the problem of crop classification in images. However, sometimes, the hardest part is to gather qualitative labels and gather enough data to train models. Notably, this difficulty arises in the analysis of satellite images, where labeling the data is hard to perform manually. In this work, we've faced the same problem (lack of data) when trying to build a classification model for HS detection in images. The issue of lack of data can be solved by generating synthetic data using simple methods like oversampling (OS) to more complex techniques like Variational Autoencoders (VAE) and Generative Adversarial Networks. To the best of our knowledge, there exists no work that has compared the performance of using OS versus VAE to generate synthetic pixels to overcome the problem of data deficiency for the task of HS classification in images. Accordingly, in this work, we perform this comparison and present the evaluation results on our dataset.;2020;Not health related;Not health related
"Shah, DLW; Khan, MAU; Abrar, M; Amin, F; Alkhamees, BF; Alsalman, H";Enhancing the Quality and Authenticity of Synthetic Mammogram Images for Improved Breast Cancer Detection;Breast cancer is widespread throughout the world and can be cured if diagnosed early. Mammography is an irreplaceable and critical technique in modern medicine that serves as a foundation for the detection of breast cancer. In medical imaging, the reliability of synthetic mammogram images is produced by deep convolutional generative adversarial networks (DCGAN). Human validation to assess the quality of synthetic images to examine and calculate the perceptual variations between synthetic images and their real-world counterparts is a difficult task. Thus, this research focused on improving the quality and authenticity of synthetic mammogram images. For this, we explored and identified a new research gap because radiologists consistently expressed much higher confidence levels in real mammogram images in their assessment process. This research highlights the key difference between synthetic and real mammograms by defining mean scores. The defined mean identifies a large gap, with real mammographic images receiving an average score of 0.73 and a synthetic score of 0.31. A statistical analysis was performed, which produced a T-statistic of -6.35, a p-value less than 0.001, and a 95% confidence interval ranging from -0.50 to -0.28. These results have a wide range of implications. It emphasizes the urgent need for further improvements in the generative model, improving the legitimacy and caliber of synthetic mammogram images. Our research highlights how crucial it is to incorporate synthetic images into clinical practice with caution and thought. Ethical considerations must encompass the potential consequences of relying on synthetic data in medical decision-making, along with concerns related to diagnostic accuracy and patient safety.;2024;Health related;Health related
"Billot, B; Greve, DN; Puonti, O; Thielscher, A; Van Leemput, K; Fischl, B; Dalca, AV; Iglesias, JE";SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining;Despite advances in data augmentation and transfer learning, convolutional neural networks (CNNs) difficultly generalise to unseen domains. When segmenting brain scans, CNNs are highly sensitive to changes in resolution and contrast: even within the same MRI modality, performance can decrease across datasets. Here we introduce SynthSeg, the first segmentation CNN robust against changes in contrast and resolution. SynthSeg is trained with synthetic data sampled from a generative model conditioned on segmentations. Crucially, we adopt a domain randomisation strategy where we fully randomise the contrast and resolution of the synthetic training data. Consequently, SynthSeg can segment real scans from a wide range of target domains without retraining or fine-tuning, which enables straightforward analysis of huge amounts of heterogeneous clinical data. Because SynthSeg only requires segmentations to be trained (no images), it can learn from labels obtained by automated methods on diverse populations (e.g., ageing and diseased), thus achieving robustness to a wide range of morphological variability. We demonstrate SynthSeg on 5,000 scans of six modalities (including CT) and ten resolutions, where it exhibits unparallelled generalisation compared with supervised CNNs, state-of-the-art domain adaptation, and Bayesian segmentation. Finally, we demonstrate the generalisability of SynthSeg by applying it to cardiac MRI and CT scans.;2023;Health related;Health related
"De Bacco, C; Power, EA; Larremore, DB; Moore, C";Community detection, link prediction, and layer interdependence in multilayer networks;Complex systems are often characterized by distinct types of interactions between the same entities. These can be described as a multilayer network where each layer represents one type of interaction. These layers may be interdependent in complicated ways, revealing different kinds of structure in the network. In this work we present a generative model, and an efficient expectation-maximization algorithm, which allows us to perform inference tasks such as community detection and link prediction in this setting. Our model assumes overlapping communities that are common between the layers, while allowing these communities to affect each layer in a different way, including arbitrary mixtures of assortative, disassortative, or directed structure. It also gives us a mathematically principled way to define the interdependence between layers, by measuring how much information about one layer helps us predict links in another layer. In particular, this allows us to bundle layers together to compress redundant information and identify small groups of layers which suffice to predict the remaining layers accurately. We illustrate these findings by analyzing synthetic data and two real multilayer networks, one representing social support relationships among villagers in South India and the other representing shared genetic substring material between genes of the malaria parasite.;2017;Not health related;Not health related
"He, XR; Liu, Y";Not Enough Data? Joint Inferring Multiple Diffusion Networks via Network Generation Priors;Network Inference, i.e., discovering latent diffusion networks from observed cascades, has been studied extensively in recent years, leading to a series of excellent work. However, it has been observed that the accuracy of existing methods deteriorates significantly when the number of cascades are limited (compared with the large number of nodes), which is the norm in real world applications. Meanwhile, we are able to collect cascades on many different topics or over a long time period: the associated influence networks (either topic-specific or time-specific) are highly correlated while the number of cascade observations associated with each network is very limited. In this work, we propose a generative model, referred to as the Multi Cascades model (MCM), to address the challenge of data scarcity by exploring the commonality between multiple related diffusion networks. MCM builds a hierarchical graphical model, where all the diffusion networks share the same network prior, e.g., the popular Stochastic Blockmodels or the latent space models. The parameters of the network priors can be effectively learned by gleaning evidence from a large number of inferred networks. In return, each individual network can be inferred more accurately thanks to the prior information. Furthermore, we develop efficient inference and learning algorithms so that MCM is scalable for practical applications. The results on both synthetic datasets and real-world datasets demonstrate that MCM infers both topic-specific and time-varying diffusion networks more accurately.;2017;Not health related;Not health related
"Protopapas, P; Huijse, P; Estévez, PA; Zegers, P; Príncipe, JC; Marquette, JB";A NOVEL, FULLY AUTOMATED PIPELINE FOR PERIOD ESTIMATION IN THE EROS 2 DATA SET;We present a new method to discriminate periodic from nonperiodic irregularly sampled light curves. We introduce a periodic kernel and maximize a similarity measure derived from information theory to estimate the periods and a discriminator factor. We tested the method on a data set containing 100,000 synthetic periodic and nonperiodic light curves with various periods, amplitudes, and shapes generated using a multivariate generative model. We correctly identified periodic and nonperiodic light curves with a completeness of similar to 90% and a precision of similar to 95%, for light curves with a signal-to-noise ratio (S/N) larger than 0.5. We characterize the efficiency and reliability of the model using these synthetic light curves and apply the method on the EROS-2 data set. A crucial consideration is the speed at which the method can be executed. Using a hierarchical search and some simplification on the parameter search, we were able to analyze 32.8 million light curves in similar to 18 hr on a cluster of GPGPUs. Using the sensitivity analysis on the synthetic data set, we infer that 0.42% of the sources in the LMC and 0.61% of the sources in the SMC show periodic behavior. The training set, catalogs, and source code are all available at http://timemachine.iic.harvard.edu.;2015;Not health related;Not health related
"Tan, ZQ; Song, YF; Ou, ZJ";Calibrated adversarial algorithms for generative modelling;Generative adversarial networks are useful for unsupervised learning but may be difficult to train. We study a class of adversarial algorithms based on f-divergence minimization and provide an extension by allowing two objective functions instead of one to be chosen (hence calibrated) for updating the discriminator and the generator, respectively. The extension is derived and justified from theoretical analysis, which identifies specific objective functions for achieving stable gradients in the corresponding updates. Our experiments on synthetic data and MNIST and CIFAR-10 datasets demonstrate that the proposed method consistently achieves competitive or superior results when compared with various existing methods.;2019;Not health related;Not health related
"Trevithick, A; Chan, M; Stengel, M; Chan, ER; Liu, C; Yu, ZD; Khamis, S; Chandraker, M; Ramamoorthi, R; Nagano, K";Real-Time Radiance Fields for Single-Image Portrait View Synthesis;We present a one-shot method to infer and render a photorealistic 3D representation from a single unposed image (e.g., face portrait) in real-time. Given a single RGB input, our image encoder directly predicts a canonical triplane representation of a neural radiance field for 3D-aware novel view synthesis via volume rendering. Our method is fast (24 fps) on consumer hardware, and produces higher quality results than strong GAN-inversion baselines that require test-time optimization. To train our triplane encoder pipeline, we use only synthetic data, showing how to distill the knowledge from a pretrained 3D GAN into a feedforward encoder. Technical contributions include a Vision Transformer-based triplane encoder, a camera data augmentation strategy, and a well-designed loss function for synthetic data training. We benchmark against the state-of-the-art methods, demonstrating significant improvements in robustness and image quality in challenging real-world settings. We showcase our results on portraits of faces (FFHQ) and cats (AFHQ), but our algorithm can also be applied in the future to other categories with a 3D-aware image generator.;2023;Not health related;Not health related
"Kwak, S; Jeong, J; Lee, H; Kim, W; Seo, D; Yun, W; Lee, W; Shin, J";Few-Shot Anomaly Detection via Personalization;Even with a plenty amount of normal samples, anomaly detection has been considered as a challenging machine learning task due to its one-class nature, i. e., the lack of anomalous samples in training time. It is only recently that a few-shot regime of anomaly detection became feasible in this regard, e. g., with a help from large vision-language pre-trained models such as CLIP, despite its wide applicability. In this paper, we explore the potential of large text-to-image generative models in performing few-shot industrial anomaly detection. Specifically, recent text-to-image models have shown unprecedented ability to generalize from few images to extract their common and unique concepts, and even encode them into a textual token to personalize the model: so-called textual inversion. Here, we question whether this personalization is specific enough to discriminate the given images from their potential anomalies, which are often, e. g., open-ended, local, and hard-to-detect. We observe that standard textual inversion exhibits a weaker understanding in localized details within objects, which is not enough for detecting industrial anomalies accurately. Thus, we explore the utilization of model personalization to address anomaly detection and propose Anomaly Detection via Personalization (ADP). ADP enables extracting fine-grained local details shared in the images with simple-yet an effective regularization scheme from the zero-shot transferability of CLIP. We also propose a self-tuning scheme to further optimize the performance of our detection pipeline, leveraging synthetic data generated from the personalized generative model. Our experiments show that the proposed inversion scheme could achieve state-of-the-art results on two industrial anomaly benchmarks, MVTec-AD and VisA, in the regime of few normal samples.;2024;Not health related;Not health related
"Azzam, M; Wu, WH; Cao, WM; Wu, S; Wong, HS";KTransGAN: Variational Inference-Based Knowledge Transfer for Unsupervised Conditional Generative Learning;Class-conditional generative models have gained popularity due to their characteristics of learning disentangled representations. However, these models typically require labeled examples in training. In this paper, we explore the feasibility of training these models on completely unlabeled data, under the assumption that we have access to other labeled data. The labeled data share the same label space, while their domain is shifted. Our model, which we refer to as KTransGAN, incorporates a classifier to transfer knowledge from the labeled data and performs collaborative learning with the conditional generator. By adopting these measures, KTransGAN is able to approximate the conditional distribution of the unlabeled data and simultaneously introduces a new solution to the unsupervised domain adaptation problem. To mitigate the training difficulty of our generative adversarial networks-based model, variational encoding and feature matching are also considered. From the empirical results, KTransGAN exhibits outstanding performance on a number of synthetic datasets and multiple real-world benchmarks. The quality of the synthesized instances is far superior to the pure variational autoencoding model. For example, on the CIFAR-10 dataset, our model scores 35.3 in FID, while the other model scores 128.45. In addition, the synthesis quality is close to the case when the model is trained in a fully supervised setting over the same number of training iterations. Regarding the classification performance, for instance, our model surpasses the highest state-of-the-art results (89.19%) by a large margin and achieves a test accuracy of 95.31% on the unlabeled data SVHN, while MNIST represents the labeled data. These results highlight the effectiveness of our proposed framework.;2021;Not health related;Not health related
"Vu, H; Bui, ND";On the scalability of data augmentation techniques for low-resource machine translation between Chinese and Vietnamese;Neural Machine Translation (NMT) has constantly been shown to be a standard choice to build a translation system, in both academia and industry. For low-resource language pairs, data augmentation techniques have been widely used to tackle the data shortage problem in NMT. In this paper, we investigate the scaling behaviour of transformer-based NMT model to the increasing amount of synthetic data. Through the experiments, conducted in the Chinese-to-Vietnamese translation task, we aim to provide a guideline to the application of several methods such as back-translation, tagged back-translation, self-training and sentence concatenation in a low-resource, less-related language pair. Our results suggest that choosing the appropriate amount of synthetic data is a crucial task when building NMT systems. In addition, when combining methods, it is recommended to tag the data sources before training.;2023;Not health related;Not health related
Baird, HS;Document Recognition Without Strong Models;Can a high-performance document image recognition system be built without detailed knowledge of the application? Having benefited from the statistical machine-learning revolution of the last twenty years, our architectures rely less on hand-crafted special-case rules and more on models trained on labeled-sample data sets. But urgent questions remain. When we can't collect (and label) enough real training data, does it help to complement them with data synthesized using generative models? Is it ever completely safe to rely on synthetic data? If we can't manage to train (or craft) a single complete, near-perfect, application-specific strong model to drive recognition, can we make progress by combining several imperfect or incomplete weak models? Can recognition that is carried out jointly over weak models perform optimally while still running fast? Can a recognizer automatically pick a strong model of its input? Must we always pre-train models for every kind (style) of input expected, or can a recognizer adapt to unknown styles? Can weak models adapt autonomously, growing stronger and so driving accuracy higher, without any human intervention? Can one model criticize-and then proceed to correct-other models, even while it is being criticized and corrected in turn by them? After twenty-five years of research on these questions we have partial answers, many in the affirmative: in addition to promising laboratory demonstrations, we can take pride in successful applications. I'll illustrate the evolution of the state of the art with concrete examples, and point out open problems.;2011;Not health related;Not health related
"Tra, V; Duong, BP; Kim, JM";Improving Diagnostic Performance of a Power Transformer Using an Adaptive Over-Sampling Method for Imbalanced Data;Dissolved gas analysis (DGA) of insulating oil in power transformers can offer valuable information related to faults. Due to the poor and unbalanced characteristics of typical DGA datasets, which threaten the generalization capability of artificial intelligent (AI)-based models, we propose the use of a new over-sampling technique called ASMOTE (adaptive synthetic minority over-sampling TEchnique) in the pre-processing step to enrich the dataset. ASMOTE can significantly improve the generalization performance of AI-based models by providing a sufficient synthetic dataset to train an AI classifier. To authenticate the effectiveness of the ASMOTE algorithm, we validate the transformer diagnostic accuracy of some typical classification algorithms such as multilayer perceptron (MLP), support vector machine (SVM), and k-nearest neighbor (k-NN) using synthetic datasets created by the SMOTE technique. In addition, the use of DGA ratios is also considered. By investigating the interactions between byproduct gases in insulating oil and transformer faults, the non-code ratios of the dissolved emissions are chosen as the characterizing input to the AI-based models. Moreover, with the ability to extract discriminate faulty information of a transformer from DGA data, MLP is used as a preferable classifier for diagnosing symptoms present in transformers. The empirical results of this study demonstrate that the proposed technique remarkably increases the diagnostic performance of power transformer faults.;2019;Not health related;Not health related
"Hilal, W; Wilkinson, C; Giuliano, A; Alsadi, N; Surucu, O; Gadsden, SA; Yawney, J";Minority class augmentation using GANs to improve the detection of anomalies in critical operations;With the ever-increasing adoption of interconnected technologies and rapid digitization observed in modern-day life, many online networks and applications face constant threats to the security and integrity of their operations or services. For example, fraudsters and malicious entities are continuously evolving their techniques and approaches to bypass current measures in place to prevent financial fraud, vandalism in online knowledge bases and social networks like Wikipedia, and malicious cyber-attacks. As such, many of the supervised models proposed to detect these malicious actions face degradations in detection performance and are rendered obsolete over time. Furthermore, fraudulent or anomalous data representing these attacks are often scarce or very difficult to access, which further restricts the performance of supervised models. Generative adversarial networks (GANs) are a relatively new class of generative models that rely on unsupervised learning. Moreover, they have proven to effectively replicate the distributions of real data provided to them. These models can generate synthetic data with a degree of quality such that their resemblance to real data is almost indistinguishable, as demonstrated in image and video applications - like with the rise of DeepFakes. Based on the success of GANs in applications involving image-based data, this study examines the performance of several different GAN architectures as an oversampling technique to address the data imbalance issue in credit card fraud data. A comparative analysis is presented in this paper of different types of GANs used to fabricate training data for a classification model, and their impact on the performance of said classifier. Furthermore, we demonstrate that it is possible to achieve greater detection performance using GANs as an oversampling approach in imbalanced data problems.;2022;Not health related;Not health related
"Benedetti, M; Realpe-Gómez, J; Biswas, R; Perdomo-Ortiz, A";Quantum-Assisted Learning of Hardware-Embedded Probabilistic Graphical Models;"Mainstream machine-learning techniques such as deep learning and probabilistic programming rely heavily on sampling from generally intractable probability distributions. There is increasing interest in the potential advantages of using quantum computing technologies as sampling engines to speed up these tasks or to make them more effective. However, some pressing challenges in state-of-the-art quantum annealers have to be overcome before we can assess their actual performance. The sparse connectivity, resulting from the local interaction between quantum bits in physical hardware implementations, is considered the most severe limitation to the quality of constructing powerful generative unsupervised machine-learning models. Here, we use embedding techniques to add redundancy to data sets, allowing us to increase the modeling capacity of quantum annealers. We illustrate our findings by training hardware-embedded graphical models on a binarized data set of handwritten digits and two synthetic data sets in experiments with up to 940 quantum bits. Our model can be trained in quantum hardware without full knowledge of the effective parameters specifying the corresponding quantum Gibbs-like distribution; therefore, this approach avoids the need to infer the effective temperature at each iteration, speeding up learning; it also mitigates the effect of noise in the control parameters, making it robust to deviations from the reference Gibbs distribution. Our approach demonstrates the feasibility of using quantum annealers for implementing generative models, and it provides a suitable framework for benchmarking these quantum technologies on machine-learning-related tasks.";2017;Not health related;Not health related
"Livezey, JA; Bujan, AF; Sommer, FT";Learning Overcomplete, Low Coherence Dictionaries with Linear Inference;Finding overcomplete latent representations of data has applications in data analysis, signal processing, machine learning, theoretical neuroscience and many other fields. In an overcomplete representation, the number of latent features exceeds the data dimensionality, which is useful when the data is undersampled by the measurements (compressed sensing or information bottlenecks in neural systems) or composed from multiple complete sets of linear features, each spanning the data space. Independent Components Analysis (ICA) is a linear technique for learning sparse latent representations, which typically has a lower computational cost than sparse coding, a linear generative model which requires an iterative, nonlinear inference step. While well suited for finding complete representations, we show that overcompleteness poses a challenge to existing ICA algorithms. Specifically, the coherence control used in existing ICA and other dictionary learning algorithms, necessary to prevent the formation of duplicate dictionary features, is ill-suited in the overcomplete case. We show that in the overcomplete case, several existing ICA algorithms have undesirable global minima that maximize coherence. We provide a theoretical explanation of these failures and, based on the theory, propose improved coherence control costs for overcomplete ICA algorithms. Further, by comparing ICA algorithms to the computationally more expensive sparse coding on synthetic data, we show that the limited applicability of overcomplete, linear inference can be extended with the proposed cost functions. Finally, when trained on natural images, we show that the coherence control biases the exploration of the data manifold, sometimes yielding suboptimal, coherent solutions. All told, this study contributes new insights into and methods for coherence control for linear ICA, some of which are applicable to many other nonlinear models.;2019;Not health related;Health related
"Hufnagel, H; Pennec, X; Ehrhardt, J; Handels, H; Ayache, N";Shape analysis using a point-based statistical shape model built on correspondence probabilities;A fundamental problem when computing statistical shape models is the determination of correspondences between the instances of the associated data set. Often, homologies between points that represent the surfaces are assumed which might lead to imprecise mean shape and variability results. We propose an approach where exact correspondences are replaced by evolving correspondence probabilities. These are the basis for a novel algorithm that computes a generative statistical shape model. We developed an unified MAP framework to compute the model parameters ('mean shape' and 'modes of variation') and the nuisance parameters which leads to an optimal adaption of the model to the set of observations. The registration of the model on the instances is solved using the Expectation Maximization - Iterative Closest Point algorithm which is based on probabilistic correspondences and proved to be robust and fast. The alternated optimization of the MAP explanation with respect to the observation and the generative model parameters leads to very efficient and closed-form solutions for (almost) all parameters. Experimental results on brain structure data sets demonstrate the efficiency and well-posedness of the approach. The algorithm is then extended to an automatic classification method using the k-means clustering and applied to synthetic data as well as brain structure classification problems.;2007;Not health related;Not health related
"Polykovskiy, D; Vetrov, D";Deterministic Decoding for Discrete Data in Variational Autoencoders;Variational autoencoders are prominent generative models for modeling discrete data. However, with flexible decoders, they tend to ignore the latent codes. In this paper, we study a VAE model with a deterministic decoder (DD-VAE) for sequential data that selects the highest-scoring tokens instead of sampling. Deterministic decoding solely relies on latent codes as the only way to produce diverse objects, which improves the structure of the learned manifold. To implement DD-VAE, we propose a new class of bounded support proposal distributions and derive Kullback-Leibler divergence for Gaussian and uniform priors. We also study a continuous relaxation of deterministic decoding objective function and analyze the relation of reconstruction accuracy and relaxation parameters. We demonstrate the performance of DD-VAE on multiple datasets, including molecular generation and optimization problems.;2020;Not health related;Not health related
"Kayisu, AK; Kambale, WV; Benarbia, T; Bokoro, PN; Kyamakya, K";A Comprehensive Literature Review on Artificial Dataset Generation for Repositioning Challenges in Shared Electric Automated and Connected Mobility;"In the near future, the incorporation of shared electric automated and connected mobility (SEACM) technologies will significantly transform the landscape of transportation into a sustainable and efficient mobility ecosystem. However, these technological advances raise complex scientific challenges. Problems related to safety, energy efficiency, and route optimization in dynamic urban environments are major issues to be resolved. In addition, the unavailability of realistic and various data of such systems makes their deployment, design, and performance evaluation very challenging. As a result, to avoid the constraints of real data collection, using generated artificial datasets is crucial for simulation to test and validate algorithms and models under various scenarios. These artificial datasets are used for the training of ML (Machine Learning) models, allowing researchers and operators to evaluate performance and predict system behavior under various conditions. To generate artificial datasets, numerous elements such as user behavior, vehicle dynamics, charging infrastructure, and environmental conditions must be considered. In all these elements, symmetry is a core concern; in some cases, asymmetry is more realistic; however, in others, reaching/maintaining as much symmetry as possible is a core requirement. This review paper provides a comprehensive literature survey of the most relevant techniques generating synthetic datasets in the literature, with a particular focus on the shared electric automated and connected mobility context. Furthermore, this paper also investigates central issues of these complex and dynamic systems regarding how artificial datasets could be used in the training of ML models to address the repositioning problem. Hereby, symmetry is undoubtedly a crucial consideration for ML models. In the case of datasets, it is imperative that they accurately emulate the symmetry or asymmetry observed in real-world scenarios to be effectively represented by the generated datasets. Then, this paper investigates the current challenges and limitations of synthetic datasets, such as the reliability of simulations to the real world, and the validation of generative models. Additionally, it explores how ML-based algorithms can be used to optimize vehicle routing, charging infrastructure usage, demand forecasting, and other important operational elements. In conclusion, this paper outlines a series of interesting new research avenues concerning the generation of artificial data for SEACM systems.";2024;Not health related;Not health related
"Wang, HY; Li, P; Lang, X; Tao, DP; Ma, J; Li, X";FTGAN: A Novel GAN-Based Data Augmentation Method Coupled Time-Frequency Domain for Imbalanced Bearing Fault Diagnosis;For imbalanced bearing fault diagnosis, generative adversarial networks (GANs) are a common data augmentation (DA) approach. Nevertheless, current GAN-based methods cannot update the generator from time-frequency domain simultaneously, downgrading the authenticity of signal time-frequency character. In this article, Fourier-like transform GAN (FTGAN), a novel GAN method, is proposed by introducing a Fourier-like transformer (FLT) based on autoencoder (AE) to improve synthetic data quality. FLT approximates the discrete Fourier transform (DFT) by the neural network, learning a universal map from time to frequency domain during training. FTGAN with FLT can decouple input into a time-frequency domain, fitting the distribution of time and frequency of data simultaneously. Multidomain distribution is manipulated in FTGAN without introducing additional signal transformation means. Furthermore, train on real, test on synthetic (TRTS) and train on synthetic, test on real (TSTR) analyses of 1-D data are introduced to evaluate data quality. Real and synthetic data are applied as training or test sets of diagnostic classifiers by turns so that data quality can be analyzed through diagnosis results. Experiment results show that the proposed method can generate bearing fault signals closer to real data in the time and frequency domains, effectively improving the performance under an imbalanced dataset.;2023;Not health related;Not health related
"Deshpande, S; Minhas, F; Graham, S; Rajpoot, N";SAFRON: Stitching Across the Frontier Network for Generating Colorectal Cancer Histology Images;Automated synthesis of histology images has several potential applications including the development of data-efficient deep learning algorithms. In the field of computational pathology, where histology images are large in size and visual context is crucial, synthesis of large high-resolution images via generative modeling is an important but challenging task due to memory and computational constraints. To address this challenge, we propose a novel framework called SAFRON (Stitching Across the FROntier Network) to construct realistic, large high-resolution tissue images conditioned on input tissue component masks. The main novelty in the framework is integration of stitching in its loss function which enables generation of images of arbitrarily large sizes after training on relatively small image patches while preserving morphological features with minimal boundary artifacts. We have used the proposed framework for generating, to the best of our knowledge, the largest-sized synthetic histology images to date (up to 11Kx8K pixels). Compared to existing approaches, our framework is efficient in terms of the memory required for training and computations needed for synthesizing large high-resolution images. The quality of generated images was assessed quantitatively using Frechet Inception Distance as well as by 7 trained pathologists, who assigned a realism score to a set of images generated by SAFRON. The average realism score across all pathologists for synthetic images was as high as that of real images. We also show that training with additional synthetic data generated by SAFRON can significantly boost prediction performance of gland segmentation and cancer detection algorithms in colorectal cancer histology images. (C) 2022 Elsevier B.V. All rights reserved.;2022;Health related;Health related
"Xiao, QK; Qin, MY; Yin, YT";Skeleton-based Chinese sign language recognition and generation for bidirectional communication between deaf and hearing people;Chinese sign language (CSL) is one of the most widely used sign language systems in the world. As such, the automatic recognition and generation of CSL is a key technology enabling bidirectional communication between deaf and hearing people. Most previous studies have focused solely on sign language recognition (SLR), which only addresses communication in a single direction. As such, there is a need for sign language generation (SLG) to enable communication in the other direction (i.e., from hearing people to deaf people). To achieve a smoother exchange of ideas between these two groups, we propose a skeleton-based CSL recognition and generation framework based on a recurrent neural network (RNN), to support bidirectional CSL communication. This process can also be extended to other sequence-to-sequence information interactions. The core of the proposed framework is a two-level probability generative model. Compared with previous techniques, this approach offers a more flexible approximate posterior distribution, which can produce skeletal sequences of varying styles that are recognizable to humans. In addition, the proposed generation method compensated for a lack of training data. A series of experiments in bidirectional communication were conducted on the large 500 CSL dataset. The proposed algorithm achieved high recognition accuracy for both real and synthetic data, with a reduced runtime. Furthermore, the generated data improved the performance of the discriminator. These results suggest the proposed bidirectional communication framework and generation algorithm to be an effective new approach to CSL recognition. (c) 2020 Elsevier Ltd. All rights reserved.;2020;Not health related;Not health related
"Nussberger, J; Boesel, F; Lenz, S; Binder, H; Hess, M";Synthetic observations from deep generative models and binary omics data with limited sample size;Deep generative models can be trained to represent the joint distribution of data, such as measurements of single nucleotide polymorphisms (SNPs) from several individuals. Subsequently, synthetic observations are obtained by drawing from this distribution. This has been shown to be useful for several tasks, such as removal of noise, imputation, for better understanding underlying patterns, or even exchanging data under privacy constraints. Yet, it is still unclear how well these approaches work with limited sample size. We investigate such settings specifically for binary data, e.g. as relevant when considering SNP measurements, and evaluate three frequently employed generative modeling approaches, variational autoencoders (VAEs), deep Boltzmann machines (DBMs) and generative adversarial networks (GANs). This includes conditional approaches, such as when considering gene expression conditional on SNPs. Recovery of pair-wise odds ratios (ORs) is considered as a primary performance criterion. For simulated as well as real SNP data, we observe that DBMs generally can recover structure for up to 300 variables, with a tendency of over-estimating ORs when not carefully tuned. VAEs generally get the direction and relative strength of pairwise relations right, yet with considerable under-estimation of ORs. GANs provide stable results only with larger sample sizes and strong pair-wise relations in the data. Taken together, DBMs and VAEs (in contrast to GANs) appear to be well suited for binary omics data, even at rather small sample sizes. This opens the way for many potential applications where synthetic observations from omics data might be useful.;2021;Not health related;Not health related
"Parida, S; Motlicek, P";Abstract Text Summarization: A Low Resource Challenge;Text summarization is considered as a challenging task in the NLP community. The availability of datasets for the task of multilingual text summarization is rare, and such datasets are difficult to construct. In this work, we build an abstract text summarizer for the German language text using the state-of-the-art Transformer model. We propose an iterative data augmentation approach which uses synthetic data along with the real summarization data for the German language. To generate synthetic data, the Common Crawl (German) dataset is exploited, which covers different domains. The synthetic data is effective for the low resource condition and is particularly helpful for our multilingual scenario where availability of summarizing data is still a challenging issue. The data are also useful in deep learning scenarios where the neural models require a large amount of training data for utilization of its capacity. The obtained summarization performance is measured in terms of ROUGE and BLEU score. We achieve an absolute improvement of +1.5 and +16.0 in ROUGE1 F1 (R1 F1) on the development and test sets, respectively, compared to the system which does not rely on data augmentation.;2019;Not health related;Not health related
"Meng, N; Ge, Z; Zeng, TJ; Lam, EY";LightGAN: A Deep Generative Model for Light Field Reconstruction;A light field image captured by a plenoptic camera can be considered a sampling of light distribution within a given space. However, with the limited pixel count of the sensor, the acquisition of a high-resolution sample often comes at the expense of losing parallax information. In this work, we present a learning-based generative framework to overcome such tradeoff by directly simulating the light field distribution. An important module of our model is the high-dimensional residual block, which fully exploits the spatio-angular information. By directly learning the distribution, our approach can generate both high-quality sub-aperture images and densely-sampled light fields. Experimental results on both real-world and synthetic datasets demonstrate that the proposed method outperforms other state-of-the-art approaches and achieves visually more realistic results.;2020;Not health related;Not health related
"Al-Ghalibi, M; Lawonn, K";Topic Aspects-Based Generative Mixture Model for Movie Recommendation System using Deep Convolutional Network;Movie recommendation systems have become ubiquitous in most sides of our lives. Currently, they are far from optimal. This paper presents a movielense recommendation system based on machine learning through utilizing the deep convolutional network and depending on generative modeling of public previous aspects mixtures. The objective of this paper is to introduce such a recommendation system to help users in selecting datasets of movies according to certain pre-specified measurements and data. The applied methodology is pivoted on implementing the system by using different sentimental analysis algorithms. These algorithms are keen to provide a solution for the full stack developers through using a trained model using their datasets. This will give suggestions based on their previous activity or recommended by other users' interests demonstrated on their website. Thus to help users visualize their interest or to form the better scope of visualization. The presented system has proved better results concerning accuracy and efficiency in comparison with some other similar works. When experimentations on both real and synthetic datasets were conducted, the system showed percentile improvement of about 91.07%in the training dataset and 93.49%in the testing dataset respectively. This system is convenient for several application fields like time series network visualization, business process modeling, various data mining applications, e-commerce websites, besides most online platforms that people use including social media.;2020;Not health related;Not health related
"Kumar, AJS; Chong, RS; Crowston, JG; Chua, J; Bujor, I; Husain, R; Vithana, EN; Girard, MJA; Ting, DSW; Cheng, CY; Aung, T; Popa-Cherecheanu, A; Schmetterer, L; Wong, D";Evaluation of Generative Adversarial Networks for High-Resolution Synthetic Image Generation of Circumpapillary Optical Coherence Tomography Images for Glaucoma;"IMPORTANCE Deep learning (DL) networks require large data sets for training, which can be challenging to collect clinically. Generative models could be used to generate large numbers of synthetic optical coherence tomography (OCT) images to train such DL networks for glaucoma detection. OBJECTIVE To assess whether generative models can synthesize circumpapillary optic nerve head OCT images of normal and glaucomatous eyes and determine the usability of synthetic images for training DL models for glaucoma detection. DESIGN, SETTING, AND PARTICIPANTS Progressively growing generative adversarial network models were trained to generate circumpapillary OCT scans. Image gradeability and authenticity were evaluated on a clinical set of 100 real and 100 synthetic images by 2 clinical experts. DL networks for glaucoma detection were trained with real or synthetic images and evaluated on independent internal and external test data sets of 140 and 300 real images, respectively. MAIN OUTCOMES AND MEASURES Evaluations of the clinical set between the experts were compared. Glaucoma detection performance of the DL networks was assessed using area under the curve (AUC) analysis. Class activation maps provided visualizations of the regions contributing to the respective classifications. RESULTS A total of 990 normal and 862 glaucomatous eyes were analyzed. Evaluations of the clinical set were similar for gradeability (expert 1: 92.0%; expert 2: 93.0%) and authenticity (expert 1: 51.8%; expert 2: 51.3%). The best-performing DL network trained on synthetic images had AUC scores of 0.97 (95% CI, 0.95-0.99) on the internal test data set and 0.90 (95% CI, 0.87-0.93) on the external test data set, compared with AUCs of 0.96 (95% CI, 0.94-0.99) on the internal test data set and 0.84 (95% CI, 0.80-0.87) on the external test data set for the network trained with real images. An increase in the AUC for the synthetic DL network was observed with the use of larger synthetic data set sizes. Class activation maps showed that the regions of the synthetic images contributing to glaucoma detection were generally similar to that of real images. CONCLUSIONS AND RELEVANCE DL networks trained with synthetic OCT images for glaucoma detection were comparable with networks trained with real images. These results suggest potential use of generative models in the training of DL networks and as a means of data sharing across institutions without patient information confidentiality issues.";2022;Health related;Health related
"Sanchez, G; Lecaignard, F; Otman, A; Maby, E; Mattout, J";Active SAmpling Protocol (ASAP) to Optimize Individual Neurocognitive Hypothesis Testing: A BCI-Inspired Dynamic Experimental Design;The relatively young field of Brain-Computer Interfaces has promoted the use of electrophysiology and neuroimaging in real-time. In the meantime, cognitive neuroscience studies, which make extensive use of functional exploration techniques, have evolved toward model-based experiments and fine hypothesis testing protocols. Although these two developments are mostly unrelated, we argue that, brought together, they may trigger an important shift in the way experimental paradigms are being designed, which should prove fruitful to both endeavors. This change simply consists in using real-time neuroimaging in order to optimize advanced neurocognitive hypothesis testing. We refer to this new approach as the instantiation of an Active SAmpling Protocol (ASAP). As opposed to classical (static) experimental protocols, ASAP implements online model comparison, enabling the optimization of design parameters (e.g., stimuli) during the course of data acquisition. This follows the well-known principle of sequential hypothesis testing. What is radically new, however, is our ability to perform online processing of the huge amount of complex data that brain imaging techniques provide. This is all the more relevant at a time when physiological and psychological processes are beginning to be approached using more realistic, generative models which may be difficult to tease apart empirically. Based upon Bayesian inference, ASAP proposes a generic and principled way to optimize experimental design adaptively. In this perspective paper, we summarize the main steps in ASAP. Using synthetic data we illustrate its superiority in selecting the right perceptual model compared to a classical design. Finally, we briefly discuss its future potential for basic and clinical neuroscience as well as some remaining challenges.;2016;Health related;Health related
"Chen, SM; Wang, WJ; Xia, BH; You, XG; Peng, QM; Cao, ZH; Ding, WP";CDE-GAN: Cooperative Dual Evolution-Based Generative Adversarial Network;Generative adversarial networks (GANs) have been a popular deep generative model for real-world applications. Despite many recent efforts on GANs that have been contributed, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this article, motivated by the cooperative co-evolutionary algorithm, we propose a cooperative dual evolution-based GAN (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to the generator(s) and discriminators into a unified evolutionary adversarial framework to conduct effective adversarial multiobjective optimization. Thus, it exploits the complementary properties and injects dual mutation diversity into the training, to steadily diversify the estimated density in capturing multimodes and improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation (E-Generators and E-Discriminators), evolved by its own evolutionary algorithm. Additionally, we further propose a Soft Mechanism to balance the tradeoff between E-Generators and E-Discriminators to conduct steady training for CDE-GAN. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets demonstrate that the proposed CDE-GAN achieves a competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html.;2021;Not health related;Not health related
"Parikh, H; Vajao, C; Xu, L; Tchetgen, ET";Validating Causal Inference Methods;The fundamental challenge of drawing causal inference is that counterfactual outcomes are not fully observed for any unit. Furthermore, in observational studies, treatment assignment is likely to be confounded. Many statistical methods have emerged for causal inference under unconfoundedness conditions given pre-treatment covariates, including: propensity score-based methods, prognostic score-based methods, and doubly robust methods. Unfortunately for applied researchers, there is no 'one-size-fits-all' causal method that can perform optimally universally.In practice, causal methods are primarily evaluated quantitatively on handcrafted simulated data. Such data-generative procedures can be of limited value because they are typically stylized models of reality. They are simplified for tractability and lack the complexities of real-world data. For applied researchers, it is critical to understand how well a method performs for data at hand. Our work introduces a deep generative model-based framework, Credence, to validate causal inference methods. The framework's novelty stems from its ability to generate synthetic data anchored at the empirical distribution for the observed sample, and therefore virtually indistinguishable from the latter. The approach allows the user to specify ground truth for the form and magnitude of causal effects and confounding bias as functions of covariates. Thus simulated data sets are used to evaluate the potential performance of various causal estimation methods when applied to data similar to the observed sample. We demonstrate Credence's ability to accurately assess the relative performance of causal estimation techniques in an extensive simulation study and two real-world data applications from Lalonde and Project STAR studies.;2022;Not health related;Health related
"Xu, IRL; Van Booven, DJ; Goberdhan, S; Breto, A; Porto, J; Alhusseini, M; Algohary, A; Stoyanova, R; Punnen, S; Mahne, A; Arora, H";Generative Adversarial Networks Can Create High Quality Artificial Prostate Cancer Magnetic Resonance Images;The recent integration of open-source data with machine learning models, especially in the medical field, has opened new doors to studying disease progression and/or regression. However, the ability to use medical data for machine learning approaches is limited by the specificity of data for a particular medical condition. In this context, the most recent technologies, like generative adversarial networks (GANs), are being looked upon as a potential way to generate high-quality synthetic data that preserve the clinical variability of a condition. However, despite some success, GAN model usage remains largely minimal when depicting the heterogeneity of a disease such as prostate cancer. Previous studies from our group members have focused on automating the quantitative multi-parametric magnetic resonance imaging (mpMRI) using habitat risk scoring (HRS) maps on the prostate cancer patients in the BLaStM trial. In the current study, we aimed to use the images from the BLaStM trial and other sources to train the GAN models, generate synthetic images, and validate their quality. In this context, we used T2-weighted prostate MRI images as training data for Single Natural Image GANs (SinGANs) to make a generative model. A deep learning semantic segmentation pipeline trained the model to segment the prostate boundary on 2D MRI slices. Synthetic images with a high-level segmentation boundary of the prostate were filtered and used in the quality control assessment by participating scientists with varying degrees of experience (more than ten years, one year, or no experience) to work with MRI images. Results showed that the most experienced participating group correctly identified conventional vs. synthetic images with 67% accuracy, the group with one year of experience correctly identified the images with 58% accuracy, and the group with no prior experience reached 50% accuracy. Nearly half (47%) of the synthetic images were mistakenly evaluated as conventional. Interestingly, in a blinded quality assessment, a board-certified radiologist did not significantly differentiate between conventional and synthetic images in the context of the mean quality of synthetic and conventional images. Furthermore, to validate the usability of the generated synthetic images from prostate cancer MRIs, we subjected these to anomaly detection along with the original images. Importantly, the success rate of anomaly detection for quality control-approved synthetic data in phase one corresponded to that of the conventional images. In sum, this study shows promise that high-quality synthetic images from MRIs can be generated using GANs. Such an AI model may contribute significantly to various clinical applications which involve supervised machine-learning approaches.;2023;Health related;Health related
"Adeboye, O; Dargahi, T; Babaie, M; Saraee, M; Yu, CM";DeepClean: A Robust Deep Learning Technique for Autonomous Vehicle Camera Data Privacy;Autonomous Vehicles (AVs) are equipped with several sensors which produce various forms of data, such as geo-location, distance, and camera data. The volume and utility of these data, especially camera data, have contributed to the advancement of high-performance self-driving applications. However, these vehicles and their collected data are prone to security and privacy attacks. One of the main attacks against AV-generated camera data is location inference, in which camera data is used to extract knowledge for tracking the users. A few research studies have proposed privacy-preserving approaches for analysing AV-generated camera data using powerful generative models, such as Variational Auto Encoder (VAE) and Generative Adversarial Network (GAN). However, the related work considers a weak geo-localisation attack model, which leads to weak privacy protection against stronger attack models. This paper proposes DeepClean, a robust deep-learning model that combines VAE and a private clustering technique. DeepClean learns distinct labelled object structures of the image data as clusters and generates a more visual representation of the non-private object clusters, e.g., roads. It then distorts the private object areas using a private Gaussian Mixture Model (GMM) to learn distinct cluster structures of the labelled object areas. The synthetic images generated from our model guarantee privacy and resist a robust location inference attack by less than 4% localisation accuracy. This result implies that using DeepClean for synthetic data generation makes it less likely for a subject to be localised by an attacker, even when using a robust geo-localisation attack. The overall image utility level of the generated synthetic images by DeepClean is comparable to the benchmark studies.;2022;Not health related;Not health related
"Behjati, R; Arisholm, E; Bedregal, MM; Tan, C";Synthetic Test Data Generation Using Recurrent Neural Networks: A Position Paper;Testing in production-like test environments is an essential part of quality assurance processes in many industries. Provisioning of such test environments, for information-intensive services, involves setting up databases that are rich-enough to enable simulating a wide variety of user scenarios. While production data is perhaps the gold-standard here, many organizations, particularly within the public sectors, are not allowed to use production data for testing purposes due to privacy concerns. The alternatives are to use anonymized data, or synthetically generated data. In this paper, we elaborate on these alternatives and compare them in an industrial context. Further we focus on synthetic data generation and investigate the use of recurrent neural networks for this purpose. In our preliminary experiments, we were able to generate representative and highly accurate data using a recurrent neural network. These results open new research questions that we discuss here, and plan to investigate in our future research.;2019;Not health related;Not health related
"Daunizeau, J; Friston, KJ";A mesostate-space model for EEG and MEG;We present a multi-scale generative model for EEG, that entails a minimum number of assumptions about evoked brain responses, namely: (1) bioelectric activity is generated by a set of distributed sources, (2) the dynamics of these sources can be modelled as random fluctuations about a small number of mesostates, (3) mesostates evolve in a temporal structured way and are functionally connected (i.e. influence each other), and (4) the number of mesostates engaged by a cognitive task is small (e.g. between one and a few). A Variational Bayesian learning scheme is described that furnishes the posterior density on the models parameters and its evidence. Since the number of meso-sources specifies the model, the model evidence can be used to compare models and find the optimum number of meso-sources. In addition to estimating the dynamics at each cortical dipole, the mesostate-space model and its inversion provide a description of brain activity at the level of the mesostates (i.e. in terms of the dynamics of meso-sources that are distributed over dipoles). The inclusion of a mesostate level allows one to compute posterior probability maps of each dipole being active (i.e. belonging to an active mesostate). Critically, this model accommodates constraints on the number of meso-sources, while retaining the flexibility of distributed source models in explaining data. In short, it bridges the gap between standard distributed and equivalent current dipole models. Furthermore, because it is explicitly spatiotemporal, the model can embed any stochastic dynamical causal model (e.g. a neural mass model) as a Markov process prior on the mesostate dynamics. The approach is evaluated and compared to standard inverse EEG techniques, using synthetic data and real data. The results demonstrate the added-value of the mesostate-space model and its variational inversion. (c) 2007 Elsevier Inc. All rights reserved.;2007;Health related;Not health related
"Sabuncu, MR; Balci, SK; Shenton, ME; Golland, P";Image-Driven Population Analysis Through Mixture Modeling;We present iCluster, a fast and efficient algorithm that clusters a set of images while co-registering them using a parameterized, nonlinear transformation model. The output of the algorithm is a small number of template images that represent different modes in a population. This is in contrast with traditional, hypothesis-driven computational anatomy approaches that assume a single template to construct an atlas. We derive the algorithm based on a generative model of an image population as a mixture of deformable template images. We validate and explore our method in four experiments. In the first experiment, we use synthetic data to explore the behavior of the algorithm and inform a design choice on parameter settings. In the second experiment, we demonstrate the utility of having multiple atlases for the application of localizing temporal lobe brain structures in a pool of subjects that contains healthy controls and schizophrenia patients. Next, we employ iCluster to partition a data set of 415 whole brain MR volumes of subjects aged 18 through 96 years into three anatomical subgroups. Our analysis suggests that these subgroups mainly correspond to age groups. The templates reveal significant structural differences across these age groups that confirm previous findings in aging research. In the final experiment, we run iCluster on a group of 15 patients with dementia and 15 age-matched healthy controls. The algorithm produces two modes, one of which contains dementia patients only. These results suggest that the algorithm can be used to discover subpopulations that correspond to interesting structural or functional modes.;2009;Health related;Health related
"Juraev, S; Ghimire, A; Alikhanov, J; Kakani, V; Kim, H";Exploring Human Pose Estimation and the Usage of Synthetic Data for Elderly Fall Detection in Real-World Surveillance;The world's elderly population continues to grow at an unprecedented rate, creating a need to monitor the safety of an aging population. One of the current problems is accurately classifying elderly physical activities, especially falling down, and delivering prompt assistance to someone in need. Owing to the advancements in deep learning research, vision based solutions are employed for action recognition. One such popular approach is human pose estimation based action recognition or fall detection. Nevertheless, due to a lack of large-scale elderly fall datasets and the continuation of numerous challenges such as varying camera angles, illumination, and occlusion accurately classifying falls has been a problematic. To address these problems, this research first carried out a comprehensive study of the AI Hub dataset collected from real lives of elderly people in order to benchmark the performance of state-of-the-art human pose estimation methods. Secondly, owing to the limited number of real datasets, augmentation with synthetic data was applied and performance improvement was validated based on changes in the degree of accuracy. Third, this study shows that a Transformer network applied to elderly action recognition outperforms LSTM-based networks by a noticeable margin. Lastly, by observing the quantitative and qualitative performances of different networks, this paper proposes an efficient solution for elderly activity recognition and fall detection in the context of surveillance cameras.;2022;Health related;Not health related
"Gao, YQ; Kong, BY; Mosalam, KM";Deep leaf-bootstrapping generative adversarial network for structural image data augmentation;Employing Deep Learning (DL) technologies to solve Civil Engineering problems is an emerging topic in recent years. However, due to the lack of labeled data, it is difficult to obtain accurate results with DL. One commonly used method to tackle this issue is to use affine transformation to augment the data set, but it can only generate new images that are highly correlated with the original ones. Moreover, unlike normal natural objects, distribution of structural images is much more complex and mixed. To address these challenges, Generative Adversarial Network (GAN) can be one feasible choice. We introduce one specific generative model, namely, Deep Convolutional Generative Adversarial Network (DCGAN) and propose a Leaf-Bootstrapping (LB) method to improve the performance of this DCGAN. To effectively and quantitatively evaluate the quality of the synthetic images generated by DCGAN to complement human evaluation, Self-Inception Score (SIS) and Generalization Ability (GA) are proposed. We also propose a pipeline based on Transfer Learning (TL) using synthetic images to help enhance a weak classifier performance under the condition of low-data regime and limited computational resources. Finally, we conduct computer experiments with the proposed methods for two scenarios (scene level identification and damage state check) and one special synthetic data aggregation case. The results demonstrate the effectiveness and robustness of the proposed methods.;2019;Not health related;Not health related
"Besedin, A; Blanchart, P; Crucianu, M; Ferecatu, M";Deep online classification using pseudo-generative models;In this work we propose a new deep learning based approach for online classification on streams of high -dimensional data. While requiring very little historical data storage, our approach is able to alleviate catastrophic forgetting in the scenario of continual learning with no assumption on the stationarity of the data in the stream. To make up for the absence of historical data, we propose a new generative autoencoder endowed with an auxiliary loss function that ensures fast task-sensitive convergence. To evaluate our approach we perform experiments on two well-known image datasets, MNIST and LSUN, in a continuous streaming mode. We extend the experiments to a large multi-class synthetic dataset that allows to check the performance of our method in more challenging settings with up to 1000 distinct classes. Our approach is able to perform classification on dynamic data streams with an accuracy close to the results obtained in the offline classification setup where all the data are available for the full duration of training. In addition, we demonstrate the ability of our method to adapt to unseen data classes and new instances of already known data categories, while avoiding catastrophic forgetting of previously acquired knowledge.;2020;Not health related;Not health related
"Xue, ZF; Mao, WJ; Liu, Y";Image-level dataset synthesis with an end-to-end trainable framework;Dataset synthesis via virtual engines like Unity is attracting much more attention in recent years due to its low cost at obtaining ground-truth labels. For this kind of work, virtual environments are constructed within the engine to mimic the real-world, either with great manual efforts or learning-based methods. The latter shows superiority over the former when the target real-world scenes are changeable, from which the attributes of environments can be automatically adjusted based on the distribution difference between the synthetic and real-world datasets. However, the non-differentiability of whole pipeline hinders the efficiency of attribute optimization. To this end, this paper proposes to simulate synthetic datasets from a fine-grained perspective, such that the system can be trained at an end-to-end manner. Specifically, it is converted into an image-level data synthesis problem, and designs a constraint using the content loss between two images. As the rendering process of virtual engine is mathematically unknown, which blocks the back propagation of the gradients, a generative model is trained to approximate the engine. As a result, the whole framework becomes fully differentiable and the attributes can be optimized efficiently by gradient descent. Experimental result shows the efficiency of our method in obtaining useful synthetic training datasets. Besides, it is found that the image-level method enables to learn the potential distribution of real-world data, which is hard to be achieved by existing methods. As far as we know, it is the first attempt to finish this task with a differentiable process.;2022;Not health related;Not health related
"Aleardi, M; Vinciguerra, A; Stucchi, E; Hojat, A";Stochastic electrical resistivity tomography with ensemble smoother and deep convolutional autoencoders;To reduce both the computational cost of probabilistic inversions and the ill-posedness of geophysical problems, model and data spaces can be reparameterized into low-dimensional domains where the inverse solution can be computed more efficiently. Among the many compression methods, deep learning algorithms based on deep generative models provide an efficient approach for model and data space reduction. We present a probabilistic electrical resistivity tomography inversion in which the data and model spaces are compressed through deep convolutional variational autoencoders, while the optimization procedure is driven by the ensemble smoother with multiple data assimilation, an iterative ensemble-based algorithm. This method iteratively updates an initial ensemble of models that are generated according to a previously defined prior model. The inversion outcome consists of the most likely solution and a set of realizations of the variables of interest from which the posterior uncertainties can be numerically evaluated. We test the method on synthetic data computed over a schematic subsurface model, and then we apply the inversion to field measurements. The model predictions and the uncertainty assessments provided by the presented approach are also compared with the results of a Markov Chain Monte Carlo sampling working in the compressed domains, a gradient-based algorithm and with the outcomes of an ensemble-based inversion running in the uncompressed spaces. A finite-element code constitutes the forward operator. Our experiments show that the implemented inversion provides most likely solutions and uncertainty quantifications comparable to those yielded by the ensemble-based inversion running in the full model and data spaces, and the Markov Chain Monte Carlo sampling, but with a significant reduction of the computational cost.;2022;Not health related;Not health related
"Crosskey, M; Wang, P; Sakaguchi, R; Morton, KD";Physics-Based Data Augmentation for High Frequency 3D Radar Systems;"The detection of side-attack explosive hazards remains challenging due to the significant variation in size, shape, construction materials, and placement on or above the surface. Some of the most challenging-to-detect side-attack explosive hazards are those placed inside of naturally occurring clutter such as vegetation. High-frequency radar systems with 3D resolution have been observed to be an effective technology for detecting and discriminating surface-laid side-attack explosive hazards from both natural and manmade clutter. Automated target recognition on the 3D voxel radar data is a complex problem that is well suited for deep convolutional neural networks. The main drawback of such approaches is the requirement for a large amount of training data, which is expensive and time-consuming to collect. Ad hoc and generative models have been used to augment data for deep learning with some degree of success; however, these methods often generate examples closely resembling instances from the training data, and any deviations are potentially not physically realistic for the sensing phenomenology. More accurate and effective augmentation can be accomplished by leveraging sensor physics along with large amounts of readily available background data. Observations of target signatures under clutter-free conditions can be inserted into a cluttered scene in a way consistent with the physics governing the sensor. We show that our physics-based data augmentation technique yields realistic synthetic data that is useful for augmenting the available training data and leads to improved discrimination performance.";2018;Not health related;Not health related
"Bonchi, F; Gullo, F; Mishra, B; Ramazzotti, D";Probabilistic Causal Analysis of Social Influence;Mastering the dynamics of social influence requires separating, in a database of information propagation traces, the genuine causal processes from temporal correlation, i.e., homophily and other spurious causes. However, most studies to characterize social influence, and, in general, most data-science analyses focus on correlations, statistical independence, or conditional independence. Only recently, there has been a resurgence of interest in causal data science, e.g., grounded on causality theories. In this paper we adopt a principled causal approach to the analysis of social influence from information-propagation data, rooted in the theory of probabilistic causation. Our approach consists of two phases. In the first one, in order to avoid the pitfalls of misinterpreting causation when the data spans a mixture of several subtypes (Simpson's paradox), we partition the set of propagation traces into groups, in such a way that each group is as less contradictory as possible in terms of the hierarchical structure of information propagation. To achieve this goal, we borrow the notion of agony [ 26] and define the Agony-bounded Partitioning problem, which we prove being hard, and for which we develop two efficient algorithms with approximation guarantees. In the second phase, for each group from the first phase, we apply a constrained MLE approach to ultimately learn a minimal causal topology. Experiments on synthetic data show that our method is able to retrieve the genuine causal arcs w.r.t. a ground-truth generative model. Experiments on real data show that, by focusing only on the extracted causal structures instead of the whole social graph, the effectiveness of predicting influence spread is significantly improved.;2018;Not health related;Not health related
"Karlé, E; Tyagi, H";Dynamic Ranking with the BTL Model: A Nearest Neighbor based Rank Centrality Method;Many applications such as recommendation systems or sports tournaments involve pairwise comparisons within a collection of n items, the goal being to aggregate the binary outcomes of the comparisons in order to recover the latent strength and/or global ranking of the items. In recent years, this problem has received significant interest from a theoretical perspective with a number of methods being proposed, along with associated statistical guarantees under the assumption of a suitable generative model. While these results typically collect the pairwise comparisons as one comparison graph G, however in many applications - such as the outcomes of soccer matches during a tournament - the nature of pairwise outcomes can evolve with time. Theoretical results for such a dynamic setting are relatively limited compared to the aforementioned static setting. We study in this paper an extension of the classic BTL (Bradley-Terry-Luce) model for the static setting to our dynamic setup under the assumption that the probabilities of the pairwise outcomes evolve smoothly over the time domain [0, 1]. Given a sequence of comparison graphs (Gt,)t,is an element of T on a regular grid T subset of [0, 1], we aim at recovering the latent strengths of the items wt* is an element of Rn at any time t is an element of [0, 1]. To this end, we adapt the Rank Centrality method - a popular spectral approach for ranking in the static case - by locally averaging the available data on a suitable neighborhood of t. When (Gt,)t,is an element of T is a sequence of Erdo center dot s-Renyi graphs, we provide non-asymptotic 2 pound and too error bounds for estimating wt* which in particular establishes the consistency of this method in terms of n, and the grid size |T |. We also complement our theoretical analysis with experiments on real and synthetic data.;2023;Not health related;Not health related
"Yuan, YH; Xia, GZ; Zhang, XM; Zhou, C";Synthesis-Style Auto-Correlation-Based Transformer: A Learner on Ionospheric TEC Series Forecasting;Accurate 1-day global total electron content (TEC) forecasting is essential for ionospheric monitoring and satellite communications. However, it faces challenges due to limited data and difficulty in modeling long-term dependencies. This study develops a highly accurate model for 1-day global TEC forecasting. We utilized generative TEC data augmentation based on the International Global Navigation Satellite Service (IGS) data set from 1998 to 2017 to enhance the model's prediction ability. Our model takes the TEC sequence of the previous 2 days as input and predicts the global TEC value for each hourly step of the next day. We compared the performance of our model with 1-day predicted ionospheric products provided by both the Center for Orbit Determination in Europe (C1PG) and Beihang University (B1PG). We proposed a two-step framework: (a) a time series generative model to produce realistic synthetic TEC data for training, and (b) an auto-correlation-based transformer model designed to capture long-range dependencies in the TEC sequence. Experiments demonstrate that our model significantly improves 1-day forecast accuracy over prior approaches. On the 2018 benchmark data set, the global root mean squared error (RMSE) of our model is reduced to 1.17 TEC units (TECU), while the RMSE of the C1PG model is 2.07 TECU. Reliability is higher in middle and high latitudes but lower in low latitudes (RMSE < 2.5 TECU), indicating room for improvement. This study highlights the potential of using data augmentation and auto-correlation-based transformer models trained on synthetic data to achieve high-quality 1-day global TEC forecasting.;2023;Not health related;Not health related
"Song, LC; Xu, YH; Zhang, LF; Du, B; Zhang, Q; Wang, XG";Learning From Synthetic Images via Active Pseudo-Labeling;Synthetic visual data refers to the data automatically rendered by the mature computer graphic algorithms. With the rapid development of these techniques, we can now collect photo-realistic synthetic images with accurate pixel-level annotations without much effort. However, due to the domain gaps between synthetic data and real data, in terms of not only visual appearance but also label distribution, directly applying models trained on synthetic images to real ones can hardly yield satisfactory performance. Since the collection of accurate labels for real images is very laborious and time-consuming, developing algorithms which can learn from synthetic images is of great significance. In this paper, we propose a novel framework, namely Active Pseudo-Labeling (APL), to reduce the domain gaps between synthetic images and real images. In APL framework, we first predict pseudo-labels for the unlabeled real images in the target domain by actively adapting the style of the real images to source domain. Specifically, the style of real images is adjusted via a novel task guided generative model, and then pseudo-labels are predicted for these actively adapted images. Lastly, we fine-tune the source-trained model in the pseudo-labeled target domain, which helps to fit the distribution of the real data. Experiments on both semantic segmentation and object detection tasks with several challenging benchmark data sets demonstrate the priority of our proposed method compared to the existing state-of-the-art approaches.;2020;Not health related;Not health related
"Marinescu, RV; Lorenzi, M; Blumberg, SB; Young, AL; Planell-Morell, P; Oxtoby, NP; Eshaghi, A; Yong, KX; Crutch, SJ; Golland, P; Alexander, DC";Disease Knowledge Transfer Across Neurodegenerative Diseases;We introduce Disease Knowledge Transfer (DKT), a novel technique for transferring biomarker information between related neurodegenerative diseases. DKT infers robust multimodal biomarker trajectories in rare neurodegenerative diseases even when only limited, unimodal data is available, by transferring information from larger multimodal datasets from common neurodegenerative diseases. DKT is a joint-disease generative model of biomarker progressions, which exploits biomarker relationships that are shared across diseases. Our proposed method allows, for the first time, the estimation of plausible multimodal biomarker trajectories in Posterior Cortical Atrophy (PCA), a rare neurodegenerative disease where only unimodal MRI data is available. For this we train DKT on a combined dataset containing subjects with two distinct diseases and sizes of data available: (1) a larger, multimodal typical AD (tAD) dataset from the TADPOLE Challenge, and (2) a smaller unimodal Posterior Cortical Atrophy (PCA) dataset from the Dementia Research Centre (DRC), for which only a limited number of Magnetic Resonance Imaging (MRI) scans are available. Although validation is challenging due to lack of data in PCA, we validate DKT on synthetic data and two patient datasets (TADPOLE and PCA cohorts), showing it can estimate the ground truth parameters in the simulation and predict unseen biomarkers on the two patient datasets. While we demonstrated DKT on Alzheimer's variants, we note DKT is generalisable to other forms of related neurodegenerative diseases. Source code for DKT is available online: https://github.com/mrazvan22/dkt.;2019;Health related;Health related
"Cheng, ZQ; Ligouri, A; Fogle, R; Webb, T";Capturing human motion in natural environments;The problem of capturing human motion in a natural environment is discussed from the perspective of needs, significance, scenarios, and technical challenges. The technologies that can be potentially used to capture human motion and activity in a natural environment are briefly discussed with an emphasis on computer vision-based markerless motion capture technology. Three representative markerless motion capture methods for capturing human motion from video imagery are implemented in this paper. The synthetic data generated by modeling and simulation and the data collected in laboratory environments are used for the training and validation. The initial results of three methods are presented and analyzed, and the advantages and disadvantages of each are discussed and compared. (C) 2015 Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license.;2015;Not health related;Not health related
"Fan, C; Li, XQ; Zhao, Y; Wang, JY";Quantitative assessments on advanced data synthesis strategies for enhancing imbalanced AHU fault diagnosis performance;The accurate and reliable fault diagnosis of air handling units (AHUs) has profound impacts on building energy efficiency and indoor thermal comforts. Data-driven fault diagnosis methods have gained increasing popularity considering the wide availabilities of operational data and advances in data analytics. In practice, the data-driven fault diagnosis performance can be severely degraded by the imbalanced nature of building operational data, i.e., the data samples of faulty operations are much smaller than that of normal operations. This study serves as a comprehensive study to investigate the potential of different data synthesis techniques in enhancing the performance of imbalanced AHU fault diagnosis. A variety of data synthesis strategies, ranging from conventional random sampling-based to advanced variational autoencoder-based techniques, have been developed for synthetic data generation. Data experiments have been designed to quantitatively evaluate the value of data synthesis in data scenarios considering various data amounts and imbalanced ratios. The research results indicate that synthetic data can significantly enhance the performance of imbalanced AHU fault diagnosis by up to 8.94%. Optimal data synthesis strategies have been identified in different data scenarios. The research outcomes are helpful for the development of reliable data-driven tools for practical tasks in building energy management. (c) 2021 Elsevier B.V. All rights reserved.;2021;Not health related;Not health related
"Dang, QV; Lee, GS";Scene Text Segmentation via Multi-Task Cascade Transformer With Paired Data Synthesis;The scene text segmentation task provides a wide range of practical applications. However, the number of images in the available datasets for scene text segmentation is not large enough to effectively train deep learning-based models, leading to limited performance. To solve this problem, we employ paired data generation to secure sufficient data samples for text segmentation via Text Image-conditional GANs. Furthermore, existing models implicitly model text attributes such as size, layout, font, and structure, which hinders their performance. To remedy this, we propose a Multi-task Cascade Transformer network that explicitly learns these attributes using large volumes of generated synthetic data. The transformer-based network includes two auxiliary tasks and one main task for text segmentation. The auxiliary tasks help the network learn text regions to focus on, as well as the structure of the text through different words and fonts, to support the main task. To bridge the gap between different datasets, we train the proposed network on paired synthetic data before fine-tuning it on real data. Our experiments on publicly available scene text segmentation datasets show that our method outperforms existing methods.;2023;Not health related;Not health related
"Xing, DT; Tzes, A";Synthetic Aerial Dataset for UAV Detection via Text-to-Image Diffusion Models;In this work, we present an approach to generate a synthetic aerial dataset for efficient Unmanned Aerial Vehicle (UAV) detection. We propose controlling the output of a text-to-image diffusion model by applying additional input conditions. Specifically, we train a diffusion model that enables conditional inputs, i.e., binary masks that specify all tractable parameters, including quantity, scale, pose, color, background, etc. Diverse photorealistic images with corresponding ground truth bounding boxes are generated automatically in an end-to-end manner. Without any interference, the dataset can be scaled to a large magnitude to facilitate the training process of UAV detection. Experimental results of YOLOv7 trained on the synthetic dataset demonstrate an extensive precision increment on unseen datasets of real images.;2023;Not health related;Not health related
"Hufnagel, H; Pennec, X; Ehrhardt, J; Ayache, N; Handels, H";Computation of a Probabilistic Statistical Shape Model in a Maximum-a-posteriori Framework;Objectives: When analyzing shapes and shape variabilities, the first step is bringing those shapes into correspondence. This is a fundamental problem even when solved by manually determining exact correspondences such as landmarks. We developed a method to represent a mean shape and a variability model for a training data set based on probabilistic correspondence computed between the observations. Methods: First, the observations are matched on each other with an affine transformation found by the Expectation-Maximization Iterative-Closest-Points (EM-ICP) registration. We then propose a maximum-a-posteriori (MAP) framework in order to compute the statistical shape model (SSM) parameters which result in an optimal adaptation of the model to the observations. The optimization of the MAP explanation is realized with respect to the observation parameters and the generative model parameters in a global criterion and leads to very efficient and closed-form solutions for (almost) all parameters. Results: We compared our probabilistic SSM to a SSM based on one-to-one correspondences and the PCA (classical SSM). Experiments on synthetic data served to test the performances on non-convex shapes (15 training shapes) which have proved difficult in terms of proper correspondence determination. e then computed the SSMs for real putamen data (21 training shapes). The evaluation was done by measuring the generalization ability as well as the specificity of both SSMs and showed that especially shape detail differences are better modeled by the probabilistic SSM (Hausdorff distance in generalization ability approximate to 25% smaller). Conclusions: The experimental outcome shows the efficiency and advantages of the new approach as the probabilistic SSM performs better in modeling shape details and differences.;2009;Not health related;Not health related
"Li, C; Edara, P; Shang, Y";Crash Frequency Modeling Using Realistic Artificial Data;\Accurate prediction of crash frequency is important in highway safety research. One obstacle for developing crash frequency models is the lack of real crash data. One way to address this obstacle is to generate realistic artificial data (RAD) that mimics the known causal relationships between contributing factors and crashes. There is no existing research demonstrating use of RAD in predicting crashes. This study first generates a RAD dataset using a transformer-based tabular generative adversarial network (TTCAN) and then uses it to predict crash frequency. Five traditional machine learning models and one deep learning model were tested. Results showed that the deep learning model, TabNet, outperformed the traditional machine learning models. The model performance was also tested using observed (real) crash data. The performance ranking of the six models on real data and RAD was the same, thus demonstrating that synthetic data can be used to test promising machine learning models.;2023;Not health related;Not health related
"Kim, G; Hong, T; Yim, M; Nam, J; Park, J; Yim, J; Hwang, W; Yun, S; Han, D; Park, S";OCR-Free Document Understanding Transformer;"Understanding document images (e.g., invoices) is a core but challenging task since it requires complex functions such as reading text and a holistic understanding of the document. Current Visual Document Understanding (VDU) methods outsource the task of reading text to off-the-shelf Optical Character Recognition (OCR) engines and focus on the understanding task with the OCR outputs. Although such OCR-based approaches have shown promising performance, they suffer from 1) high computational costs for using OCR; 2) inflexibility of OCR models on languages or types of documents; 3) OCR error propagation to the subsequent process. To address these issues, in this paper, we introduce a novel OCR-free VDU model named Donut, which stands for Document understanding transformer. As the first step in OCR-free VDU research, we propose a simple architecture (i.e., Transformer) with a pre-training objective (i.e., cross-entropy loss). Donut is conceptually simple yet effective. Through extensive experiments and analyses, we show a simple OCR-free VDU model, Donut, achieves state-of-the-art performances on various VDU tasks in terms of both speed and accuracy. In addition, we offer a synthetic data generator that helps the model pre-training to be flexible in various languages and domains. The code, trained model, and synthetic data are available at https://github.com/clovaai/donut.";2022;Not health related;Not health related
"Zheng, RB; Lyzinski, V; Priebe, CE; Tang, M";Vertex Nomination Between Graphs via Spectral Embedding and Quadratic Programming;Given a network and a subset of interesting vertices whose identities are only partially known, the vertex nomination problem seeks to rank the remaining vertices in such a way that the interesting vertices are ranked at the top of the list. An important variant of this problem is vertex nomination in the multiple graphs setting. Given two graphs G(1), G(2) with common vertices and a vertex of interest x is an element of G(1), we wish to rank the vertices of G(2) such that the vertices most similar to x are ranked at the top of the list. The current article addresses this problem and proposes a method that first applies adjacency spectral graph embedding to embed the graphs into a common Euclidean space, and then solves a penalized linear assignment problem to obtain the nomination lists. Since the spectral embedding of the graphs are only unique up to orthogonal transformations, we present two approaches to eliminate this potential nonidentifiability. One approach is based on orthogonal Procrustes and is applicable when there are enough vertices with known correspondence between the two graphs. Another approach uses adaptive point set registration and is applicable when there are few or no vertices with known correspondence. We show that our nomination scheme leads to accurate nomination under a generative model for pairs of random graphs that are approximately low-rank and possibly with pairwise edge correlations. We illustrate our algorithm's performance through simulation studies on synthetic data as well as analysis of a high-school friendship network and analysis of transition rates between web pages on the Bing search engine. Supplementary materials for this article are available and include R code, data, and an appendix with detailed proofs.;2022;Not health related;Not health related
"Guo, JX; Lu, SD; Cai, H; Zhang, WN; Yu, Y; Wang, J";Long Text Generation via Adversarial Training with Leaked Information;Automatically generating coherent and semantically meaningful text has many applications in machine translation, dialogue systems, image captioning, etc. Recently, by combining with policy gradient, Generative Adversarial Nets (GAN) that use a discriminative model to guide the training of the generative model as a reinforcement learning policy has shown promising results in text generation. However, the scalar guiding signal is only available after the entire text has been generated and lacks intermediate information about text structure during the generative process. As such, it limits its success when the length of the generated text samples is long (more than 20 words). In this paper, we propose a new framework, called LeakGAN, to address the problem for long text generation. We allow the discriminative net to leak its own high-level extracted features to the generative net to further help the guidance. The generator incorporates such informative signals into all generation steps through an additional MANAGER module, which takes the extracted features of current generated words and outputs a latent vector to guide the WORKER module for next-word generation. Our extensive experiments on synthetic data and various real world tasks with Turing test demonstrate that LeakGAN is highly effective in long text generation and also improves the performance in short text generation scenarios. More importantly, without any supervision, LeakGAN would be able to implicitly learn sentence structures only through the interaction between MANAGER and WORKER.;2018;Not health related;Not health related
"Bernton, E; Jacob, PE; Gerber, M; Robert, CP";Approximate Bayesian computation with the Wasserstein distance;A growing number of generative statistical models do not permit the numerical evaluation of their likelihood functions. Approximate Bayesian computation has become a popular approach to overcome this issue, in which one simulates synthetic data sets given parameters and compares summaries of these data sets with the corresponding observed values. We propose to avoid the use of summaries and the ensuing loss of information by instead using the Wasserstein distance between the empirical distributions of the observed and synthetic data. This generalizes the well-known approach of using order statistics within approximate Bayesian computation to arbitrary dimensions. We describe how recently developed approximations of the Wasserstein distance allow the method to scale to realistic data sizes, and we propose a new distance based on the Hilbert space filling curve. We provide a theoretical study of the method proposed, describing consistency as the threshold goes to 0 while the observations are kept fixed, and concentration properties as the number of observations grows. Various extensions to time series data are discussed. The approach is illustrated on various examples, including univariate and multivariate g-and-k distributions, a toggle switch model from systems biology, a queuing model and a Levy-driven stochastic volatility model.;2019;Not health related;Not health related
"Iranzo-Sánchez, J; Díaz-Munío, GVG; Civera, J; Juan, A";The MLLP-UPV Supervised Machine Translation Systems for WMT19 News Translation Task;This paper describes the participation of the MLLP research group of the Universitat Politecnica de Valencia in the WMT 2019 News Translation Shared Task. In this edition, we have submitted systems for the German <-> English and German <-> French language pairs, participating in both directions of each pair. Our submitted systems, based on the Transformer architecture, make ample use of data filtering, synthetic data and domain adaptation through fine-tuning.;2019;Not health related;Not health related
"Szlobodnyik, G; Farkas, L";Data Augmentation by Guided Deep Interpolation;State-of-the-art machine learning algorithms require large amount of high quality data. In practice, however, the sample size is commonly low and data is imbalanced along different class labels. Low sample size and imbalanced class distribution can significantly deteriorate the predictive performance of machine learning models. In order to overcome data quality issues, we propose a novel data augmentation method, Guided Deep Interpolation (GDI). It is based on a convolutional auto-encoder network, which is equipped with an auxiliary linear self-expressive layer. The network is trained by minimizing a composite objective function so that to extract the underlying clustered structure of semantic similarities of data points while high reconstruction quality is also preserved. The trained network is used to define a sampling strategy and a synthetic data generation procedure. Making use of the weights of the self-expressive layer, we introduce a measure of semantic variability to quantify how similar a data point to other data points on average. Based on the proposed measure of semantic variability, a joint distribution is defined. Using the distribution we can draw pairs of similar data points so that one point is semantically underrepresented (isolated) while its pair possesses relatively high semantic variability. A sampled pair is interpolated in the deep feature space of the network so that to increase semantic variability while preserve class label of the semantically underrepresented data point. The trained decoder is used to determine pixel space representations of latent space interpolations. The resulting data augmentation procedure generates synthetic samples by increasing the semantic variability of semantically underrepresented instances in a class label preserving way. Our experimental results show that the proposed method outperforms traditional and generative model-based data augmentation methods on low sample size and imbalanced data sets. (C) 2021 Elsevier B.V. All rights reserved.;2021;Not health related;Not health related
"Furdui, A; Zhang, TY; Worring, M; Cesar, P; El Ali, A";AC-WGAN-GP: Augmenting ECG and GSR Signals using Conditional Generative Models for Arousal Classification;Computational recognition of human emotion using Deep Learning techniques requires learning from large collections of data. However, the complex processes involved in collecting and annotating physiological data lead to datasets with small sample sizes. Models trained on such limited data often do not generalize well to real-world settings. To address the problem of data scarcity, we use an Auxiliary Conditioned Wasserstein Generative Adversarial Network with Gradient Penalty (AC-WGAN-GP) to generate synthetic data. We compare the recognition performance between real and synthetic signals as training data in the task of binary arousal classification. Experiments on GSR and ECG signals show that generative data augmentation significantly improves model performance (avg. 16.5%) for binary arousal classification in a subject-independent setting.;2021;Health related;Not health related
"Sun, CH; Xu, K; Marina, MK; Benn, H";GenDT: Mobile Network Drive Testing Made Efficient with Generative Modeling;Drive testing continues to play a key role in mobile network optimization for operators but its high cost is a big concern. Alternative approaches like virtual drive testing (VDT) target device testing in the lab whereas MDT or crowdsourcing based approaches are limited by the incentives users have to participate and contribute measurements. With the aim of augmenting drive testing and significantly reducing its cost, we propose GenDT, a novel deep generative model that synthesizes high-fidelity time series of key radio network key performance indicators (KPIs). The training of GenDT relies on a relatively small amount of real-world measurement data along with corresponding and easily accessible network and environment context data. Through this, GenDT learns the relationship between context and radio network KPIs as they vary over time, and therefore trained GenDT model can subsequently be relied on to generate time series for different KPIs for new drive test routes (trajectories) without having to collect field measurements. GenDT represents an initial attempt at enabling efficient drive testing via generative modeling. Evaluations with real-world mobile network drive testing measurement datasets from two countries demonstrate that GenDT can synthesize significantly more dependable data than a range of baselines. We further show that GenDT has the potential to significantly reduce the drive testing related measurement effort, and that GenDT-generated data yields similar results to that with real data in the context of two downstream use cases QoE prediction and handover analysis.;2022;Not health related;Not health related
"Rizvi, SKJ; Azad, MA; Fraz, MM";Spectrum of Advancements and Developments in Multidisciplinary Domains for Generative Adversarial Networks (GANs);The survey paper summarizes the recent applications and developments in the domain of Generative Adversarial Networks (GANs) i.e. a back propagation based neural network architecture for generative modeling. GANs is one of the most highlighted research avenue due to its synthetic data generation capabilities and benefits of representations comprehended irrespective of the application. While several reviews for GANs in the arena of image processing have been conducted by present but none have given attention on the review of GANs over multi-disciplinary domains. Therefore, in this survey, use of GAN in multidisciplinary applications areas and its implementation challenges have been done by conducting a rigorous search for journal/research article related to GAN and in this regard five renowned journal databases i.e. ACM Digital Library, Elsevier, IEEE Explore, Science Direct, Springer and proceedings of best domain specific conference are considered. By employing hybrid research methodology and article inclusion and exclusion criteria, 100 research articles are considered encompassing 23 application domains for the survey. In this paper applications of GAN in various practical domain and their implementation challenges its associated advantages and disadvantages have been discussed. For the first time a survey of this type have been done where GAN with wide range of application and its associated advantages and disadvantages issue have been reviewed. Finally, this article presents several diversified prominent developing trends in the respective research domain which will provide a visionary perspective regarding ongoing GANs related research and eventually help to develop an intuition for problem solving using GANs.;2021;Not health related;Not health related
"Garrido, S; Borysov, S; Rich, J; Pereira, F";Estimating causal effects with the neural autoregressive density estimator;The estimation of causal effects is fundamental in situations where the underlying system will be subject to active interventions. Part of building a causal inference engine is defining how variables relate to each other, that is, defining the functional relationship between variables entailed by the graph conditional dependencies. In this article, we deviate from the common assumption of linear relationships in causal models by making use of neural autoregressive density estimators and use them to estimate causal effects within Pearl's do-calculus framework. Using synthetic data, we show that the approach can retrieve causal effects from non-linear systems without explicitly modeling the interactions between the variables and include confidence bands using the non-parametric bootstrap. We also explore scenarios that deviate from the ideal causal effect estimation setting such as poor data support or unobserved confounders.;2021;Not health related;Not health related
"Hosseini, R; Hassanpour, N; Liu, LP; Hassoun, S";Pathway-Activity Likelihood Analysis and Metabolite Annotation for Untargeted Metabolomics Using Probabilistic Modeling;Motivation: Untargeted metabolomics comprehensively characterizes small molecules and elucidates activities of biochemical pathways within a biological sample. Despite computational advances, interpreting collected measurements and determining their biological role remains a challenge. Results: To interpret measurements, we present an inference-based approach, termed Probabilistic modeling for Untargeted Metabolomics Analysis (PUMA). Our approach captures metabolomics measurements and the biological network for the biological sample under study in a generative model and uses stochastic sampling to compute posterior probability distributions. PUMA predicts the likelihood of pathways being active, and then derives probabilistic annotations, which assign chemical identities to measurements. Unlike prior pathway analysis tools that analyze differentially active pathways, PUMA defines a pathway as active if the likelihood that the path generated the observed measurements is above a particular (user-defined) threshold. Due to the lack of ground truth metabolomics datasets, where all measurements are annotated and pathway activities are known, PUMA is validated on synthetic datasets that are designed to mimic cellular processes. PUMA, on average, outperforms pathway enrichment analysis by 8%. PUMA is applied to two case studies. PUMA suggests many biological meaningful pathways as active. Annotation results were in agreement to those obtained using other tools that utilize additional information in the form of spectral signatures. Importantly, PUMA annotates many measurements, suggesting 23 chemical identities for metabolites that were previously only identified as isomers, and a significant number of additional putative annotations over spectral database lookups. For an experimentally validated 50-compound dataset, annotations using PUMA yielded 0.833 precision and 0.676 recall.;2020;Not health related;Not health related
"Najar, F; Bourouis, S; Bouguila, N; Belghith, S";A new hybrid discriminative/generative model using the full-covariance multivariate generalized Gaussian mixture models;Discriminative models have been shown to be more advantageous for pattern recognition problem in machine learning. For this study, the main focus is developing a new hybrid model that combines the advantages of a discriminative technique namely the support vector machines (SVM) with the full efficiency offered through covariance multivariate generalized Gaussian mixture models (MGGMM). This new hybrid MGGMM applies the Fisher and Kullback-Leibler kernels derived from MGGMM to improve the kernel function of SVM. This approach is based on two different learning techniques explicitly: the Fisher scoring algorithm and the Bayes inference technique based on Markov Chain Monte Carlo and Metropolis-Hastings algorithm. These learning methods work with two model selection approaches (minimum message length and marginal likelihood) to determine the number of clusters. The effectiveness of the framework is demonstrated through extensive experiments including synthetic datasets, facial expression recognition and human activity recognition.;2020;Not health related;Not health related
"Ovalle-Magallanes, E; Avina-Cervantes, JG; Cruz-Aceves, I; Ruiz-Pinales, J";Transfer Learning for Stenosis Detection in X-ray Coronary Angiography;Coronary artery disease is the most frequent type of heart disease caused by an abnormal narrowing of coronary arteries, also called stenosis or atherosclerosis. It is also the leading cause of death globally. Currently, X-ray Coronary Angiography (XCA) remains the gold-standard imaging technique for medical diagnosis of stenosis and other related conditions. This paper presents a new method for the automatic detection of coronary artery stenosis in XCA images, employing a pre-trained (VGG16, ResNet50, and Inception-v3) Convolutional Neural Network (CNN) via Transfer Learning. The method is based on a network-cut and fine-tuning approach. The optimal cut and fine-tuned layers were selected following 20 different configurations for each network. The three networks were fine-tuned using three strategies: only real data, only artificial data, and artificial with real data. The synthetic dataset consists of 10,000 images (80% for training, 20% for validation) produced by a generative model. These different configurations were analyzed and compared using a real dataset of 250 real XCA images (125 for testing and 125 for fine-tuning), regarding their randomly initiated CNNs and a fourth custom CNN, trained as well with artificial and real data. The results showed that pre-trained VGG16, ResNet50, and Inception-v3 cut on an early layer and fine-tuned, overcame the referencing CNNs performance. Specifically, Inception-v3 provided the best stenosis detection with an accuracy of 0.95, a precision of 0.93, sensitivity, specificity, and F-1 score of 0.98, 0.92, and 0.95, respectively. Moreover, a class activation map is applied to identify the high attention regions for stenosis detection.;2020;Health related;Health related
"Lai, SY; Yang, YT; Xu, JA; Chen, YF; Huang, H";Neural Machine Translation Based on Back-Translation for Multilingual Translation Evaluation Task;This paper presents the systems developed by Beijing Jiaotong University for the CCMT 2020 multilingual translation evaluation task. For this translation task, we need to build a Japanese-English translation system based on only Japanese-Chinese and English-Chinese data. Our method mainly relies on synthetic data generated by back translation. We implemented three different architectures, namely Transformer-big, Transformer-base and Dynamic-Conv. We also implemented multi-model ensemble technique to further boost the final result. Experiments show that our machine translation system achieved high accuracy without relying on any bilingual training data.;2020;Not health related;Not health related
"Luo, H; Chen, WH; Xu, XZ; Gu, JY; Zhang, YQ; Liu, C; Jiang, YQ; He, ST; Wang, F; Li, H";An Empirical Study of Vehicle Re-Identification on the AI City Challenge;This paper introduces our solution for the Track2 in AI City Challenge 2021 (AICITY21). The Track2 is a vehicle re-identification (ReID) task with both the real-world data and synthetic data. We mainly focus on four points, i.e. training data, unsupervised domain-adaptive (UDA) training, post-processing, model ensembling in this challenge. (1) Both cropping training data and using synthetic data can help the model learn more discriminative features. (2) Since there is a new scenario in the test set that dose not appear in the training set, UDA methods perform well in the challenge. (3) Post-processing techniques including re-ranking, image-to-track retrieval, inter-camera fusion, etc, significantly improve final performance. (4) We ensemble CNN-based models and transformer-based models which provide different representation diversity. With aforementioned techniques, our method finally achieves 0.7445 mAP score, yielding the first place in the competition. Codes are available at https://github.com/michuanhaohao/AICITY2021_Track2_DMT.;2021;Not health related;Not health related
"Gowgi, P; Srinivasa, SG";Density Transformation and Parameter Estimation from Back Propagation Algorithm;We look at the neural network as a non-linear probability density function (pdf) transformer by stochastic learning cumulative (SLC) technique. We formulate a potential function that drives a neural network to non-linearly transform the input pdf to the desired pdf. We show the working of the algorithm using synthetic data drawn from three different pdfs and estimate the parameters of the distributions. The estimated parameter values match with the true values and the maximum likelihood estimates. We also derive bounds on the number of hidden neurons needed for parametric estimation in terms of the input data statistics.;2016;Not health related;Health related
"Xiong, ZT; Huang, W; Hu, JT; Zhu, XX";THE Benchmark: Transferable Representation Learning for Monocular Height Estimation;Generating 3-D city models rapidly is crucial for many applications. Monocular height estimation (MHE) is one of the most efficient and timely ways to obtain large-scale geometric information. However, existing works focus primarily on training and testing models using unbiased datasets, which does not align well with real-world applications. Therefore, we propose a new benchmark dataset to study the transferability of height estimation models in a cross-dataset setting. To this end, we first design and construct a large-scale benchmark dataset for cross-dataset transfer learning on the height estimation task. This benchmark dataset includes a newly proposed large-scale synthetic dataset, a newly collected real-world dataset, and four existing datasets from different cities. Next, a new experimental protocol, few-shot cross-dataset transfer, is designed. Furthermore, in this article, we propose a scale-deformable convolution (SDC) module to enhance the window-based Transformer for handling the scale-variation problem in the height estimation task. Experimental results have demonstrated the effectiveness of the proposed methods in traditional and cross-dataset transfer settings.;2023;Not health related;Not health related
"Simoes, LD; Costa, HJD; Aires, MNO; Medeiros, RP; Costa, FB; Bretas, AS";A power transformer differential protection based onsupport vector machine and wavelet transform;This paper presents a power transformer differential protection scheme based on support vector machines (SVM) combined with high-frequency features extracted with the real-time boundary stationary wavelet transform (RTBSWT). SVM models are derived with synthetic data, considering a wide variety of events, such as inter-turn faults, external faults during CT saturation, and evolving external-to-internal faults. A comparative performance assessment is carried out considering accuracy and other reliability indices, as well as operating time, and good results were achieved. The simplicity of the presented SVM-based relay, without hard-to-derive parameters, built on the classical differential protection framework, highlights potential aspects towards real-life implementation.;2021;Not health related;Not health related
"Chen, D; Qi, XD; Zheng, Y; Lu, YZ; Huang, YB; Li, ZJ";Synthetic data augmentation by diffusion probabilistic models to enhance weed recognition;Weed management plays an important role in crop yield and quality protection. Conventional weed control methods largely rely on intensive, blanket herbicide application, which incurs significant management costs and poses hazards to the environment and human health. Machine vision-based automated weeding has gained increasing attention for sustainable weed management through weed recognition and site-specific treatments. However, it remains a challenging task to reliably recognize weeds in variable field conditions, in part due to the difficulty curating large-scale, expert-labeled weed image datasets for supervised training of weed recognition algorithms. Data augmentation methods, including traditional geometric/color transformations and more advanced generative adversarial networks (GANs) can supplement data collection and labeling efforts by algorithmically expanding the scale of datasets. Recently, diffusion models have emerged in the field of image synthesis, providing a new means for augmenting image datasets to power machine vision systems. This study presents a novel investigation of the efficacy of diffusion models for generating weed images to enhance weed identification. Experiments on two public multi-class large weed datasets showed that diffusion models yielded the best trade-off between sample fidelity and diversity and obtained the highest Fre ' chet Inception Distance, compared to GANs (BigGAN, StyleGAN2, StyleGAN3). For instance, on a ten-class weed dataset (CottonWeedID10), the inclusion of synthetic weed images led to improvements by 1.17% (97.30% to 98.47), 1.21% (97.92% to 99.13%), and 2.30% (96.06% to 98.27%) in accuracy, precision, and recall, respectively, in weed classification by four deep learning models (i.e., VGG16, Inception-v3, Inception-v3, and ResNet50). Models trained using only 10% of real images with the remainder being synthetic data resulted in testing accuracy exceeding 94%.;2024;Not health related;Health related
"Chadebec, C; Allassonnière, S";Data Augmentation with Variational Autoencoders and Manifold Sampling;We propose a new efficient way to sample from a Variational Autoencoder in the challenging low sample size setting (A code is available at https://github.com/clementchadebec/Data_Augmentation_with_VAE-DALI). This method reveals particularly well suited to perform data augmentation in such a low data regime and is validated across various standard and real-life data sets. In particular, this scheme allows to greatly improve classification results on the OASIS database where balanced accuracy jumps from 80.7% for a classifier trained with the raw data to 88.6% when trained only with the synthetic data generated by our method. Such results were also observed on 3 standard data sets and with other classifiers.;2021;Not health related;Not health related
"Abdelmoumin, G; Whitaker, J; Rawat, DB; Rahman, A";A Survey on Data-Driven Learning for Intelligent Network Intrusion Detection Systems;"An effective anomaly-based intelligent IDS (AN-Intel-IDS) must detect both known and unknown attacks. Hence, there is a need to train AN-Intel-IDS using dynamically generated, real-time data in an adversarial setting. Unfortunately, the public datasets available to train AN-Intel-IDS are ineluctably static, unrealistic, and prone to obsolescence. Further, the need to protect private data and conceal sensitive data features has limited data sharing, thus encouraging the use of synthetic data for training predictive and intrusion detection models. However, synthetic data can be unrealistic and potentially bias. On the other hand, real-time data are realistic and current; however, it is inherently imbalanced due to the uneven distribution of anomalous and non-anomalous examples. In general, non-anomalous or normal examples are more frequent than anomalous or attack examples, thus leading to skewed distribution. While imbalanced data are commonly predominant in intrusion detection applications, it can lead to inaccurate predictions and degraded performance. Furthermore, the lack of real-time data produces potentially biased models that are less effective in predicting unknown attacks. Therefore, training AN-Intel-IDS using imbalanced and adversarial learning is instrumental to their efficacy and high performance. This paper investigates imbalanced learning and adversarial learning for training AN-Intel-IDS using a qualitative study. It surveys and synthesizes generative-based data augmentation techniques for addressing the uneven data distribution and generative-based adversarial techniques for generating synthetic yet realistic data in an adversarial setting using rapid review, structured reporting, and subgroup analysis.";2022;Not health related;Not health related
"Krause, J; Grabsch, H; Kloor, M; Jendrusch, M; Echle, A; Buelow, RD; Boor, P; Luedde, T; Brinker, TJ; Trautwein, C; Pearson, AT; Quirke, P; Jenniskens, J; Offermans, K; van den Brandt, PA; Kather, JN";Deep learning detects genetic alterations in cancer histology generated by adversarial networks;Deep learning can detect microsatellite instability (MSI) from routine histology images in colorectal cancer (CRC). However, ethical and legal barriers impede sharing of images and genetic data, hampering development of new algorithms for detection of MSI and other biomarkers. We hypothesized that histology images synthesized by conditional generative adversarial networks (CGANs) retain information about genetic alterations. To test this, we developed a 'histology CGAN' which was trained on 256 patients (training cohort 1) and 1457 patients (training cohort 2). The CGAN synthesized 10 000 synthetic MSI and non-MSI images which contained a range of tissue types and were deemed realistic by trained observers in a blinded study. Subsequently, we trained a deep learning detector of MSI on real or synthetic images and evaluated the performance of MSI detection in a held-out set of 142 patients. When trained on real images from training cohort 1, this system achieved an area under the receiver operating curve (AUROC) of 0.742 [0.681, 0.854]. Training on the larger cohort 2 only marginally improved the AUROC to 0.757 [0.707, 0.869]. Training on purely synthetic data resulted in an AUROC of 0.743 [0.658, 0.801]. Training on both real and synthetic data further increased AUROC to 0.777 [0.715, 0.821]. We conclude that synthetic histology images retain information reflecting underlying genetic alterations in colorectal cancer. Using synthetic instead of real images to train deep learning systems yields non-inferior classifiers. This approach can be used to create large shareable data sets or to augment small data sets with rare molecular features. (c) 2021 The Authors. The Journal of Pathology published by John Wiley & Sons, Ltd. on behalf of The Pathological Society of Great Britain and Ireland.;2021;Health related;Health related
"Greco, G; Guzzo, A; Nardiello, G";FD-VAE: A Feature Driven VAE Architecture for Flexible Synthetic Data Generation;Variational autoencoders (VAEs) are artificial neural networks used to learn effective data encodings in an unsupervised manner. Each input x provided to a VAE is indeed mapped to an internal representation, say z, in a low-dimensional space, called the latent space, from which an approximate version x of x can be eventually reconstructed via a decoding phase. VAEs are very popular generative models because, by randomly sampling points from the latent space, we can generate novel and unseen data that still reflect the characteristics of the dataset used for the training. In many application domains, however, generating random instances is not enough. Rather, we would like mechanisms that can generate instances enjoying some high-level features that are desired by the users. To accomplish this goal, a novel VAE architecture -named Feature Driven VAE is-presented. Internally, it uses Gaussian Mixture Models to structure the latent space into meaningful partitions, and it allows us to generate data with any desired combination of features, even when that specific combination has been never seen in the training examples. The architecture is orthogonal to the underlying application domain. However, to show its practical effectiveness, a specialization to the case of image generation has been presented and implemented. Results of experimental activity conducted on top of it are eventually discussed.;2020;Not health related;Not health related
"Tiago, C; Snare, SR; Sprem, J; McLeod, K";A Domain Translation Framework With an Adversarial Denoising Diffusion Model to Generate Synthetic Datasets of Echocardiography Images;Currently, medical image domain translation operations show a high demand from researchers and clinicians. Amongst other capabilities, this task allows the generation of new medical images with sufficiently high image quality, making them clinically relevant. Deep Learning (DL) architectures, most specifically deep generative models, are widely used to generate and translate images from one domain to another. The proposed framework relies on an adversarial Denoising Diffusion Model (DDM) to synthesize echocardiography images and perform domain translation. Contrary to Generative Adversarial Networks (GANs), DDMs are able to generate high quality image samples with a large diversity. If a DDM is combined with a GAN, this ability to generate new data is completed at an even faster sampling time. In this work we trained an adversarial DDM combined with a GAN to learn the reverse denoising process, relying on a guide image, making sure relevant anatomical structures of each echocardiography image were kept and represented on the generated image samples. For several domain translation operations, the results verified that such generative model was able to synthesize high quality image samples: MSE: 11.50 +/- 3.69, PSNR (dB): 30.48 +/- 0.09, SSIM: 0.47 +/- 0.03. The proposed method showed high generalization ability, introducing a framework to create echocardiography images suitable to be used for clinical research purposes.;2023;Health related;Health related
"Mariotti, O; Mac Aodha, O; Bilen, H";ViewNet: Unsupervised Viewpoint Estimation from Conditional Generation;Understanding the 3D world without supervision is currently a major challenge in computer vision as the annotations required to supervise deep networks for tasks in this domain are expensive to obtain on a large scale. In this paper, we address the problem of unsupervised viewpoint estimation. We formulate this as a self-supervised learning task, where image reconstruction provides the supervision needed to predict the camera viewpoint. Specifically, we make use of pairs of images of the same object at training time, from unknown viewpoints, to self-supervise training by combining the viewpoint information from one image with the appearance information from the other. We demonstrate that using a perspective spatial transformer allows efficient viewpoint learning, outperforming existing unsupervised approaches on synthetic data, and obtains competitive results on the challenging PASCAL3D+ dataset.;2021;Not health related;Not health related
"Ding, YRB; Suneja, S; Zheng, YH; Laredo, J; Morari, A; Kaiser, G; Ray, B";VELVET: a noVel Ensemble Learning approach to automatically locate VulnErable sTatements;Automatically locating vulnerable statements in source code is crucial to assure software security and alleviate developers' debugging efforts. This becomes even more important in today's software ecosystem, where vulnerable code can flow easily and unwittingly within and across software repositories like GitHub. Across such millions of lines of code, traditional static and dynamic approaches struggle to scale. Although existing machine-learning-based approaches look promising in such a setting, most work detects vulnerable code at a higher granularity - at the method or file level. Thus, developers still need to inspect a significant amount of code to locate the vulnerable statement(s) that need to be fixed. This paper presents VELVET, a novel ensemble learning approach to locate vulnerable statements. Our model combines graph-based and sequence-based neural networks to successfully capture the local and global context of a program graph and effectively understand code semantics and vulnerable patterns. To study VELVET's effectiveness, we use an off-the-shelf synthetic dataset and a recently published real-world dataset. In the static analysis setting, where vulnerable functions are not detected in advance, VELVET achieves 4.5x better performance than the baseline static analyzers on the real-world data. For the isolated vulnerability localization task, where we assume the vulnerability of a function is known while the specific vulnerable statement is unknown, we compare VELVET with several neural networks that also attend to local and global context of code. VELVET achieves 99.6% and 43.6% top-1 accuracy over synthetic data and real-world data, respectively, outperforming the baseline deep learning models by 5.3-29.0%.;2022;Not health related;Not health related
"Chojnacki, S; Klopotek, MA";Scale Invariant Bipartite Graph Generative Model;The purpose of this article is to present new undirected bigraph generator. Bigraphs (or bipartite graphs) contain nodes of two types and there exist edges only between nodes of different types. This data structure can be observed in various real-life scenarios. Random generator can be used to describe and better understand the scenarios. Moreover, the generator can output a wide range of synthetic datasets. We believe that the datasets can be utilized to evaluate performance of various algorithms that are deployed in such settings. The generative procedure is based on the preferential attachment principle. The principle is combined with the iterative growth mechanism and results in the power-law node degree distribution. Our algorithm extends the classic Barabasi - Albert model. We obtain the same scaling exponent as in the classic model, when we set equal parameters for both modalities. However, when we abandon the symmetry we are able to build graphs with wider spectrum of scaling exponents.;2012;Not health related;Not health related
"Saini, SK; Dhamnani, S; Srinivasan, A; Ibrahim, AA; Chavan, P";Multiple Treatment Effect Estimation using Deep Generative Model with Task Embedding;Causal inference using observational data on multiple treatments is an important problem in a wide variety of fields. However, the existing literature tends to focus only on causal inference in case of binary or multinoulli treatments. These models are either incompatible with multiple treatments, or extending them to multiple treatments is computationally expensive. We use a previous formulation of causal inference using variational autoencoder (VAE) and propose a novel architecture to estimate the causal effect of any subset of the treatments. The higher order effects of multiple treatments are captured through a task embedding. The task embedding allows the model to scale to multiple treatments. The model is applied on real digital marketing dataset to evaluate the next best set of marketing actions. For evaluation, the model is compared against competitive baseline models on two semi-synthetic datasets created using the covariates from the real dataset. The performance is measured along four evaluation metrics considered in the causal inference literature and one proposed by us. The proposed evaluation metric measures the loss in the expected outcome when a particular model is used for decision making as compared to the ground truth. The proposed model outperforms the baselines along all five evaluation metrics. It outperforms the best baseline by over 30% along these evaluation metrics. The proposed approach is also shown to be robust when a subset of the confounders is not observed. The results on real data show the importance of the flexible modeling approach provided by the proposed model.;2019;Health related;Health related
"Naveed, MH; Hashmi, US; Tajved, N; Sultan, N; Imran, A";Assessing Deep Generative Models on Time Series Network Data;To achieve zero touch automation in next generation wireless networks through artificial intelligence (AI), large amounts of training data is required. This training data is publicly unavailable and is a major hindrance in research on AI applications to wireless communication. One solution is using limited real data to generate synthetic data that can be used in lieu of real data. Generative Adversarial Networks (GAN) have been used successfully for this purpose. In this paper, we choose two publicly available GAN - based models and one deep learning - based auto-regressive model. We then compare their performance at generating synthetic time-series wireless network traffic data. We also assess the impact of data scarcity on the generated data quality by varying the level of data available to the models for training. Moreover, in order to assess the usefulness of this generated data, we compare the performance of a gradient boosting regressor trained solely on generated data, real data, and a mix of both at forecasting network traffic. Our experiments show that the GANs perform better than the auto-regressive approach in each aspect considered in this work and forecasting models trained to predict network load based on data generated by these GANs yield error rates comparable to models trained on real data. Finally, augmenting small amounts of real data with generated data leads to minor performance gains in some cases.;2022;Not health related;Not health related
"Saleern, K; Alkan, B; Dudley-McEvoy, S";Data Driven Machine Learning Model for Condition Monitoring and Anomaly Detection in Power Grids;The power system complexity and associated stability problems are greatly linked to the increasing penetration conventional energy sources and loads, such as renewable energies. The application of renewable for climate change, sustainabilily. and Net Zero come at the cost of deteriorated power quality, faults, instability, and disturbances in the power system. It gives rise to various problems such as equipment malfunctioning, power factor problems, transformer healing, inertia, voltage sags/swells, transmission lines overloading, etc. This requires and adjudicates the need for efficient monitoring and identification of faults and anomalies happening in the power system so as to accordingly mitigate these in a timely manner. The fault data however is not readily available and requires on-site inspection and accumulation. This paper thus aims at developing a synthetic database for various abnormal power system conditions captured from a well-known Kundr's two area system. These include symmetrical and asymmetrical faults, frequency, and phase variations, as well as voltage amplitude disturbances (sag/swell). The synthetic database is then combined with artificial intelligence techniques to enable fault detection and identification featuring low linear complexity and small memory requirements. The paper includes a benchmark study for three unsupervised anomaly detection algorithms, evaluating their performance in terms of both Area under the ROC Curve (AUC) and the execution time. The results show that and iNNE provide competitive results in detecting anom fault types, with iNNE providing significantly better execu time performance.;2023;Not health related;Not health related
"Wilken, P; Matusov, E";AppTek's Submission to the IWSLT 2022 Isometric Spoken Language Translation Task;To participate in the Isometric Spoken Language Translation Task of the IWSLT 2022 evaluation, constrained condition, AppTek developed neural Transformer-based systems for English-to-German with various mechanisms of length control, ranging from source-side and target-side pseudo-tokens to encoding of remaining length in characters that replaces positional encoding. We further increased translation length compliance by sentence-level selection of length-compliant hypotheses from different system variants, as well as rescoring of N-best candidates from a single system. Length-compliant back-translated and forwardtranslated synthetic data, as well as other parallel data variants derived from the original MuST-C training corpus were important for a good quality/desired length trade-off. Our experimental results show that length compliance levels above 90% can be reached while minimizing losses in MT quality as measured in BERT and BLEU scores.;2022;Not health related;Not health related
"Park, S; Elhilali, M; Han, DK; Ko, H";Amphibian Sounds Generating Network Based on Adversarial Learning;This letter proposes a generative network based on adversarial learning for synthesizing short-time audio streams and investigates the effectiveness of data augmentation for amphibian call sounds classification. Based on Fourier analysis, the generator is designed by a multi-layer perceptron composed of frequency basis learning layers and an output layer, and a discriminator is constructed by a convolutional neural network. Additionally, regularization on weights is introduced to train the networks with practical data that includes some disturbances. Synthetic audio streams are evaluated by quantitative comparison using inception score, and classification results are compared for real versus synthetic data. In conclusion, the proposed generative network is shown to produce realistic sounds and therefore useful for data augmentation.;2020;Not health related;Not health related
"Hebert, L; Ahamed, T; Costa, AC; O'Shaughnessy, L; Stephens, GJ";WormPose: Image synthesis and convolutional networks for pose estimation in C. elegans;Author summary Recent advances in machine learning have enabled the high-resolution estimation of bodypoint positions of freely behaving animals, but manual labeling can render these methods imprecise and impractical, especially in highly deformable animals such as the nematode C. elegans. Such animals also frequently coil, resulting in complicated shapes whose ambiguity presents difficulties for standard pose estimation methods. Efficiently solving coiled shapes in C. elegans, exhibited in a variety of important natural contexts, is the primary limiting factor for fully automated high-throughput behavior analysis. WormPose provides pose estimation that works across imaging conditions, naturally complements existing worm trackers, and harnesses the power of deep convolutional networks but with an image generator to automatically provide precise image-centerline pairings for training. We apply WormPose to on-food recordings, finding a near absence of deep delta-turns. We also show that incoherent body motions in the dwell state, which do not translate the worm, have been misidentified as an increase in reversal rate by previous, centroid-based methods. We expect that the combination of a body model and image synthesis demonstrated in WormPose will be both of general interest and important for future progress in precise pose estimation in other slender-bodied and deformable organisms. An important model system for understanding genes, neurons and behavior, the nematode worm C. elegans naturally moves through a variety of complex postures, for which estimation from video data is challenging. We introduce an open-source Python package, WormPose, for 2D pose estimation in C. elegans, including self-occluded, coiled shapes. We leverage advances in machine vision afforded from convolutional neural networks and introduce a synthetic yet realistic generative model for images of worm posture, thus avoiding the need for human-labeled training. WormPose is effective and adaptable for imaging conditions across worm tracking efforts. We quantify pose estimation using synthetic data as well as N2 and mutant worms in on-food conditions. We further demonstrate WormPose by analyzing long (similar to 8 hour), fast-sampled (similar to 30 Hz) recordings of on-food N2 worms to provide a posture-scale analysis of roaming/dwelling behaviors.;2021;Not health related;Health related
"Pakzad, A; Xu, MC; Cheung, WK; Vermant, M; Goos, T; De Sadeleer, LJ; Verleden, SE; Wuyts, WA; Hurst, JR; Jacob, J";Airway Measurement by Refinement of Synthetic Images Improves Mortality Prediction in Idiopathic Pulmonary Fibrosis;"Several chronic lung diseases, like idiopathic pulmonary fibrosis (IPF) are characterised by abnormal dilatation of the airways. Quantification of airway features on computed tomography (CT) can help characterise disease severity and progression. Physics based airway measurement algorithms that have been developed have met with limited success, in part due to the sheer diversity of airway morphology seen in clinical practice. Supervised learning methods are not feasible due to the high cost of obtaining precise airway annotations. We propose synthesising airways by style transfer using perceptual losses to train our model: Airway Transfer Network (ATN). We compare our ATN model with a state-of-the-art GAN-based network (simGAN) using a) qualitative assessment; b) assessment of the ability of ATN and simGAN based CT airway metrics to predict mortality in a population of 113 patients with IPF. ATN was shown to be quicker and easier to train than simGAN. ATN-based airway measurements showed consistently stronger associations with mortality than simGAN-derived airway metrics on IPF CTs. Airway synthesis by a transformation network that refines synthetic data using perceptual losses is a realistic alternative to GAN-based methods for clinical CT analyses of idiopathic pulmonary fibrosis. Our source code can be found at https://github.com/ashkanpakzad/ATN that is compatible with the existing open-source airway analysis framework, AirQuant.";2022;Health related;Health related
"Buffington, T; Cabrera, JM; Kurzawski, A; Ezekoye, OA";Deep-Learning Emulators of Transient Compartment Fire Simulations for Inverse Problems and Room-Scale Calorimetry;"This work describes a deep learning methodology for emulating temperature outputs produced by the Fire Dynamics Simulator (FDS), a CFD software. An array of artificial neural networks (ANNs) is trained to predict transient temperatures at specified locations for a transient heat release rate (HRR) input. These locations correspond to the locations of thermocouples used in an experimental burn structure. In order to build the training set, A Gaussian process (GP) framework is used to develop a generative model that produces random viable HRR ramps. Although this procedure may require thousands of FDS runs to build a sufficient training set, the application of transfer learning can reduce the required number of runs by nearly an order of magnitude. This refers to the process of initially training an ANN to predict the output of the Consolidated Model of Fire and Smoke Transport (CFAST) and then transferring its knowledge to an ANN that learns to predict FDS outputs. CFAST is a much faster model than FDS, so a large training set can be generated quickly. The final state of the ANN trained to emulate CFAST is used as the initial state of an ANN that learns to emulate FDS. The result is a model that produces FDS temperature predictions with a mean absolute error (MAE) of less than 2 degrees C and runs over five orders of magnitude faster than FDS. The emulators are also capable of learning inverse mappings; i.e. for a given temperature output, they can predict the HRR ramp that would cause FDS to produce the temperature response. This ability to invert for the HRR profile is exercised on data collected from eight fire experiments with peak HRRs up to 200 kW, including four propane burner fires, two methanol pool fires, and two n-Hexane pool fires. The model inverts for the experimental HRR with a MAE of 5.8 kW-15.4 kW (11.3%-16.7%) for the burner tests and 5.0 kW-25.5 kW (12.1%-28.6%) for the pool fire tests, with a tendency to underestimate the HRR of the pool fires. Finally, the computational speed of the emulators allows for the incorporation of CFD physics in Bayesian parameter inversion. As an example, this is demonstrated to infer the radiative fraction from experimental and synthetic data in conjunction with reported uncertainties from the FDS Validation Guide.";2021;Not health related;Not health related
"Simpson, F; Davies, I; Lalchand, V; Vullo, A; Durrande, N; Rasmussen, C";Kernel Identification Through Transformers;Kernel selection plays a central role in determining the performance of Gaussian Process (GP) models, as the chosen kernel determines both the inductive biases and prior support of functions under the GP prior. This work addresses the challenge of constructing custom kernel functions for high-dimensional GP regression models. Drawing inspiration from recent progress in deep learning, we introduce a novel approach named KITT: Kernel Identification Through Transformers. KITT exploits a transformer-based architecture to generate kernel recommendations in under 0.1 seconds, which is several orders of magnitude faster than conventional kernel search algorithms. We train our model using synthetic data generated from priors over a vocabulary of known kernels. By exploiting the nature of the self-attention mechanism, KITT is able to process datasets with inputs of arbitrary dimension. We demonstrate that kernels chosen by KITT yield strong performance over a diverse collection of regression benchmarks.;2021;Not health related;Not health related
"Harada, S; Kashima, H";InfoCEVAE: treatment effect estimation with hidden confounding variables matching;Treatment effect estimation is a fundamental problem in various domains for effective decision making. While many studies assume that observational data include all the confounding variables, we cannot practically guarantee that observational data include such confounding variables, and there might be confounding variables that are not included in observational data, referred to as hidden confounding variables. Recently, variational autencoder (VAE) based methods have been successfully applied to treatment effect estimation problem. However, although they can recover a large class of latent variable models, they do not give the correct treatment effect, even when they achieve an optimal solution due to the nature of VAE loss function. We propose an efficient VAE-based method that employs information theory to estimate treatment effect and combines it with a matching technique. To the best of our knowledge, this is the first work that gives the correct treatment effect given an optimal solution using VAE-based methods. Experiments on a semi-real dataset and synthetic dataset demonstrate that the proposed method mitigates VAE problems and observational bias effectively, even under hidden confounding variables, and outperforms strong baseline methods.;2022;Health related;Health related
"Wingate, D; Kane, J; Wolinsky, M; Sylvester, Z";A New Approach for Conditioning Process-Based Geologic Models to Well Data;Generating a realistic earth model that simultaneously fits data observed at multiple well locations has been a long-standing problem in petroleum geology. Two insights are offered for solving this problem in a Bayesian framework. The first is conceptual-it connects geologic inversion to the new field of probabilistic programming and shows that the usual description of a Bayesian problem in terms of a graphical model is inadequate for describing a process-based geologic model due to the dynamics of the generative algorithm. This is a paradigm shift in probabilistic modeling where stochastic generative models are represented using a syntax resembling modern programming languages. Probabilistic programming allows one to generalize this structure to include complex programming concepts, while also simplifying the process of developing new inference algorithms. The second insight is algorithmic and involves using variational inference to derive a simpler, more computationally tractable approximation to the posterior probability density function. If this surrogate distribution is close to the true posterior, it allows for very fast simulation of an arbitrary number of models that all fit the data equally well. This study focuses on the particular geologic formation known as submarine lobes: elongated pancake-like formations which are sequentially laid down, one on top of the other over geologic time, forming potential petroleum reservoirs. The location and orientation of the lobes at each time step are the variables that are optimized so that, at the final time step, all available well data are approximately fit. The methodology is illustrated on synthetic data as a proof-of-concept, and compared to several alternatives. An important conclusion is that, even though the variational approximation is crude, it produces better predictions than any point-based method, including maximum likelihood. The fact that probabilistic programming outperforms conventional Bayesian approaches in the case of lobe models offers the potential for attacking more complicated forward models where multiple geologic processes are simultaneously active.;2016;Not health related;Not health related
"Ausset, G; Ciffreo, T; Portier, F; Clemencon, S; Papin, T";Individual Survival Curves with Conditional Normalizing Flows;Survival analysis, or time-to-event modelling, is a classical statistical problem that has garnered a lot of interest for its practical use in epidemiology, demographics or actuarial sciences. Recent advances on the subject from the point of view of machine learning have been concerned with precise per-individual predictions instead of population studies, driven by the rise of individualized medicine. We introduce here a conditional normalizing flow based estimate of the time-to-event density as a way to model highly flexible and individualized conditional survival distributions. We use a novel hierarchical formulation of normalizing flows to enable efficient fitting of flexible conditional distributions without overfitting and show how the normalizing flow formulation can be efficiently adapted to the censored setting. We experimentally validate the proposed approach on a synthetic dataset as well as four open medical datasets and an example of a common financial problem.;2021;Not health related;Health related
"Yin, ML; Zou, ZR; Zhang, ER; Cavinato, C; Humphrey, JD; Karniadakis, GE";A generative modeling framework for inferring families of biomechanical constitutive laws in data-sparse regimes;Quantifying biomechanical properties of the human vasculature could deepen our under-standing of cardiovascular diseases. Standard nonlinear regression in constitutive modeling requires considerable high-quality data and an explicit form of the constitutive model as prior knowledge. By contrast, we propose a novel approach that combines generative deep learning with Bayesian inference to efficiently infer families of constitutive relationships in data-sparse regimes. Inspired by the concept of functional priors, we develop a generative adversarial network (GAN) that incorporates a neural operator as the generator and a fully-connected neural network as the discriminator. The generator takes a vector of noise conditioned on measurement data as input and yields the predicted constitutive relationship, which is scrutinized by the discriminator in the following step. We demonstrate that this framework can accurately estimate means and standard deviations of the constitutive relationships of the murine aorta using data collected either from model-generated synthetic data or ex vivo experiments for mice with genetic deficiencies. In addition, the framework learns priors of constitutive models without explicitly knowing their functional form, providing a new model-agnostic approach to learning hidden constitutive behaviors from data.;2023;Health related;Health related
"Ahmad, P; Wang, Y; Havaei, M";CT-SGAN: Computed Tomography Synthesis GAN;Diversity in data is critical for the successful training of deep learning models. Leveraged by a recurrent generative adversarial network, we propose the CT-SGAN model that generates large-scale 3D synthetic CT-scan volumes (>= 224 x 224 x 224) when trained on a small dataset of chest CT-scans. CT-SGAN offers an attractive solution to two major challenges facing machine learning in medical imaging: a small number of given i.i.d. training data, and the restrictions around the sharing of patient data preventing to rapidly obtain larger and more diverse datasets. We evaluate the fidelity of the generated images qualitatively and quantitatively using various metrics including Frechet Inception Distance and Inception Score. We further show that CT-SGAN can significantly improve lung nodule detection accuracy by pre-training a classifier on a vast amount of synthetic data.;2021;Health related;Health related
"Pan, SY; Wang, TH; Qiu, RLJ; Axente, M; Chang, CW; Peng, JB; Patel, AB; Shelton, J; Patel, SA; Roper, J; Yang, XF";2D medical image synthesis using transformer-based denoising diffusion probabilistic model;Objective. Artificial intelligence (AI) methods have gained popularity in medical imaging research. The size and scope of the training image datasets needed for successful AI model deployment does not always have the desired scale. In this paper, we introduce a medical image synthesis framework aimed at addressing the challenge of limited training datasets for AI models.Approach. The proposed 2D image synthesis framework is based on a diffusion model using a Swin-transformer-based network. This model consists of a forward Gaussian noise process and a reverse process using the transformer based diffusion model for denoising. Training data includes four image datasets: chest x-rays, heart MRI, pelvic CT, and abdomen CT. We evaluated the authenticity, quality, and diversity of the synthetic images using visual Turing assessments conducted by three medical physicists, and four quantitative evaluations: the Inception score (IS), Frechet Inception Distance score (FID), feature similarity and diversity score (DS, indicating diversity similarity) between the synthetic and true images. To leverage the framework value for training AI models, we conducted COVID-19 classification tasks using real images, synthetic images, and mixtures of both images.Main results. Visual Turing assessments showed an average accuracy of 0.64 (accuracy converging to 50% indicates a better realistic visual appearance of the synthetic images), sensitivity of 0.79, and specificity of 0.50. Average quantitative accuracy obtained from all datasets were IS = 2.28, FID = 37.27, FDS = 0.20, and DS = 0.86. For the COVID-19 classification task, the baseline network obtained an accuracy of 0.88 using a pure real dataset, 0.89 using a pure synthetic dataset, and 0.93 using a dataset mixed of real and synthetic data.Significance. A image synthesis framework was demonstrated for medical image synthesis, which can generate high-quality medical images of different imaging modalities with the purpose of supplementing existing training sets for AI model deployment. This method has potential applications in many data-driven medical imaging research.;2023;Health related;Health related
"Xing, XD; Felder, F; Nan, Y; Papanastasiou, G; Walsh, S; Yang, G";You Don't Have to Be Perfect to Be Amazing: Unveil the Utility of Synthetic Images;Synthetic images generated from deep generative models have the potential to address data scarcity and data privacy issues. The selection of synthesis models is mostly based on image quality measurements, and most researchers favor synthetic images that produce realistic images, i.e., images with good fidelity scores, such as low Frechet Inception Distance (FID) and high Peak Signal-To-Noise Ratio (PSNR). However, the quality of synthetic images is not limited to fidelity, and a wide spectrum of metrics should be evaluated to comprehensively measure the quality of synthetic images. In addition, quality metrics are not truthful predictors of the utility of synthetic images, and the relations between these evaluation metrics are not yet clear. In this work, we have established a comprehensive set of evaluators for synthetic images, including fidelity, variety, privacy, and utility. By analyzing more than 100k chest X-ray images and their synthetic copies, we have demonstrated that there is an inevitable trade-off between synthetic image fidelity, variety, and privacy. In addition, we have empirically demonstrated that the utility score does not require images with both high fidelity and high variety. For intra- and cross-task data augmentation, mode-collapsed images and low-fidelity images can still demonstrate high utility. Finally, our experiments have also showed that it is possible to produce images with both high utility and privacy, which can provide a strong rationale for the use of deep generative models in privacy-preserving applications. Our study can shore up comprehensive guidance for the evaluation of synthetic images and elicit further developments for utility-aware deep generative models in medical image synthesis.;2023;Health related;Health related
"Turan, M; Durmus, F";UC-NfNet: Deep learning-enabled assessment of ulcerative colitis from colonoscopy images;Ulcerative colitis (UC) belongs to the inflammatory bowel disease (IBD) family, which is mainly caused by inflammation of the tissue in the colon and rectum. The severity of this infection can radically affect the patient's overall well-being. Although there is no definitive treatment for this disease, diagnosis of the severity of the disease through colonoscopy imaging and the use of personalized treatment can prevent progression to more malignant stages. Inter-and intra-observer variability combined with the complex nature of UC infection makes medical assessment cumbersome. Diagnosis and treatment of UC can be made more accurate and robust if disease severity can be determined in a standardized and automated manner. Therefore, the development of a computerized tool that can be integrated into the clinical decision-making process of UC classification is of great importance. In this work, we present an automated UC classification method, UC-NfNet, complemented by a synthetic data generation pipeline aimed at classifying colonoscopy UC images. We show that our model quantitatively outperforms state-of-the-art classification models such as ConViT, Inception-v4, NFNets, ResNets and Swin Transformer. In an independent reader study of five gastroenterologists, the average agreement between the UC-NfNet and individual gastroenterologists was higher than the agreement between individual gastroenterologists. This robust evaluation of the proposed AI system paves the way for clinical trials of AI -assisted UC classification. The code and dataset are publicly available at https://github.com/DeepMIALab/UC-NfNet.;2022;Health related;Health related
"Walton, N; Brown, J; Fritsch, W; Brown, D; Nobre, G; Sobes, V";Methodology for physics-informed generation of synthetic neutron time-of-flight measurement data;Accurate neutron cross section data are a vital input to the simulation of nuclear systems for a wide range of applications from energy production to national security. The evaluation of experimental data is a key step in producing accurate cross sections. There is a widely recognized lack of reproducibility in the evaluation process due to its artisanal nature and therefore there is a call for improvement within the nuclear data community. This can be realized by automating/standardizing viable parts of the process, namely, parameter estimation by fitting theoretical models to experimental data. There are numerous candidate methods to approach this type of problem, but many rely on large, labeled datasets that are not accessible to the nuclear data evaluator. For a reaction cross-section, there are usually just a handful of datasets, none of which can be considered labeled because evaluators never have access to the exact solution (cross section). This work leverages problem-specific physics, Monte Carlo sampling, and a general methodology for data synthesis to generate unlimited, labeled experimental cross-section data of high-utility. The synthesized data is said to be of high-utility because it is statistically similar to the observed data. Heuristic and, where applicable, rigorous statistical comparisons to observed data support this claim. The methodology is split into two generative models. The first generates a realization of an energy-differential cross section for a given isotope. The second takes the output from the first as a determined input and generates noisy experimental observables (radiation detector signals) from the determined cross section realization. The latter is the primary development of this article and is based/limited to transmission measurements at Rensselaer Polytechnic Institute (RPI). The former leverages an existing method for model parameter sampling in the resolved resonance region (RRR), thus limiting the current demonstration to the RRR of incident neutron energies. An open-source software is published alongside this article that executes the complete methodology to produce high-utility synthetic datasets. The goal of this work is to provide an approach and corresponding tool that will allow the evaluation community to begin exploring more data-driven, ML-based solutions to long-standing challenges in the field. (c) 2023 Elsevier B.V. All rights reserved.;2024;Not health related;Not health related
"Soleimani, M; Kezunovic, M";Economic Analysis of Transformer Loss of Life Mitigation Using Energy Storage and PV Generation;High penetration of electric vehicles (EVs) can potentially put the utility assets such as transformers under overload stress causing decrease in their lifetime. The decrease in PV and battery energy storage system (BESS) prices has made them viable solutions to mitigate this situation. In this paper, the economic aspect of their optimal coordination is studied to assess transformer loss of life and hottest spot temperature (HST). Monte Carlo simulation is employed to provide synthetic data of EVs load in a residential complex and model their stochastic behavior. For load, temperature, energy price and PV generation, data for City of College Station, Texas, USA in 2018 is acquired and a case study is developed for one year. The results illustrate using BESS and PV is economically effective and mitigates distribution transformer loss of life.;2020;Not health related;Not health related
"Coletta, A; Jerome, J; Savani, R; Vyetrenko, S";Conditional Generators for Limit Order Book Environments: Explainability, Challenges, and Robustness;Limit order books are a fundamental and widespread market mechanism. This paper investigates the use of conditional generative models for order book simulation. For developing a trading agent, this approach has drawn recent attention as an alternative to traditional backtesting, due to its ability to react to the presence of the trading agent. We explore the dependence of a state-of-the-art conditional generative adversarial network (CGAN) upon its input features, highlighting both strengths and weaknesses. To do this, we use adversarial attacks on the model's features and its mechanism. We then show how these insights can be used to improve the CGAN, both in terms of its realism and robustness. We finish by laying out a roadmap for future work.;2023;Not health related;Not health related
"Blakely, L; Reno, MJ";Identifying Errors in Service Transformer Connections;Distribution system models play a critical role in the modern grid, driving distributed energy resource integration through hosting capacity analysis and providing insight into critical areas of interest such as grid resilience and stability. Thus, the ability to validate and improve existing distribution system models is also critical. This work presents a method for identifying service transformers which contain errors in specifying the customers connected to the low-voltage side of that transformer. Pairwise correlation coefficients of the smart meter voltage time series are used to detect when a customer is not in the transformer grouping that is specified in the model. The proposed method is demonstrated both on synthetic data as well as a real utility feeder, and it successfully identifies errors in the transformer labeling in both datasets.;2020;Not health related;Not health related
"Lakumarapu, NK; Lee, B; Indurthi, S; Han, HJ; Zaidi, MA; Kim, S";End-to-End Offline Speech Translation System for IWSLT 2020 using Modality Agnostic Meta-Learning;In this paper, we describe the system submitted to the IWSLT 2020 Offline Speech Translation Task. We adopt the Transformer architecture coupled with the meta-learning approach to build our end-to-end Speech- to-Text Translation (ST) system. Our meta-learning approach tackles the data scarcity of the ST task by leveraging the data available from Automatic Speech Recognition (ASR) and Machine Translation (MT) tasks. The meta-learning approach combined with synthetic data augmentation techniques improves the model performance significantly and achieves BLEU scores of 24.58, 27.51, and 27.61 on IWSLT test 2015, MuST-C test, and Europarl-ST test sets respectively.;2020;Not health related;Not health related
"Pavez, V; Hermosilla, G; Pizarro, F; Fingerhuth, S; Yunge, D";Thermal Image Generation for Robust Face Recognition;This article shows how to create a robust thermal face recognition system based on the FaceNet architecture. We propose a method for generating thermal images to create a thermal face database with six different attributes (frown, glasses, rotation, normal, vocal, and smile) based on various deep learning models. First, we use StyleCLIP, which oversees manipulating the latent space of the input visible image to add the desired attributes to the visible face. Second, we use the GANs N' Roses (GNR) model, a multimodal image-to-image framework. It uses maps of style and content to generate thermal imaging from visible images, using generative adversarial approaches. Using the proposed generator system, we create a database of synthetic thermal faces composed of more than 100k images corresponding to 3227 individuals. When trained and tested using the synthetic database, the Thermal-FaceNet model obtained a 99.98% accuracy. Furthermore, when tested with a real database, the accuracy was more than 98%, validating the proposed thermal images generator system.;2022;Not health related;Not health related
"Manco, G; Ritacco, E; Rullo, A; Saccà, D; Serra, E";Machine learning methods for generating high dimensional discrete datasets;The development of platforms and techniques for emerging Big Data and Machine Learning applications requires the availability of real-life datasets. A possible solution is to synthesize datasets that reflect patterns of real ones using a two-step approach: first, a real dataset X is analyzed to derive relevant patterns Z and, then, to use such patterns for reconstructing a new dataset X ' that preserves the main characteristics of X. This survey explores two possible approaches: (1) Constraint-based generation and (2) probabilistic generative modeling. The former is devised using inverse mining (IFM) techniques, and consists of generating a dataset satisfying given support constraints on the itemsets of an input set, that are typically the frequent ones. By contrast, for the latter approach, recent developments in probabilistic generative modeling (PGM) are explored that model the generation as a sampling process from a parametric distribution, typically encoded as neural network. The two approaches are compared by providing an overview of their instantiations for the case of discrete data and discussing their pros and cons. This article is categorized under: Fundamental Concepts of Data and Knowledge > Big Data Mining Technologies > Machine Learning Algorithmic Development > Structure Discovery;2022;Not health related;Not health related
"Liu, JZ; Yuan, HQ; Yuan, ZQ; Liu, L; Lu, B; Yu, M";Visual transformer with stable prior and patch-level attention for single image dehazing;"Single-image dehazing aims to recover blurred image details and improve image quality, which is a challenging ill-posed problem due to severe information degradation. In the image dehazing task, extracting local features from adjacent regions is particularly important. However, Transformer-based methods lack relative awareness of patch-level features. Furthermore, due to the sensitivity of self-attention to textcolorreddata distribution, the model suffers severe performance degradation when migrating from synthetic domain to real domain. To alleviate the above problems, we propose visual transformer with stable prior and patch-level attention (VSPPA) for image dehazing. Firstly, we propose a region-aware patch-level attention module to obtain the positional correlation between local patches and contexts, which can enhance the concentration of local patch-related features. Next, due to the instability problem caused by distribution shifts, we introduce dataset-independent prior to guide the transformer model, thereby preventing feature drift thus to improve the robustness of the model. Finally, domain-drift leads to insufficient dehazing when the model trained on synthetic data while migrates to the real environment, we come up with a introduce a patch filling strategy (PFS) for fuzzy data to narrow the domain gap and realize the generalization in real scenes. Extensive experiments show that the model achieves State-of-the Art on the SOTS synthetic dataset and effective generalization to real-world scenarios.& COPY; 2023 Elsevier B.V. All rights reserved.";2023;Not health related;Not health related
"Li, QG; Shi, JQ; Liu, TW; Guo, L; Qin, ZG";A Probabilistic Approach Towards Modeling Email Network With Realistic Features;Email plays a very important role in our daily life. Much work have been put into practice on email network. Those studies mostly require real email network datasets and reliable models to analyze user information and understand the mechanisms of network evolution. However, much research work is constrained by the absence of real large-scale email datasets. Although email communication is ubiquitous, there are very few large-scale available email datasets satisfied different research purposes. Due to privacy policy and restricted permissions, it is arduous to collect a real large-scale email dataset in a short time. Various social network models are usually used to create synthetic email networks. However, these models focus on modeling several structural properties of network without considering user behaviour patterns. They are not appropriate to generate large-scale realistic synthetic email network datasets. Towards this end, we propose a probabilistic model by which we can construct large-scale synthetic email datasets with a small captured email log. What is more important is that the generated synthetic dataset matches real email network properties and individual communication patterns. Moreover, it has linear complexity, and can be paralleled easily. Experimental results on Enron dataset demonstrate the above benefits of our model.;2014;Not health related;Not health related
"Bahar, P; Wilken, P; Alkhouli, T; Guta, A; Golik, P; Matusov, E; Herold, C";Start-Before-End and End-to-End: Neural Speech Translation by AppTek and RWTH Aachen University;AppTek and RWTH Aachen University team together to participate in the offline and simultaneous speech translation tracks of IWSLT 2020. For the offline task, we create both cascaded and end-to-end speech translation systems, paying attention to careful data selection and weighting. In the cascaded approach, we combine high-quality hybrid automatic speech recognition (ASR) with the Transformer-based neural machine translation (NMT). Our end-to-end direct speech translation systems benefit from pretraining of adapted encoder and decoder components, as well as synthetic data and fine-tuning and thus are able to compete with cascaded systems in terms of MT quality. For simultaneous translation, we utilize a novel architecture that makes dynamic decisions, learned from parallel data, to determine when to continue feeding on input or generate output words. Experiments with speech and text input show that even at low latency this architecture leads to superior translation results.;2020;Not health related;Not health related
"Kar, A; Prakash, A; Liu, MY; Cameracci, E; Yuan, J; Rusiniak, M; Acuna, D; Torralba, A; Fidler, S";Meta-Sim: Learning to Generate Synthetic Datasets;Training models to high-end performance requires availability of large labeled datasets, which are expensive to get. The goal of our work is to automatically synthesize labeled datasets that are relevant for a downstream task. We propose Meta-Sim, which learns a generative model of synthetic scenes, and obtain images as well as its corresponding ground-truth via a graphics engine. We parametrize our dataset generator with a neural network, which learns to modify attributes of scene graphs obtained from probabilistic scene grammars, so as to minimize the distribution gap between its rendered outputs and target data. If the real dataset comes with a small labeled validation set, we additionally aim to optimize a meta-objective, i.e. downstream task performance. Experiments show that the proposed method can greatly improve content generation quality over a human-engineered probabilistic scene grammar, both qualitatively and quantitatively as measured by performance on a downstream task.;2019;Not health related;Not health related
"Omelianchuk, K; Atrasevych, V; Chernodub, A; Skurzhanskyi, O";GECToR - Grammatical Error Correction: Tag, Not Rewrite;In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Our system is pre-trained on synthetic data and then fine-tuned in two stages: first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. We design custom token-level transformations to map input tokens to target corrections. Our best single-model/ensemble GEC tagger achieves an F-0.5 of 65.3/66.5 on CoNLL-2014 (test) and F-0.5 of 72.4/73.6 on BEA-2019 (test). Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system. The code and trained models are publicly available(1).;2020;Not health related;Not health related
"Deb, D; Tripathi, S; Puri, P";MUNCH: Modelling Unique 'N Controllable Heads;The automated generation of 3D human heads has been an intriguing and challenging task for computer vision researchers. Prevailing methods synthesize realistic avatars but with limited control over the diversity and quality of rendered outputs and suffer from limited correlation between shape and texture of the character. We propose a method that offers quality, diversity, control, and realism along with explainable network design, all desirable features to game-design artists in the domain. First, our proposed Geometry Generator identifies disentangled latent directions and generate novel and diverse samples. A Render Map Generator then learns to synthesize multiply high-fidelty physically-based render maps including Albedo, Glossiness, Specular, and Normals. For artists preferring fine-grained control over the output, we introduce a novel Color Transformer Model that allows semantic color control over generated maps. We also introduce quantifiable metrics called Uniqueness and Novelty and a combined metric to test the overall performance of our model. Demo for both shapes & textures can be found: https://munch- seven.vercel.app/. We will release our model along with the synthetic dataset.;2023;Not health related;Not health related
"Wang, ZW; You, JC; Liu, W; Wang, XJ";Transformer assisted dual U-net for seismic fault detection;Automatic seismic fault identification for seismic data is essential for oil and gas resource exploration. The traditional manual method cannot accommodate the needs of processing massive seismic data. With the development of artificial intelligence technology, deep learning techniques based on pattern recognition have become a popular research area for seismic fault identification. Despite the progress made with U-shaped neural networks (Unet), they still fall short in meeting the stringent requirements of fault prediction in complex structures. We propose a novel approach by combining a standard Unet with a transformer Unet to create a parallel dual Unet model, called Dual Unet with Transformer. To improve the accuracy of fault prediction, we compare six loss functions (including Binary Cross Entropy loss, Dice coefficient loss, Tversky loss, Local Tversky loss, Multi-scale Structural Similarity and Intersection over Union loss) using synthetic data, based on three evolution metrics involving Dice coefficient, Sensitivity and Specificity, find that the binary cross entropy loss function is the most robust one. An example comparing the prediction performance of different Unet models on synthetic data demonstrates the superior performance of our Dual Unet model, verifying the practical application value. To further validate the practical feasibility of our proposed method, we use real seismic data with a complex fault system and find that our proposed model is more accurate in predicting the fault system compared to well-developed Unet models such as the classical Unet and classical coherence cube algorithm, without transfer learning. This confirms the potential for wide-scale application of our proposed model.;2023;Not health related;Not health related
"Wang, XX; Lin, YF; Xiong, Y; Zhang, SH; He, YM; He, YQ; Zhang, ZK; Plasek, JM; Zhou, L; Bates, DW; Tang, CL";Using an optimized generative model to infer the progression of complications in type 2 diabetes patients;Background: People live a long time in pre-diabetes/early diabetes without a formal diagnosis or management. Heterogeneity of progression coupled with deficiencies in electronic health records related to incomplete data, discrete events, and irregular event intervals make identification of pre-diabetes and critical points of diabetes progression challenging. Methods: We utilized longitudinal electronic health records of 9298 patients with type 2 diabetes or prediabetes from 2005 to 2016 from a large regional healthcare delivery network in China. We optimized a generative Markov-Bayesian-based model to generate 5000 synthetic illness trajectories. The synthetic data were manually reviewed by endocrinologists. Results: We build an optimized generative progression model for type 2 diabetes using anchor information to reduce the number of parameters learning in the third layer of the model from O(N x W) to O((N - C) x W), where N is the number of clinical findings, W is the number of complications, C is the number of anchors. Based on this model, we infer the relationships between progression stages, the onset of complication categories, and the associated diagnoses during the whole progression of type 2 diabetes using electronic health records. Discussion: Our findings indicate that 55.3% of single complications and 31.8% of complication patterns could be predicted early and managed appropriately to potentially delay (as it is a progressive disease) or prevented (by lifestyle modifications that keep patient from developing/triggering diabetes in the first place). Conclusions: The full type 2 diabetes patient trajectories generated by the chronic disease progression model can counter a lack of real-world evidence of desired longitudinal timeframe while facilitating population health management.;2022;Health related;Health related
"Chamana, M; Mather, B";Variability Extraction and Synthesis via Multi-Resolution Analysis Using Distribution Transformer High-Speed Power Data;A library of load-variability classes is created to produce scalable synthetic data sets using historical high-speed raw data. These data are collected from distribution monitoring units connected at the secondary side of a distribution transformer. Because of the irregular patterns and large volume of historical high-speed data sets, the utilization of current load characterization and modeling techniques are challenging. Multi-resolution analysis techniques are applied to extract the necessary components and eliminate the unnecessary components from the historical high-speed raw data to create the library of classes, which are then utilized to create new synthetic load data sets. A validation is performed to ensure that the synthesized data sets contain the same variability characteristics as the training data sets. The synthesized data sets are intended to be utilized in quasi-static time-series studies for distribution system planning studies on a granular scale, such as detailed PV interconnection studies.;2017;Not health related;Not health related
"Cai, HJ; Song, Y; Ji, YJ; Li, ZH; He, AZ";Displacement extraction of background-oriented schlieren images using Swin Transformer;"Displacement extraction of background-oriented schlieren (BOS) is an essential step in BOS reconstruction, which directly determines the accuracy of the results. Typically, the displacement is calculated from the background images with and without inhomogeneous flow using the cross-correlation (CC) or optical flow (OF) method. This paper discusses the disadvantages of the CC and OF methods, and an end-to-end deep neural network was designed to estimate the BOS displacement. The proposed network is based on a Swin Transformer, which can build long-range correlations. A synthetic dataset used for training was generated using the simulated flow field by computational fluid dynamics. After training, the displacement can be obtained using the BOS image pair without additional parameters. Finally, the effectiveness of the proposed network was verified through experiments. The experiments illustrate that the proposed method performs stably on synthetic and real experimental images and outperforms conventional CC or OF methods and classic convolutional neural networks for OF tasks. & COPY; 2023 Optica Publishing Group";2023;Not health related;Not health related
"Li, Y; Peng, JY; Ye, JT; Zhang, YY; Xu, FH; Xiong, ZW";NLOST: Non-Line-of-Sight Imaging with Transformer;Time-resolved non-line-of-sight (NLOS) imaging is based on the multi-bounce indirect reflections from the hidden objects for 3D sensing. Reconstruction from NLOS measurements remains challenging especially for complicated scenes. To boost the performance, we present NLOST, the first transformer-based neural network for NLOS reconstruction. Specifically, after extracting the shallow features with the assistance of physics-based priors, we design two spatial-temporal self attention encoders to explore both local and global correlations within 3D NLOS data by splitting or downsampling the features into different scales, respectively. Then, we design a spatial-temporal cross attention decoder to integrate local and global features in the token space of transformer, resulting in deep features with high representation capabilities. Finally, deep and shallow features are fused to reconstruct the 3D volume of hidden scenes. Extensive experimental results demonstrate the superior performance of the proposed method over existing solutions on both synthetic data and real-world data captured by different NLOS imaging systems.;2023;Not health related;Not health related
"Tarnavskyi, M; Chernodub, A; Omelianchuk, K";Ensembling and Knowledge Distilling of Large Sequence Taggers for Grammatical Error Correction;In this paper, we investigate improvements to the GEC sequence tagging architecture with a focus on ensembling of recent cutting-edge Transformer-based encoders in Large configurations. We encourage ensembling models by majority votes on span-level edits because this approach is tolerant to the model architecture and vocabulary size. Our best ensemble achieves a new SOTA result with an F-0.5 score of 76.05 on BEA-2019 (test), even without pre-training on synthetic datasets. In addition, we perform knowledge distillation with a trained ensemble to generate new synthetic training datasets, Troy-Blogs and Troy-1BW. Our best single sequence tagging model that is pre-trained on the generated Troy-datasets in combination with the publicly available synthetic PIE dataset achieves a near-SOTA(1) result with an F-0.5 score of 73.21 on BEA-2019 (test). The code, datasets, and trained models are publicly available.(2);2022;Not health related;Not health related
"Yang, C; Xie, WD; Zisserman, A";It's About Time: Analog Clock Reading in the Wild;"In this paper, we present a framework for reading analog clocks in natural images or videos. Specifically, we make the following contributions: First, we create a scalable pipeline for generating synthetic clocks, significantly reducing the requirements for the labour-intensive annotations; Second, we introduce a clock recognition architecture based on spatial transformer networks (STN), which is trained end-to-end for clock alignment and recognition. We show that the model trained on the proposed synthetic dataset generalises towards real clocks with good accuracy, advocating a Sim2Real training regime; Third, to further reduce the gap between simulation and real data, we leverage the special property of time, i.e. uniformity, to generate reliable pseudo-labels on real unlabelled clock videos, and show that training on these videos offers further improvements while still requiring zero manual annotations. Lastly, we introduce three benchmark datasets based on COCO, Open Images, and The Clock movie, with full annotations for time, accurate to the minute.";2022;Not health related;Not health related
"Park, MS; Lee, D; Kwon, Y; Kim, E; Choi, YS";Data undersampling models for the efficient rule-based retrosynthetic planning;Computer-aided retrosynthetic planning for organic molecules, which is based on a large synthetic database, is a significant part of the recent development of autonomous robotic chemists. As in other AI fields, however, the class imbalance problem in the dataset affects the prediction performance of retrosynthetic paths. Here, we demonstrate that applying undersampling models to the imbalanced reaction dataset can improve the prediction of retrosynthetic templates for target molecules. We report improvements in the top-1 and top-10 prediction accuracies by 13.8% (13.1, 5.4%) and 8.8% (6.9, 2.4%) for undersampling based on the similarity (random, dissimilarity) clustering of molecular structures of products, respectively. These results demonstrate the importance of deep understanding of the statistical distribution, internal structure, and sampling for the training dataset. For practical applications, the target-oriented undersampling model is proposed and confirmed by the improved prediction performance of 9.3 and 4.2% for the top-1 and top-10 accuracies, respectively.;2021;Not health related;Not health related
"Pennisi, M; Salanitri, FP; Palazzo, S; Pino, C; Rundo, F; Giordano, D; Spampinato, C";GAN Latent Space Manipulation and Aggregation for Federated Learning in Medical Imaging;"Federated learning aims at improving data privacy by training local models on distributed nodes and at integrating information on a central node, without data sharing. However, this calls for effective integration methods that are currently missing as existing strategies, e.g., averaging model gradients, are unable to deal with data multimodality due to different distributions at multiple nodes. In this work, we tackle this problem by having multiple nodes that share a synthetic version of their own data, built in a way to hide patient-specific visual cues, with a central node that is responsible for training a deep model for medical image classification. Synthetic data are generated through an aggregation strategy consisting in: 1) learning the distribution of original data via a Generative Adversarial Network (GAN); 2) projecting private data samples in the GAN latent space; 3) clustering the projected samples and generating synthetic images by interpolating the cluster centroids, thus reducing the possibility of collision with latent vectors corresponding to real samples and a consequent leak of sensitive information. The proposed approach is tested over two X-ray datasets for Tuberculosis classification to simulate a realistic scenario with two different nodes and non-i.i.d. data. Experimental results show that our approach yields performance comparable to, or even outperforming, training on the full joint dataset. We also show quantitatively and qualitatively that images synthesized with our approach are significantly different from original images, thus limiting the possibility to recover original data through attacks.";2022;Health related;Health related
"Kiebel, SJ; Klöppel, S; Weiskopf, N; Friston, KJ";Dynamic causal modeling:: A generative model of slice timing in fMRI;Dynamic causal modeling (DCM) of functional magnetic resonance imaging (fMRI) data allows one to make inferences about the architecture of distributed networks in the brain, in terms of effective connectivity. fMRI data are usually acquired using echo planar imaging (EPI). EPI sequences typically acquire slices at different times over a few seconds. DCM, in its original inception, was not informed about these slice timings and assumed that all slices were acquired simultaneously. It has been shown that DCM can cope with slice timing differences of up to 1 s. However, many fMRI studies employ a repetition time (TR) of 3 to 5 s, which precludes a straightforward DCM of these data. We show that this limitation can be overcome easily by including slice timing in the DCM. Using synthetic data we show that the extended DCM furnishes veridical posterior means, even if there are large slice-timing differences. Model comparisons show that, in general, the extended DCM out-performs the original model. We contrast the modeling of slice timing, in the context of DCM, with the less effective approach of 'slice-timing correction', prior to modeling. We apply our procedure to real data and show that slice timings are important parameters. We conclude that, generally, one should use DCM with slice timing. (c) 2006 Elsevier Inc. All rights reserved.;2007;Health related;Not health related
"Fagereng, JA; Thambawita, V; Storas, AM; Parasa, S; de Lange, T; Halvorsen, P; Riegler, MA";PolypConnect: Image inpainting for generating realistic gastrointestinal tract images with polyps;Early identification of a polyp in the lower gastrointestinal (GI) tract can lead to prevention of life-threatening colorectal cancer. Developing computer-aided diagnosis (CAD) systems to detect polyps can improve detection accuracy and efficiency and save the time of the domain experts called endoscopists. Lack of annotated data is a common challenge when building CAD systems. Generating synthetic medical data is an active research area to overcome the problem of having relatively few true positive cases in the medical domain. To be able to efficiently train machine learning (ML) models, which are the core of CAD systems, a considerable amount of data should be used. In this respect, we propose the PolypConnect pipeline, which can convert non-polyp images into polyp images to increase the size of training datasets for training. We present the whole pipeline with quantitative and qualitative evaluations involving endoscopists. The polyp segmentation model trained using synthetic data, and real data shows a 5.1% improvement of mean intersection over union (mIOU), compared to the model trained only using real data. The codes of all the experiments are available on GitHub to reproduce the results.;2022;Health related;Health related
"Tao, J; Michailidis, G";A Statistical Framework for Detecting Electricity Theft Activities in Smart Grid Distribution Networks;Electricity distribution networks have undergone rapid change with the introduction of smart meter technology, that have advanced sensing and communications capabilities, resulting in improved measurement and control functions. However, the same capabilities have enabled various cyber-attacks. A particular attack focuses on electricity theft, where the attacker alters (increases) the electricity consumption measurements recorded by the smart meter of other users, while reducing her own measurement. Thus, such attacks, since they maintain the total amount of power consumed at the distribution transformer are hard to detect by techniques that monitor mean levels of consumption patterns. To address this data integrity problem, we develop statistical techniques that utilize information on higher order statistics of electricity consumption and thus are capable of detecting such attacks and also identify the users (attacker and victims) involved. The models work both for independent and correlated electricity consumption streams. The results are illustrated on synthetic data, as well as emulated attacks leveraging real consumption data.;2020;Not health related;Not health related
"Vorontsov, K; Potapenko, A";Additive regularization of topic models;Probabilistic topic modeling of text collections has been recently developed mainly within the framework of graphical models and Bayesian inference. In this paper we introduce an alternative semi-probabilistic approach, which we call additive regularization of topic models (ARTM). Instead of building a purely probabilistic generative model of text we regularize an ill-posed problem of stochastic matrix factorization by maximizing a weighted sum of the log-likelihood and additional criteria. This approach enables us to combine probabilistic assumptions with linguistic and problem-specific requirements in a single multi-objective topic model. In the theoretical part of the work we derive the regularized EM-algorithm and provide a pool of regularizers, which can be applied together in any combination. We show that many models previously developed within Bayesian framework can be inferred easier within ARTM and in some cases generalized. In the experimental part we show that a combination of sparsing, smoothing, and decorrelation improves several quality measures at once with almost no loss of the likelihood.;2015;Not health related;Not health related
"Chang, JHR; Bresler, M; Chherawala, Y; Delaye, A; Deselaers, T; Dixon, R; Tuzel, O";DATA INCUBATION-SYNTHESIZING MISSING DATA FOR HANDWRITING RECOGNITION;In this paper, we demonstrate how a generative model can be used to build a better recognizer through the control of content and style. We are building an online handwriting recognizer from a modest amount of training samples. By training our controllable handwriting synthesizer on the same data, we can synthesize handwriting with previously underrepresented content (e.g., URLs and email addresses) and style (e.g., cursive and slanted). Moreover, we propose a framework to analyze a recognizer that is trained with a mixture of real and synthetic training data. We use the framework to optimize data synthesis and demonstrate significant improvement on handwriting recognition over a model trained on real data only. Overall, we achieve a 66% reduction in Character Error Rate.;2022;Not health related;Not health related
"Solyman, A; Zappatore, M; Zhenyu, W; Mahmoud, Z; Alfatemi, A; Ibrahim, AO; Gabralla, LA";Optimizing the impact of data augmentation for low-resource grammatical error correction;"Grammatical Error Correction (GEC) refers to the automatic identification and amendment of grammat-ical, spelling, punctuation, and word-positioning errors in monolingual texts. Neural Machine Translation (NMT) is nowadays one of the most valuable techniques used for GEC but it may suffer from scarcity of training data and domain shift, depending on the addressed language. However, current techniques (e.g., tuning pre-trained language models or developing spell-confusion methods without focusing on lan-guage diversity) tackling the data sparsity problem associated with NMT create mismatched data distri-butions. This paper proposes new aggressive transformation approaches to augment data during training that extend the distribution of authentic data. In particular, it uses augmented data as auxiliary tasks to provide new contexts when the target prefix is not helpful for the next word prediction. This enhances the encoder and steadily increases its contribution by forcing the GEC model to pay more attention to the text representations of the encoder during decoding. The impact of these approaches was investi-gated using the Transformer-based for low-resource GEC task, and Arabic GEC was used as a case study. GEC models trained with our data tend more to source information, are more domain shift robustness, and have less hallucinations with tiny training datasets and domain shift. Experimental results showed that the proposed approaches outperformed the baseline, the most common data augmentation methods, and classical synthetic data approaches. In addition, a combination of the three best approaches Misspelling, Swap, and Reverse achieved the best F1 score in two benchmarks and outperformed previous Arabic GEC approaches.& COPY; 2023 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).";2023;Not health related;Not health related
"Boutin, R; Bouveyron, C; Latouche, P";Embedded topics in the stochastic block model;Communication networks such as emails or social networks are now ubiquitous and their analysis has become a strategic field. In many applications, the goal is to automatically extract relevant information by looking at the nodes and their connections. Unfortunately, most of the existing methods focus on analysing the presence or absence of edges and textual data is often discarded. However, all communication networks actually come with textual data on the edges. In order to take into account this specificity, we consider in this paper networks for which two nodes are linked if and only if they share textual data. We introduce a deep latent variable model allowing embedded topics to be handled called ETSBM to simultaneously perform clustering on the nodes while modelling the topics used between the different clusters. ETSBM extends both the stochastic block model (SBM) and the embedded topic model (ETM) which are core models for studying networks and corpora, respectively. The inference is done using a variational-Bayes expectation-maximisation algorithm combined with a stochastic gradient descent. The methodology is evaluated on synthetic data and on a real world dataset.;2023;Not health related;Not health related
"Wang, YZ; Xiong, JM; Yan, XF; Wei, MQ";USCFormer: Unified Transformer With Semantically Contrastive Learning for Image Dehazing;Haze severely degrades the visibility of scene objects and deteriorates the performance of autonomous driving, traffic monitoring, and other vision-based intelligent transportation systems. As a potential remedy, we propose a novel unified Transformer with semantically contrastive learning for image dehazing, dubbed USCFormer. USCFormer has three key contributions. First, USCFormer absorbs the respective strengths of CNN and Transformer by incorporating them into a unified Transformer format. Thus, it allows the simultaneous capture of global-local dependency features for better image dehazing. Second, by casting clean/hazy images as the positive/negative samples, the contrastive constraint encourages the restored image to be closer to the ground-truth images (positives) and away from the hazy ones (negatives). Third, we regard the semantic information as important prior knowledge to help USCFormer mitigate the effects of haze on the scene and preserve image details and colors by leveraging intra-object semantic correlation. Experiments on synthetic datasets and real-world hazy photos fully validate the superiority of USCFormer in both perceptual quality assessment and subjective evaluation. Code is available at https://github.com/yz-wang/USCFormer.;2023;Not health related;Not health related
"Aksu, T; Liu, ZY; Kan, MY; Chen, NF";Velocidapter: Task-oriented Dialogue Comprehension Modeling Pairing Synthetic Text Generation with Domain Adaptation;We introduce a synthetic dialogue generation framework, Velocidapter, which addresses the corpus availability problem for dialogue comprehension. Velocidapter augments datasets by simulating synthetic conversations for a task-oriented dialogue domain, requiring a small amount of bootstrapping work for each new domain. We evaluate the efficacy of our framework on a task-oriented dialogue comprehension dataset, MRCWOZ, which we curate by annotating questions for slots in the restaurant, taxi, and hotel domains of the MultiWOZ 2.2 dataset (Zang et al., 2020). We run experiments within a low-resource setting, where we pretrain a model on SQuAD, fine-tuning it on either a small original data or on the synthetic data generated by our framework. Velocidapter shows significant improvements using both the transformer-based BERTBase and BiDAF as base models. We further show that the framework is easy to use by novice users and conclude that Velocidapter can greatly help training over task-oriented dialogues, especially for low-resourced emerging domains.;2021;Not health related;Not health related
"Kiran, PVRS; VijayaramKumar, S; Vijayakumar, PS; Varakhedi, V; Upendranath, V";Application of Kalman Filter to prognostic method for estimating the RUL of a Bridge Rectifier;Prediction of the Remaining Useful Lifetime (RUL) of the system brings down the maintenance cost, downtime and also helps to take corrective measures. This results in avoiding catastrophic events. In this Paper, The RUL prediction is done based on KalmanFilter approach with dynamic curve fitting. The desired state (which is synthetic data) of the system is estimated based on a second order Kalman Filter, where Newtonian Kinematic model is used in tracking the significant feature state of the system. The dynamic curve fitting is done based on Least Square Error Sense method. The dynamically fitted curve is extrapolated until the failure threshold is reached and subsequently RUL is estimated. The algorithm thus developed is validated by a single phase full wave bridge rectifier analogous to aircraft Transformer Rectifier Unit (TRU), to obtain the real time significant feature data. The experimental results are compared with those of developed algorithms and results show Kalman filter based algorithm is similar to 95% accurate.;2013;Not health related;Not health related
"Ghorban, F; Milani, N; Schugk, D; Roese-Koerner, L; Su, Y; Müller, D; Kummert, A";Conditional multichannel generative adversarial networks with an application to traffic signs representation learning;Generative adversarial networks (GANs) are known to produce photorealistic representations. However, we show in this study that this is only valid when the input channels come from a regular RGB camera sensor. In order to alleviate this shortcoming, we propose a general solution to which we refer to as multichannel GANs (MCGANs). In contrast to the existing approaches, MCGANs can process multiple channels with different textures and resolutions. This is achieved by using known concepts in deep learning such as weight sharing and specially separated convolutions. The proposed pipeline enables particular kernels to learn low-level characteristics from the different channels without the need for exhaustive hyper-parameter tuning. We demonstrate the improved representational ability of the framework on traffic sign samples that are captured by a camera with a so-called red-clear-clear-clear pixel topology. Furthermore, we extend our solution by applying the concept of conditions, that offers a whole spectrum of new features, especially for the generation of traffic signs. Throughout this paper, we further discuss relevant applications for the generated synthetic data.;2019;Not health related;Not health related
"Lee, MCH; Oktay, O; Schuh, A; Schaap, M; Glocker, B";Image-and-Spatial Transformer Networks for Structure-Guided Image Registration;Image registration with deep neural networks has become an active field of research and exciting avenue for a long standing problem in medical imaging. The goal is to learn a complex function that maps the appearance of input image pairs to parameters of a spatial transformation in order to align corresponding anatomical structures. We argue and show that the current direct, non-iterative approaches are sub-optimal, in particular if we seek accurate alignment of Structures-of-Interest (SoI). Information about SoI is often available at training time, for example, in form of segmentations or landmarks. We introduce a novel, generic framework, Image-and-Spatial Transformer Networks (ISTNs), to leverage SoI information allowing us to learn new image representations that are optimised for the downstream registration task. Thanks to these representations we can employ a test-specific, iterative refinement over the transformation parameters which yields highly accurate registration even with very limited training data. Performance is demonstrated on pairwise 3D brain registration and illustrative synthetic data.;2019;Health related;Health related
Bouguila, N;Bayesian hybrid generative discriminative learning based on finite Liouville mixture models;Recently hybrid generative discriminative approaches have emerged as an efficient knowledge representation and data classification engine. However, little attention has been devoted to the modeling and classification of non-Gaussian and especially proportional vectors. Our main goal, in this paper, is to discover the true structure of this kind of data by building probabilistic kernels from generative mixture models based on Liouville family, from which we develop the Beta-Liouville distribution, and which includes the well-known Dirichlet as a special case. The Beta-Liouville has a more general covariance structure than the Dirichlet which makes it more practical and useful. Our learning technique is based on a principled purely Bayesian approach which resulted models are used to generate support vector machine (SVM) probabilistic kernels based on information divergence. In particular, we show the existence of closed-form expressions of the Kullback-Leibler and Renyi divergences between two Beta-Liouville distributions and then between two Dirichlet distributions as a special case. Through extensive simulations and a number of experiments involving synthetic data, visual scenes and texture images classification, we demonstrate the effectiveness of the proposed approaches. (C) 2010 Elsevier Ltd. All rights reserved.;2011;Not health related;Not health related
"Bavirisetti, DP; Martinsen, HR; Kiss, GH; Lindseth, F";A Multi-Task Vision Transformer for Segmentation and Monocular Depth Estimation for Autonomous Vehicles;In this paper, we investigate the use of Vision Transformers for processing and understanding visual data in an autonomous driving setting. Specifically, we explore the use of Vision Transformers for semantic segmentation and monocular depth estimation using only a single image as input. We present state-of-the-art Vision Transformers for these tasks and combine them into a multitask model. Through multiple experiments on four different street image datasets, we demonstrate that the multitask approach significantly reduces inference time while maintaining high accuracy for both tasks. Additionally, we show that changing the size of the Transformer-based backbone can be used as a trade-off between inference speed and accuracy. Furthermore, we investigate the use of synthetic data for pre-training and show that it effectively increases the accuracy of the model when real-world data is limited.;2023;Not health related;Not health related
"Chen, Z; Wang, YS; Guan, T; Xu, LY; Liu, WK";Transformer-Based 3D Face Reconstruction With End-to-End Shape-Preserved Domain Transfer;Learning-based face reconstruction methods have recently shown promising performance in recovering face geometry from a single image. However, the lack of training data with 3D annotations severely limits the performance. To tackle this problem, we proposed a novel end-to-end 3D face reconstruction network consisting of a conditional GAN (cGAN) for cross-domain face synthesis and a novel mesh transformer for face reconstruction. Our method first uses cGAN to translate the realistic face images to the specific rendered style, with a 2D facial edge consistency loss function. The domain-transferred images are then fed into face reconstruction network which uses a novel mesh transformer to output 3D mesh vertices. To exploit the domain-transferred in-the-wild images, we further propose a reprojection consistency loss to restrict face reconstruction network in a self-supervised way. Our approach can be trained with annotated dataset, synthetic dataset and in-the-wild images to learn a unified face model. Extensive experiments have demonstrated the effectiveness of our method.;2022;Not health related;Not health related
"Pavez, V; Hermosilla, G; Silva, M; Farias, G";Advanced Deep Learning Techniques for High-Quality Synthetic Thermal Image Generation;In this paper, we introduce a cutting-edge system that leverages state-of-the-art deep learning methodologies to generate high-quality synthetic thermal face images. Our unique approach integrates a thermally fine-tuned Stable Diffusion Model with a Vision Transformer (ViT) classifier, augmented by a Prompt Designer and Prompt Database for precise image generation control. Through rigorous testing across various scenarios, the system demonstrates its capability in producing accurate and superior-quality thermal images. A key contribution of our work is the development of a synthetic thermal face image database, offering practical utility for training thermal detection models. The efficacy of our synthetic images was validated using a facial detection model, achieving results comparable to real thermal face images. Specifically, a detector fine-tuned with real thermal images achieved a 97% accuracy rate when tested with our synthetic images, while a detector trained exclusively on our synthetic data achieved an accuracy of 98%. This research marks a significant advancement in thermal image synthesis, paving the way for its broader application in diverse real-world scenarios.;2023;Not health related;Not health related
"Su, JS; Sennrich, R; Huang, H; Di, H; Ren, HJ; Ouchi, K; Guo, JH; Wu, HM; Liu, J; Chen, YF; Xu, JA";BJTU-Toshiba's Submission to CCMT 2021 QE and APE Task;This paper presents the systems developed by Beijing Jiao-tong University and Toshiba (China) Co., Ltd. for the CCMT 2021 quality estimation (QE) and automatic-post editing (APE) task. For QE task, we mainly rely on multiple pretrained language models, and propose a multi-phase pre-finetuning scheme, to adapt the pretrained models to the target domain and task. The pre-finetuning scheme consists of language-adaptative finetuning, domain-adaptative finetuning and task-adaptative finetuning. For APE task, we use BERT-initialized Transformer as the backbone model, and create different groups of synthetic data by different data augmentation methods, i.e. forward translation, round-trip translation and multi-source denoising autoencoder. Multi-model ensemble is adopted in both tasks. Experiment results on the development set show high accuracy on both QE and APE tasks, demonstrating the effectiveness of our proposed methods.;2021;Not health related;Not health related
"Maghoumi, M; Taranta, EM; LaViola, J";DeepNAG: Deep Non-Adversarial Gesture Generation;Synthetic data generation to improve classification performance (data augmentation) is a well-studied problem. Recently, generative adversarial networks (GAN) have shown superior image data augmentation performance, but their suitability in gesture synthesis has received inadequate attention. Further, GANs prohibitively require simultaneous generator and discriminator network training. We tackle both issues in this work. We first discuss a novel, device-agnostic GAN model for gesture synthesis called DeepGAN. Thereafter, we formulate DeepNAG by introducing a new differentiable loss function based on dynamic time warping and the average Hausdorff distance, which allows us to train DeepGAN's generator without requiring a discriminator. Through evaluations, we compare the utility of DeepGAN and DeepNAG against two alternative techniques for training five recognizers using data augmentation over six datasets. We further investigate the perceived quality of synthesized samples via an Amazon Mechanical Turk user study based on the HYPE infinity benchmark. We find that DeepNAG outperforms DeepGAN in accuracy, training time (up to 17x faster), and realism, thereby opening the door to a new line of research in generator network design and training for gesture synthesis. Our source code is available at https://www.deepnag.com.;2021;Not health related;Not health related
"Moussa, D; Maier, A; Spruck, A; Seiler, J; Riess, C";FORENSIC LICENSE PLATE RECOGNITION WITH COMPRESSION-INFORMED TRANSFORMERS;Forensic license plate recognition (FLPR) remains an open challenge in legal contexts such as criminal investigations, where unreadable license plates (LPs) need to be deciphered from highly compressed and/or low resolution footage, e.g., from surveillance cameras. In this work, we propose a side-informed Transformer architecture that embeds knowledge on the input compression level to improve recognition under strong compression. We show the effectiveness of Transformers for license plate recognition (LPR) on a low-quality real-world dataset. We also provide a synthetic dataset that includes strongly degraded, illegible LP images and analyze the impact of knowledge embedding on it. The network outperforms existing FLPR methods and standard state-of-the art image recognition models while requiring less parameters. For the severest degraded images, we can improve recognition by up to 8.9 percent points.(1);2022;Not health related;Not health related
"Castillo-Hair, SM; Seelig, G";Machine Learning for Designing Next-Generation mRNA Therapeutics;Over just the last 2 years, mRNA therapeutics and vaccines have undergone a rapid transition from an intriguing concept to real-world impact. However, whereas some aspects of mRNA therapeutics, such as the use of chemical modifications to increase stability and reduce immunogenicity, have been extensively optimized for over two decades, other aspects, particularly the selection and design of the noncoding leader and trailer sequences which control translation efficiency and stability, have received comparably less attention. In practice, such 5' and 3' untranslated regions (UTRs) are often borrowed from highly expressed human genes with few or no modifications, as in the case for the Pfizer/BioNTech Covid vaccine. Focusing on the S'UTR, we here argue that model-driven design is a promising alternative that provides unprecedented control over S'UTR function. We review recent work that combines synthetic biology with machine learning to build quantitative models that relate ribosome loading, and thus translation efficiency, to the 5'UTR sequence. We first introduce an experimental approach that uses polysome profiling and high-throughput sequencing to quantify ribosome loading for hundreds of thousands of S'UTRs in parallel. We apply this approach to measure ribosome loading in synthetic RNA libraries with a random sequence inserted into the 5'UTR. We then review Optimus 5-Prime, a convolutional neural network model trained on the experimental data. We highlight that very accurate models of biological regulation can be learned from synthetic data sets with degenerate 5'UTRs. We validate model predictions not only on held-out data sets from our random library but also on a large library of over 30 000 human S'UTR fragments and using translation reporter data collected independently by other groups. Both the experiment and model are compatible with commonly used chemically modified nucleosides, in particular, pseudouridine (psi) and 1-methyll-pseudouridine (m(1)psi). We find that, in general, 5 1 UTRs have very similar impacts when combined with different proteincoding sequences and even in the context of different chemical modifications. We demonstrate that Optimus 5-Prime can be combined with design algorithms to generate de novo sequences with precisely defined translation efficiencies. We emphasize recent developments in design algorithms that rely on activation maximization and generative modeling to improve both the fitness and diversity of designed sequences. Compared with prior approaches such as genetic algorithms, we show that these approaches are not only faster but also less likely to get stuck in local sequence optima. Finally, we discuss how the approach reviewed here can be generalized to other gene regions and applications.;2022;Health related;Health related
"D'Amicantonio, G; Bondarau, E; De With, PHN";Homography Estimation for Camera Calibration in Complex Topological Scenes;Surveillance videos and images are used for a broad set of applications, ranging from traffic analysis to crime detection. Extrinsic camera calibration data is important for most analysis applications. However, security cameras are susceptible to environmental conditions and small camera movements, resulting in a need for an automated re-calibration method that can account for these varying conditions. In this paper, we present an automated camera-calibration process leveraging a dictionarybased approach that does not require prior knowledge on any camera settings. The method consists of a custom implementation of a Spatial Transformer Network (STN) and a novel topological loss function. Experiments reveal that the proposed method improves the IoU metric by up to 12% w.r.t. a state-of-the-art model across five synthetic datasets and the World Cup 2014 dataset.;2023;Not health related;Not health related
"Lavda, F; Gregorová, M; Kalousis, A";Data-Dependent Conditional Priors for Unsupervised Learning of Multimodal Data;One of the major shortcomings of variational autoencoders is the inability to produce generations from the individual modalities of data originating from mixture distributions. This is primarily due to the use of a simple isotropic Gaussian as the prior for the latent code in the ancestral sampling procedure for data generations. In this paper, we propose a novel formulation of variational autoencoders, conditional prior VAE (CP-VAE), with a two-level generative process for the observed data where continuouszand a discretecvariables are introduced in addition to the observed variablesx. By learning data-dependent conditional priors, the new variational objective naturally encourages a better match between the posterior and prior conditionals, and the learning of the latent categories encoding the major source of variation of the original data in an unsupervised manner. Through sampling continuous latent code from the data-dependent conditional priors, we are able to generate new samples from the individual mixture components corresponding, to the multimodal structure over the original data. Moreover, we unify and analyse our objective under different independence assumptions for the joint distribution of the continuous and discrete latent variables. We provide an empirical evaluation on one synthetic dataset and three image datasets, FashionMNIST, MNIST, and Omniglot, illustrating the generative performance of our new model comparing to multiple baselines.;2020;Not health related;Not health related
"Mamede, C; Pinconschi, E; Abreu, R; Campos, J";Exploring Transformers for Multi-Label Classification of Java Vulnerabilities;Deep learning (DL) techniques have demonstrated potential in reasoning complex patterns of vulnerable code from high-level abstractions. Recent advancements in the area, such as the introduction of transformer-based models, like BERT, help overcome the problem of the available vulnerability detection datasets being too small to enable most DL models to capture all relevant patterns. They mitigate the challenge by leveraging knowledge from a general domain to solve problems in specific domains. In this paper, we explore different BERT-based models for multi-label classification of vulnerabilities in Java on a synthetic dataset. The models yield up to 99% in accuracy and 94% in f1-score. We remove biases in the training dataset and observe drops of up to 13% of the f1-score. We further assess the generalizability of the models on realistic samples and notice that one model, in particular, predicted unknown vulnerabilities with an f1-score of nearly 85%.;2022;Not health related;Not health related
"Zhao, BC; Yu, SZ; Ma, WF; Yu, MX; Mei, SX; Wang, AT; He, J; Yuille, A; Kortylewski, A";OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images;Enhancing the robustness of vision algorithms in real-world scenarios is challenging. One reason is that existing robustness benchmarks are limited, as they either rely on synthetic data or ignore the effects of individual nuisance factors. We introduce OOD-CV , a benchmark dataset that includes out-of-distribution examples of 10 object categories in terms of pose, shape, texture, context and the weather conditions, and enables benchmarking models for image classification, object detection, and 3D pose estimation. In addition to this novel dataset, we contribute extensive experiments using popular baseline methods, which reveal that: 1) Some nuisance factors have a much stronger negative effect on the performance compared to others, also depending on the vision task. 2) Current approaches to enhance robustness have only marginal effects, and can even reduce robustness. 3) We do not observe significant differences between convolutional and transformer architectures. We believe our dataset provides a rich testbed to study robustness and will help push forward research in this area.;2022;Not health related;Not health related
"De Melo, POSV; Faloutsos, C; Assunçao, R; Alves, R; Loureiro, AAF";Universal and Distinct Properties of Communication Dynamics: How to Generate Realistic Inter-event Times;With the advancement of information systems, means of communications are becoming cheaper, faster, and more available. Today, millions of people carrying smartphones or tablets are able to communicate practically any time and anywhere they want. They can access their e-mails, comment on weblogs, watch and post videos and photos (as well as comment on them), and make phone calls or text messages almost ubiquitously. Given this scenario, in this article, we tackle a fundamental aspect of this new era of communication: How the time intervals between communication events behave for different technologies and means of communications. Are there universal patterns for the Inter-Event Time Distribution (IED)? How do inter-event times behave differently among particular technologies? To answer these questions, we analyzed eight different datasets from real andmodern communication data and found four well-defined patterns seen in all the eight datasets. Moreover, we propose the use of the Self-Feeding Process (SFP) to generate inter-event times between communications. The SFP is an extremely parsimonious point process that requires at most two parameters and is able to generate inter-event times with all the universal properties we observed in the data. We also show three potential applications of the SFP: as a framework to generate a synthetic dataset containing realistic communication events of any one of the analyzed means of communications, as a technique to detect anomalies, and as a building block for more specific models that aim to encompass the particularities seen in each of the analyzed systems.;2015;Not health related;Not health related
"Islam, F; Nath, B; Kamruzzaman, J";Reactive load control of parallel transformer operations using Neural Networks;Artificial Neural Network (ANN) is used in various fields including control and analysis of power systems. ANN in its learning process establishes the relationship between input variables by means of its weights updating, and provides a good response to another nonidentical but similar input. This paper proposes the use of neural network to control the on-load tap changer of parallel operation of two transformers supplying power to a local area. For simplicity, only two transformers are considered although operation of multiple transformers can be dealt with in a similar manner. A synthetic data set relating to tap changer operation sequence was used for training a backpropagation. network to decide automatically on transformer's on-load tap changer whether to raise, lower or hold the same desired position. Preliminary results show that a trained neural network can be successfully used for on load tap changing operation of transformers.;2002;Not health related;Not health related
"Wu, ZY; Lau, CY; Zhou, QA; Wu, JL; Wang, YX; Liu, QF; Lei, Z; Liu, HB";Surgivisor: Transformer-based semi-supervised instrument segmentation for endoscopic surgery;Precise instrument segmentation helps tracking of instruments in surgery. The most of the existing instrument segmentation methods are fully supervised, which are based on 100% labeled data. However, the annotation for instrument segmentation are really expensive, which need the skilled professionals who can identify the parts and types of the surgical instruments. In this work, we propose a transformer-based semi-supervised instrument segmentation for endoscopic surgery, called Surgivisor. First, we present a data augmentation technique to generate synthetic data from endoscopic images to overcome the complex background and instrument collision problem, by fully using the information of unlabeled data and pseudo labels. Second, we propose a mutual prototype loss and a dual structural similarity loss to address illumination reflection and bloody condition issues in the training phase. With the two improvements, the effectiveness of proposed method is validated by the experiments on EndoVis Challenges. It exceeds the state-of-the-art results on the sub-tasks of binary, part, and type.;2024;Health related;Health related
"Ahn, WJ; Kang, G; Choi, HD; Lim, MT";Domain adaptation for complex shadow removal with shadow transformer network;Shadows observed in practical scenes have complex shapes, and removing them is a very challenging task in computer vision. In particular, previous studies on complex shadow removal have limitations in that they can be learned only on paired datasets. Taking the issues into consideration, we present a new domain-adaptive shadow removal framework. The proposed approach includes domain adaptation, detection, and removal stages. The shadow-preserving domain translator in the first stage compensates for the lack of real data through domain transformation of the synthetic data. In the second stage, efficient shadow detection is performed through the domain adaptive mean teacher network. Last, a novel attention network removes complex shadows using detected shadows as a query, effectively removing complex shadows. The feasibility and effectiveness of the proposed framework are validated through the newly collected Grand Theft Auto-Road Shadow dataset. The proposed method outperforms existing methods for quantitative and qualitative metrics related to shadow detection and removal.;2023;Not health related;Not health related
"Maya, P; Shree, SV; Roopasree, K; Soman, KP";Discrimination of Internal Fault Current and Inrush Current in a Power Transformer using Empirical Wavelet Transform;Transformers are crucial equipment in a power system, which require reliable solutions for their protection to ensure smooth operation. Identification between internal fault current and in rush current is a challenging problem in the design of transformer protection relay. Transformers are often tripped when inrush current flows in the system causing problems in operation and maintenance in addition to the customer disturbance. Conventional identification methods have limitations in providing accurate solution to this problem. This work investigates the scope of a classification method based on EWT and SVM in distinguishing internal fault current and inrush current in a power transformer. Validation of this method is done using generated synthetic data from MATLAB/SIMULINK. Feature extraction of the generated data is done using EWT algorithm. These features are used for training SVM. Later, accuracy of classification is checked using test vectors. Different kernel functions for SVM are also tested for improved accuracy. (C) 2015 The Authors. Published by Elsevier Ltd.;2015;Not health related;Not health related
"Li, QW; Kailkhura, B; Anirudh, R; Zhang, JZ; Zhou, Y; Liang, YB; Han, TYJ; Varshney, PK";MR-GAN: Manifold Regularized Generative Adversarial Networks for Scientific;Despite the growing interest in applying generative adversarial networks (GANs) in complex scientific applications, training GANs on scientific data remains a challenging problem from both theoretical and practical standpoints. One reason for this is that the generator is unable to accurately capture the underlying complex manifold structure of the real scientific data using only gradients from the discriminator. In this paper, we address this challenge using a novel approach that exploits the unique geometry of the scientific data to improve the quality of the generated data. Specifically, we improve the training of the GAN using an additional term referred to as a manifold regularizer which encourages the generator to respect the unique geometry of the scientific data manifold and generate high quality data. We theoretically prove that the addition of this regularization term leads to improved performance for different classes of GANs including deep convolutional GAN and Wasserstein GAN. Finally, we carry out performance comparisons on diverse datasets: synthetic data (Gaussian mixture), natural image data (celebrity face images (CelebA)), and scientific experimental data (scanning electron microscopy images of organic crystalline materials). In most of these applications, we find that the proposed manifold regularization-based approach helps in avoiding mode collapse, produces stable training, and leads to significant gains in terms of geometry score compared to its unregularized counterparts.;2021;Not health related;Not health related
"Zhang, SB; Alshurafa, N";Deep Generative Cross-modal On-body Accelerometer Data Synthesis from Videos;Human activity recognition (HAR) based on wearable sensors has brought tremendous benefit to several industries ranging from healthcare to entertainment. However, to build reliable machine-learned models from wearables, labeled on-body sensor datasets obtained from real-world settings are needed. It is often prohibitively expensive to obtain large-scale, labeled on-body sensor datasets from real-world deployments. The lack of labeled datasets is a major obstacle in the wearable sensor-based activity recognition community. To overcome this problem, I aim to develop two deep generative cross-modal architectures to synthesize accelerometer data streams from video data streams. In the proposed approach, a conditional generative adversarial network (cGAN) is first used to generate sensor data conditioned on video data. Then, a conditional variational autoencoder (cVAE)-cGAN is proposed to further improve representation of the data. The effectiveness and efficacy of the proposed methods will be evaluated through two popular applications in HAR: eating recognition and physical activity recognition. Extensive experiments will be conducted on public sensor-based activity recognition datasets by building models with synthetic data and comparing the models against those trained from real sensor data. This work aims to expand labeled on-body sensor data, by generating synthetic on-body sensor data from video, which will equip the community with methods to transfer labels from video to on-body sensors.;2020;Health related;Health related
"Li, ZY; Cheng, W; Chen, Y; Chen, HF; Wang, W";Interpretable Click-Through Rate Prediction through Hierarchical Attention;Click-through rate (CTR) prediction is a critical task in online advertising and marketing. For this problem, existing approaches, with shallow or deep architectures, have three major drawbacks. First, they typically lack persuasive rationales to explain the outcomes of the models. Unexplainable predictions and recommendations may be difficult to validate and thus unreliable and untrustworthy. In many applications, inappropriate suggestions may even bring severe consequences. Second, existing approaches have poor efficiency in analyzing high-order feature interactions. Third, the polysemy of feature interactions in different semantic subspaces is largely ignored. In this paper, we propose InterHAt that employs a Transformer with multi-head self-attention for feature learning. On top of that, hierarchical attention layers are utilized for predicting CTR while simultaneously providing interpretable insights of the prediction results. InterHAt captures high-order feature interactions by an efficient attentional aggregation strategy with low computational complexity. Extensive experiments on four public real datasets and one synthetic dataset demonstrate the effectiveness and efficiency of InterHAt.;2020;Not health related;Not health related
"Barrere, K; Soullard, Y; Lemaitre, A; Coüasnon, B";A Light Transformer-Based Architecture for Handwritten Text Recognition;Transformer models have been showing ground-breaking results in the domain of natural language processing. More recently, they started to gain interest in many others fields as in computer vision. Traditional Transformer models typically require a significant amount of training data to achieve satisfactory results. However, in the domain of handwritten text recognition, annotated data acquisition remains costly resulting in small datasets compared to those commonly used to train a Transformer-based model. Hence, training Transformer models able to transcribe handwritten text from images remains challenging. We propose a light encoder-decoder Transformer-based architecture for handwriting text recognition, containing a small number of parameters compared to traditional Transformer architectures. We trained our architecture using a hybrid loss, combining the well-known connectionist temporal classification with the cross-entropy. Experiments are conducted on the well-known IAM dataset with and without the use of additional synthetic data. We show that our network reaches state-of-the-art results in both cases, compared with other larger Transformer-based models.;2022;Not health related;Not health related
"Ta, N; Chen, HP; Lyu, Y; Wang, X; Shi, ZA; Liu, ZH";A complementary and contrastive network for stimulus segmentation and generalization;"Existing convolutional neural networks (CNNs) have achieved remarkable performance in medical image segmentation tasks. However, they still fail to generalize well to unseen datasets due to the limited size and diversity of training data as well as distribution shifts. Meanwhile, CNN-based methods have inherent limi-tations in capturing global contexts and suffer semantic dilution issues in the decoder stage, which leads to sub-optimal predictions especially under low inter-class discrepancy and complex backgrounds. In this paper, we propose a novel framework named CCNet that learns complementary and contrastive features for accurate seg-mentation. Firstly, a novel complementary feature extraction module is formulated to learn global-local features by coordinating Transformer and CNN-style parallel branches. Secondly, a global context refinement module is constructed to adaptively generate a set of layer-specific global maps, so as to remedy semantic dilution. Thirdly, a mutual attentive module is designed to alleviate background confusion, in which contrastive cues are mutually captured from the foreground and background view by cascaded dual attention blocks. Moreover, we implement synthetic data augmentation to deal with training data scarcity and distribution shifts, thereby improving the out-of-distribution generalization of our model. Extensive experiments demonstrate that our CCNet achieves outstanding performance in polyp, skin lesion, and nuclei segmentation tasks, outperforming the state-of-the-arts. & COPY; 2023 Published by Elsevier B.V.";2023;Health related;Health related
"Wang, Y; Liu, YY; Zhou, PB; Geng, GH; Zhang, Q";SparseFormer: Sparse transformer network for point cloud classification;"Compared to the traditional self-attention structure of Transformers, the MLP-like structure offers advantages such as simplicity and improved performance. However, effectively and efficiently learning features from sparse, irregular, and unordered 3D point cloud data remains a challenge. To address this issue, we propose SparseFormer, a sparse transformer network designed specifically for point cloud processing tasks. SparseFormer incorporates a sparse MLP module that enables accurate feature learning while considering the unique characteristics of 3D point cloud data. Additionally, we enhance the context information by utilizing a multi-scale feature aggregation module. Experimental results demonstrate the superior performance of SparseFormer on classification tasks using benchmark datasets, including the ModelNet40 synthetic dataset and the ScanObjectNN real-world dataset. In the classification experiment on the ScanObjectNN dataset, SparseFormer achieves a mean accuracy of 84.1% and an overall accuracy of 85.5%.& COPY; 2023 Elsevier Ltd. All rights reserved.";2023;Not health related;Not health related
"Zhi, CRD; Huang, HM; Fan, YH; Song, DK";A Feature Refinement Patch Embedding-Based Recognition Method for Printed Tibetan Cursive Script;Recognition of Tibetan cursive scripts has important applications in the field of automated Tibetan office software and ancient document conservation. However, there are few studies on recognition of Tibetan cursive scripts. This paper proposes a printed Tibetan cursive script recognition method based on feature refinement patch embedding. Firstly, the feature refinement patch embedding module (FRPE) serializes the line text image of feature sequences. Secondly, a global modeling of feature vectors is carried out by using a single transformer encoder. Finally, the output of the recognition result is decoded by using a fully connected layer. Experimental results show that, compared with the baseline model, the proposed method improves the accuracy by 9.52% on the dataset CSTPD, a database containing six Tibetan cursive fonts. Moreover, it achieves an average accuracy rate of 92.5% on the dataset CSTPD. Similarly, it also works better than the baseline model on Tibetan text recognition synthetic data for natural scene images.;2024;Not health related;Not health related
"Xiong, ZT; Zhu, XX";KNOWLEDGE TRANSFER FOR LABEL-EFFICIENT MONOCULAR HEIGHT ESTIMATION;Estimating height from monocular remote sensing images is one of the most efficient ways for building large-scale 3D city models. However, existing deep learning based methods usually require a large amount of training data, which could be cost-consuming or even not possible to obtain. Towards a label-efficient deep learning model, we propose a new task and dataset for weak-shot monocular height estimation. In this task, only the relative height labels between pairs of a small portion of points are given, which is cheaper and more friendly for humans to annotate. In addition, to enhance the model performance under the sparse and weak-shot supervision, we propose a Transformer-based network for transferring the learned knowledge from a large-scale synthetic dataset to real-world data. Experimental results have shown the effectiveness of the proposed method on a public dataset under the sparse and weak supervision.;2022;Not health related;Not health related
"Messé, A; Benali, H; Marrelec, G";Relating Structural and Functional Connectivity in MRI: A Simple Model for a Complex Brain;Advances in magnetic resonance imaging (MRI) allow to gain critical insight into the structure of neural networks and their functional dynamics. To relate structural connectivity [as quantified by diffusion-weighted imaging (DWI) tractography] and functional connectivity [as obtained from functional MRI (fMRI)], increasing emphasis has been put on computational models of brain activity. In the present study, we use structural equation modeling (SEM) with structural connectivity to predict functional connectivity. The resulting model takes the simple form of a spatial simultaneous autoregressive model (sSAR), whose parameters can be estimated in a Bayesian framework. On synthetic data, results showed very good accuracy and reliability of the inference process. On real data, we found that the sSAR performed significantly better than two other reference models as well as than structural connectivity alone, but that the Bayesian procedure did not bring significant improvement in fit compared to two simpler approaches. Nonetheless, we also found that the values of the region-specific parameters inferred using Bayesian inference differed significantly across resting-state networks. These results demonstrate 1) that a simple abstract model is able to perform better that more complex models based on more realistic assumptions, 2) that the parameters of the sSAR can be estimated and can potentially be used as biomarkers, but also 3) that the sSAR, while being the best-performing model, is at best still a very crude model of the relationship between structure and function in MRI.;2015;Health related;Not health related
"Reizenstein, J; Shapovalov, R; Henzler, P; Sbordone, L; Labatut, P; Novotny, D";Common Objects in 3D: Large-Scale Learning and Evaluation of Real-life 3D Category Reconstruction;Traditional approaches for learning 3D object categories have been predominantly trained and evaluated on synthetic datasets due to the unavailability of real 3D-annotated category-centric data. Our main goal is to facilitate advances in this field by collecting real-world data in a magnitude similar to the existing synthetic counterparts. The principal contribution of this work is thus a large-scale dataset, called Common Objects in 3D, with real multi-view images of object categories annotated with camera poses and ground truth 3D point clouds. The dataset contains a total of 1.5 million frames from nearly 19,000 videos capturing objects from 50 MS-COCO categories and, as such, it is significantly larger than alternatives both in terms of the number of categories and objects. We exploit this new dataset to conduct one of the first large-scale in-the-wild evaluations of several new-view-synthesis and category-centric 3D reconstruction methods. Finally, we contribute NerFormer - a novel neural rendering method that leverages the powerful Transformer to reconstruct an object given a small number of its views.;2021;Not health related;Not health related
"Tandon, R; Kirkpatrick, A; Mitchell, CS";sEBM: Scaling Event Based Models to Predict Disease Progression via Implicit Biomarker Selection and Clustering;The Event Based Model (EBM) is a probabilistic generative model to explore biomarker changes occurring as a disease progresses. Disease progression is hypothesized to occur through a sequence of biomarker dysregulation events. The EBM estimates the biomarker dysregulation event sequence. It computes the data likelihood for a given dysregulation sequence, and subsequently evaluates the posterior distribution on the dysregulation sequence. Since the posterior distribution is intractable, Markov Chain Monte-Carlo is employed to generate samples under the posterior distribution. However, the set of possible sequences increases as N! where N is the number of biomarkers (data dimension) and quickly becomes prohibitively large for effective sampling via MCMC. This work proposes the scaled EBM (sEBM) to enable event based modeling on large biomarker sets (e.g. high-dimensional data). First, sEBM implicitly selects a subset of biomarkers useful for modeling disease progression and infers the event sequence only for that subset. Second, sEBM clusters biomarkers with similar positions in the event sequence and only orders the clusters, with each successive cluster corresponding to the next stage in disease progression. These two modifications used to construct the sEBM method provably reduces the possible space of event sequences by multiple orders of magnitude. The novel modifications are supported by theory and experiments on synthetic and real clinical data provides validation for sEBM to work in higher dimensional settings. Results on synthetic data with known ground truth shows that sEBM outperforms previous EBM variants as data dimensions increase. sEBM was successfully implemented with up to 300 biomarkers, which is a 6-fold increase over previous EBM applications. A real-world clinical application of sEBM is performed using 119 neuroimaging markers from publicly available Alzheimer's Disease Neuroimaging Initiative (ADNI) data to stratify subjects into 6 stages of disease progression. Subjects included cognitively normal (CN), mild cognitive impairment (MCI), and Alzheimer's Disease (AD). sEBM stage is differentiated for the 3 groups (chi(2) p - value < 4.6e - 32). Increased sEBM stage is a strong predictor of conversion risk to AD (p - value < 2.3e - 14) for MCI subjects, as verified with a Cox proportional-hazards model adjusted for age, sex, education and APOE4 status. Like EBM, sEBM does not rely on apriori defined diagnostic labels and only uses cross-sectional data.;2023;Health related;Health related
"Pham, NQ; Ha, TL; Nguyen, TN; Nguyen, TS; Salesky, E; Stüker, S; Niehues, J; Waibel, A";Relative Positional Encoding for Speech Recognition and Direct Translation;Transformer models are powerful sequence-to-sequence architectures that are capable of directly mapping speech inputs to transcriptions or translations. However, the mechanism for modeling positions in this model was tailored for text modeling, and thus is less ideal for acoustic inputs. In this work, we adapt the relative position encoding scheme to the Speech Transformer, where the key addition is relative distance between input states in the self-attention network. As a result, the network can better adapt to the variable distributions present in speech data. Our experiments show that our resulting model achieves the best recognition result on the Switchboard benchmark in the non-augmentation condition, and the best published result in the MuST-C speech translation benchmark. We also show that this model is able to better utilize synthetic data than the Transformer, and adapts better to variable sentence segmentation quality for speech translation.;2020;Not health related;Not health related
"Cruz-Guerrero, IA; Mendoza-Chavarría, JN; Campos-Delgado, DU; Fabelo, H; Ortega, S; Callico, GM";CLASSIFICATION OF BRAIN TISSUES IN HYPERSPECTRAL IMAGES USING VISION TRANSFORMERS;Hyperspectral (HS) imaging is a non-invasive technique able to identify the components of a sample by its reflectance properties. Nonetheless, the classification task of HS images is a complex problem, so advanced techniques as deep learning (DL) have been proposed in the literature to perform this task. Although these methods have generated competitive results, there are still open problems, such as the limitation of using global information and the high computational cost. Recently, vision transformers (ViT) have emerged as alternatives in some DL problems with excellent results on synthetic data. In this work, we propose to use ViTs to classify HS images of in-vivo real brain tissue to detect Glioblastoma-type tumor tissue. The classification results demonstrate that ViTs generate high performance predictions, with an overall average accuracy of over 99% and 86% for intra-patient and inter-patient training approaches, respectively.;2023;Health related;Health related
"Xu, XL; Geng, GH; Cao, X; Li, K; Zhou, MQ";TDNet: transformer-based network for point cloud denoising;This study proposes a novel, to the best of our knowledge, transformer-based end-to-end network (TDNet) for point cloud denoising based on encoder-decoder architecture. The encoder is based on the structure of a transformer in natural language processing (NLP). Even though points and sentences are different types of data, the NLP transformer can be improved to be suitable for a point cloud because the point can be regarded as a word. The improved model facilitates point cloud feature extraction and transformation of the input point cloud into the underlying high-dimensional space, which can characterize the semantic relevance between points. Subsequently, the decoder learns the latent manifold of each sampled point from the high-dimensional features obtained by the encoder, finally achieving a clean point cloud. An adaptive sampling approach is introduced during denoising to select points closer to the dean point cloud to reconstruct the surface. This is based on the view that a 3D object is essentially a 2D manifold. Extensive experiments demonstrate that the proposed network is superior in terms of quantitative and qualitative results for synthetic data sets and real-world terracotta warrior fragments. (C) 2021 Optical Society of America;2022;Not health related;Not health related
"Clavijo, JJ; Martínez, JF";Adversarial learning of permanent seismic deformation from GNSS coordinate timeseries;Deformation produced by an earthquake has a wide variety of forms. Therefore, there are a variety of models for quantifying the amount of deformation observed on GNSS coordinate timeseries, each of them based on different assumptions about the underlying mechanism that generates the data. Hence, it is of interest to look for methods relying on minimal assumptions about the observed position series. In this work we propose a semiparametric method, based on adversarial learning, to perform inference of the permanent seismic deformation. The only assumption made is that the probability distributions of GNSS fixed-length coordinate series for periods with and without observable seismic deformation differs mainly in the permanent deformation, represented by an additive scaled heaviside function. A dataset based on the series of GNSS coordinates published by the Nevada Geodetic Laboratory was built, and an adversarial model was trained over this dataset. In order to train the algorithm, an initial labeling of the samples was conducted using time, position an magnitude information of seismic events from the USGS database. It was shown that learning was possible with the available real data, and multiple sanity checks were run, showing consistency of the offset estimations compared with a trajectory model based estimator and with published offsets for well studied events on the South American active margin. To assess the capabilities of the method in a more controlled environment, further experiments were conducted on synthetic data. Those experiments confirmed that the presence of postseismic transient signals does not impede learning. As a derivative, our proposal allows to refine imperfect initial estimations for the presence/absence of seismic deformation.;2023;Not health related;Not health related
"Gholampour, PM; Verma, RM";Adversarial Robustness of Phishing Email Detection Models;Developing robust detection models against phishing emails has long been the main concern of the cyber defense community. Currently, public phishing/legitimate datasets lack adversarial email examples which keeps the detection models vulnerable. To address this problem, we developed an augmented phishing/legitimate email dataset, utilizing different adversarial text attack techniques. Next, the models were retrained with the adversarial dataset. Results showed that accuracy and F1 score of the models improved under subsequent attacks. In another experiment, synthetic phishing emails were generated using a fine-tuned GPT-2 model. The detection model was retrained with a newly formed synthetic dataset. Subsequently, we observed that the accuracy and robustness of the model did not improve significantly under black box attack methods. In the last experiment, we proposed a defensive technique to classify adversarial examples to their true labels using a K-Nearest Neighbor approach with 94% accuracy in our prediction.;2023;Not health related;Not health related
"Harrison, LM; David, O; Friston, KJ";Stochastic models of neuronal dynamics;Cortical activity is the product of interactions among neuronal populations. Macroscopic electrophysiological phenomena are generated by these interactions. In principle, the mechanisms of these interactions afford constraints on biologically plausible models of electrophysiological responses. In other words, the macroscopic features of cortical activity can be modelled in terms of the microscopic behaviour of neurons. An evoked response potential (ERP) is the mean electrical potential measured from an electrode on the scalp, in response to some event. The purpose of this paper is to outline a population density approach to modelling EPPs. We propose a biologically plausible model of neuronal activity that enables the estimation of physiologically meaningful parameters from electrophysiological data. The model encompasses four basic characteristics of neuronal activity and organization: (i) neurons are dynamic units, (ii) driven by stochastic forces, (iii) organized into populations with similar biophysical properties and response characteristics and (iv) multiple populations interact to form functional networks. This leads to a formulation of population dynamics in terms of the Fokker-Planck equation. The solution of this equation is the temporal evolution of a probability density over state-space, representing the distribution of an ensemble of trajectories. Each trajectory corresponds to the changing state of a neuron. Measurements can be modelled by taking expectations over this density, e.g. mean membrane potential, firing rate or energy consumption per neuron. The key motivation behind our approach is that ERPs represent an average response over many neurons. This means it is sufficient to model the probability density over neurons, because this implicitly models their average state. Although the dynamics of each neuron can be highly stochastic, the dynamics of the density is not. This means we can use Bayesian inference and estimation tools that have already been established for deterministic systems. The potential importance of modelling density dynamics (as opposed to more conventional neural mass models) is that they include interactions among the moments of neuronal states (e.g. the mean depolarization may depend on the variance of synaptic currents through nonlinear mechanisms). Here, we formulate a population model, based on biologically informed model-neurons with spike-rate adaptation and synaptic dynamics. Neuronal sub-populations are coupled to form an observation model, with the aim of estimating and making inferences about coupling among sub-populations using real data. We approximate the time-dependent solution of the system using a bi-orthogonal set and first-order perturbation expansion. For didactic purposes, the model is developed first in the context of deterministic input, and then extended to include stochastic effects. The approach is demonstrated using synthetic data, where model parameters are identified using a Bayesian estimation scheme we have described previously.;2005;Health related;Health related
"Gooya, A; Lekadir, K; Castro-Mateos, I; Pozo, JM; Frangi, AF";Mixture of Probabilistic Principal Component Analyzers for Shapes from Point Sets;Inferring a probability density function (pdf) for shape from a population of point sets is a challenging problem. The lack of point-to-point correspondences and the non-linearity of the shape spaces undermine the linear models. Methods based on manifolds model the shape variations naturally, however, statistics are often limited to a single geodesic mean and an arbitrary number of variation modes. We relax the manifold assumption and consider a piece-wise linear form, implementing a mixture of distinctive shape classes. The pdf for point sets is defined hierarchically, modeling a mixture of Probabilistic Principal Component Analyzers (PPCA) in higher dimension. A Variational Bayesian approach is designed for unsupervised learning of the posteriors of point set labels, local variation modes, and point correspondences. By maximizing the model evidence, the numbers of clusters, modes of variations, and points on the mean models are automatically selected. Using the predictive distribution, we project a test shape to the spaces spanned by the local PPCA's. The method is applied to point sets from: i) synthetic data, ii) healthy versus pathological heart morphologies, and iii) lumbar vertebrae. The proposed method selects models with expected numbers of clusters and variation modes, achieving lower generalization-specificity errors compared to state-of-the-art.;2018;Not health related;Health related
"Dang, QV; Lee, GS";SCENE TEXT SEGMENTATION BY PAIRED DATA SYNTHESIS;Scene text segmentation task has numerous practical applications. However, the number of images in the available datasets for scene text segmentation is too small to effectively train deep learning-based models, leading to limited performance. To solve this problem, we perform the segmentation in two aspects: paired data synthesis and methodology. The former is executed via the proposed Text Image-conditional GANs to generate realistic paired data. We exploit real-world images by self-supervised pre-training scheme via inpainting approach before training the proposed GANs to produce realistic synthetic data. The latter is carried out by the proposed scene text segmentation network to optimize learning the generated paired data, called Multi-task Cascade Transformer. It includes two auxiliary tasks and one main task for text segmentation. The functions of the two auxiliary tasks are to learn the text region to focus on, together with learning the structure of text through their fonts, and then they support the main task. We implement three publicly available datasets for scene text segmentation: ICDAR13 FST, Total Text, and TextSeg datasets to demonstrate the effectiveness of our method. Our experimental result outperforms existing methods.;2023;Not health related;Not health related
"Zhou, YX; Ji, AK; Zhang, LM";Sewer defect detection from 3D point clouds using a transformer-based deep learning model;Targeting the defect classification from 3D point clouds, this research develops a deep learning method named the Transformer-based point cloud classification network (TransPCNet) to obtain superior classification results. The developed TransPCNet primarily consists of the feature embedding module, the attention module, and the classification module, where the first two modules are to enhance the feature extraction and learning capability for assisting the classification module to classify the 3D point clouds more accurately. In addition, a novel loss function is proposed to support the TransPCNet by strengthening feature learning and tackling data imbalance. The effectiveness of the developed TransPCNet is demonstrated on a publicly available dataset with both real and synthetic point clouds. In comparison with other state-of-the-art methods, the TransPCNet outperforms others with improvements of over 13.6%, 15.2%, and 13.7% in terms of precision, recall, and F1-score on the overall dataset. Moreover, the TransPCNet is robust and efficient in different scenarios, where the synthetic data is beneficial to enhancing the detection accuracy on real datasets. Overall, this research contributes to developing TransPCNet to conduct 3D point cloud classification, resulting in a more accurate and effective result with great practical potential.;2022;Not health related;Not health related
"Shrivastava, A; Dhole, KD; Bhatt, A; Raghunath, S";Saying No is An Art: Contextualized Fallback Responses for Unanswerable Dialogue Queries;Despite end-to-end neural systems making significant progress in the last decade for task-oriented as well as chit-chat based dialogue systems, most dialogue systems rely on hybrid approaches which use a combination of rule-based, retrieval and generative approaches for generating a set of ranked responses. Such dialogue systems need to rely on a fallback mechanism to respond to out-of-domain or novel user queries which are not answerable within the scope of the dialogue system. While, dialogue systems today rely on static and unnatural responses like I don't know the answer to that question or I'm not sure about that, we design a neural approach which generates responses which are contextually aware with the user query as well as say no to the user. Such customized responses provide paraphrasing ability and contextualization as well as improve the interaction with the user and reduce dialogue monotonicity. Our simple approach makes use of rules over dependency parses and a text-to-text transformer fine-tuned on synthetic data of question-response pairs generating highly relevant, grammatical as well as diverse questions. We perform automatic and manual evaluations to demonstrate the efficacy of the system.;2021;Not health related;Not health related
"Bao, H; Deng, J; Xing, SH; Zhong, YS; Shi, WQ; Marteau, B; Das, B; Shehata, B; Deshpande, S; Wang, MD";Rare Heart Transplant Rejection Classification Using Diffusion-Based Synthetic Image Augmentation;Heart Transplant Rejection (HTR) is a rare condition that requires early detection to prevent lasting damage to the transplanted heart. Unfortunately, the current HTR grading through biopsy image classification lacks consistency among pathologists. In addition, it is a time-consuming task. In this work, we have developed an automated diagnosis pipeline to streamline the heart transplant histopathology image quantification and classification, in order to provide objectivity for clinical decision support for pathologists. Traditionally, developing an automated image classification requires a substantial amount of labeled data. However, HTR is a rare condition and the dataset is usually unbalanced. For example, the dataset from DNA Based Transplant Rejection (DTRT) comprises 1,509 rejection tile images and 190 times more non-rejection tile images. To address the small data sample challenge in training the classifiers, we developed a novel strategy that used diffusion model to generate synthetic images of rejection. We conducted comprehensive HTR grade classification comparing results using dataset with synthetic rejection tiles versus the dataset without any synthetic rejection tiles. The introduction of synthetic augmentation resulted in an improvement from 0.781 to 0.981 for sensitivity, and an improvement from 0.984 to over 0.998 in AUROC. This study illustrated that synthetic data augmentation is a feasible strategy in developing AI solutions for rare diseases. In the future, we will expand in this direction to benefit more rare disease clinical decision support development.;2023;Health related;Health related
"Cai, Q; Abdel-Aty, M; Yuan, JH; Lee, J; Wu, YN";Real-time crash prediction on expressways using deep generative models;"Real-time crash prediction is essential for proactive traffic safety management. However, developing an accurate prediction model is challenging as the traffic data of crash and non-crash cases are extremely imbalanced. Most of the previous studies undersampled non-crash cases to balance the data, which may not capture the heterogeneity of the full non-crash data. This study aims to use the emerging deep learning method called deep convolutional generative adversarial network (DCGAN) model to fully understand the traffic data leading to crashes. With the full understanding of the traffic data of crashes, the DCGAN model could generate more synthetic data related to crashes to balance the dataset. All non-crash data could be used for developing the prediction models. To capture the correlations between different variables, the data are augmented to 2-D matrix as the input for the DCGAN model. The suggested model is evaluated based on data from expressways and compared to two counterparts: (1) synthetic minority over-sampling technique (SMOTE); (2) random undersampling technique. The results suggest that the DCGAN could better understand the crash data characteristics by generating data with better fit of the real data distribution. Four different crash prediction algorithms (i.e., logistic regression model, support vector machine, artificial neural network, and convolutional neural network) are developed based on each balanced data and totally twelve models were estimated. The results indicate that the convolutional neural network model based on the DCGAN balanced data could provide the best prediction accuracy, validating that the proposed oversampling method could be used for the data balance. Besides, compared to other two models, only the DCGAN-based model could identify the significant effects of speed difference between the upstream and downstream locations which could help guide traffic management strategies. With the prediction model developed based on the balanced data by DCGAN, it is expected that more crashes could be predicted and prevented with more appropriate proactive traffic safety management strategies such as Variable Speed Limits (VSL) and Dynamic Message Signs (DMS).";2020;Not health related;Not health related
"Zhong, ZH; Cao, MD; Ji, X; Zheng, YQ; Sato, I";Blur Interpolation Transformer for Real-World Motion from Blur;This paper studies the challenging problem of recovering motion from blur, also known as joint deblurring and interpolation or blur temporal super-resolution. The challenges are twofold: 1) the current methods still leave considerable room for improvement in terms of visual quality even on the synthetic dataset, and 2) poor generalization to real-world data. To this end, we propose a blur interpolation transformer (BiT) to effectively unravel the underlying temporal correlation encoded in blur. Based on multi-scale residual Swin transformer blocks, we introduce dual-end temporal supervision and temporally symmetric ensembling strategies to generate effective features for time-varying motion rendering. In addition, we design a hybrid camera system to collect the first real-world dataset of one-to-many blur-sharp video pairs. Experimental results show that BiT has a significant gain over the state-of-the-art methods on the public dataset Adobe240. Besides, the proposed real-world dataset effectively helps the model generalize well to real blurry scenarios. Code and data are available at https://github.com/zzh-tech/BiT.;2023;Not health related;Not health related
"Chen, YJ; Yang, ZL; Zheng, XW; Chang, YD; Li, XT";PointFormer: A Dual Perception Attention-Based Network for Point Cloud Classification;Point cloud classification is a fundamental but still challenging task in 3-D computer vision. The main issue is that learning representational features from initial point cloud objects is always difficult for existing models. Inspired by the Transformer, which has achieved successful performance in the field of natural language processing, we propose a purely attention-based network, named PointFormer, for point cloud classification. Specifically, we design a novel simple point multiplicative attention mechanism. Based on that, we then construct both a local attention block and a global attention block to learn fine geometric features and overall representational features of the point cloud, respectively. Consequently, compared to the existing approaches, PointFormer has superior perception of local details and overall contours of the point cloud objects. In addition, we innovatively propose the Graph-Multiscale Perceptual Field (GMPF) testing strategy that can significantly improve the overall performance of the proposed PointFormer. We have conducted extensive experiments on the real-world dataset ScanObjectNN and the synthetic dataset ModelNet40. The results show that the PointFormer has stronger robustness and achieves highly competitive performance compared to other state-of-the-art approaches. The code is available at https://github.com/Yi-Jun-Chen/PointFormer.;2023;Not health related;Not health related
"Wan, ZY; Zhang, B; Chen, DD; Liao, J";Bringing Old Films Back to Life;We present a learning-based framework, recurrent transformer network (RTN), to restore heavily degraded old films. Instead of performing frame-wise restoration, our method is based on the hidden knowledge learned from adjacent frames that contain abundant information about the occlusion, which is beneficial to restore challenging artifacts of each frame while ensuring temporal coherency. Moreover, contrasting the representation of the current frame and the hidden knowledge makes it possible to infer the scratch position in an unsupervised manner, and such defect localization generalizes well to real-world degradations. To better resolve mixed degradation and compensate for the flow estimation error during frame alignment, we propose to leverage more expressive transformer blocks for spatial restoration. Experiments on both synthetic dataset and real-world old films demonstrate the significant superiority of the proposed RTN over existing solutions. In addition, the same framework can effectively propagate the color from keyframes to the whole video, ultimately yielding compelling restored films. The implementation and model will be released at https.//github.comiraywzy/Bringtng-Old-Films Back-to-Life.;2022;Not health related;Not health related
"Wang, YW; Chen, CP; Lu, CL; Chan, BC";Semi-Supervised Sound Event Detection Using Self-Attention and Multiple Techniques of Consistency Training;We present a system that detects sound events and their time boundaries in audio signals. The proposed system is based on the mean-teacher framework of semi-supervised learning of a deep neural network with the transformer architecture for a self-attention mechanism. The network can be trained efficiently with a small amount of strongly labeled synthetic data and a large amount of weakly labeled or unlabeled real data. The model parameters are learned with multiple consistency criteria, including interpolation consistency, shift consistency, and clip-level consistency, to improve the generalization and representation power. We also apply data augmentation with spectral and temporal masks to increase data diversity. Finally, an adaptive post-processing stage is applied to effectively smooth the frame-level network output. The proposed system is evaluated on the data released for DCASE 2020 Task 4. It achieves the state-of-the-art performance of event-based F-score of 46.30%, segment-based F-score of 72.21%, and polyphonic sound detection score (PSDS) of 69.01%. These numbers are better than the performance of 41.54 %, 68.11%, and 63.56% attained by a reference system without the proposed transformer blocks, consistency objective functions, and data augmentation.;2021;Not health related;Not health related
"Bindschaedler, V; Shokri, R; Gunter, CA";Plausible Deniability for Privacy-Preserving Data Synthesis;"Releasing full data records is one of the most challenging problems in data privacy. On the one hand, many of the popular techniques such as data de-identification are problematic because of their dependence on the background knowledge of adversaries. On the other hand, rigorous methods such as the exponential mechanism for differential privacy are often computationally impractical to use for releasing high dimensional data or cannot preserve high utility of original data due to their extensive data perturbation. This paper presents a criterion called plausible deniability that provides a formal privacy guarantee, notably for releasing sensitive datasets: an output record can be released only if a certain amount of input records are indistinguishable, up to a privacy parameter. This notion does not depend on the background knowledge of an adversary. Also, it can efficiently be checked by privacy tests. We present mechanisms to generate synt he tic data sets with similar statistical properties to the input data and the same format. We study this technique both theoretically and experimentally. A key theoretical result shows that, with proper randomization, the plausible deniability mechanism generates differentially private synthetic data. We demonstrate the efficiency of this generative technique on a large dataset; it is shown to preserve the utility of original data with respect to various statistical analysis and machine learning measures.";2017;Not health related;Not health related
"Lee, MCH; Petersen, K; Pawlowski, N; Glocker, B; Schaap, M";TeTrIS: Template Transformer Networks for Image Segmentation With Shape Priors;In this paper, we introduce and compare different approaches for incorporating shape prior information into neural network-based image segmentation. Specifically, we introduce the concept of template transformer networks, where a shape template is deformed to match the underlying structure of interest through an end-to-end trained spatial transformer network. This has the advantage of explicitly enforcing shape priors, and this is free of discretization artifacts by providing a soft partial volume segmentation. We also introduce a simple yet effective way of incorporating priors in the state-of-the-art pixel-wise binary classification methods such as fully convolutional networks and U-net. Here, the template shape is given as an additional input channel, incorporating this information significantly reduces false positives. We report results on synthetic data and sub-voxel segmentation of coronary lumen structures in cardiac computed tomography showing the benefit of incorporating priors in neural network-based image segmentation.;2019;Not health related;Not health related
"Wick, C; Zoellner, J; Gruning, T";Rescoring Sequence-to-Sequence Models for Text Line Recognition with CTC-Prefixes;In contrast to Connectionist Temporal Classification (CTC) approaches, Sequence-To-Sequence (S2S) models for Handwritten Text Recognition (HTR) suffer from errors such as skipped or repeated words which often occur at the end of a sequence. In this paper, to combine the best of both approaches, we propose to use the CTC-Prefix-Score during S2S decoding. Hereby, during beam search, paths that are invalid according to the CTC confidence matrix are penalised. Our network architecture is composed of a Convolutional Neural Network (CNN) as visual backbone, bidirectional Long-Short-Term-Memory-Cells (LSTMs) as encoder, and a decoder which is a Transformer with inserted mutual attention layers. The CTC confidences are computed on the encoder while the Transformer is only used for character-wise S2S decoding. We evaluate this setup on three HTR data sets: IAM, Rimes, and StAZH. On IAM, we achieve a competitive Character Error Rate (CER) of 2.95% when pretraining our model on synthetic data and including a character-based language model for contemporary English. Compared to other state-of-the-art approaches, our model requires about 10-20 times less parameters. Access our shared implementations via this link to GitHub.;2022;Not health related;Not health related
"Becker, S; Hug, R; Huebner, W; Arens, M; Morris, BT";MissFormer: (In-)Attention-Based Handling of Missing Observations for Trajectory Filtering and Prediction;In applications such as object tracking, time-series data inevitably carry missing observations. Following the success of deep learning-based models for various sequence learning tasks, these models increasingly replace classic approaches in object tracking applications for inferring the objects' motion states. While traditional tracking approaches can deal with missing observations, most of their deep counterparts are, by default, not suited for this. Towards this end, this paper introduces a transformer-based approach for handling missing observations in variable input length trajectory data. The model is formed indirectly by successively increasing the complexity of the demanded inference tasks. Starting from reproducing noise-free trajectories, the model then learns to infer trajectories from noisy inputs. By providing missing tokens, binary-encoded missing events, the model learns to in-attend to missing data and infers a complete trajectory conditioned on the remaining inputs. In the case of a sequence of successive missing events, the model then acts as a pure prediction model. The abilities of the approach are demonstrated on synthetic data and real-world data reflecting prototypical object tracking scenarios.;2021;Not health related;Not health related
"He, XY; Qian, X";A real-time surface defect detection system for industrial products with long-tailed distribution;"Applying visual recognition algorithms in surface defect detection has aroused increasing interest in industries. Despite the compelling speed advantages over manual detection, many algorithms fail to inspect defects from tail classes, especially where one defect dominates while the others have a few instances. One reason is that most of those computer vision models are proposed for class-balanced datasets while surface defects on industrial products often follow long-tail distributions. Existing studies alleviate this problem by simply adding synthetic data to the tail classes or manually adjusting weights. Herein, we propose: 1) a transformer embedded backbone structure to extract more representative features from the targets; 2) a 3-grids coordinate loss for predicting targets with multi-scale to reduce the targets miss rate. Our system can detect different kinds of surface defects at 125FPS, achieve 9.8% higher mAP and 3-22% higher AP of tail classes than YOLOv4 on long-tailed magnetic tiles datasets. Besides, our experiment on steel plates dataset shows that the effectiveness of our system is not limited to a certain industrial scenario, making it useful for a wide range of automated inspection tasks.";2021;Not health related;Not health related
"Kothari, P; Alahi, A";Safety-Compliant Generative Adversarial Networks for Human Trajectory Forecasting;Human trajectory forecasting in crowds presents the challenges of modelling social interactions and outputting collision-free multimodal distribution. Following the success of Social Generative Adversarial Networks (SGAN), recent works propose various GAN-based designs to better model human motion in crowds. Despite superior performance in reducing distance-based metrics, current networks fail to output socially acceptable trajectories, as evidenced by high collisions in model predictions. To counter this, we introduce SGANv2: an improved safety-compliant SGAN architecture equipped with spatio-temporal interaction modelling and a transformer-based discriminator. The spatio-temporal modelling ability helps to learn the human social interactions better while the transformer-based discriminator design improves temporal sequence modelling. Additionally, SGANv2 utilizes the learned discriminator even at test-time via a collaborative sampling strategy that not only refines the colliding trajectories but also prevents mode collapse, a common phenomenon in GAN training. Through extensive experimentation on multiple real-world and synthetic datasets, we demonstrate the efficacy of SGANv2 to provide socially-compliant multimodal trajectories.;2023;Not health related;Not health related
"Szeghy, D; Aslan, M; Fóthi, A; Mészáros, B; Milacski, ZA; Lorincz, A";Structural Extensions of Basis Pursuit: Guarantees on Adversarial Robustness;While deep neural networks are sensitive to adversarial noise, sparse coding using the Basis Pursuit (BP) method is robust against such attacks, including its multi-layer extensions. We prove that the stability theorem of BP holds upon the following generalizations: (i) the regularization procedure can be separated into disjoint groups with different weights, (ii) neurons or full layers may form groups, and (iii) the regularizer takes various generalized forms of the l(1) norm. This result provides the proof for the architectural generalizations of (Cazenavette et al., 2021) including (iv) an approximation of the complete architecture as a shallow sparse coding network. Due to this approximation, we settled to experimenting with shallow networks and studied their robustness against the Iterative Fast Gradient Sign Method on a synthetic dataset and MNIST. We introduce classification based on the l(2) norms of the groups and show numerically that it can be accurate and offers considerable speedups. In this family, linear transformer shows the best performance. Based on the theoretical results and the numerical simulations, we highlight numerical matters that may improve performance further. The proofs of our theorems can be found in the supplementary material*.;2022;Not health related;Health related
"Ho, JT; Hsu, GS; Yanushkevich, S; Gavrilova, ML";Outline Generation Transformer for Bilingual Scene Text Recognition;We propose the Outline Generation Transformer (OGT) for bilingual Scene Text Recognition (STR). As most STR approaches focus on English, we consider both English and Chinese as Chinese is also a major language, and it is a common scene in many areas/countries where both languages can be seen. The OGT consists of an Outline Generator (OG) and a transformer with a language model embedded. The OG detects the character outline of the text and embeds the outline features into a transformer with the outline-query cross-attention layer to better locate each character and enhance the text recognition performance. The training of OGT has two phases, one is training on synthetic data where the text outline masks are made available, followed by the other training on real data where the text outline masks can only be estimated. The proposed OGT is evaluated on several benchmark datasets and compared with state-of-the-art methods.;2023;Not health related;Not health related
"Li, WB; Chu, XK; Su, YY; Yao, D; Zhao, SW; Wu, RZ; Zhang, SZ; Tao, JR; Deng, H; Bi, JP";FingFormer: Contrastive Graph-based Finger Operation Transformer for Unsupervised Mobile Game Bot Detection;This paper studies the task of detecting bots for online mobile games. Considering the fact of lacking labeled cheating samples and restricted available data in the real detection systems, we aim to study the finger operations captured by screen sensors to infer the potential bots in an unsupervised way. In detail, we introduce a Transformer-style detection model, namely FingFormer. It studies the finger operations in the format of graph structure in order to capture the spatial and temporal relatedness between the two hands' operations. To optimize the model in an unsupervised way, we introduce two contrastive learning strategies to refine both finger moving patterns and players' operation habits. We conduct extensive experiments under different experimental environments, including the synthetic dataset, the offline dataset, as well as the large-scale online data flow from three mobile games. The multifacet experiments illustrate the proposed model is both effective and general to detect the bots for different mobile games.;2022;Not health related;Not health related
Endo, Y;User-Controllable Latent Transformer for StyleGAN Image Layout Editing;Latent space exploration is a technique that discovers interpretable latent directions and manipulates latent codes to edit various attributes in images generated by generative adversarial networks (GANs). However, in previous work, spatial control is limited to simple transformations (e.g., translation and rotation), and it is laborious to identify appropriate latent directions and adjust their parameters. In this paper, we tackle the problem of editing the StyleGAN image layout by annotating the image directly. To do so, we propose an interactive framework for manipulating latent codes in accordance with the user inputs. In our framework, the user annotates a StyleGAN image with locations they want to move or not and specifies a movement direction by mouse dragging. From these user inputs and initial latent codes, our latent transformer based on a transformer encoder-decoder architecture estimates the output latent codes, which are fed to the StyleGAN generator to obtain a result image. To train our latent transformer, we utilize synthetic data and pseudo-user inputs generated by off-the-shelf StyleGAN and optical flow models, without manual supervision. Quantitative and qualitative evaluations demonstrate the effectiveness of our method over existing methods.;2022;Not health related;Not health related
"Grimm, F; Cimiano, P";BiQuAD: Towards QA based on deeper text understanding;Recent question answering and machine reading benchmarks frequently reduce the task to one of pinpointing spans within a certain text passage that answers the given question. Typically, these systems are not required to actually understand the text on a deeper level that allows for more complex reasoning on the information contained. We introduce a new dataset called BiQuAD that requires deeper comprehension in order to answer questions in both extractive and deductive fashion. The dataset consist of 4, 190 closed-domain texts and a total of 99, 149 question-answer pairs. The texts are synthetically generated soccer match reports that verbalize the main events of each match. All texts are accompanied by a structured Datalog program that represents a (logical) model of its information. We show that state-of-the-art QA models do not perform well on the challenging long form contexts and reasoning requirements posed by the dataset. In particular, transformer based state-of-theart models achieve F1-scores of only 39.0. We demonstrate how these synthetic datasets align structured knowledge with natural text and aid model introspection when approaching complex text understanding.;2021;Not health related;Not health related
"Xu, JS; Moyer, D; Grant, PE; Golland, P; Iglesias, JE; Adalsteinsson, E";SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI;Volumetric reconstruction of fetal brains from multiple stacks of MR slices, acquired in the presence of almost unpredictable and often severe subject motion, is a challenging task that is highly sensitive to the initialization of slice-to-volume transformations. We propose a novel slice-to-volume registration method using Transformers trained on synthetically transformed data, which model multiple stacks of MR slices as a sequence. With the attention mechanism, our model automatically detects the relevance between slices and predicts the transformation of one slice using information from other slices. We also estimate the underlying 3D volume to assist slice-to-volume registration and update the volume and transformations alternately to improve accuracy. Results on synthetic data show that our method achieves lower registration error and better reconstruction quality compared with existing state-of-the-art methods. Experiments with real-world MRI data are also performed to demonstrate the ability of the proposed model to improve the quality of 3D reconstruction under severe fetal motion.;2022;Health related;Not health related
"Rao, Q; Yu, X; Navasardyan, S; Shi, H";Sim2RealVS: A New Benchmark for Video Stabilization with a Strong Baseline;Video stabilization is highly desirable when videos undergo severe jittering artifacts. The difficulty of obtaining sufficient training data obstructs the development of video stabilization. In this work, we address this issue by presenting a Sim2RealVS benchmark with more than 1,300 pairs of shaky and stable videos. Our benchmark is curated by an in-game simulator with diverse scenes and various jittering effects. Moreover, we propose a simple yet strong baseline approach, named Motion-Trajectory Smoothing Network (MTSNet), by fully exploiting our Sim2RealVS data. Our MTSNet consists of three main steps: motion estimation, global trajectory smoothing and frame warping. In motion estimation, we design a Motion Correction and Completion (MCC) module to rectify the optical flow with low confidence, such as in textureless regions, thus providing more consistent motion estimation for next steps. Benefiting from our synthetic data, we can explicitly learn a Trajectory Smoothing Transformer (TST) with ground-truth supervision to smooth global trajectories. In training TST, we propose two fully-supervised losses, i.e., a motion magnitude similarity loss and a motion tendency similarity loss. After training, our TST is able to produce smooth motion trajectories for the shaky input videos. Extensive qualitative and quantitative results demonstrate that our MTSNet achieves superior performance on both synthetic and real-world data.;2023;Not health related;Not health related
"He, J; Bartocci, E; NiCkovic, D; Isakovic, H; Grosu, R";DeepSTL - From English Requirements to Signal Temporal Logic;Formal methods provide very powerful tools and techniques for the design and analysis of complex systems. Their practical application remains however limited, due to the widely accepted belief that formal methods require extensive expertise and a steep learning curve. Writing correct formal specifications in form of logical formulas is still considered to be a difficult and error prone task. In this paper we propose DeepSTL, a tool and technique for the translation of informal requirements, given as free English sentences, into Signal Temporal Logic (STL), a formal specification language for cyber-physical systems, used both by academia and advanced research labs in industry. A major challenge to devise such a translator is the lack of publicly available informal requirements and formal specifications. We propose a two-step workflow to address this challenge. We first design a grammar-based generation technique of synthetic data, where each output is a random STL formula and its associated set of possible English translations. In the second step, we use a state-of- the-art transformer-based neural translation technique, to train an accurate attentional translator of English to STL. The experimental results show high translation quality for patterns of English requirements that have been well trained, making this workflow promising to be extended for processing more complex translation tasks.;2022;Not health related;Not health related
"Yu, XW; Creamer, MS; Randi, F; Sharma, AK; Linderman, SW; Leifer, AM";Fast deep neural correspondence for tracking and identifying neurons in C. elegans using semi-synthetic training;We present an automated method to track and identify neurons in C. elegans, called `fast Deep Neural Correspondence' or fDNC, based on the transformer network architecture. The model is trained once on empirically derived semi-synthetic data and then predicts neural correspondence across held-out real animals. The same pre-trained model both tracks neurons across time and identifies corresponding neurons across individuals. Performance is evaluated against hand-annotated datasets, including NeuroPAL (Yemini et al., 2021). Using only position information, the method achieves 79.1% accuracy at tracking neurons within an individual and 64.1% accuracy at identifying neurons across individuals. Accuracy at identifying neurons across individuals is even higher (78.2%) when the model is applied to a dataset published by another group (Chaudhary et al., 2021). Accuracy reaches 74.7% on our dataset when using color information from NeuroPAL. Unlike previous methods, fDNC does not require straightening or transforming the animal into a canonical coordinate system. The method is fast and predicts correspondence in 10 ms making it suitable for future real-time applications.;2021;Not health related;Health related
"Cornell, S; Omologo, M; Squartini, S; Vincent, E";Overlapped Speech Detection and speaker counting using distant;We study the problem of detecting and counting simultaneous, overlapping speakers in a multichannel, distant-microphone scenario. Focusing on a supervised learning approach, we treat Voice Activity Detection (VAD), Overlapped Speech Detection (OSD), joint VAD and OSD (VAD+OSD) and speaker counting in a unified way, as instances of a general Overlapped Speech Detection and Counting (OSDC) multi-class supervised learning problem. We consider a Temporal Convolutional Network (TCN) and a Transformer based architecture for this task, and compare them with previously proposed state-of-the art methods based on Recurrent Neural Networks (RNN) or hybrid Convolutional-Recurrent Neural Networks (CRNN). In addition, we propose ways of exploiting multichannel input by means of early or late fusion of single-channel features with spatial features extracted from one or more microphone pairs. We conduct an extensive experimental evaluation on the AMI and CHiME-6 datasets and on a purposely made multichannel synthetic dataset. We show that the Transformer-based architecture performs best among all architectures and that neural network based spatial localization features outperform signal-based spatial features and significantly improve performance compared to single-channel features only. Finally, we find that training with a speaker counting objective improves OSD compared to training with a VAD+OSD objective.;2022;Not health related;Not health related
"Xiong, SS; Tziafas, G; Kasaei, H";Enhancing Fine-Grained 3D Object Recognition using Hybrid Multi-Modal Vision Transformer-CNN Models;Robots operating in human-centered environments, such as retail stores, restaurants, and households, are often required to distinguish between similar objects in different contexts with a high degree of accuracy. However, fine-grained object recognition remains a challenge in robotics due to the high intra-category and low inter-category dissimilarities. In addition, the limited number of fine-grained 3D datasets poses a significant problem in addressing this issue effectively. In this paper, we propose a hybrid multi-modal Vision Transformer (ViT) and Convolutional Neural Networks (CNN) approach to improve the performance of fine-grained visual classification (FGVC). To address the shortage of FGVC 3D datasets, we generated two synthetic datasets. The first dataset consists of 20 categories related to restaurants with a total of 100 instances, while the second dataset contains 120 shoe instances. Our approach was evaluated on both datasets, and the results indicate that our hybrid multi-modal model outperforms both CNN-only and ViT-only baselines, achieving a recognition accuracy of 94.50% and 93.51% on the restaurant and shoe datasets, respectively. Additionally, we have made our FGVC RGB-D datasets available to the research community to enable further experimentation and advancement. Furthermore, we integrated our proposed method with a robot framework and demonstrated its potential as a fine-grained perception tool in both simulated and real-world robotic scenarios.;2023;Not health related;Not health related
"Choi, E; Xu, Z; Li, YJ; Dusenberry, MW; Flores, G; Xue, Y; Dai, AM";Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer;Effective modeling of electronic health records (EHR) is rapidly becoming an important topic in both academia and industry. A recent study showed that using the graphical structure underlying EHR data (e.g. relationship between diagnoses and treatments) improves the performance of prediction tasks such as heart failure prediction. However, EHR data do not always contain complete structure information. Moreover, when it comes to claims data, structure information is completely unavailable to begin with. Under such circumstances, can we still do better than just treating EHR data as a flat-structured bag-of-features? In this paper, we study the possibility of jointly learning the hidden structure of EHR while performing supervised prediction tasks on EHR data. Specifically, we discuss that Transformer is a suitable basis model to learn the hidden EHR structure, and propose Graph Convolutional Transformer, which uses data statistics to guide the structure learning process. The proposed model consistently outperformed previous approaches empirically, on both synthetic data and publicly available EHR data, for various prediction tasks such as graph reconstruction and readmission prediction, indicating that it can serve as an effective general-purpose representation learning algorithm for EHR data.;2020;Health related;Health related
"Gao, L; Shen, HS; Min, F";Swin Transformer for simultaneous denoising and interpolation of seismic data;Seismic data are often characterized by low quality due to noise contamination or missing traces. Convolutional neural networks are popular in dealing with denoising and interpolation. However, fixed-size convolution kernels have limited feature extraction range, and popular networks aim at either denoising or interpolating. In this paper, we propose a Swin Transformer convolutional residual network (SCRN) for simultaneous denoising and interpolation. We step-by-step show on synthetic datasets that SCRN can effectively denoise, interpolate, or denoise and interpolate simultaneously. Following this, the trained simultaneous denoising and interpolation model is directly used to handle multi-tasks on the field datasets. We assess the reconstruction effect of SCRN based on synthetic and field datasets. Comparison methods include both supervised ones (DnCNN, Unet and RIDNet) and unsupervised ones (DDUL, MultiResUNet and DL-POCS). Experimental results show that SCRN outperforms the counterparts in terms of (1) quantitative evaluation indices, (2) event continuity and weak signal retention, (3) generalization seismic data ability to suppress various noise levels and interpolate different sampling rates, and (4) preservation of first-arriving edge signals. These results indicate that SCRN can effectively reconstruct seismic data.;2024;Not health related;Not health related
"Yin, YC; Lin, ZN; Jin, MH; Fanti, G; Sekar, V";Practical GAN-based Synthetic IP Header Trace Generation using NetShare;We explore the feasibility of using Generative Adversarial Networks (GANs) to automatically learn generative models to generate synthetic packet- and flow header traces for networking tasks (e.g., telemetry, anomaly detection, provisioning). We identify key fidelity, scalability, and privacy challenges and tradeoffs in existing GAN-based approaches. By synthesizing domain-specific insights with recent advances in machine learning and privacy, we identify design choices to tackle these challenges. Building on these insights, we develop an end-to-end framework, NetShare. We evaluate NetShare on six diverse packet header traces and find that: (1) across all distributional metrics and traces, it achieves 46% more accuracy than baselines and (2) it meets users' requirements of downstream tasks in evaluating accuracy and rank ordering of candidate approaches.;2022;Not health related;Not health related
"Filatov, N; Kindulov, M";Low Rank Adaptation for Stable Domain Adaptation of Vision Transformers;Unsupervised domain adaptation plays a crucial role in semantic segmentation tasks due to the high cost of annotating data. Existing approaches often rely on large transformer models and momentum networks to stabilize and improve the self-training process. In this study, we investigate the applicability of low-rank adaptation (LoRA) to domain adaptation in computer vision. Our focus is on the unsupervised domain adaptation task of semantic segmentation, which requires adapting models from a synthetic dataset (GTA5) to a real-world dataset (City-scapes). We employ the Swin Transformer as the feature extractor and TransDA domain adaptation framework. Through experiments, we demonstrate that LoRA effectively stabilizes the self-training process, achieving similar training dynamics to the exponentially moving average (EMA) mechanism. Moreover, LoRA provides comparable metrics to EMA under the same limited computation budget. In GTA5 -> Cityscapes experiments, the adaptation pipeline with LoRA achieves a mIoU of 0.515, slightly surpassing the EMA baseline's mIoU of 0.513, while also offering an 11% speedup in training time and video memory saving. These re-sults highlight LoRA as a promising approach for domain adaptation in computer vision, offering a viable alternative to momentum networks which also saves computational resources.;2023;Not health related;Not health related
"Godoy, RV; Dwivedi, A; Shahmohammadi, M; Liarokapis, M";Lightmyography Based Decoding of Human Intention Using Temporal Multi-Channel Transformers;For the development of muscle-machine interfaces (MuMIs), researchers have relied mainly on Electromyography (EMG) signals. However, these signals require complex hardware systems, as well as specialized signal processing and feature extraction methods. To overcome these issues, in our previous work, we proposed a novel MuMI for decoding human intention and motion, called Lightmyography (LMG). To improve the performance of this interface even further, in this work, we employ two novel deep learning techniques called Temporal Multi-Channel Transformer (TMC-T) and Temporal Multi-Channel Vision Transformer (TMC-ViT) for the classification of hand gestures based on the LMG data. The performance of these two Transformer-based methods is evaluated and compared with other well-known deep learning and classical machine learning methods. This work also addresses the influence of varying parameters defined during the training phase of decoding models, such as the size and shape of the input data packet. A series of data augmentation techniques were also employed to generate synthetic data and increase the dataset size so as to train deep learning models more efficiently.;2022;Not health related;Not health related
"Augusma, A; Vaufreydaz, D; Letué, F";Multimodal Group Emotion Recognition In-the-wild Using Privacy-Compliant Features;This paper explores privacy-compliant group-level emotion recognition in-the-wild within the EmotiW Challenge 2023. Group-level emotion recognition can be useful in many felds including social robotics, conversational agents, e-coaching and learning analytics. This research imposes itself using only global features avoiding individual ones, i.e. all features that can be used to identify or track people in videos (facial landmarks, body poses, audio diarization, etc.). The proposed multimodal model is composed of a video and an audio branches with a cross-attention between modalities. The video branch is based on a fne-tuned ViT architecture. The audio branch extracts Mel-spectrograms and feed them through CNN blocks into a transformer encoder. Our training paradigm includes a generated synthetic dataset to increase the sensitivity of our model on facial expression within the image in a data-driven way. The extensive experiments show the signifcance of our methodology. Our privacy-compliant proposal performs fairly on the EmotiW challenge, with 79.24% and 75.13% of accuracy respectively on validation and test set for the best models. Noticeably, our fndings highlight that it is possible to reach this accuracy level with privacy-compliant features using only 5 frames uniformly distributed on the video.;2023;Not health related;Not health related
"Zou, Q; Priya, S; Nagpal, P; Jacob, M";Joint Cardiac T1 Mapping and Cardiac Cine Using Manifold Modeling;The main focus of this work is to introduce a single free-breathing and ungated imaging protocol to jointly estimate cardiac function and myocardial T-1 maps. We reconstruct a time series of images corresponding to k-space data from a free-breathing and ungated inversion recovery gradient echo sequence using a manifold algorithm. We model each image in the time series as a non-linear function of three variables: cardiac and respiratory phases and inversion time. The non-linear function is realized using a convolutional neural networks (CNN) generator, while the CNN parameters, as well as the phase information, are estimated from the measured k-t space data. We use a dense conditional auto-encoder to estimate the cardiac and respiratory phases from the central multi-channel k-space samples acquired at each frame. The latent vectors of the auto-encoder are constrained to be bandlimited functions with appropriate frequency bands, which enables the disentanglement of the latent vectors into cardiac and respiratory phases, even when the data are acquired with intermittent inversion pulses. Once the phases are estimated, we pose the image recovery as the learning of the parameters of the CNN generator from the measured k-t space data. The learned CNN generator is used to generate synthetic data on demand by feeding it with appropriate latent vectors. The proposed approach capitalizes on the synergies between cine MRI and T-1 mapping to reduce the scan time and improve patient comfort. The framework also enables the generation of synthetic breath-held cine movies with different inversion contrasts, which improves the visualization of the myocardium. In addition, the approach also enables the estimation of the T-1 maps with specific phases, which is challenging with breath-held approaches.;2023;Health related;Health related
"Gaido, M; Di Gangi, MA; Negri, M; Turchi, M";End-to-End Speech-Translation with Knowledge Distillation: FBK@IWSLT2020;This paper describes FBK's participation in the IWSLT 2020 offline speech translation (ST) task. The task evaluates systems' ability to translate English TED talks audio into German texts. The test talks are provided in two versions: one contains the data already segmented with automatic tools and the other is the raw data without any segmentation. Participants can decide whether to work on custom segmentation or not. We used the provided segmentation. Our system is an end-to-end model based on an adaptation of the Transformer for speech data. Its training process is the main focus of this paper and it is based on: i) transfer learning (ASR pretraining and knowledge distillation), ii) data augmentation (SpecAugment, time stretch and synthetic data), iii) combining synthetic and real data marked as different domains, and iv) multitask learning using the CTC loss. Finally, after the training with word-level knowledge distillation is complete, our ST models are fine-tuned using label smoothed cross entropy. Our best model scored 29 BLEU on the MuST-C En-De test set, which is an excellent result compared to recent papers, and 23.7 BLEU on the same data segmented with VAD, showing the need for researching solutions addressing this specific data condition.;2020;Not health related;Not health related
"Nguyen, TT; Ren, Z; Nguyen, TT; Jo, J; Nguyen, QVH; Yin, HZ";Portable graph-based rumour detection against multi-modal heterophily;The propagation of rumours on social media poses an important threat to societies, so that various techniques for graph-based rumour detection have been proposed recently. Existing works, however, are based on homophilic graphs: entities that are connected to each other often have the same label. However, recent studies found that heterophily is more common in real-world social networks, i.e., entities with different labels are also often linked to each other due to 'innocent' retweets or camouflage behaviours by malicious users. Especially, the heterophily problem is even more challenging in multi-modal social graphs, in which neighbouring entities might differ in terms of both labels and modalities. To cope with multi-modal homophily in graph-based rumour detection, we propose a Portable Graph Transformer-based Rumour Detection model (PHAROS) with novel multi-modal homophily measures. It integrates label information in the learning process, which enables us to generate discriminative neighbourhoods of entities. Our model can handle multiple modalities (a natural characteristic of social graphs) and is portable to be combined with existing graph-based models. Extensive experiments on real and synthetic data show the superiority, efficiency, robustness, and portability of PHAROS and its heterophily resilience.;2024;Not health related;Not health related
"Galhotra, S; Mazumdar, A; Pal, S; Saha, B";Community Recovery in the Geometric Block Model;To capture the inherent geometric features of many community detection problems, we propose to use a new random graph model of communities that we call a Geometric Block Model. The geometric block model builds on the random geometric graphs (Gilbert, 1961), one of the basic models of random graphs for spatial networks, in the same way that the well-studied stochastic block model builds on the Erdos-Re ' nyi random graphs. It is also a natural extension of random community models inspired by the recent theoretical and practical advancements in community detection. To analyze the geometric block model, we first provide new connectivity results for random annulus graphs which are generalizations of random geometric graphs. The connectivity properties of geometric graphs have been studied since their introduction, and analyzing them has been more difficult than their Erdos-Re ' nyi counterparts due to correlated edge formation. We then use the connectivity results of random annulus graphs to provide necessary and sufficient conditions for efficient recovery of communities for the geometric block model. We show that a simple triangle-counting algorithm to detect communities in the geometric block model is near-optimal. For this we consider the following two regimes of graph density. In the regime where the average degree of the graph grows logarithmically with the number of vertices, we show that our algorithm performs extremely well, both theoretically and practically. In contrast, the triangle-counting algorithm is far from being optimum for the stochastic block model in the logarithmic degree regime. We simulate our results on both real and synthetic datasets to show superior performance of both the new model as well as our algorithm.;2023;Not health related;Not health related
"Han, M; Kang, M; Jung, H; Hwang, SJ";Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data;We consider a novel question answering (QA) task where the machine needs to read from large streaming data (long documents or videos) without knowing when the questions will be given, which is difficult to solve with existing QA methods due to their lack of scalability. To tackle this problem, we propose a novel end-to-end deep network model for reading comprehension, which we refer to as Episodic Memory Reader (EMR) that sequentially reads the input contexts into an external memory, while replacing memories that are less important for answering unseen questions. Specifically, we train an RL agent to replace a memory entry when the memory is full, in order to maximize its QA accuracy at a future timepoint, while encoding the external memory using either the GRU or the Transformer architecture to learn representations that considers relative importance between the memory entries. We validate our model on a synthetic dataset (bAbI) as well as real-world large-scale textual QA (TriviaQA) and video QA (TVQA) datasets, on which it achieves significant improvements over rule-based memory scheduling policies or an RL-based baseline that independently learns the query-specific importance of each memory.;2019;Not health related;Not health related
"Danu, M; Nita, CI; Vizitiu, A; Suciu, C; Itu, LM";Deep learning based generation of synthetic blood vessel surfaces;In recent years, the medical imaging area showed a notably increased interest in Deep Learning (DL) based applications. Deep learning is a machine learning (ML) technique which learns features and tasks directly from data, trying to model human abstract thinking. Since deep learning can create features without a human intervention, it allows data scientists to use more complex sets of features in comparison with traditional machine learning approaches. In addition to this, the robustness to natural variations in the data is automatically learned and the deep learning architecture is flexible, so that the same neural network based approach can be applied to many different applications and data types. Our goal is to apply DL based techniques in the context of medical imaging with the purpose of developing a workflow for diagnosing cardiovascular pathologies or cerebral aneurysms. Since a major challenge of this approach is the lack of large training databases, in this paper we are focusing on performing data augmentation by generating realistic synthetic anatomical models of blood vessels. For this task we used geometries describing vessel-like structures and also real anatomies extracted from patients. We chose to experiment with two state of the art models: Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN). We address the problem of employing neural network based models on three dimensional surfaces. Such surfaces typically have an unstructured representation consisting of points and polygons and are not compatible with typical neural network architectures. We propose a technique based on surface voxelization which consists on representing the unstructured surface mesh as a threedimensional image, therefore becoming inherently compatible with a standard convolutional neural network. We performed experiments on three datasets containing both two and three dimensional surfaces representing blood vessel-like structures. We show that state of the art, deep learning based generative models, are capable of generating voxelized three dimensional surfaces of high quality that are visually indistinguishable from the training samples.;2019;Health related;Health related
"Annys, A; Jannis, D; Verbeeck, J";Deep learning for automated materials characterisation in core-loss electron energy loss spectroscopy;Electron energy loss spectroscopy (EELS) is a well established technique in electron microscopy that yields information on the elemental content of a sample in a very direct manner. One of the persisting limitations of EELS is the requirement for manual identification of core-loss edges and their corresponding elements. This can be especially bothersome in spectrum imaging, where a large amount of spectra are recorded when spatially scanning over a sample area. This paper introduces a synthetic dataset with 736,000 labeled EELS spectra, computed from available generalized oscillator strength tables, that represents 107 K, L, M or N core-loss edges and 80 chemical elements. Generic lifetime broadened peaks are used to mimic the fine structure due to band structure effects present in experimental core-loss edges. The proposed dataset is used to train and evaluate a series of neural network architectures, being a multilayer perceptron, a convolutional neural network, a U-Net, a residual neural network, a vision transformer and a compact convolutional transformer. An ensemble of neural networks is used to further increase performance. The ensemble network is used to demonstrate fully automated elemental mapping in a spectrum image, both by directly mapping the predicted elemental content and by using the predicted content as input for a physical model-based mapping.;2023;Not health related;Not health related
"Zhuang, Z; Li, TH; Wang, HK; Sun, J";Blind Image Deblurring with Unknown Kernel Size and Substantial Noise;Blind image deblurring (BID) has been extensively studied in computer vision and adjacent fields. Modern methods for BID can be grouped into two categories: single-instance methods that deal with individual instances using statistical inference and numerical optimization, and data-driven methods that train deep-learning models to deblur future instances directly. Data-driven methods can be free from the difficulty in deriving accurate blur models, but are fundamentally limited by the diversity and quality of the training data-collecting sufficiently expressive and realistic training data is a standing challenge. In this paper, we focus on single-instance methods that remain competitive and indispensable. However, most such methods do not prescribe how to deal with unknown kernel size and substantial noise, precluding practical deployment. Indeed, we show that several state-of-the-art (SOTA) single-instance methods are unstable when the kernel size is overspecified, and/or the noise level is high. On the positive side, we propose a practical BID method that is stable against both, the first of its kind. Our method builds on the recent ideas of solving inverse problems by integrating physical models and structured deep neural networks, without extra training data. We introduce several crucial modifications to achieve the desired stability. Extensive empirical tests on standard synthetic datasets, as well as real-world NTIRE2020 and RealBlur datasets, show the superior effectiveness and practicality of our BID method compared to SOTA single-instance as well as data-driven methods. The code of our method is available at https://github.com/sun-umn/Blind-Image-Deblurring.;2023;Not health related;Not health related
"Qin, XL; Song, HH; Fan, JQ; Zhang, KH";Spatio-spectral Cross-Attention Transformer for Hyperspectral image and Multispectral image fusion;This paper presents a novel Spatio-spectral Cross-Attention Transformer (SCAformer) for HyperSpectral Image and MultiSpectral Image (HSI/MSI) fusion. Specifically, we first design a Parallel Spatio-spectral Cross-Attention (P-SCA) module composed of a Spectral-wise Multi-head Cross-Attention (S-MCA) and a Window-based MCA (W-MCA), to yield more effective global spectra and local texture feature transferring between the HSI-MSI pairs. Afterwards, we develop a Spatial Fusion Module (SFM) that encodes rich local texture details to fuse the pairwise outputs of P-SCA in the pixel space. Finally, we construct a High-frequency Extraction Module (HEM) to further complement the edge details. The HEM first spatially-wise modulates the features to preserve spatial details, and then leverages Discrete Wavelet Transform (DWT) to decompose the modulated representation into a set of high-frequency components to complement the edge details in the fused image. Extensive experiments on three synthetic datasets (i.e. CAVE, Harvard and Pavia Centre) and a real dataset demonstrate that the proposed SCAformer outperforms the state-of-the-art methods in terms of all evaluation metrics.;2023;Not health related;Not health related
"Yang, ZR; Xu, MM; Liu, SW; Sheng, H; Zheng, HX";Spatial-Spectral Attention Bilateral Network for Hyperspectral Unmixing;Autoencoders (AEs) are widely utilized in hyperspectral unmixing (HU) as an unsupervised learning model. In particular, convolutional AE networks are popular for processing multidimensional hyperspectral features. Nonetheless, the traditional convolutional AE network's receptive field is constrained in the unmixing task, and establishing the connection between the local spatial neighborhood and the local spectrum fails to improve unmixing performance significantly. To address these limitations, a bilateral global attention network based on both spatial and spectral information is proposed. It enables the network to obtain respective feature dependencies in the two dimensions and achieve optimal fusion of both features. The network comprises two information extraction branches. The spatial information extraction branch uses the Swin Transformer block to acquire the global spatial attention of the overall image, while the spectral information extraction branch designates a simplified spectral channel attention mechanism to gain spectral attention weight maps. The network's efficacy is demonstrated through a comparative study using a synthetic dataset and two real datasets. The code of this work is available at https://github.com/UPCGIT/SSABN.;2023;Not health related;Not health related
"Alletto, S; Abati, D; Calderara, S; Cucchiara, R; Rigazio, L";Self-Supervised Optical Flow Estimation by Projective Bootstrap;Dense optical flow estimation is complex and time consuming, with state-of-the-art methods relying either on large synthetic data sets or on pipelines requiring up to a few minutes per frame pair. In this paper, we address the problem of optical flow estimation in the automotive scenario in a self-supervised manner. We argue that optical flow can be cast as a geometrical warping between two successive video frames and devise a deep architecture to estimate such transformation in two stages. First, a dense pixel-level flow is computed with a projective bootstrap on rigid surfaces. We show how such global transformation can be approximated with a homography and extend spatial transformer layers so that they can be employed to compute the flow field implied by such transformation. Subsequently, we refine the prediction by feeding a second, deeper network that accounts for moving objects. A final reconstruction loss compares the warping of frame X-t with the subsequent frame Xt+1 and guides both estimates. The model has the speed advantages of end-to-end deep architectures while achieving competitive performances, both outperforming recent unsupervised methods and showing good generalization capabilities on new automotive data sets.;2019;Not health related;Not health related
"Fu, JY; Xiang, ZY; Qiao, CY; Bai, TM";PT-FlowNet: Scene Flow Estimation on Point Clouds With Point Transformer;As a low-level task of 3D perception, scene flow is a fundamental representation of dynamic scenes and provides non-rigid motion descriptions for the objects in the 3D environment, which can strongly support many upper-level applications. Inspired by the revolutionary success of deep learning, many attention-based neural networks have recently been proposed to estimate scene flow from consecutive point clouds. However, extracting effective features and estimating accurate point motions for irregular and occluded point clouds remains a challenging task. In this letter, we propose PT-FlowNet, the first end-to-end scene flow estimation network embedding the point transformer (PT) into all functional stages of the task. In particular, we design novel PT-based modules for point feature extraction, iterative flow update, and flow refinement stage to encourage effective point-level feature aggregation. Experimental results on FlyingThings3D and KITTI datasets show that our PT-FlowNet achieves state-of-the-art performance. Trained on synthetic data only, our PT-FlowNet can generalize to real-world scans and outperforms the existing methods by at least 36.2% for the EPE3D metric on the KITTI dataset.;2023;Not health related;Not health related
"Bhagavatula, C; Zhu, CC; Luu, K; Savvides, M";Faster Than Real-time Facial Alignment: A 3D Spatial Transformer Network Approach in Unconstrained Poses;Facial alignment involves finding a set of landmark points on an image with a known semantic meaning. However, this semantic meaning of landmark points is often lost in 2D approaches where landmarks are either moved to visible boundaries or ignored as the pose of the face changes. In order to extract consistent alignment points across large poses, the 3D structure of the face must be considered in the alignment step. However, extracting a 3D structure from a single 2D image usually requires alignment in the first place. We present our novel approach to simultaneously extract the 3D shape of the face and the semantically consistent 2D alignment through a 3D Spatial Transformer Network (3DSTN) to model both the camera projection matrix and the warping parameters of a 3D model. By utilizing a generic 3D model and a Thin Plate Spline (TPS) warping function, we are able to generate subject specific 3D shapes without the need for a large 3D shape basis. In addition, our proposed network can be trained in an end-to-end framework on entirely synthetic data from the 300W-LP dataset. Unlike other 3D methods, our approach only requires one pass through the network resulting in a faster than real-time alignment. Evaluations of our model on the Annotated Facial Landmarks in the Wild (AFLW) and AFLW2000-3D datasets show our method achieves state-of-the-art performance over other 3D approaches to alignment.;2017;Not health related;Not health related
"Li, SY; Jin, XY; Xuan, Y; Zhou, XY; Chen, WH; Wang, YX; Yan, XF";Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting;"Time series forecasting is an important problem across many domains, including predictions of solar plant energy output, electricity consumption, and traffic jam situation. In this paper, we propose to tackle such forecasting problem with Transformer [1]. Although impressed by its performance in our preliminary study, we found its two major weaknesses: (1) locality-agnostics: the point-wise dot-product self-attention in canonical Transformer architecture is insensitive to local context, which can make the model prone to anomalies in time series; (2) memory bottleneck: space complexity of canonical Transformer grows quadratically with sequence length L, making directly modeling long time series infeasible. In order to solve these two issues, we first propose convolutional self-attention by producing queries and keys with causal convolution so that local context can be better incorporated into attention mechanism. Then, we propose LogSparse Transformer with only O(L(log L)(2)) memory cost, improving forecasting accuracy for time series with fine granularity and strong long-term dependencies under constrained memory budget. Our experiments on both synthetic data and real-world datasets show that it compares favorably to the state-of-the-art.";2019;Not health related;Not health related
"Tong, BW; Kong, FN; Kang, T; Luo, T; Shi, ZF";A dual-stream hybrid model for blind image quality assessment;"Blind image quality assessment (BIQA) is a fundamental task in computer vision. Humans can evaluate image quality from local and global aspects without information on reference images. Inspired by this, we propose a BIQA method named DS-IQA by mimicking human visual system (HVS). A dual-stream hybrid module is established to get dual-stream quality-aware features. A CNN branch is used to mimic the active inference process of HVS to extract local quality-aware features. An enhanced Transformer-branch is used to extract global quality-aware features by modeling nonlocal relations of image patches. Finally, a quality evaluator based on Transformer layers is developed to map the dual-stream features and output the final quality score. The proposed approach is evaluated on five databases. The PLCC of DS-IQA reaches 0.975, 0.938, and 0.963 respectively on synthetic databases (LIVE, TID2013, CSIQ), and individual distortion experimental on TID2013 shows that DS-IQA outperforms in 8 of the 24 distortion categories on TID2013. On authentic databases (LIVEC, KonIQ-10k), the PLCC of DS-IQA reaches 0.887, 0.918, experiments show the superiority of the proposed method over other state-of-the-art BIQA metrics.& COPY; 2023 Elsevier Inc. All rights reserved.";2023;Not health related;Not health related
"Bian, W; Li, CL; Hou, HW; Liu, XF";Iterative convolutional enhancing self-attention Hawkes process with time relative position encoding;Modeling Hawkes process using deep learning is superior to traditional statistical methods in the goodness of fit. However, methods based on RNN or self-attention are deficient in long-time dependence and recursive induction, respectively. Universal Transformer (UT) is an advanced framework to integrate these two requirements simultaneously due to its continuous transformation of self-attention in the depth of the position. In addition, migration of the UT framework involves the problem of effectively matching Hawkes process modeling. Thus, in this paper, an iterative convolutional enhancing self-attention Hawkes process with time relative position encoding (ICAHP-TR) is proposed, which is based on improved UT. First, the embedding maps from dense layers are carried out on sequences of arrival time points and markers to enrich event representation. Second, the deep network composed of UT extracts hidden historical information from event expression with the characteristics of recursion and the global receptive field. Third, two designed mechanics, including the relative positional encoding on the time step and the convolution enhancing perceptual attention are adopted to avoid losing dependencies between relative and adjacent positions in the Hawkes process. Finally, the hidden historical information is mapped by Dense layers as parameters in Hawkes process intensity function, thereby obtaining the likelihood function as the network loss. The experimental results show that the proposed methods demonstrate the effectiveness of synthetic datasets and real-world datasets from the perspective of both the goodness of fit and predictive ability compared with other baseline methods.;2023;Not health related;Not health related
"Harsuko, R; Alkhalifah, TA";StorSeismic: A New Paradigm in Deep Learning for Seismic Processing;Machine learned tasks on seismic data are often trained sequentially and separately, even though they utilize the same features (i.e., geometrical) of the data. We present StorSeismic as a dataset-centric framework for seismic data processing, which consists of neural network (NN) pretraining and fine-tuning procedures. We, specifically, utilize a NN as a preprocessing tool to extract and store seismic data features of a particular dataset for any downstream tasks. After pretraining, the resulting model can be utilized later, through a fine-tuning procedure, to perform different tasks using limited additional training. Used often in natural language processing (NLP) and lately in vision tasks, bidirectional encoder representations from transformer (BERT), a form of a transformer model, provides an optimal platform for this framework. The attention mechanism of BERT, applied here on a sequence of traces within the shot gather, is able to capture and store key geometrical features of the seismic data. We pretrain StorSeismic on field data, along with synthetically generated ones, in the self-supervised step. Then, we use the labeled synthetic data to fine-tune the pretrained network in a supervised fashion to perform various seismic processing tasks, such as denoising, velocity estimation, first arrival picking, and normal moveout (NMO). Finally, the fine-tuned model is used to obtain satisfactory inference results on the field data.;2022;Not health related;Not health related
"Zhang, Q; Rothe, S; Koukourakis, N; Czarske, J";Learning the matrix of few-mode fibers for high-fidelity spatial mode transmission;Few-mode fibers (FMFs) are promising for advancements in transmission capacity in classical and quantum communications. However, the inherent modal crosstalk limits the practical application of FMF. One reliable way to overcome this obstacle is the measurement of the complex transmission matrix (TM), describing the light propagation behavior of fiber. The TM can be obtained by performing mode decomposition (MD) of the spatial modes at the output of the fiber. MD techniques require the retrieval of both the amplitude and phase components of the detected light field, which is commonly done by using holography. However, the provision of a reference wave is highly unfavorable for the implementation of a holography-based MD in communication technology, especially for long fibers. Using deep neural networks to process intensity-only images, this drawback can be overcome. We introduce the mode transformer network, which can perform MD on 23 modes and has been trained offline using synthetic data. Experimentally, we demonstrate, for the first time, not only the measurement of complex TM of an FMF but also the inversion of the TM using a deep learning-based MD method. For mode transmission, we achieve an average fidelity of 97%. The short duration of the determination of TM allows for overcoming time-varying effects due to, e.g., mechanical stress or temperature fluctuations. The proposed reference-less calibration is promising for fiber communication with classical light and single photons, such as at quantum key distribution. (C) 2022 Author(s).;2022;Not health related;Not health related
"Yang, ZR; Xu, MM; Liu, SW; Sheng, H; Wan, JH";UST-Net: A U-Shaped Transformer Network Using Shifted Windows for Hyperspectral Unmixing;Autoencoders (AEs) are commonly utilized for acquiring low-dimensional data representations and performing data reconstruction, which makes them suitable for hyperspectral unmixing (HU). However, AE networks trained pixel by pixel and those employing localized convolutional filters disregard the global material distribution and distant interdependencies, resulting in the loss of necessary spatial feature information essential for the unmixing process. To overcome this limitation, we propose an innovative deep neural network model named U-shaped transformer network using shifted windows (UST-Net). UST-Net prioritizes spatial information in the scene that is more discriminative and significant by using multihead self-attention blocks based on shifted windows. Unlike patch-based unmixing networks, UST-Net operates on the complete image, eliminating inconsistencies associated with patches. Moreover, the downsampling and upsampling stages are used to extract hyperspectral image (HSI) feature maps at different scales. This process generates a context-rich and spatially accurate abundance map without losing local details. The experimental results of one synthetic dataset and three real datasets demonstrate that UST-Net significantly outperforms both traditional and several other advanced neural network methods. Our code is publicly available at https://github.com/UPCGIT/UST-Net.;2023;Not health related;Not health related
"Kundu, S; Maulik, U; Sheshanarayana, R; Ghosh, S";Vehicle Smoke Synthesis and Attention-Based Deep Approach for Vehicle Smoke Detection;Third world countries are suffering from extreme vehicular air pollution due to dominating number of fossil fuel-driven vehicles on the road. Therefore, in these countries, automatic surveillance systems are in high demand for close monitoring to identify and penalize vehicles emitting excessive smoke. In recent times, deep learning-based computer vision systems are rigorously working on the same. Their accuracy strongly depends on the number of the training images taken under various imaging conditions. However, there are very few publicly available vehicle smoke datasets that could be used for training purposes. To capture on-road videos for the creation of a dataset is another challenging and time-consuming task. To aid and enhance the vehicular smoke monitoring system, in this article, we propose, a holistic dual-level framework for dataset enhancement by smoke generation along with a transformer network for efficient identification. We have created a realistic vehicle smoke generation algorithm using a range of mask patterns and filtering, which helps us to train our deep neural model by generating sufficient synthetic data. We have also proposed a transformer network on the YOLOv5 backbone, which efficiently identifies the smoke region and the smoky vehicle from the image frame simultaneously. We have shown that the lambda-implemented attention-based detection network outperforms the other state-of-the-art techniques on three baseline datasets. Sample demo videos are available at the link https://github.com/srimantacse/VehicleSmoke.;2023;Not health related;Not health related
"Bountos, NI; Michail, D; Papoutsis, I";Learning From Synthetic InSAR With Vision Transformers: The Case of Volcanic Unrest Detection;The detection of early signs of volcanic unrest preceding an eruption in the form of ground deformation in interferometric synthetic aperture radar (InSAR) data is critical for assessing volcanic hazard. In this work, we treat this as a binary classification problem of InSAR images and propose a novel deep learning methodology that exploits a rich source of synthetically generated interferograms to train quality classifiers that perform equally well in real interferograms. The imbalanced nature of the problem, with orders of magnitude fewer positive samples, coupled with the lack of a curated database with labeled InSAR data, sets a challenging task for conventional deep learning architectures. We propose a new framework for domain adaptation, in which we learn class prototypes from synthetic data with vision transformers. We report detection accuracy that amounts to the highest reported accuracy on a large test set for volcanic unrest detection. Moreover, we built upon this knowledge by learning a new, nonlinear, projection between the learned representations and prototype space, using pseudo-labels produced by our model from an unlabeled real InSAR dataset. This leads to the new state-of-the-art with 97.1% accuracy on our test set. We demonstrate the robustness of our approach by training a simple ResNet-18 convolutional neural network on the unlabeled real InSAR dataset with pseudo-labels generated from our top transformer prototype model. Our methodology provides a significant improvement in performance without the need of manually labeling any sample, opening the road for further exploitation of synthetic InSAR data in various remote sensing applications.;2022;Not health related;Not health related
"Sajjadi, MSM; Meyer, H; Pot, E; Bergmann, U; Greff, K; Radwan, N; Vora, S; Lucic, M; Duckworth, D; Dosovitskiy, A; Uszkoreit, J; Funkhouser, T; Tagliasacchi, A";Scene Representation Transformer: Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations;A classical problem in computer vision is to infer a 3D scene representation from few images that can be used to render novel views at interactive rates. Previous work focuses on reconstructing pre-defined 3D representations, e.g. textured meshes, or implicit representations, e.g. radiance fields, and often requires input images with precise camera poses and long processing times for each novel scene. In this work, we propose the Scene Representation Transformer (SRT), a method which processes posed or unposed RGB images of a new area, infers a set-latent scene representation, and synthesises novel views, all in a single feed-forward pass. 'lb calculate the scene representation, we propose a generalization of the Vision Transformer to sets of images, enabling global information integration, and hence 3D reasoning. An efficient decoder transformer parameterizes the light field by attending into the scene representation to render novel views. Learning is supervised end-to-end by minimizing a novel-view reconstruction error. We show that this method outperforms recent baselines in terms of PSNR and speed on synthetic datasets, including a new dataset created for the paper. Further, we demonstrate that SRT scales to support interactive visualization and semantic segmentation of real-world outdoor environments using Street View imagery.;2022;Not health related;Not health related
"Bouchacourt, D; Ibrahim, M; Morcos, AS";Grounding inductive biases in natural images: invariance stems from variations in data;To perform well on unseen and potentially out-of-distribution samples, it is desirable for machine learning models to have a predictable response with respect to transformations affecting the factors of variation of the input. Here, we study the relative importance of several types of inductive biases towards such predictable behavior: the choice of data, their augmentations, and model architectures. Invariance is commonly achieved through hand-engineered data augmentation, but do standard data augmentations address transformations that explain variations in real data? While prior work has focused on synthetic data, we attempt here to characterize the factors of variation in a real dataset, ImageNet, and study the invariance of both standard residual networks and the recently proposed vision transformer with respect to changes in these factors. We show standard augmentation relies on a precise combination of translation and scale, with translation recapturing most of the performance improvement-despite the (approximate) translation invariance built in to convolutional architectures, such as residual networks. In fact, we found that scale and translation invariance was similar across residual networks and vision transformer models despite their markedly different architectural inductive biases. We show the training data itself is the main source of invariance, and that data augmentation only further increases the learned invariances. Notably, the invariances learned during training align with the ImageNet factors of variation we found. Finally, we find that the main factors of variation in ImageNet mostly relate to appearance and are specific to each class.;2021;Not health related;Not health related
"Yu, CD; Chang, YP; Liang, X; Liang, C; Xie, ZP";Deep learning for particle image velocimetry with attentional transformer and cross-correlation embedded;Deep learning-powered methodologies have realized remarkable advancements in the fluid mechanics community, including applications in the particle image velocimetry (PIV) task. However, previous deep learning based methods still lack robustness and generalization in the real flow scenarios. To solve this problem, we put forward a deep learning architecture called DeepST-CC for PIV estimation, which embeds an attentional transformer and cross-correlation strategy. Specifically, we introduce the Swin Transformer into the optical flow model Recurrent All-pairs Field Transforms (RAFT) to enhance the features of flow images. Then, the global matching between features is efficiently computed by applying a 4D correlation volume. Afterwards, the conventional cross-correlation method derives the initial velocity field from a coarse correlation, which is fed to the GRU-based flow update module. This approach enhances the robustness of the proposed model by incorporating coarse velocity information. Finally, a supervised learning strategy is performed to guide the model training on the synthetic dataset. Extensive experimental are conducted to demonstrate that our proposed approach delivers exceptional performance on the public dataset. In addition, DeepST-CC exhibits good generalization ability towards complex experimental PIV images.;2024;Not health related;Not health related
"Zhou, Y; Fu, JR; Smedby, Ö; Moreno, R";Synthesis of Pediatric Brain Tumor Images With Mass Effect;In children, brain tumors are the leading cause of cancer-related death. The amount of labeled data in children is much lower than that for adult subjects. This paper proposes a new method to synthesize high-quality pathological pediatric MRI brain images from pathological adult ones. To realistically simulate the appearance of brain tumors, the proposed method considers the mass effect, i.e., the deformation induced by the tumor to the surrounding tissue. First, a probabilistic U-Net was trained to predict a deformation field that encodes the mass effect from the healthy-pathological image pair. Second, the learned deformation field was utilized to warp the healthy mask to simulate the mass effect. The tumor mask is also added to the warped mask. Finally, a label-to-image transformer, i.e., the SPADE GAN, was trained to synthesize a pathological image from the segmentation masks of gray matter, white matter, CSF and the tumor. The synthetic images were evaluated in two quantitative ways: i) three supervised segmentation pipelines were trained on datasets with and without synthetic images. Two pipelines show over 1% improvements in the Dice scores when the datasets were augmented with synthetic data. ii) The Frechet inception distance was measured between real and synthetic image distributions. Results show that SPADE outperforms the state-of-the-art Pix2PixHD method in both T1w and T2w modalities. The source code can be accessed on https://github.com/audreyeternal/pediatric-tumor-generation.;2023;Health related;Health related
"Wang, YR; Wang, SY; Sun, LH";Point Cloud Upsampling via a Coarse-to-Fine Network;Point clouds captured by 3D scanning are usually sparse and noisy. Reconstructing a high-resolution 3D model of an object is a challenging task in computer vision. Recent point cloud upsampling approaches aim to generate a dense point set, while achieving both distribution uniformity and proximity-to-surface directly via an end-to-end network. Although dense reconstruction from low to high resolution can be realized by using these techniques, it lacks abundant details for dense outputs. In this work, we propose a coarse-to-fine network PUGL-Net for point cloud reconstruction that first predicts a coarse high-resolution point cloud via a global dense reconstruction module and then increases the details by aggregating local point features. On the one hand, a transformer-based mechanism is designed in the global dense reconstruction module. It aggregates residual learning in a self-attention scheme for effective global feature extraction. On the other hand, the coordinate offset of points is learned in a local refinement module. It further refines the coarse points by aggregating KNN features. Evaluated through extensive quantitative and qualitative evaluation on synthetic data set, the proposed coarse-to-fine architecture generates point clouds that are accurate, uniform and dense, it outperforms most existing state-of-the-art point cloud reconstruction works.;2022;Not health related;Not health related
"Yan, K; Lu, C; Ma, X; Ji, ZW; Huang, J";Intelligent fault diagnosis for air handing units based on improved generative adversarial network and deep reinforcement learning;Data-driven Automatic fault detection and diagnosis (AFDD) for air handling units (AHUs) is crucial for ensuring the stable operation and energy consumption of the heating ventilation air-conditioning (HVAC) system. However, traditional machine learning methods often underperform when confronted with insufficient training sample data, especially when lacking samples from the fault types. Based on the issues of insufficient samples from the fault types and imbalanced training dataset, this study proposes a novel AFDD approach using transformer integrated conditional Wasserstein generative adversarial network and deep reinforcement learning (TCWGAN-DRL) to synthesize the fault data and select high quality synthetic data samples. Firstly, we utilize the proposed TransCWGAN to synthesize fault samples. Then, reinforcement learning is utilized to select high quality synthetic samples. Finally, the filtered samples and the real fault samples are merged to form the training dataset for conventional supervised learning classifiers. Experimental results demonstrate that the enriched training dataset can effectively improve the AFDD results and outperforms recently published existing methods, for instance, compared to the suboptimal model, our method exhibits an increase in fault recognition accuracy of 4.9%, 3.66%, and 4.02% when the number of real fault samples is 15, 20, and 30, respectively.;2024;Not health related;Not health related
"Mahmoud, Z; Li, CL; Zappatore, M; Solyman, A; Alfatemi, A; Ibrahim, AO; Abdelmaboud, A";Semi-supervised learning and bidirectional decoding for effective grammar correction in low-resource scenarios;The correction of grammatical errors in natural language processing is a crucial task as it aims to enhance the accuracy and intelligibility of written language. However, developing a grammatical error correction (GEC) framework for low-resource languages presents significant challenges due to the lack of available training data. This article proposes a novel GEC framework for low-resource languages, using Arabic as a case study. To generate more training data, we propose a semi-supervised confusion method called the equal distribution of synthetic errors (EDSE), which generates a wide range of parallel training data. Additionally, this article addresses two limitations of the classical seq2seq GEC model, which are unbalanced outputs due to the unidirectional decoder and exposure bias during inference. To overcome these limitations, we apply a knowledge distillation technique from neural machine translation. This method utilizes two decoders, a forward decoder right-to-left and a backward decoder left-to-right, and measures their agreement using Kullback-Leibler divergence as a regularization term. The experimental results on two benchmarks demonstrate that our proposed framework outperforms the Transformer baseline and two widely used bidirectional decoding techniques, namely asynchronous and synchronous bidirectional decoding. Furthermore, the proposed framework reported the highest F1 score, and generating synthetic data using the equal distribution technique for syntactic errors resulted in a significant improvement in performance. These findings demonstrate the effectiveness of the proposed framework for improving grammatical error correction for low-resource languages, particularly for the Arabic language.;2023;Not health related;Not health related
"Sinclair, M; Schuh, A; Hahn, K; Petersen, K; Bai, Y; Batten, J; Schaap, M; Glocker, B";Atlas-ISTN: Joint segmentation, registration and atlas construction with image-and-spatial transformer networks;Deep learning models for semantic segmentation are able to learn powerful representations for pixel-wise predictions, but are sensitive to noise at test time and may lead to implausible topologies. Image registration models on the other hand are able to warp known topologies to target images as a means of segmentation, but typically require large amounts of training data, and have not widely been benchmarked against pixel-wise segmentation models. We propose the Atlas Image-and-Spatial Transformer Network (Atlas-ISTN), a framework that jointly learns segmentation and registration on 2D and 3D image data, and constructs a population-derived atlas in the process. Atlas-ISTN learns to segment multiple structures of interest and to register the constructed atlas labelmap to an intermediate pixel-wise segmentation. Additionally, Atlas-ISTN allows for test time refinement of the model's parameters to optimize the alignment of the atlas labelmap to an intermediate pixel-wise segmentation. This process both mitigates for noise in the target image that can result in spurious pixel-wise predictions, as well as improves upon the one pass prediction of the model. Benefits of the Atlas-ISTN framework are demonstrated qualitatively and quantitatively on 2D synthetic data and 3D cardiac computed tomography and brain magnetic resonance image data, out-performing both segmentation and registration baseline models. Atlas-ISTN also provides inter-subject correspondence of the structures of interest.(c) 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ );2022;Not health related;Not health related
"Wang, WD; Feng, H; Zhou, WA; Liao, ZK; Li, HQ";Model-Aware Pre-Training for Radial Distortion Rectification;Camera lenses often suffer from optical aberrations, causing radial distortion in the captured images. In those images, there exists a clear and general physical distortion model. However, in existing solutions, such rich geometric prior is under-utilized, and the formulation of an effective prediction target is under-explored. To this end, we introduce Radial Distortion TRansformer (RDTR), a new framework for radial distortion rectification. Our RDTR includes a model-aware pre-training stage for distortion feature extraction and a deformation estimation stage for distortion rectification. Technically, on the one hand, we formulate the general radial distortion (i.e., barrel distortion and pincushion distortion) in camera-captured images with a shared geometric distortion model and perform a unified model-aware pre-training for its learning. With the pre-training, the network is capable of encoding the specific distortion pattern of a radially distorted image. After that, we transfer the learned representations to the learning of distortion rectification. On the other hand, we introduce a new prediction target called backward warping flow for rectifying images with any resolution while avoiding image defects. Extensive experiments are conducted on our synthetic dataset, and the results demonstrate that our method achieves state-of-the-art performance while operating in real-time. Besides, we also validate the generalization of RDTR on real-world images. Our source code and the proposed dataset are publicly available at https://github.com/wwd-ustc/RDTR.;2023;Not health related;Not health related
"Luo, Y; Huang, QD; Ling, J; Lin, KL; Zhou, T";Local and global knowledge distillation with direction-enhanced contrastive learning for single-image deraining;"Single image deraining (SID) is a challenging problem since the rainy images contain a variety of backgrounds with rain streaks of different directions and densities. Though previous convolutional neural network based methods for SID have shown promising performance, their characterization ability is limited as they suffer from the local receptive fields and ignore long-range dependencies. Some methods try to solve it by designing complicated network architectures, which yields high computational costs. To address these problems, we consider both local and global features in the proposed recurrent attention-distilling network (RADN). Specifically, in the shallow layer, the local contextual information is extracted by a local extract module with channel and pixel attention blocks to focus on features of important channels and spatial locations. In the deep layer, the global intrinsic features are characterized by a refined transformer block with a self-attention (SA) mechanism to capture the long-range dependencies. Meanwhile, a teacher network is pre-trained by a rain-to-rain mapping to supervise the proposed RADN learning the rain intrinsic features quicker with lightweight. Moreover, we propose a direction-enhanced contrastive learning (DeCL) strategy which incorporates the potential rainy images into negative contrastive pairs to improve the model generalization ability. Extensive experiments show that the proposed method can achieve a competitive performance to state-of-the-art methods on both real and synthetic datasets. The source code is available at https: //github.com/Meky-hqd/RADN.& COPY; 2023 Elsevier B.V. All rights reserved.";2023;Not health related;Not health related
"Cao, H; Zhang, YZ; Shan, DX; Liu, XZ; Zhao, JQ";TRF-Net: a transformer-based RGB-D fusion network for desktop object instance segmentation;To perform object-specific tasks on the desktop, robots need to perceive different objects. The challenge is to calculate the pixel-wise mask for each object, even in the presence of occlusions and unseen objects. We take a step toward this problem by proposing a metric learning-based network called TRF-Net to perform desktop object instance segmentation. We design two ResNet-based branches to process the RGB and depth images separately. Then, we propose a Transformer-based fusion module called TranSE to fuse the features from both branches. This module also transfers the fused features to the decoder part, which helps generate fine-grained decoder features. After that, we propose a multi-scale feature embedding loss function called MFE loss to reduce the intra-class distance and increase the inter-class distance, which contributes to the feature clustering in embedding space. Due to the lack of large-scale real-world datasets for desktop objects, the proposed TRF-Net is trained with the synthetic dataset and tested with the small-scale real-world dataset. The target objects in the testing dataset do not present in the training dataset, ensuring the novelty of testing objects. We demonstrate that our method can produce accurate instance segmentation masks, outperforming other state-of-the-art methods on desktop object instance segmentation.;2023;Not health related;Not health related
"Wang, SZ; Zhou, TF; Lu, Y; Di, HJ";Detail-Preserving Transformer for Light Field Image Super-resolution;Recently, numerous algorithms have been developed to tackle the problem of light field super-resolution (LFSR), i.e., super-resolving low-resolution light fields to gain high-resolution views. Despite delivering encouraging results, these approaches are all convolution-based, and are naturally weak in global relation modeling of sub-aperture images necessarily to characterize the inherent structure of light fields. In this paper, we put forth a novel formulation built upon Transformers, by treating LFSR as a sequence-to-sequence reconstruction task. In particular, our model regards sub-aperture images of each vertical or horizontal angular view as a sequence, and establishes long-range geometric dependencies within each sequence via a spatial-angular locally-enhanced self-attention layer, which maintains the locality of each subaperture image as well. Additionally, to better recover image details, we propose a detail-preserving Transformer (termed as DPT), by leveraging gradient maps of light field to guide the sequence learning. DPT consists of two branches, with each associated with a Transformer for learning from an original or gradient image sequence. The two branches are finally fused to obtain comprehensive feature representations for reconstruction. Evaluations are conducted on a number of light field datasets, including real-world scenes and synthetic data. The proposed method achieves superior performance comparing with other state-of-the-art schemes. Our code is publicly available at: https://github.com/BITszwang/DPT.;2022;Not health related;Not health related
"Xiong, YG; Xiao, XM; Yao, MB; Liu, HQ; Yang, H; Fu, YG";MarsFormer: Martian Rock Semantic Segmentation With Transformer;"Semantic segmentation of Mars scenes has a crucial role in Mars rovers science missions. Current convolutional neural network (CNN)-based composition of U-Net has powerful information extraction capabilities; however, convolutional localization suffers from the limited global context modeling capability. Although transformer global modeling has performed well, it still encounters obstacles in the extraction and retention of low-level features. This issue is particularly relevant for Martian rocks with their varying shapes, textures, and sizes in Mars scenes. In this article, we propose a novel transformer semantic segmentation framework for Martian rock images, called MarsFormer, that consists of an encoder-decoder structure connected through a feature enhancement module (FEM) and a window transformer block (WTB). Specifically, multiscale hierarchical features are generated by the mix transformer (MiT) encoders, upgraded-FFN decoder (UFD) fuse and filter features at different scales, preserving the rich local and global contextual information. FEM enhances the inter-multiscale feature correlation from both spatial and channel perspectives. WTB captures the long-range contexts and preserves the local features. We built two datasets of synthetic and real Martian rocks. The synthetic dataset is SynMars, referencing data from the ZhuRong rover taken from its virtual terrain engine. The other dataset is MarsData-V2, from real Mars scenes, and published recently in our previous study. Extensive experiments conducted on both datasets showed that MarsFormer achieves superiority in Martian rock segmentation, obtaining state-of-the-art performance with favorable computational simplicity. The data are available at: https://github.com/CVIR-Lab/SynMars.";2023;Not health related;Not health related
"Liu, B; Fang, SY";Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining;Removing rain streaks from rainy images can improve the accuracy of computer vision applications such as object detection. In order to make full use of the frequency domain analysis characteristics of wavelet and combine the advantages of Convolutional Neural Network (CNN) and Transformer, a Multi-level Wavelet Network Based on CNN-Transformer Hybrid Attention (MWN-CTHA) for single image deraining is proposed. MWN-CTHA obtains multi-scale low-frequency and high-frequency images through multi-level non-separable lifting wavelet transform and uses CNN-Transformer Hybrid Attention Block (CTHAB) to learn global structure and detail information from low-frequency and high-frequency, respectively. CTHAB consists of CA-SA Layer (CSL) and Detail-enhanced Attention Feed-forward Layer (DAFL). CSL uses the non-local modeling ability of self-attention to capture long-range rain streaks and uses convolutional attention to enhance the search ability for local rain streaks, where convolution can assist self-attention to achieve better feature representation. DAFL utilizes Depth-wise Convolutional Layer to supplement detailed features and filters the information of feed-forward layer through Dual-branch Attention. The experimental results on the four synthetic datasets demonstrate that the proposed method achieves higher PSNR and SSIM than the state-of-the-art method DANet, with an improvement of 1.07 dB and 0.0098, respectively. The code is available at .;2023;Not health related;Not health related
"Kholgh, DK; Kostakos, P";PAC-GPT: A Novel Approach to Generating Synthetic Network Traffic With GPT-3;The application of machine learning models, particularly in cybersecurity, has surged significantly in the past few years. However, the effectiveness of these models is predominantly tethered to the quality and breadth of the training data they ingest. The scarcity of realistic datasets within the cybersecurity field constitutes a considerable challenge to the development of industry-grade tools intended for real-world application scenarios. Specifically, current datasets are either significantly outdated or fall short on both qualitative and quantitative fronts, primarily because many organizations exhibit reluctance in data sharing, stemming from privacy concerns or the potential threat to trade secrets. To address this challenge, the paper introduces PAC-GPT, a novel framework to generate reliable synthetic data for machine learning methods based on Open AI's Generative Pre-trained Transformer 3 (GPT-3). The core components of this framework are two modules, namely a Flow Generator, which is responsible for capturing and regenerating patterns in a series of network packets, and Packet Generator, which can generate individual network packets given the network flow. We also propose a packet generator based on LLM chaining and then proceed to assess, compare, and evaluate its performance using metrics such as loss, accuracy and success rate, concluding that transformers are a suitable approach for synthetic packet generation with minimal fine-tuning performed. Lastly, a streamlined command line interface (CLI) tool has been devised to facilitate the seamless access of this innovative data generation strategy by professionals from various disciplines.;2023;Not health related;Not health related
"Sadad, T; Aurangzeb, RA; Imran; Safran, M; Alfarhood, S; Kim, J";Classification of Highly Divergent Viruses from DNA/RNA Sequence Using Transformer-Based Models;Viruses infect millions of people worldwide each year, and some can lead to cancer or increase the risk of cancer. As viruses have highly mutable genomes, new viruses may emerge in the future, such as COVID-19 and influenza. Traditional virology relies on predefined rules to identify viruses, but new viruses may be completely or partially divergent from the reference genome, rendering statistical methods and similarity calculations insufficient for all genome sequences. Identifying DNA/RNA-based viral sequences is a crucial step in differentiating different types of lethal pathogens, including their variants and strains. While various tools in bioinformatics can align them, expert biologists are required to interpret the results. Computational virology is a scientific field that studies viruses, their origins, and drug discovery, where machine learning plays a crucial role in extracting domain- and task-specific features to tackle this challenge. This paper proposes a genome analysis system that uses advanced deep learning to identify dozens of viruses. The system uses nucleotide sequences from the NCBI GenBank database and a BERT tokenizer to extract features from the sequences by breaking them down into tokens. We also generated synthetic data for viruses with small sample sizes. The proposed system has two components: a scratch BERT architecture specifically designed for DNA analysis, which is used to learn the next codons unsupervised, and a classifier that identifies important features and understands the relationship between genotype and phenotype. Our system achieved an accuracy of 97.69% in identifying viral sequences.;2023;Health related;Health related
"Liu, W; Wang, H; Xi, ZZ; Zhang, RQ";Smooth Deep Learning Magnetotelluric Inversion Based on Physics-Informed Swin Transformer and Multiwindow Savitzky-Golay Filter;Despite exhibiting excellent inversion results for synthetic data in magnetotelluric (MT) inversion, applying deep learning (DL) to directly inverting MT field data remains challenging. In this study, different from most previous works that mainly focus on generating massive representative resistivity models to cover the solutions of the field data or constructing a strong network by employing advanced DL techniques, we provide a new perspective in that a multiwindow Savitzky-Golay (MWSG) filter is proposed to first smooth the apparent resistivity and phase derived from the MT field measurements before network prediction. This smoothing operation aims to promote the actual apparent resistivity and phase to be close in morphology and smoothness to the training input data, i.e., to adapt the field data to the training sample data. Then, the smoothed apparent resistivity and phase, instead of the original ones, are fed into the well-trained network for instantaneous inversion. Because we create a set of layered resistivity models with gradual-changing resistivity to act as desired output during network training, it together with the proposed MWSG filter enables this work to achieve smooth inversion. Besides, we introduce Swin Transformer (SwinT) to improve the efficiency of MT DL inversion, based on which a physics-informed SwinT (PISwinT) is implemented to enhance the generalization capability. We demonstrate the proposed PISwinT-MWSG smooth inversion method in both synthetic and field MT cases, and it is expected to improve the adaptability and practicability of the DL method to directly solve the inverse problems in MT surveys.;2023;Not health related;Not health related
"Li, P; Zhao, JY; Wu, JY; Deng, C; Han, YQ; Wang, HQ; Yu, T";OPAL: Occlusion Pattern Aware Loss for Unsupervised Light Field Disparity Estimation;Light field disparity estimation is an essential task in computer vision. Currently, supervised learning-based methods have achieved better performance than both unsupervised and optimization-based methods. However, the generalization capacity of supervised methods on real-world data, where no ground truth is available for training, remains limited. In this paper, we argue that unsupervised methods can achieve not only much stronger generalization capacity on real-world data but also more accurate disparity estimation results on synthetic datasets. To fulfill this goal, we present the Occlusion Pattern Aware Loss, named OPAL, which successfully extracts and encodes general occlusion patterns inherent in the light field for calculating the disparity loss. OPAL enables: i) accurate and robust disparity estimation by teaching the network how to handle occlusions effectively and ii) significantly reduced network parameters required for accurate and efficient estimation. We further propose an EPI transformer and a gradient-based refinement module for achieving more accurate and pixel-aligned disparity estimation results. Extensive experiments demonstrate our method not only significantly improves the accuracy compared with SOTA unsupervised methods, but also possesses stronger generalization capacity on real-world data compared with SOTA supervised methods. Last but not least, the network training and inference efficiency are much higher than existing learning-based methods. Our code will be made publicly available.;2024;Not health related;Not health related
"Lo, PC; Lim, EP";A transformer framework for generating context-aware knowledge graph paths;Contextual Path Generation (CPG) refers to the task of generating knowledge path(s) between a pair of entities mentioned in an input textual context to determine the semantic connection between them. Such knowledge paths, also called contextual paths, can be very useful in many advanced information retrieval applications. Nevertheless, CPG involves several technical challenges, namely, sparse and noisy input context, missing relations in knowledge graphs, and generation of ill-formed and irrelevant knowledge paths. In this paper, we propose a transformer-based model architecture. In this approach, we leverage a mixture of pre-trained word and knowledge graph embeddings to encode the semantics of input context, a transformer decoder to perform path generation controlled by encoded input context and head entity to stay relevant to the context, and scaling methods to sample a well-formed path. We evaluate our proposed CPG models derived using the above architecture on two real datasets, both consisting of Wikinews articles as input context documents and ground truth contextual paths, as well as a large synthetic dataset to conduct larger-scale experiments. Our experiments show that our proposed models outperform the baseline models, and the scaling methods contribute to better quality contextual paths. We further analyze how CPG accuracy can be affected by different amount of context data, and missing relations in the knowledge graph. Finally, we demonstrate that an answer model for knowledge graph questions adapted for CPG could not perform well due to the lack of an effective path generation module.;2023;Not health related;Not health related
"Tang, ZX; Wu, BY; Wu, WH; Ma, DB";Fault Detection via 2.5D Transformer U-Net with Seismic Data Pre-Processing;Seismic fault structures are important for the detection and exploitation of hydrocarbon resources. Due to their development and popularity in the geophysical community, deep-learning-based fault detection methods have been proposed and achieved SOTA results. Due to the efficiency and benefits of full spatial information extraction, 3D convolutional neural networks (CNNs) are used widely to directly detect faults on seismic data volumes. However, using 3D data for training requires expensive computational resources and can be limited by hardware facilities. Although 2D CNN methods are less computationally intensive, they lead to the loss of correlation between seismic slices. To mitigate the aforementioned problems, we propose to predict a 2D fault section using multiple neighboring seismic profiles, that is, 2.5D fault detection. In CNNs, convolution layers mainly extract local information and pooling layers may disrupt the edge features in seismic data, which tend to cause fault discontinuities. To this end, we incorporate the Transformer module in U-net for feature extraction to enhance prediction continuity. To reduce the data discrepancies between synthetic and different real seismic datasets, we apply a seismic data standardization workflow to improve the prediction stability on real datasets. Netherlands F3 real data tests show that, when training on synthetic data labels, the proposed 2.5D Transformer U-net-based method predicts more subtle faults and faults with higher spatial continuity than the baseline full 3D U-net model.;2023;Not health related;Not health related
"da Rocha, MVG; Alves, KSTR; Queiroz, ERC; Oliveira, FLC; Hell, MB; de Aguiar, EP";Power Transformers Thermal Modeling Based on the Modified Set-Membership Evolving Multivariable Gaussian and Variable Step-Size Evolving Multivariable Gaussian;"Knowledge of temperature distribution in power transformers is essential for the management of electrical distribution systems. Monitoring the hot-spot temperature of a power transformer can extend its lifetime. This paper introduces two novel models called Modified Set-Membership evolving multivariable Gaussian (MSM-eMG) and variable step-size evolving multivariable Gaussian (VS-eMG) for time series forecasting. Both approaches are an enhanced version of the evolving multivariable Gaussian model that use adaptive filtering to update the learning rate parameter, which updates the centers of the clusters, aiming to achieve better performance of the models. To evaluate their performance were used two data sets from a real power transformer; the first data set of the transformer has no overload conditions, and the second one has it. A synthetic data set was also used, as a benchmark, in order to show the effectiveness of these models in different scenarios. The obtained results are compared with the performance of the original evolving multivariable Gaussian and with other classical evolving and non-evolving models suggested in the literature. Both proposed models obtained the lowest errors in all simulations and presented a competitive number of rules in the real data, suggesting these models are flexible and efficient approaches to forecast complex data with high accuracy.";2022;Not health related;Not health related
"Bai, NN; Wang, XF; Han, RD; Wang, Q; Liu, ZN";PAFormer: Anomaly Detection of Time Series With Parallel-Attention Transformer;Time-series anomaly detection is a critical task with significant impact as it serves a pivotal role in the field of data mining and quality management. Current anomaly detection methods are typically based on reconstruction or forecasting algorithms, as these methods have the capability to learn compressed data representations and model time dependencies. However, most methods rely on learning normal distribution patterns, which can be difficult to achieve in real-world engineering applications. Furthermore, real-world time-series data is highly imbalanced, with a severe lack of representative samples for anomalous data, which can lead to model learning failure. In this article, we propose a novel end-to-end unsupervised framework called the parallel-attention transformer (PAFormer), which discriminates anomalies by modeling both the global characteristics and local patterns of time series. Specifically, we construct parallel-attention (PA), which includes two core modules: the global enhanced representation module (GERM) and the local perception module (LPM). GERM consists of two pattern units and a normalization module, with attention weights that indicate the relationship of each data point to the whole series (global). Due to the rarity of anomalous points, they have strong associations with adjacent data points. LPM is composed of a learnable Laplace kernel function that learns the neighborhood relevancies through the distributional properties of the kernel function (local). We employ the PA to learn the global-local distributional differences for each data point, which enables us to discriminate anomalies. Finally, we propose a two-stage adversarial loss to optimize the model. We conduct experiments on five public benchmark datasets (real-world datasets) and one synthetic dataset. The results show that PAFormer outperforms state-of-the-art baselines.;2023;Not health related;Not health related
"Beygi, S; Fazel-Zarandi, M; Cervone, A; Krishnan, P; Jonnalagadda, SR";Logical Reasoning for Task Oriented Dialogue Systems;In recent years, large pretrained models have been used in dialogue systems to improve successful task completion rates. However, lack of reasoning capabilities of dialogue platforms make it difficult to provide relevant and fluent responses, unless the designers of a conversational experience spend a considerable amount of time implementing these capabilities in external rule based modules. In this work, we propose a novel method to fine-tune pretrained transformer models such as Roberta and T5, to reason over a set of facts in a given dialogue context. Our method includes a synthetic data generation mechanism which helps the model learn logical relations, such as comparison between list of numerical values, inverse relations (and negation), inclusion and exclusion for categorical attributes, and application of a combination of attributes over both numerical and categorical values, and spoken form for numerical values, without need for additional training data. We show that the transformer based model can perform logical reasoning to answer questions when the dialogue context contains all the required information, otherwise it is able to extract appropriate constraints to pass to downstream components (e.g. a knowledge base) when partial information is available. We observe that transformer based models such as UnifiedQA-T5 can be fine-tuned to perform logical reasoning (such as numerical and categorical attributes' comparison) over attributes seen at training time (e.g., accuracy of 90%+ for comparison of smaller than k(max)=5 values over heldout test dataset).;2022;Not health related;Not health related
"Kwon, YS; Sung, MY; Yoon, SE";Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction;Super-resolution of LiDAR range images is crucial to improving many downstream tasks such as object detection, recognition, and tracking. While deep learning has made a remarkable advances in super-resolution techniques, typical convolutional architectures limit upscaling factors to specific output resolutions in training. Recent work has shown that a continuous representation of an image and learning its implicit function enable almost limitless upscaling. However, the detailed approach, predicting values (depths) for neighbor pixels in the input and then linearly interpolating them, does not best fit the LiDAR range images since it does not fill the unmeasured details but creates a new image with regression in a high-dimensional space. In addition, the linear interpolation blurs sharp edges providing important boundary information of objects in 3-D points. To handle these problems, we propose a novel network, Implicit LiDAR Network (ILN), which learns not the values per pixels but weights in the interpolation so that the superresolution can be done by blending the input pixel depths but with non-linear weights. Also, the weights can be considered as attentions from the query to the neighbor pixels, and thus an attention module in the recent Transformer architecture can be leveraged. Our experiments with a novel large-scale synthetic dataset demonstrate that the proposed network reconstructs more accurately than the state-of-the-art methods, achieving much faster convergence in training.;2022;Not health related;Not health related
"Galvao, RKH; Kienitz, KH; Hadjiloucas, S; Walker, GC; Bowen, JW; Soares, SFC; Araújo, MCU";Multivariate Analysis of the Dielectric Response of Materials Modeled using Networks of Resistors and Capacitors;We discuss the modeling of dielectric responses of electromagnetically excited networks which are composed of a mixture of capacitors and resistors. Such networks can be employed as lumped-parameter circuits to model the response of composite materials containing conductive and insulating grains. The dynamics of the excited network systems are studied using a state space model derived from a randomized incidence matrix. Time and frequency domain responses from synthetic data sets generated from state space models are analyzed for the purpose of estimating the fraction of capacitors in the network. Good results were obtained by using either the time-domain response to a pulse excitation or impedance data at selected frequencies. A chemometric framework based on a Successive Projections Algorithm (SPA) enables the construction of multiple linear regression (MLR) models which can efficiently determine the ratio of conductive to insulating components in composite material samples. The proposed method avoids restrictions commonly associated with Archie's law, the application of percolation theory or Kohlrausch-Williams-Watts models and is applicable to experimental results generated by either time domain transient spectrometers or continuous-wave instruments. Furthermore, it is quite generic and applicable to tomography, acoustics as well as other spectroscopies such as nuclear magnetic resonance, electron paramagnetic resonance and, therefore, should be of general interest across the dielectrics community.;2013;Not health related;Not health related
"Tian, YJ; Bai, KL";End-to-End Multitask Learning With Vision Transformer;Multitask learning (MTL) is a challenging puzzle, particularly in the realm of computer vision (CV). Setting up vanilla deep MTL requires either hard or soft parameter sharing schemes that employ greedy search to find the optimal network designs. Despite its widespread application, the performance of MTL models is vulnerable to under-constrained parameters. In this article, we draw on the recent success of vision transformer (ViT) to propose a multitask representation learning method called multitask ViT (MTViT), which proposes a multiple branch transformer to sequentially process the image patches (i.e., tokens in transformer) that are associated with various tasks. Through the proposed cross-task attention (CA) module, a task token from each task branch is regarded as a query for exchanging information with other task branches. In contrast to prior models, our proposed method extracts intrinsic features using the built-in self-attention mechanism of the ViT and requires just linear time on memory and computation complexity, rather than quadratic time. Comprehensive experiments are carried out on two benchmark datasets, including NYU-Depth V2 (NYUDv2) and CityScapes, after which it is found that our proposed MTViT outperforms or is on par with existing convolutional neural network (CNN)-based MTL methods. In addition, we apply our method to a synthetic dataset in which task relatedness is controlled. Surprisingly, experimental results reveal that the MTViT exhibits excellent performance when tasks are less related.;2023;Not health related;Not health related
"Li, Y; Cao, JT; Xu, Y; Zhu, LP; Dong, ZY";Deep learning based on Transformer architecture for power system short-term voltage stability assessment with class imbalance;Most existing data-driven power system short-term voltage stability assessment (STVSA) approaches presume class-balanced input data. However, in practical applications, the occurrence of short-term voltage instability following a disturbance is minimal, leading to a significant class imbalance problem and a consequent decline in classifier performance. This work proposes a Transformer-based STVSA method to address this challenge. By utilizing the basic Transformer architecture, a stability assessment Transformer (StaaT) is developed as a classification model to reflect the correlation between the operational states of the system and the resulting stability outcomes. To combat the negative impact of imbalanced datasets, this work employs a conditional Wasserstein generative adversarial network with gradient penalty (CWGAN-GP) for synthetic data generation, aiding in the creation of a balanced, representative training set for the classifier. Semi-supervised clustering learning is implemented to enhance clustering quality, addressing the lack of a unified quantitative criterion for short-term voltage stability. Numerical tests on the IEEE 39-bus test system extensively demonstrate that the proposed method exhibits robust performance under class imbalances up to 100:1 and noisy environments, and maintains consistent effectiveness even with an increased penetration of renewable energy. Comparative results reveal that the CWGAN-GP generates more balanced datasets than traditional oversampling methods and that the StaaT outperforms other deep learning algorithms. This study presents a compelling solution for real-world STVSA applications that often face class imbalance and data noise challenges.;2024;Not health related;Not health related
"Siyaev, A; Jo, GS";Neuro-Symbolic Speech Understanding in Aircraft Maintenance Metaverse;In the emerging world of metaverses, it is essential for speech communication systems to be aware of context to interact with virtual assets in the 3D world. This paper proposes the metaverse for aircraft maintenance training and education of Boeing-737, supplied with legacy manuals, 3D models, 3D simulators, and aircraft maintenance knowledge. Furthermore, to navigate and control operational flow in the metaverse, which is strictly followed by maintenance manuals, the context-aware speech understanding module Neuro-Symbolic Speech Executor (NSSE) is presented. Unlike conventional speech recognition methods, NSSE applies Neuro-Symbolic AI, which combines neural networks and traditional symbolic reasoning, to understand users' requests and reply based on context and aircraft-specific knowledge. NSSE is developed with an industrially flexible approach by applying only synthetic data for training. Nevertheless, the evaluation process performed with various automatic speech recognition metrics on real users' data showed sustainable results with an average accuracy of 94.7%, Word Error Rate (WER) of 7.5%, and the generalization ability to handle speech requests of users with the non-native pronunciation. The proposed Aircraft Maintenance Metaverse is a cheap and scalable solution for aviation colleges since it replaces expensive physical aircraft with virtual one that can be easily modified and updated. Moreover, the Neuro-Symbolic Speech Executor, playing the role of field expert, provides technical guidance and all the resources to facilitate effective training and education of aircraft maintenance.;2021;Not health related;Health related
"Yin, HZ; Cui, B; Sun, YZ; Hu, ZT; Chen, L";LCARS: A Spatial Item Recommender System;Newly emerging location-based and event-based social network services provide us with a new platform to understand users' preferences based on their activity history. A user can only visit a limited number of venues/events and most of them are within a limited distance range, so the user-item matrix is very sparse, which creates a big challenge to the traditional collaborative filtering-based recommender systems.. The problem becomes even more challenging when people travel to a new city where they have no activity information. In this article, we propose LCARS, a location-content-aware recommender system that offers a particular user a set of venues (e.g., restaurants and shopping malls) or events (e.g., concerts and exhibitions) by giving consideration to both personal interest and local preference. This recommender system can facilitate people's travel not only near the area in which they live, but also in a city that is new to them. Specifically, LCARS consists of two components: offline modeling and online recommendation. The offline modeling part, called LCA-LDA, is designed to learn the interest of each individual user and the local preference of each individual city by capturing item cooccurrence patterns and exploiting item contents. The online recommendation part takes a querying user along with a querying city as input, and automatically combines the learned interest of the querying user and the local preference of the querying city to produce the top-k recommendations. To speed up the online process, a scalable query processing technique is developed by extending both the Threshold Algorithm (TA) and TA-approximation algorithm. We evaluate the performance of our recommender system on two real datasets, that is, DoubanEvent and Foursquare, and one large-scale synthetic dataset. The results show the superiority of LCARS in recommending spatial items for users, especially when traveling to new cities, in terms of both effectiveness and efficiency. Besides, the experimental analysis results also demonstrate the excellent interpretability of LCARS.;2014;Not health related;Not health related
"Papi, S; Gaido, M; Negri, M; Turchi, M";Dealing with training and test segmentation mismatch: FBK@IWSLT2021;This paper describes FBK's system submission to the IWSLT 2021 Offline Speech Translation task. We participated with a direct model, which is a Transformer-based architecture trained to translate English speech audio data into German texts. The training pipeline is characterized by knowledge distillation and a two-step fine-tuning procedure. Both knowledge distillation and the first fine-tuning step are carried out on manually segmented real and synthetic data, the latter being generated with an MT system trained on the available corpora. Differently, the second fine-tuning step is carried out on a random segmentation of the MuST-C v2 En-De dataset. Its main goal is to reduce the performance drops occurring when a speech translation model trained on manually segmented data (i.e. an ideal, sentencelike segmentation) is evaluated on automatically segmented audio (i.e. actual, more realistic testing conditions). For the same purpose, a custom hybrid segmentation procedure that accounts for both audio content (pauses) and for the length of the produced segments is applied to the test data before passing them to the system. At inference time, we compared this procedure with a baseline segmentation method based on Voice Activity Detection (VAD). Our results indicate the effectiveness of the proposed hybrid approach, shown by a reduction of the gap with manual segmentation from 8.3 to 1.4 BLEU points.;2021;Not health related;Not health related
"Li, YC; Guo, JW; Qiu, HH; Chen, FY; Zhang, JQ";Denoising Diffusion Probabilistic Models and Transfer Learning for citrus disease diagnosis;ProblemsPlant Disease diagnosis based on deep learning mechanisms has been extensively studied and applied. However, the complex and dynamic agricultural growth environment results in significant variations in the distribution of state samples, and the lack of sufficient real disease databases weakens the information carried by the samples, posing challenges for accurately training models.AimThis paper aims to test the feasibility and effectiveness of Denoising Diffusion Probabilistic Models (DDPM), Swin Transformer model, and Transfer Learning in diagnosing citrus diseases with a small sample.MethodsTwo training methods are proposed: The Method 1 employs the DDPM to generate synthetic images for data augmentation. The Swin Transformer model is then used for pre-training on the synthetic dataset produced by DDPM, followed by fine-tuning on the original citrus leaf images for disease classification through transfer learning. The Method 2 utilizes the pre-trained Swin Transformer model on the ImageNet dataset and fine-tunes it on the augmented dataset composed of the original and DDPM synthetic images.Results and conclusionThe test results indicate that Method 1 achieved a validation accuracy of 96.3%, while Method 2 achieved a validation accuracy of 99.8%. Both methods effectively addressed the issue of model overfitting when dealing with a small dataset. Additionally, when compared with VGG16, EfficientNet, ShuffleNet, MobileNetV2, and DenseNet121 in citrus disease classification, the experimental results demonstrate the superiority of the proposed methods over existing approaches to a certain extent.;2023;Not health related;Health related
"Liu, HQ; Yao, MB; Xiao, XM; Xiong, YG";RockFormer: A U-Shaped Transformer Network for Martian Rock Segmentation;Martian rock segmentation aims to separate rock pixels from background, which plays a crucial role in downstream tasks, such as traversing and geologic analysis by Mars rovers. The U-Nets have achieved certain results in rock segmentation. However, due to the inherent locality of convolution operations, U-Nets are inadequate in modeling global context and long-range spatial dependencies. Although emerging Transformers can solve this, they suffer from difficulties in extracting and retaining sufficient low-level local information. These shortcomings limit the performance of the existing networks for Martian rocks that are variable in shape, size, texture, and color. Therefore, we propose RockFormer, the first U-shaped Transformer framework for Mars rock segmentation, consisting of a hierarchical encoder-decoder architecture with a feature refining module (FRM) connected between them. Specifically, the encoder hierarchically generates multiscale features using an improved vision Transformer (improved-ViT), where both abundant local information and long-range contexts are exploited. The FRM removes less representative features and captures global dependencies between multiscale features, improving RockFormer's robustness to Martian rocks with diverse appearances. The decoder is responsible for aggregating these features for pixelwise rock prediction. For evaluation, we establish two Mars rock datasets, including both real and synthesized images. One is MarsData-V2, an extension of our previously published MarsData collected from real Mars rocks. The other is SynMars, a synthetic dataset sequentially photographed from a virtual terrain built referring to the TianWen-1 dataset. Extensive experiments on the two datasets show the superiority of RockFormer for Martian rock segmentation, achieving state-of-the-art performance with decent computational simplicity.;2023;Not health related;Not health related
"Sattarov, T; Schreyer, M; Borth, D";FinDiff: Diffusion Models for Financial Tabular Data Generation;The sharing of microdata, such as fund holdings and derivative instruments, by regulatory institutions presents a unique challenge due to strict data confidentiality and privacy regulations. These challenges often hinder the ability of both academics and practitioners to conduct collaborative research effectively. The emergence of generative models, particularly diffusion models, capable of synthesizing data mimicking the underlying distributions of real-world data presents a compelling solution. This work introduces Financial Tabular Diffusion (FinDiff), a diffusion model designed to generate real-world mixed-type financial tabular data for a variety of downstream tasks, for example, economic scenario modeling, stress tests, and fraud detection. The model uses embedding encodings to model mixed modality financial data, comprising both categorical and numeric attributes. The performance of FinDiff in generating synthetic tabular financial data is evaluated against state-of-the-art baseline models using three real-world financial datasets (including two publicly available datasets and one proprietary dataset). Empirical results demonstrate that FinDiff excels in generating synthetic tabular financial data with high fidelity, privacy, and utility.;2023;Not health related;Not health related
"Skondras, P; Zervas, P; Tzimas, G";Generating Synthetic Resume Data with Large Language Models for Enhanced Job Description Classification;In this article, we investigate the potential of synthetic resumes as a means for the rapid generation of training data and their effectiveness in data augmentation, especially in categories marked by sparse samples. The widespread implementation of machine learning algorithms in natural language processing (NLP) has notably streamlined the resume classification process, delivering time and cost efficiencies for hiring organizations. However, the performance of these algorithms depends on the abundance of training data. While selecting the right model architecture is essential, it is also crucial to ensure the availability of a robust, well-curated dataset. For many categories in the job market, data sparsity remains a challenge. To deal with this challenge, we employed the OpenAI API to generate both structured and unstructured resumes tailored to specific criteria. These synthetically generated resumes were cleaned, preprocessed and then utilized to train two distinct models: a transformer model (BERT) and a feedforward neural network (FFNN) that incorporated Universal Sentence Encoder 4 (USE4) embeddings. While both models were evaluated on the multiclass classification task of resumes, when trained on an augmented dataset containing 60 percent real data (from Indeed website) and 40 percent synthetic data from ChatGPT, the transformer model presented exceptional accuracy. The FFNN, albeit predictably, achieved lower accuracy. These findings highlight the value of augmented real-world data with ChatGPT-generated synthetic resumes, especially in the context of limited training data. The suitability of the BERT model for such classification tasks further reinforces this narrative.;2023;Not health related;Not health related
"Hoyer, L; Dai, DX; Van Gool, L";DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation;As acquiring pixel-wise annotations of real-world images for semantic segmentation is a costly process, a model can instead be trained with more accessible synthetic data and adapted to real images without requiring their annotations. This process is studied in unsupervised domain adaptation (UDA). Even though a large number of methods propose new adaptation strategies, they are mostly based on outdated network architectures. As the influence of recent network architectures has not been systematically studied, we first benchmark different network architectures for UDA and newly reveal the potential of Transformers for UDA semantic segmentation. Based on the findings, we propose a novel UDA method, DAFormer. The network architecture of DAFormer consists of a Transformer encoder and a multilevel context-aware feature fusion decoder. It is enabled by three simple but crucial training strategies to stabilize the training and to avoid overfitting to the source domain: While (1) Rare Class Sampling on the source domain improves the quality of the pseudo-labels by mitigating the confirmation bias of self-training toward common classes, (2) a Thing-Class ImageNet Feature Distance and (3) a learning rate warmup promote feature transfer from ImageNet pretraining. DAFormer represents a major advance in UDA. It improves the state of the art by 10.8 mIoU for GTA -> Cityscapes and 5.4 mIoU for Synthia -> Cityscapes and enables learning even difficult classes such as train, bus, and truck well. The implementation is available at https://github.com/lhoyer/DAFormer.;2022;Not health related;Not health related
"Wang, LS; Wu, ZL; Zhong, Y; Yuan, X";Snapshot spectral compressive imaging reconstruction using convolution and contextual Transformer;Spectral compressive imaging (SCI) is able to encode a high-dimensional hyperspectral image into a two-dimensional snapshot measurement, and then use algorithms to reconstruct the spatio-spectral data-cube. At present, the main bottleneck of SCI is the reconstruction algorithm, and state-of-the-art (SOTA) reconstruction methods generally face problems of long reconstruction times and/or poor detail recovery. In this paper, we propose a hybrid network module, namely, a convolution and contextual Transformer (CCoT) block, that can simultaneously acquire the inductive bias ability of convolution and the powerful modeling ability of Transformer, which is conducive to improving the quality of reconstruction to restore fine details. We integrate the proposed CCoT block into a physics-driven deep unfolding framework based on the generalized alternating projection (GAP) algorithm, and further propose the GAP-CCoT network. Finally, we apply the GAP-CCoT algorithm to SCI reconstruction. Through experiments on a large amount of synthetic data and real data, our proposed model achieves higher reconstruction quality (>2 dB in peak signal-to-noise ratio on simulated benchmark datasets) and a shorter running time than existing SOTA algorithms by a large margin. The code and models are publicly available at https://github.com/ucaswangls/GAP-CCoT. (C) 2022 Chinese Laser Press;2022;Not health related;Not health related
"Ferreira, AD; Junior, JM; Pistori, H; Melgani, F; Gonçalves, WN";Unsupervised domain adaptation using transformers for sugarcane rows and gaps detection;Deep learning represented an impressive advance in the field of machine learning and is continually breaking records in dozens of areas of artificial intelligence, such as image recognition. Nevertheless, the success of these architectures depends on a large amount of labeled data and the annotation of training data is a costly process that is often performed manually. The cost of labeling and the difficulty of generalizing the model knowledge to unseen data poses an obstacle to the use of these techniques in real-world agricultural challenges. In this work, we propose an approach to deal with this problem when detecting crop rows and gaps and our findings can be extended to other problems related with few modifications. Our approach proposes to generate approximated segmentation maps from annotated one-pixel-wide lines using dilation. This method speeds up the pixel labeling process and reduces the line detection problem to semantic segmentation. We considered the transformer-based method, SegFormer, and compared it with ConvNet segmentation models, PSPNet and DeepLabV3+, on datasets containing aerial images of four different sugarcane farms. To evaluate the ability to transfer the knowledge learned from source datasets to target datasets, we used a very recent and current state-of-the-state unsupervised domain adaptation (UDA) model, DAFormer, which has achieved great results in adapting knowledge from synthetic data to real data. In this work, we were able to evaluate its performance using only real-world images from different but related domains. Even without using domain adaptation, the Transformer-based model, SegFormer, performed significantly better than ConvNets for unseen data, but when applying UDA using DAFormer, the results were even better, reaching from 71.1% to 94.5% relative performance regarding the average F1-score achieved when using supervised training with labeled data.;2022;Not health related;Not health related
"Hou, YB; Kang, B; Mitchell, A; Wang, WW; Kang, J; Botteldooren, D";Cooperative Scene-Event Modelling for Acoustic Scene Classification;Acoustic scene classification (ASC) can be helpful for creating context awareness for intelligent robots. Humans naturally use the relations between acoustic scenes (AS) and audio events (AE) to understand and recognize their surrounding environments. However, in most previous works, ASC and audio event classification (AEC) are treated as independent tasks, with a focus primarily on audio features shared between scenes and events, but not their implicit relations. To address this limitation, we propose a cooperative scene-event modelling (cSEM) framework to automatically model the intricate scene-event relation by an adaptive coupling matrix to improve ASC. Compared with other scene-event modelling frameworks, the proposed cSEM offers the following advantages. First, it reduces the confusion between similar scenes by aligning the information of coarse-grained AS and fine-grained AE in the latent space, and reducing the redundant information between the AS and AE embeddings. Second, it exploits the relation information between AS and AE to improve ASC, which is shown to be beneficial, even if the information of AE is derived from unverified pseudo-labels. Third, it uses a regression-based loss function for cooperative modelling of scene-event relations, which is shown to be more effective than classification-based loss functions. Instantiated from four models based on either Transformer or convolutional neural networks, cSEM is evaluated on real-life and synthetic datasets. Experiments show that cSEM-based models work well in real-life scene-event analysis, offering competitive results on ASC as compared with other multi-feature or multi-model ensemble methods. The ASC accuracy achieved on the TUT2018, TAU2019, and JSSED datasets is 81.0%, 88.9% and 97.2%, respectively.;2024;Not health related;Not health related
"Fu, Y; Wang, ZC; Zhang, T; Zhang, J";Low-Light Raw Video Denoising With a High-Quality Realistic Motion Dataset;Recently, supervised deep-learning methods have shown their effectiveness on raw video denoising in low-light. However, existing training datasets have specific drawbacks, e.g., inaccurate noise modeling in synthetic datasets, simple motion created by hand or fixed motion, and limited-quality ground truth caused by the beam splitter in real captured datasets. These defects significantly decline the performance of network when tackling real low-light video sequences, where noise distribution and motion patterns are extremely complex. In this paper, we collect a raw video denoising dataset in low-light with complex motion and high-quality ground truth, overcoming the drawbacks of previous datasets. Specifically, we capture 210 paired videos, each containing short/long exposure pairs of real video frames with dynamic objects and diverse scenes displayed on a high-end monitor. Besides, since spatial self-similarity has been extensively utilized in image tasks, harnessing this property for network design is more crucial for video denoising as temporal redundancy. To effectively exploit the intrinsic temporal-spatial self-similarity of complex motion in real videos, we propose a new Transformer-based network, which can effectively combine the locality of convolution with the long-range modeling ability of 3D temporal-spatial self-attention. Extensive experiments verify the value of our dataset and the effectiveness of our method on various metrics.;2023;Not health related;Not health related
"Wiles, O; Zisserman, A";Learning to Predict 3D Surfaces of Sculptures from Single and Multiple Views;"The objective of this work is to reconstruct the 3D surfaces of sculptures from one or more images using a view-dependent representation. To this end, we train a network, SiDeNet, to predict the Silhouette and Depth of the surface given a variable number of images; the silhouette is predicted at a different viewpoint from the inputs (e.g. from the side), while the depth is predicted at the viewpoint of the input images. This has three benefits. First, the network learns a representation of shape beyond that of a single viewpoint, as the silhouette forces it to respect the visual hull, and the depth image forces it to predict concavities (which don't appear on the visual hull). Second, as the network learns about 3D using the proxy tasks of predicting depth and silhouette images, it is not limited by the resolution of the 3D representation. Finally, using a view-dependent representation (e.g. additionally encoding the viewpoint with the input image) improves the network's generalisability to unseen objects. Additionally, the network is able to handle the input views in a flexible manner. First, it can ingest a different number of views during training and testing, and it is shown that the reconstruction performance improves as additional views are added at test-time. Second, the additional views do not need to be photometrically consistent. The network is trained and evaluated on two synthetic datasets-a realistic sculpture dataset (SketchFab), and ShapeNet. The design of the network is validated by comparing to state of the art methods for a set of tasks. It is shown that (i) passing the input viewpoint (i.e. using a view-dependent representation) improves the network's generalisability at test time. (ii) Predicting depth/silhouette images allows for higher quality predictions in 2D, as the network is not limited by the chosen latent 3D representation. (iii) On both datasets the method of combining views in a global manner performs better than a local method. Finally, we show that the trained network generalizes to real images, and probe how the network has encoded the latent 3D shape.";2019;Not health related;Not health related
"Zhou, YL; Ma, XY; Wu, DP; Li, XL";Communication-Efficient and Attack-Resistant Federated Edge Learning With Dataset Distillation;Federated Edge Learning considers a large amount of distributed edge nodes collectively train a global gradient-based model for edge computing in the Artificial Internet of Things, which significantly promotes the development of cloud computing. However, current federated learning algorithms take tens of communication rounds transmitting unwieldy model weights under ideal circumstances and hundreds when data is poorly distributed. This drawback directly results in expensive communication overhead for edge devices. Inspired by recent work on dataset distillation and distributed one-shot learning, we propose Distilled One-Shot Federated Learning (DOSFL) to significantly reduce the communication cost while achieving comparable performance. In just one round, each client distills their private dataset, sends the synthetic data to the server, and collectively trains a global model. The distilled data look like noise and are only useful to the specific model weights, i.e., become useless after the model updates. With this weight-less and gradient-less design, the total communication cost of DOSFL is up to three orders of magnitude less than FedAvg while preserving up to 99% performance of centralized training on both vision and language tasks with different models including CNN, LSTM, Transformer, etc. We demonstrate that an eavesdropping attacker cannot properly train a good model using the leaked distilled data, without knowing the initial model weights. DOSFL serves as an inexpensive method to quickly converge on a performant pre-trained model with less than 0.1% communication cost of traditional methods.;2023;Not health related;Not health related
"Shaikh, S; Daudpota, SM; Imran, AS; Kastrati, Z";Towards Improved Classification Accuracy on Highly Imbalanced Text Dataset Using Deep Neural Language Models;Data imbalance is a frequently occurring problem in classification tasks where the number of samples in one category exceeds the amount in others. Quite often, the minority class data is of great importance representing concepts of interest and is often challenging to obtain in real-life scenarios and applications. Imagine a customers' dataset for bank loans-majority of the instances belong to non-defaulter class, only a small number of customers would be labeled as defaulters, however, the performance accuracy is more important on defaulters labels than non-defaulter in such highly imbalance datasets. Lack of enough data samples across all the class labels results in data imbalance causing poor classification performance while training the model. Synthetic data generation and oversampling techniques such as SMOTE, AdaSyn can address this issue for statistical data, yet such methods suffer from overfitting and substantial noise. While such techniques have proved useful for synthetic numerical and image data generation using GANs, the effectiveness of approaches proposed for textual data, which can retain grammatical structure, context, and semantic information, has yet to be evaluated. In this paper, we address this issue by assessing text sequence generation algorithms coupled with grammatical validation on domain-specific highly imbalanced datasets for text classification. We exploit recently proposed GPT-2 and LSTM-based text generation models to introduce balance in highly imbalanced text datasets. The experiments presented in this paper on three highly imbalanced datasets from different domains show that the performance of same deep neural network models improve up to 17% when datasets are balanced using generated text.;2021;Not health related;Not health related
"Lv, JX; Zhang, L; Xu, JJ; Li, W; Li, G; Zhou, HY";Automatic segmentation of mandibular canal using transformer based neural networks;Accurate 3D localization of the mandibular canal is crucial for the success of digitally-assisted dental surgeries. Damage to the mandibular canal may result in severe consequences for the patient, including acute pain, numbness, or even facial paralysis. As such, the development of a fast, stable, and highly precise method for mandibular canal segmentation is paramount for enhancing the success rate of dental surgical procedures. Nonetheless, the task of mandibular canal segmentation is fraught with challenges, including a severe imbalance between positive and negative samples and indistinct boundaries, which often compromise the completeness of existing segmentation methods. To surmount these challenges, we propose an innovative, fully automated segmentation approach for the mandibular canal. Our methodology employs a Transformer architecture in conjunction with cl-Dice loss to ensure that the model concentrates on the connectivity of the mandibular canal. Additionally, we introduce a pixel-level feature fusion technique to bolster the model's sensitivity to fine-grained details of the canal structure. To tackle the issue of sample imbalance and vague boundaries, we implement a strategy founded on mandibular foramen localization to isolate the maximally connected domain of the mandibular canal. Furthermore, a contrast enhancement technique is employed for pre-processing the raw data. We also adopt a Deep Label Fusion strategy for pre-training on synthetic datasets, which substantially elevates the model's performance. Empirical evaluations on a publicly accessible mandibular canal dataset reveal superior performance metrics: a Dice score of 0.844, click score of 0.961, IoU of 0.731, and HD95 of 2.947 mm. These results not only validate the efficacy of our approach but also establish its state-of-the-art performance on the public mandibular canal dataset.;2023;Health related;Health related
"Duan, YX; Xu, X; Li, T; Pan, B; Shi, ZW";UnDAT: Double-Aware Transformer for Hyperspectral Unmixing;Deep-learning-based methods have attracted increasing attention on hyperspectral unmixing, where the transformer models have shown promising performance. However, recently proposed deep-learning-based hyperspectral unmixing methods usually tend to directly apply visual models, while ignoring the characteristics of hyperspectral imagery. In this article, we propose a novel double-aware transformer for hyperspectral Unmixing (UnDAT), which aims at simultaneously exploiting the region homogeneity and spectral correlation of hyperspectral imagery. One of the major assumptions of UnDAT is that hyperspectral remote-sensing images involve many homogeneous regions. Pixels inside a homogeneous region usually present similar spectral features, and the edge pixels are just the reverse. Another observation is that the pixel spectra are continuous and correlated. Based on the above assumption and observation, we construct the UnDAT by developing two modules: Score-based homogeneous-aware (SHA) module and the spectral group-aware (SGA) module. In the SHA module, a feature map rearrangement (FMR) approach is proposed to split the shallow feature maps from a linear encoder into an ordered homogeneous map (HomoMap) and an edge map and develop a homogenous region-aware strategy for deep feature representation. In the SGA module, the dependency among neighboring bands is described by dividing the hyperspectral image into multiple spectral groups and calculating the spectral similarity among bands within each group. Experiments on both real and synthetic datasets indicate the effectiveness of our model. We will publish the code of our approach if the article has the honor to be accepted.;2023;Not health related;Not health related
"Li, YY; Alkhalifah, T; Huang, JP; Li, ZC";Self-Supervised Pretraining Vision Transformer With Masked Autoencoders for Building Subsurface Model;Building subsurface models is a very important but challenging task in hydrocarbon exploration and development. The subsurface elastic properties are usually sourced from seismic data and well logs. Thus, we design a deep learning (DL) framework using vision transformer (ViT) as the backbone architecture to build the subsurface model using well log information as we apply full waveform inversion (FWI) on the seismic data. However, training a ViT network from scratch with limited well log data can be difficult to achieve good generalization. To overcome this, we implement an efficient self-supervised pretraining process using a masked autoencoder (MAE) architecture to learn important feature representations in seismic volumes. The seismic volumes required by the pretraining are randomly extracted from a seismic inversion, such as an FWI result. We can also incorporate reverse time migration (RTM) image into the seismic volumes to provide additional structure information. The pretraining task of MAE is to reconstruct the original image from the masked image with a masking ratio of 75%. This pretraining task enables the network to learn the high-level latent representations. After the pretraining process, we then fine-tune the ViT network to build the optimal mapping relationship between 2-D seismic volumes and 1-D well segments. Once the fine-tuning process is finished, we apply the trained ViT network to the whole seismic inversion domain to predict the subsurface model. At last, we use one synthetic dataset and two field datasets to test the performance of the proposed method. The test results demonstrate that the proposed method effectively integrates seismic and well information to improve the resolution and accuracy of the velocity model.;2023;Not health related;Not health related
"Kang, PQ; Jiang, S; Shull, PB";Synthetic EMG Based on Adversarial Style Transfer Can Effectively Attack Biometric-Based Personal Identification Models;"Biometric-based personal identification models are generally considered to be accurate and secure because biological signals are too complex and person-specific to be fabricated, and EMG signals, in particular, have been used as biological identification tokens due to their high dimension and non-linearity. We investigate the possibility of effectively attacking EMG-based identification models with adversarial biological input via a novel EMG signal individual-style transformer based on a generative adversarial network and tiny leaked data segments. Since two same EMG segments do not exist in nature; the leaked data can't be used to attack the model directly or it will be easily detected. Therefore, it is necessary to extract the style with the leaked personal signals and generate the attack signals with different contents. With our proposed method and tiny leaked personal EMG fragments, numerous EMG signals with different content can be generated in that person's style. EMG hand gesture data from eighteen subjects and three well-recognized deep EMG classifiers were used to demonstrate the effectiveness of the proposed attack methods. The proposed methods achieved an average of 99.41% success rate on confusing identification models and an average of 91.51% success rate on manipulating identification models. These results demonstrate that EMG classifiers based on deep neural networks can be vulnerable to synthetic data attacks. The proof-of-concept results reveal that synthetic EMG biological signals must be considered in biological identification system design across a vast array of relevant biometric systems to ensure personal identification security for individuals and institutions.";2023;Not health related;Not health related
"Chen, L; Sima, CH; Li, Y; Zheng, ZH; Xu, JJ; Geng, XW; Li, HY; He, CH; Shi, JP; Qiao, Y; Yan, JC";PersFormer: 3D Lane Detection via Perspective Transformer and the OpenLane Benchmark;Methods for 3D lane detection have been recently proposed to address the issue of inaccurate lane layouts in many autonomous driving scenarios (uphill/downhill, bump, etc.). Previous work struggled in complex cases due to their simple designs of the spatial transformation between front view and bird's eye view (BEV) and the lack of a realistic dataset. Towards these issues, we present PersFormer: an end-to-end monocular 3D lane detector with a novel Transformer-based spatial feature transformation module. Our model generates BEV features by attending to related front-view local regions with camera parameters as a reference. PersFormer adopts a unified 2D/3D anchor design and an auxiliary task to detect 2D/3D lanes simultaneously, enhancing the feature consistency and sharing the benefits of multi-task learning. Moreover, we release one of the first large-scale real-world 3D lane datasets: OpenLane, with high-quality annotation and scenario diversity. OpenLane contains 200,000 frames, over 880,000 instance-level lanes, 14 lane categories, along with scene tags and the closed-in-path object annotations to encourage the development of lane detection and more industrial-related autonomous driving methods. We show that PersFormer significantly outperforms competitive baselines in the 3D lane detection task on our new OpenLane dataset as well as Apollo 3D Lane Synthetic dataset, and is also on par with state-of-the-art algorithms in the 2D task on OpenLane. The project page is available at https://github.com/OpenPerceptionX/PersFormer_3DLane and OpenLane dataset is provided at https://github.com/OpenPerceptionX/OpenLane.;2022;Not health related;Not health related
"Buoy, R; Iwamura, M; Srun, S; Kise, K";Toward a Low-Resource Non-Latin-Complete Baseline: An Exploration of Khmer Optical Character Recognition;Many existing text recognition methods rely on the structure of Latin characters and words. Such methods may not be able to deal with non-Latin scripts that have highly complex features, such as character stacking, diacritics, ligatures, non-uniform character widths, and writing without explicit word boundaries. In addition, from a natural language processing (NLP) perspective, most non-Latin languages are considered low-resource due to the scarcity of large-scale data. This paper presents a convolutional Transformer-based text recognition method for low-resource non-Latin scripts, which uses local two-dimensional (2D) feature maps. The proposed method can handle images of arbitrarily long textlines, which may occur with non-Latin writing without explicit word boundaries, without resizing them to a fixed size by using an improved image chunking and merging strategy. It has a low time complexity in self-attention layers and allows efficient training. The Khmer script is used as the representative of non-Latin scripts because it shares many features with other non-Latin scripts, which makes the construction of an optical character recognition (OCR) method for Khmer as hard as that for other non-Latin scripts. Thus, by analogy with the AI-complete concept, a Khmer OCR method can be considered as one of the non-Latin-complete methods and can be used as a low-resource non-Latin baseline method. The proposed 2D method was trained on synthetic datasets and outperformed the baseline models on both synthetic and real datasets. Fine-tuning experiments using Khmer handwritten palm leaf manuscripts and other non-Latin scripts demonstrated the feasibility of transfer learning from the Khmer OCR method. To contribute to the low-resource language community, the training and evaluation datasets will be made publicly available.;2023;Not health related;Not health related
"Dai, M; Zheng, EH; Feng, ZH; Qi, L; Zhuang, JD; Yang, WK";Vision-Based UAV Self-Positioning in Low-Altitude Urban Environments;Unmanned Aerial Vehicles (UAVs) rely on satellite systems for stable positioning. However, due to limited satellite coverage or communication disruptions, UAVs may lose signals for positioning. In such situations, vision-based techniques can serve as an alternative, ensuring the self-positioning capability of UAVs. However, most of the existing datasets are developed for the geo-localization task of the objects captured by UAVs, rather than UAV self-positioning. Furthermore, the existing UAV datasets apply discrete sampling to synthetic data, such as Google Maps, neglecting the crucial aspects of dense sampling and the uncertainties commonly experienced in practical scenarios. To address these issues, this paper presents a new dataset, DenseUAV, that is the first publicly available dataset tailored for the UAV self-positioning task. DenseUAV adopts dense sampling on UAV images obtained in low-altitude urban areas. In total, over 27K UAV- and satellite-view images of 14 university campuses are collected and annotated. In terms of methodology, we first verify the superiority of Transformers over CNNs for the proposed task. Then we incorporate metric learning into representation learning to enhance the model's discriminative capacity and to reduce the modality discrepancy. Besides, to facilitate joint learning from both the satellite and UAV views, we introduce a mutually supervised learning approach. Last, we enhance the Recall@K metric and introduce a new measurement, SDM@K, to evaluate both the retrieval and localization performance for the proposed task. As a result, the proposed baseline method achieves a remarkable Recall@1 score of 83.01% and an SDM@1 score of 86.50% on DenseUAV. The dataset and code have been made publicly available on https://github.com/Dmmm1997/DenseUAV.;2024;Not health related;Not health related
"Khalitov, R; Yu, T; Cheng, L";Sparse factorization of square matrices with application to neural attention modeling;Square matrices appear in many machine learning problems and models. Optimization over a large square matrix is expensive in memory and in time. Therefore an economic approximation is needed. Conventional approximation approaches factorize the square matrix into a number matrices of much lower ranks. However, the low-rank constraint is a performance bottleneck if the approximated matrix is intrinsically high-rank or close to full rank. In this paper, we propose to approximate a large square matrix with a product of sparse full-rank matrices. In the approximation, our method needs only N(log N)(2) non-zero numbers for an N x N full matrix. Our new method is especially useful for scalable neural attention modeling. Different from the conventional scaled dot-product attention methods, we train neural networks to map input data to the non-zero entries of the factorizing matrices. The sparse factorization method is tested for various square matrices, and the experimental results demonstrate that our method gives a better approximation when the approximated matrix is sparse and high rank. As an attention module, our new method defeats Transformer and its several variants for long sequences in synthetic data sets and in the Long Range Arena benchmarks. Our code is publicly available(2). (C) 2022 The Author(s) .Published by Elsevier Ltd.;2022;Not health related;Not health related
"Hu, AT; Xie, RJ; Lu, ZG; Hu, AQ; Xue, MH";TableGAN-MCA: Evaluating Membership Collisions of GAN-Synthesized Tabular Data Releasing;Generative Adversarial Networks (GAN)-synthesized table publishing lets people privately learn insights without access to the private table. However, existing studies on Membership Inference (MI) Attacks show promising results on disclosing membership of training datasets of GAN-synthesized tables. Different from those works focusing on discovering membership of a given data point, in this paper, we propose a novel Membership Collision Attack against GANs (TableGAN-MCA), which allows an adversary given only synthetic entries randomly sampled from a black-box generator to recover partial GAN training data. Namely, a GAN-synthesized table immune to state-of-the-art MI attacks is vulnerable to the TableGAN-MCA. The success of TableGAN-MCA is boosted by an observation that GAN-synthesized tables potentially collide with the training data of the generator. Our experimental evaluations on TableGAN-MCA have five main findings. First, Tab/eGAN-MCA has a satisfying training data recovery rate on three commonly used real-world datasets against four generative models. Second, factors, including the size of GAN training data, GAN training epochs and the number of synthetic samples available to the adversary, are positively correlated to the success of TableGAN-MCA. Third, highly frequent data points have high risks of being recovered by TableGAN-MCA. Fourth, some unique data are exposed to unexpected high recovery risks in TableGAN-MCA, which may attribute to GAN's generalization. Fifth, as expected, differential privacy, without the consideration of the correlations between features, does not show commendable mitigation effect against the TableGAN-MCA. Finally, we propose two mitigation methods and show promising privacy and utility trade-offs when protecting against TableGAN-MCA.;2021;Not health related;Not health related
"Ferede, FA; Balasubramanian, M";SSTM: Spatiotemporal recurrent transformers for multi-frame optical flow estimation;Inaccurate optical flow estimates in and near occluded regions, and out-of-boundary regions are two of the current significant limitations of optical flow estimation algorithms. Recent state-of-the-art optical flow estimation algorithms are two-frame based methods where optical flow is estimated sequentially for each consecutive image pair in a sequence. While this approach gives good flow estimates, it fails to generalize optical flows in occluded regions mainly due to limited local evidence regarding moving elements in a scene. In this work, we propose a learning-based multi-frame optical flow estimation method that estimates two or more consecutive optical flows in parallel from multi-frame image sequences. Our underlying hypothesis is that by understanding temporal scene dynamics from longer sequences with more than two frames, we can characterize pixel-wise dependencies in a larger spatiotemporal domain, generalize complex motion patterns and thereby improve the accuracy of optical flow estimates in occluded regions. We present learning -based spatiotemporal recurrent transformers for multi-frame based optical flow estimation (SSTMs). Our method utilizes 3D Convolutional Gated Recurrent Units (3D-ConvGRUs) and spatiotemporal transformers to learn recurrent space-time motion dynamics and global dependencies in the scene and provide a generalized optical flow estimation. When compared with recent state-of-the-art two-frame and multi-frame methods on real world and synthetic datasets, performance of the SSTMs were significantly higher in occluded and out-of-boundary regions. Among all published state-of-the-art multi-frame methods, SSTM achieved state-of the-art results on the Sintel Final and KITTI2015 benchmark datasets. Software code, data and instructions: https://github.com/Computational-Ocularscience/SSTM.;2023;Not health related;Not health related
"Han, Y; Nanda, G; Moghaddam, M";Attribute-Sentiment-Guided Summarization of User Opinions From Online Reviews;Eliciting informative user opinions from online reviews is a key success factor for innovative product design and development. The unstructured, noisy, and verbose nature of user reviews, however, often complicate large-scale need finding in a format useful for designers without losing important information. Recent advances in abstractive text summarization have created the opportunity to systematically generate opinion summaries from online reviews to inform the early stages of product design and development. However, two knowledge gaps hinder the applicability of opinion summarization methods in practice. First, there is a lack of formal mechanisms to guide the generative process with respect to different categories of product attributes and user sentiments. Second, the annotated training datasets needed for supervised training of abstractive summarization models are often difficult and costly to create. This article addresses these gaps by (1) devising an efficient computational framework for abstractive opinion summarization guided by specific product attributes and sentiment polarities, and (2) automatically generating a synthetic training dataset that captures various degrees of granularity and polarity. A hierarchical multi-instance attribute-sentiment inference model is developed for assembling a high-quality synthetic dataset, which is utilized to fine-tune a pretrained language model for abstractive summary generation. Numerical experiments conducted on a large dataset scraped from three major e-Commerce retail stores for apparel and footwear products indicate the performance, feasibility, and potentials of the developed framework. Several directions are provided for future exploration in the area of automated opinion summarization for user-centered design.;2023;Not health related;Not health related
"Buoy, R; Iwamura, M; Srun, S; Kise, K; Pratikakis, I";Explainable Connectionist-Temporal-Classification-Based Scene Text Recognition;Connectionist temporal classification (CTC) is a favored decoder in scene text recognition (STR) for its simplicity and efficiency. However, most CTC-based methods utilize one-dimensional (1D) vector sequences, usually derived from a recurrent neural network (RNN) encoder. This results in the absence of explainable 2D spatial relationship between the predicted characters and corresponding image regions, essential for model explainability. On the other hand, 2D attention-based methods enhance recognition accuracy and offer character location information via cross-attention mechanisms, linking predictions to image regions. However, these methods are more computationally intensive, compared with the 1D CTC-based methods. To achieve both low latency and model explainability via character localization using a 1D CTC decoder, we propose a marginalization-based method that processes 2D feature maps and predicts a sequence of 2D joint probability distributions over the height and class dimensions. Based on the proposed method, we newly introduce an association map that aids in character localization and model prediction explanation. This map parallels the role of a cross-attention map, as seen in computationally-intensive attention-based architectures. With the proposed method, we consider a ViT-CTC STR architecture that uses a 1D CTC decoder and a pretrained vision Transformer (ViT) as a 2D feature extractor. Our ViT-CTC models were trained on synthetic data and fine-tuned on real labeled sets. These models outperform the recent state-of-the-art (SOTA) CTC-based methods on benchmarks in terms of recognition accuracy. Compared with the baseline Transformer-decoder-based models, our ViT-CTC models offer a speed boost up to 12 times regardless of the backbone, with a maximum 3.1% reduction in total word recognition accuracy. In addition, both qualitative and quantitative assessments of character locations estimated from the association map align closely with those from the cross-attention map and ground-truth character-level bounding boxes.;2023;Not health related;Not health related
"Hamdan, M; Chaudhary, H; Bali, A; Cheriet, M";Refocus attention span networks for handwriting line recognition;Recurrent neural networks have achieved outstanding recognition performance for handwriting identification despite the enormous variety observed across diverse handwriting structures and poor-quality scanned documents. We initially proposed a BiLSTM baseline model with a sequential architecture well-suited for modeling text lines due to its ability to learn probability distributions over character or word sequences. However, employing such recurrent paradigms prevents parallelization and suffers from vanishing gradients for long sequences during training. To alleviate these limitations, we propose four significant contributions to this work. First, we devised an end-to-end model composed of a split-attention CNN-backbone that serves as a feature extraction method and a self-attention Transformer encoder-decoder that serves as a transcriber method to recognize handwriting manuscripts. The multi-head self-attention layers in an encoder-decoder transformer-based enhance the model's ability to tackle handwriting recognition and learn the linguistic dependencies of character sequences. Second, we conduct various studies on transfer learning (TL) from large datasets to a small database, determining which model layers require fine-tuning. Third, we attained an efficient paradigm by combining different strategies of TL with data augmentation (DA). Finally, since the robustness of the proposed model is lexicon-free and can recognize sentences not presented in the training phase, the model is only trained on a few labeled examples with no extra cost of generating and training on synthetic datasets. We recorded comparable and outperformed Character and Word Error Rates CER/WER on four benchmark datasets to the most recent (SOTA) models.;2023;Not health related;Not health related
"Makrushin, A; Uhl, A; Dittmann, J";A Survey on Synthetic Biometrics: Fingerprint, Face, Iris and Vascular Patterns;Synthetic biometric samples are created with an ultimate goal of getting around privacy concerns, mitigating biases in biometric datasets, and reducing the sample acquisition effort to enable large-scale evaluations. The recent breakthrough in the development of neural generative models shifted the focus from image synthesis by mathematical modeling of biometric modalities to data-driven image generation. This paradigm shift on the one hand greatly improves the realism of synthetic biometric samples and therefore enables new use cases, but on the other hand new challenges and concerns arise. Despite their realism, synthetic samples have to be checked for appropriateness for the tasks they are intended which includes new quality metrics. Focusing on sample images of fingerprint, face, iris and vascular patterns, we highlight the benefits of using synthetic samples, review the use cases, and summarize and categorize the most prominent studies on synthetic biometrics aiming at showing recent progress and the direction of future research.;2023;Not health related;Not health related
"Severoglu, N; Salor, Ö";Statistical Models of EAF Harmonics Developed for Harmonic Estimation Directly From Waveform Samples Using Deep Learning Framework;In this research work, a deep learning (DL)-based method for the fast and accurate analysis of current harmonics of electric arc furnaces (EAF) is proposed. For such a system, a large amount of EAF current data is required for the training phase of the DL-based structure, which is not only a thorny but also an expensive procedure. Hence, the second focus of this research work is to gain the ability to generate EAF currents with realistic harmonic contents based on a much smaller amount of field data of EAF currents. For this purpose, EAF current data, recorded at a transformer substation supplying an EAF plant during a tap-to-tap time of the EAF operation, are examined in terms of harmonic component amplitudes and phases. Then, a significantly larger amount of EAF current data is regenerated based on the statistics of current harmonics mimicking the real EAF behavior and this synthetic data are used to train the DL-based harmonic estimator. This estimator is able to estimate both amplitudes and phases of the harmonics without computing any time- or frequency-domain features during the estimation process. Hence, the outcomes of this research work are twofold: First, detailed analysis of the EAF current harmonic behavior is achieved, which reveals the operation principles of the EAF. Second, a DL-based harmonic estimator is trained, which is able to output the amplitude and phase estimations directly out of waveform samples without any feature extraction. The proposed system aims to serve the needs of active power filters of the EAF installations in the electricity system, since it has been shown that fast and accurate harmonic amplitude and phase estimations are obtained.;2021;Not health related;Not health related
"Liu, W; Wang, H; Xi, ZZ; Wang, L";Physics-Informed Deep Learning Inversion with Application to Noisy Magnetotelluric Measurements;"Despite demonstrating exceptional inversion production for synthetic data, the application of deep learning (DL) inversion methods to invert realistic magnetotelluric (MT) measurements, which are inevitably contaminated by noise in acquisition, poses a significant challenge. Hence, to facilitate DL inversion for realistic MT measurements, this work explores developing a noise-robust MT DL inversion method by generating targeted noisy training datasets and constructing a physics-informed neural network. Different from most previous works that only considered the noise of one fixed distribution and level, we propose three noise injection strategies and compare their combinations to mitigate the adverse effect of measurement noise on MT DL inversion results: (1) add synthetic relative noise obeying Gaussian distribution; (2) propose a multiwindow Savitzky-Golay (MWSG) filtering scheme to extract potential and possible noise from the target field data and then introduce them into training data; (3) create an augmented training dataset based on the former two strategies. Moreover, we employ the powerful Swin Transformer as the backbone network to construct a U-shaped DL model (SwinTUNet), based on which a physics-informed SwinTUNet (PISwinTUNet) is implemented to further enhance its generalization ability. In synthetic examples, the proposed noise injection strategies demonstrate impressive inversion effects, regardless of whether they are contaminated by familiar or unfamiliar noise. In a field example, the combination of three strategies drives PISwinTUNet to produce considerably faithful reconstructions for subsurface resistivity structures and outperform the classical deterministic Occam inversions. The experimental results show that the proposed noise-robust DL inversion method based on the noise injection strategies and physics-informed DL architecture holds great promise in processing MT field data.";2024;Not health related;Not health related
"Üstündag, A; Zahn, M";Finite element based Kerr electro-optic reconstruction of space charge;Recently we used the onion peeling method to reconstruct the axisymmetric electric field distribution of point/plane electrodes from Kerr electro-optic measurements. The method accurately reconstructed the electric field from numerically generated data. However in the presence of experimental noise the performance was less satisfactory. The measurements were especially noisy and unstable near the needle tip which is also the interesting region since most charge injection initiates here. We develop a new algorithm for Kerr electro-optic reconstruction of space charge in axisymmetric point/plane electrode geometries, The algorithm is built on the finite element method (FEM) for Poisson's equation and will be called finite element based Kerr electro-optic reconstruction (FEBKER) hereafter. FEBKER calculates the space charge density directly to avoid the numerical problems associated with taking the divergence of the electric field, uses single parameter light intensity measurements to enable transient analysis, which otherwise is difficult since multiple parameter intensity measurements are slow due to the rotation of polarizers, and is capable of reconstruction even when the number and/or position of measurements are limited by the electrodes and/or the experimental setup, The performance of the algorithm is tested on synthetic Kerr electro-optic data obtained for an axisymmetric point/plane electrode geometry in transformer oil with specified space charge density distributions. The impact of experimental error is analyzed by incorporating random error to the synthetic data. Regularization techniques that decrease the impact of experimental error are applied. In principle FEBKER is applicable to arbitrary three-dimensional geometries as well.;2001;Not health related;Not health related
"Li, WS; Ma, PF; Wang, HP; Fang, CY";SAR-TSCC: A Novel Approach for Long Time Series SAR Image Change Detection and Pattern Analysis;Change detection has played an increasingly important role in multitemporal remote sensing applications recently. Long time series analysis is providing new information of land cover changes and improving the quality and accuracy of the change information being derived from remote sensing. The purpose of this study is to dig for more change temporal information and change pattern information from synthetic aperture radar (SAR) image time series (ITS), which is of great significance for monitoring urban area changes, conducting land use surveys, and renovating illegal constructions. In the study, a novel unified framework for long time series SAR image change detection and change pattern analysis (SAR-TSCC) was proposed for land cover change mapping. To obtain the most notable change time rapidly, a fast SAR ITS change point search method based on pruned exact linear time (SAR-PELT) algorithm was adopted. Meanwhile, the deep time series classification network, named SAR time series transformer (SAR-TST), was implemented to recognize the change patterns, which is based on time series transformer (TST) architecture. Considering the lack of real training data, a novel synthetic data generation method is developed. The combination of the synthetic and real data enhanced the generalization of the classifiers. The proposed framework was used for monitoring a large urbanization area in the northwest of Hong Kong, China. The Cosmo Skymed (CSK) time series data acquired from 2013 to 2020 were exploited for land cover change analysis. Experiment results showed that our approach achieved the state-of-the-art performance, as the time accuracy reached 86% and the classification accuracy on the four main change patterns (impulse, step, cycle, and complex) is over 99%. In particular, the proposed SAR-TST model showed remarkable advantages in the presence of insufficient real data.;2023;Not health related;Not health related
"Song, ZY; Liu, JW; Yang, J; Zhang, LN";Linear normalization attention neural Hawkes process;With the development of the Internet and the formal arrival of the era of big data, people record, store and process data in electronic form, while the bulk of the data in the real life are asynchronous event sequence data. For modeling the asynchronous event sequence, neural point process is one of the most mainstream solutions. With the more and more in-depth study of neural point process, in order to boost the prediction accuracy of the model, the complexity of the model cannot be overestimated, or the selected model itself has more nonlinearity. For example, the neural point process based on attention mechanism will lead to great complexity of the model. Meanwhile, with the development of deep learning, people find that the traditional multi-layer perceptron has great potential. Now many model architectures built with pure multi-layer perceptron without attention have been proposed, and the effect is better than the attention mechanism. Therefore, the multi-layer perceptron has been reborn and has attracted extensive attention. Inspired by this, we propose the Linear Normalization Attention Hawkes Process (LNAHP), which substitutes the multi-head dot-product attention from the transformer for linear normalization attention, and learns the hidden representation through two linear transformation layers and normalization operation, which markedly reduces the complexity of the model. The performance for different evaluation metrics for the LNAHP is verified and compared to the current baselines on real datasets from different fields and synthetic datasets, which proves the effectiveness of the LNAHP.;2023;Not health related;Not health related
"Liu, H; Wei, D; Lu, DH; Tang, XY; Wang, LS; Zheng, YF";Simultaneous alignment and surface regression using hybrid 2D-3D networks for 3D coherent layer segmentation of retinal OCT images with full and annotations;Layer segmentation is important to quantitative analysis of retinal optical coherence tomography (OCT). Recently, deep learning based methods have been developed to automate this task and yield remarkable performance. However, due to the large spatial gap and potential mismatch between the B-scans of an OCT volume, all of them were based on 2D segmentation of individual B-scans, which may lose the continuity and diagnostic information of the retinal layers in 3D space. Besides, most of these methods required dense annotation of the OCT volumes, which is labor-intensive and expertise-demanding. This work presents a novel framework based on hybrid 2D-3D convolutional neural networks (CNNs) to obtain continuous 3D retinal layer surfaces from OCT volumes, which works well with both full and sparse annotations. The 2D features of individual B-scans are extracted by an encoder consisting of 2D convolutions. These 2D features are then used to produce the alignment displacement vectors and layer segmentation by two 3D decoders coupled via a spatial transformer module. Two losses are proposed to utilize the retinal layers' natural property of being smooth for B-scan alignment and layer segmentation, respectively, and are the key to the semi-supervised learning with sparse annotation. The entire framework is trained end-to-end. To the best of our knowledge, this is the first work that attempts 3D retinal layer segmentation in volumetric OCT images based on CNNs. Experiments on a synthetic dataset and three public clinical datasets show that our framework can effectively align the B-scans for potential motion correction, and achieves superior performance to state-of-the-art 2D deep learning methods in terms of both layer segmentation accuracy and cross-B-scan 3D continuity in both fully and semi-supervised settings, thus offering more clinical values than previous works.;2024;Health related;Health related
"Zhang, ZY; Wang, ZS";Multi-Objective Prediction of Integrated Energy System Using Generative Tractive Network;Accurate load forecasting can bring economic benefits and scheduling optimization. The complexity and uncertainty arising from the coupling of different energy sources in integrated energy systems pose challenges for simultaneously predicting multiple target load sequences. Existing data-driven methods for load forecasting in integrated energy systems use multi-task learning to address these challenges. When determining the input data for multi-task learning, existing research primarily relies on data correlation analysis and considers the influence of external environmental factors in terms of feature engineering. However, such feature engineering methods lack the utilization of the characteristics of multi-target sequences. In leveraging the characteristics of multi-target sequences, language generation models trained on textual logic structures and other sequence features can generate synthetic data that can even be applied to self-training to improve model performance. This provides an idea for feature engineering in data-driven time-series forecasting models. However, because time-series data are different from textual data, existing transformer-based language generation models cannot be directly applied to generating time-series data. In order to consider the characteristics of multi-target load sequences in integrated energy system load forecasting, this paper proposed a generative tractive network (GTN) model. By selectively utilizing appropriate autoregressive feature data for temporal data, this model facilitates feature mining from time-series data. This model is capable of analyzing temporal data variations, generating novel synthetic time-series data that align with the intrinsic temporal patterns of the original sequences. Moreover, the model can generate synthetic samples that closely mimic the variations in the original time series. Subsequently, through the integration of the GTN and autoregressive feature data, various prediction models are employed in case studies to affirm the effectiveness of the proposed methodology.;2023;Not health related;Not health related
"Tiwary, K; Patro, SK; Gandomi, AH; Sahoo, KS";Model updating using causal information: a case study in coupled slab;Problems like improper sampling (sampling on unnecessary variables) and undefined prior distribution (or taking random priors) often occur in model updating. Any such limitations on model parameters can lead to lower accuracy and higher experimental costs (due to more iterations) of structural optimisation. In this work, we explored the effective dimensionality of the model updating problem by leveraging the causal information. In order to utilise the causal structure between the parameters, we used Causal Bayesian Optimisation (CBO), a recent variant of Bayesian Optimisation, to integrate observational and intervention data. We also employed generative models to generate synthetic observational data, which helps in creating a better prior for surrogate models. This case study of a coupled slab structure in a recreational building resulted in the modal updated frequencies which were extracted from the finite element of the structure and compared to measured frequencies from ambient vibration tests found in the literature. The results of mode shapes between experimental and predicted values were also compared using modal assurance criterion (MAC) percentages. The updated frequency and MAC number that was obtained using the proposed model was found in least number of iterations (impacts experimental budget) as compared to previous approaches which optimise the same parameters using same data. This also shows how the causal information has impact on experimental budget.;2022;Not health related;Not health related
"Irwan, D; Ali, M; Ahmed, AN; Jacky, G; Nurhakim, A; Han, MCP; AlDahoul, N; El-Shafie, A";Predicting Water Quality with Artificial Intelligence: A Review of Methods and Applications;The water is the main pivotal sources of irrigation in agricultural activities and affects human daily activities such as drinking. The water quality has a significant impact on various aspects and thus this review aims to addresses existing problems related to water quality prediction methods that have been found in the literature. We explore numerous quality parameters incorporated in the modelling process to measure the quality of water. Furthermore, we review the commonly adopted artificial intelligence-based models which have been utilized to forecast the water quality. 83 studies published from 2009 to 2023 were selected and reviewed based on their success in modelling and forecasting the water quality in multiple regions. We compared these articles in terms of parameters, modelling algorithms, time scale scenarios, and performance measurement indicators. This paper is beneficial to researchers that have interests to conduct future studies related to water quality forecasting. Additionally, we discuss a variety of modelling methods such as deep learning (DL) that have proven to boost the efficiency compared to traditional machine learning (ML) models. As a result, the hybrid-DL models were found to outperform other models such as standalone ML, standalone DL, and hybrid-ML. This study shows a significant limitation of the data-hungry DL models which require a big data size for modelling. Hence, at the end of this review study, we discuss the potential of some methods such as generative adversarial networks (GANs) and attention-based transformer to open the door for water quality prediction improvement. GAN has shown promising performance in other domains for synthetic data generation. The potential usage of GAN for water quality domain can overcome the limitations of lack of data and enhance the performance of the predictive models reviewed in this study. Similarly, transformer was found to be state of the art model for time series prediction and thus it can be good candidate to predict water quality.;2023;Not health related;Not health related
"Alves, KSTR; Aguiar, EPD";A novel rule-based evolving Fuzzy System applied to the thermal modeling of power transformers;Big Data advancements motivate researchers to develop and improve intelligent models to deal efficiently and effectively with data. In this scenario, time series forecasting obtains even more attention. The literature demonstrated the better performance of such models in this subject. Forecasting is widely used in strategic planning to support decision-making, providing competitive differential to organizations. In this paper, a novel rule-based evolving Fuzzy System is proposed for time series forecasting. This is a robust model able to develop and update its structure in unknown environments, capture dynamics and changes of streams, and produce accurate results even when dealing with complex data. The introduced model implements the distance correlation to improve the rules' quality by reducing their standard deviation. The model is evaluated using two synthetic datasets: the Mackey-Glass time-series and the nonlinear dynamic system identification. And finally, the introduced system is implemented to predict the hot spot temperature using three datasets from a real power transformer. Hot spot monitoring is necessary to maximize the load capacity and the lifespan of power transformers. The proposed method is evaluated in terms of root-mean-square error, non-dimensional index error, mean absolute error, runtime, and the number of final rules. The results are compared with traditional forecasting models and with some related state-of-the-art rule-based evolving Fuzzy Systems. The new evolving Fuzzy System outperformed the compared models for the Mackey-Glass time-series and the power transformers datasets concerning the errors. A statistical test comprised the superior performance of the introduced model. The algorithm also obtained a competitive execution time and number of final rules. The results demonstrate the high level of autonomy and adaptation of the model to predict accurately complex and non-stationary data. Seeing the importance of accurate models to deal with data to support decision-making, the results suggest the model's implementation as a forecasting tool in strategic planning. (C) 2021 Elsevier B.V. All rights reserved.;2021;Not health related;Not health related
"Khosravi, B; Rouzrokh, P; Mickley, JP; Faghani, S; Mulford, K; Yang, LJ; Larson, AN; Howe, BM; Erickson, BJ; Taunton, MJ; Wyles, CC";Few-shot biomedical image segmentation using diffusion models: Beyond image generation;"Background: Medical image analysis pipelines often involve segmentation, which requires a large amount of annotated training data, which is time-consuming and costly. To address this issue, we proposed leveraging generative models to achieve few-shot image segmentation. Methods: We trained a denoising diffusion probabilistic model (DDPM) on 480,407 pelvis radiographs to generate 256 x 256 px synthetic images. The DDPM was conditioned on demographic and radiologic characteristics and was rigorously validated by domain experts and objective image quality metrics (Frechet inception distance [FID] and inception score [IS]). For the next step, three landmarks (greater trochanter [GT], lesser trochanter [LT], and obturator foramen [OF]) were annotated on 45 real-patient radiographs; 25 for training and 20 for testing. To extract features, each image was passed through the pre-trained DDPM at three timesteps and for each pass, features from specific blocks were extracted. The features were concatenated with the real image to form an image with 4225 channels. The feature-set was broken into random patches, which were fed to a U-Net. Dice Similarity Coefficient (DSC) was used to compare the performance with a vanilla U-Net trained on radiographs.Results: Expert accuracy was 57.5 % in determining real versus generated images, while the model reached an FID = 7.2 and IS = 210. The segmentation UNet trained on the 20 feature-sets achieved a DSC of 0.90, 0.84, and 0.61 for OF, GT, and LT segmentation, respectively, which was at least 0.30 points higher than the naively trained model. Conclusion: We demonstrated the applicability of DDPMs as feature extractors, facilitating medical image segmentation with few annotated samples.";2023;Health related;Health related
"Klokov, AA; Pak, D; Khorin, A; Yudin, DA; Kochiev, L; Luchinskiy, VD; Bezuglyj, VD";DAPS3D: Domain Adaptive Projective Segmentation of 3D LiDAR Point Clouds;LiDARs are one of the key sources of reliable environmental ranging information for autonomous vehicles. However, segmentation of 3D scene elements (roads, buildings, people, cars, etc.) based on LiDAR point clouds has limitations. On the one hand, point- and voxel-based segmentation neural networks do not offer sufficiently high speed. On the other hand, modern labeled datasets primarily consist of street scenes recorded for driverless cars and contain little data for mobile delivery robots or cleaners that must work in parks and yards with heavy pedestrian traffic. This article aims to overcome these limitations. We have proposed a novel approach called DAPS3D to train deep neural networks for 3D semantic segmentation. This approach is based on a spherical projection of a point cloud and LiDARspecific masks, enabling the model to adapt to different types of LiDAR. First of all, we have introduced various high-speed multi-scale spherical projection segmentation models, including convolutional, recurrent, and transformer architectures. Among them, the SalsaNextRecLSTM architecture with recurrent blocks showed the best results. In particular, this model achieved the 83.5% mIoU metric for the SemanticKitti dataset with joint categories. Secondly, we have proposed several original augmentations for spherical projections of LiDAR data, including FoV, flip, and rotation augmentation, as well as a special T-Zone cutout. These augmentations increase the model's invariance when dealing with changes in the data domain. Finally, we introduce a new method to generate synthetic datasets for domain adaptation problems. We have developed two new datasets for validating 3D scene outdoor segmentation algorithms: the DAPS-1 dataset, which is based on the augmentation of the reconstructed 3D semantic map, and the DAPS-2 LiDAR dataset, collected by the on-board sensors of a cleaning robot in a park area. Particular attention is given to the performance of the developed models, demonstrating their ability to function in real-time. The code and datasets used in this study are publicly available at: github.com/subake/DAPS3D.;2023;Not health related;Not health related
"Piano, L; Pratticò, FG; Russo, AS; Lanari, L; Morra, L; Lamberti, F";Bent & Broken Bicycles: Leveraging synthetic data for damaged object re-identification;Instance-level object re-identification is a fundamental computer vision task, with applications from image retrieval to intelligent monitoring and fraud detection. In this work, we propose the novel task of damaged object re-identification, which aims at distinguishing changes in visual appearance due to deformations or missing parts from subtle intra-class variations. To explore this task, we leverage the power of computer-generated imagery to create, in a semi-automatic fashion, high-quality synthetic images of the same bike before and after a damage occurs. The resulting dataset, Bent & Broken Bicycles (BB-Bicycles), contains 39,200 images and 2,800 unique bike instances spanning 20 different bike models. As a baseline for this task, we propose TransReI3D, a multi-task, transformer-based deep network unifying damage detection (framed as a multi-label classification task) with object re-identification. The BBBicycles dataset is available at https://tinyurl.com/37tepf7m;2023;Not health related;Not health related
"Kim, K; Chun, C";Synthetic Data Generator for Solving Korean Arithmetic Word Problem;A math word problems (MWPs) comprises mathematical logic, numbers, and natural language. To solve these problems, a solver model requires an understanding of language and the ability to reason. Since the 1960s, research on the design of a model that provides automatic solutions for mathematical problems has been continuously conducted, and numerous methods and datasets have been published. However, the published datasets in Korean are insufficient. In this study, we propose a Korean data generator for the first time to address this issue. The proposed data generator comprised problem types and data variations. Moreover, it has 4 problem types and 42 subtypes. The data variation has four categories, which adds robustness to the model. In total, 210,311 pieces of data were used for the experiment, of which 210,000 data points were generated. The training dataset had 150,000 data points. Each validation and test dataset had 30,000 data points. Furthermore, 311 problems were sourced from commercially available books on mathematical problems. We used these problems to evaluate the validity of our data generator on actual math word problems. The experiments confirm that models developed using the proposed data generator can be applied to real data. The proposed generator can be used to solve Korean MWPs in the field of education and the service industry, as well as serve as a basis for future research in this field.;2022;Not health related;Not health related
"Kim, J; Kim, T; Kim, J";Two-pathway spatiotemporal representation learning for extreme water temperature prediction;Accurate predictions of extreme water temperatures are criticalto understanding the variability of the marine environment and reducing marine disasters maximized by global warming. In this study, we propose a twopathway framework with separated spatial and temporal encoders for accurate prediction of water temperature, especially extremely high water temperature, through effective spatiotemporal representation learning. The spatial and temporal encoder networks based on the Transformer's self-attention mechanism performs the task of predicting the water temperature time series at the 16 coastal locations around the Korean Peninsula for the seven consecutive days ahead at daily intervals with various combinations of patch embedding methods, positional embedding for spatial features. Comparative experiments with conventional deep convolutional and recurrent networks are also conducted for comparison. By comparing and assessing these results, the proposed two-pathway framework can improve the predictability of extremely high coastal water temperature by better capturing spatiotemporal interrelationships and long-range dependencies from open ocean and regional sea, and further determines the optimal architectural details of self-attention-based spatial and temporal encoders. Furthermore, to examine the explainability of the proposed model and its consistency with domain knowledge, spatial and temporal attention maps are visualized and analyzed that represents weights for spatiotemporal input sequences that are more relevant to predict for future predictions.;2024;Not health related;Not health related
"Henriet, S; Simsekli, U; Fuentes, B; Richard, G";A generative model for non-Intrusive load monitoring in commercial buildings;In the recent years, there has been an increasing academic and industrial interest for analyzing the electrical consumption of commercial buildings. Whilst having similarities with the Non Intrusive Load Monitoring (NILM) tasks for residential buildings, the nature of the signals that are collected from large commercial buildings introduces additional difficulties to the NILM research causing existing NILM approaches to fail. On the other hand, the amount of publicly available datasets collected from commercial buildings is very limited, which makes the NILM research even more challenging for this type of large buildings. In this study, we aim at addressing these issues. We first present an extensive statistical analysis of both commercial and residential measurements from public and private datasets and show important differences. Secondly, we develop an algorithm for generating synthetic current data based on a modelization of the current Flowing through an electrical device. We then demonstrate that our electrical device model fits well real measurements and that our simulations are realistic by using the quantitative metrics described in the previous section. Finally, to encourage research on commercial buildings we release a synthesized dataset called SHED that can be used to evaluate NILM algorithms. (C) 2018 Elsevier B.V. All rights reserved.;2018;Not health related;Not health related
"Sun, CH; Xu, K; Fiore, M; Marina, MK; Wang, Y; Ziemlicki, C";AppShot: A Conditional Deep Generative Model for Synthesizing Service-Level Mobile Traffic Snapshots at City Scale;Service-level mobile traffic data enables research studies and innovative applications with a potential to shape future service-oriented communication systems and beyond. However, real-world datasets reporting measurements at the individual service level are hard to access as such data is deemed commercially sensitive by operators. APPSHOT is a model for generating synthetic high-fidelity city-scale snapshots of service level mobile traffic. It can operate in any geographical region and relies solely on easily available spatial context information such as population density, thus allowing the generation of new and open traffic datasets for the research community. The design of APPSHOT is informed by an original characterization of service-level mobile traffic data. APPSHOT is a novel conditional GAN design instantiated by a convolutional neural network generator and two discriminators. The model features several other innovative mechanisms including multi-channel and overlapping patch based generation to address the unique challenges involved in generating mobile service traffic snapshots. Experiments with ground-truth data collected by a major European operator in multiple metropolitan areas show that APPSHOT can produce realistic network loads at the service level for areas where it has no prior traffic knowledge, and that such data can reliably support service-oriented networking studies.;2022;Not health related;Not health related
"Shakeri, S; Dos Santos, CN; Zhu, H; Ng, P; Nan, F; Wang, ZG; Nallapati, R; Xiang, B";End-to-End Synthetic Data Generation for Domain Adaptation of Question Answering Systems;We propose an end-to-end approach for synthetic QA data generation. Our model comprises a single transformer-based encoderdecoder network that is trained end-to-end to generate both answers and questions. In a nutshell, we feed a passage to the encoder and ask the decoder to generate a question and an answer token-by-token. The likelihood produced in the generation process is used as a filtering score, which avoids the need for a separate filtering model. Our generator is trained by finetuning a pretrained LM using maximum likelihood estimation. The experimental results indicate significant improvements in the domain adaptation of QA models outperforming current state-of-the-art methods.;2020;Not health related;Not health related
"Momeni, S; Fazlollahi, A; Lebrat, L; Yates, P; Rowe, C; Gao, YS; Liew, AWC; Salvado, O";Generative Model of Brain Microbleeds for MRI Detection of Vascular Marker of Neurodegenerative Diseases;Cerebral microbleeds (CMB) are increasingly present with aging and can reveal vascular pathologies associated with neurodegeneration. Deep learning-based classifiers can detect and quantify CMB from MRI, such as susceptibility imaging, but are challenging to train because of the limited availability of ground truth and many confounding imaging features, such as vessels or infarcts. In this study, we present a novel generative adversarial network (GAN) that has been trained to generate three-dimensional lesions, conditioned by volume and location. This allows one to investigate CMB characteristics and create large training datasets for deep learning-based detectors. We demonstrate the benefit of this approach by achieving state-of-the-art CMB detection of real CMB using a convolutional neural network classifier trained on synthetic CMB. Moreover, we showed that our proposed 3D lesion GAN model can be applied on unseen dataset, with different MRI parameters and diseases, to generate synthetic lesions with high diversity and without needing laboriously marked ground truth.;2021;Health related;Health related
"Strelcenia, E; Prakoonwit, S";A Survey on GAN Techniques for Data Augmentation to Address the Imbalanced Data Issues in Credit Card Fraud Detection;Data augmentation is an important procedure in deep learning. GAN-based data augmentation can be utilized in many domains. For instance, in the credit card fraud domain, the imbalanced dataset problem is a major one as the number of credit card fraud cases is in the minority compared to legal payments. On the other hand, generative techniques are considered effective ways to rebalance the imbalanced class issue, as these techniques balance both minority and majority classes before the training. In a more recent period, Generative Adversarial Networks (GANs) are considered one of the most popular data generative techniques as they are used in big data settings. This research aims to present a survey on data augmentation using various GAN variants in the credit card fraud detection domain. In this survey, we offer a comprehensive summary of several peer-reviewed research papers on GAN synthetic generation techniques for fraud detection in the financial sector. In addition, this survey includes various solutions proposed by different researchers to balance imbalanced classes. In the end, this work concludes by pointing out the limitations of the most recent research articles and future research issues, and proposes solutions to address these problems.;2023;Not health related;Not health related
"Fathy, Y; Jaber, M; Brintrup, A";Learning With Imbalanced Data in Smart Manufacturing: A Comparative Analysis;"The Internet of Things (IoT) paradigm is revolutionising the world of manufacturing into what is known as Smart Manufacturing or Industry 4.0. The main pillar in smart manufacturing looks at harnessing IoT data and leveraging machine learning (ML) to automate the prediction of faults, thus cutting maintenance time and cost and improving the product quality. However, faults in real industries are overwhelmingly outweighed by instances of good performance (faultless samples); this bias is reflected in the data captured by IoT devices. Imbalanced data limits the success of ML in predicting faults, thus presents a significant hindrance in the progress of smart manufacturing. Although various techniques have been proposed to tackle this challenge in general, this work is the first to present a framework for evaluating the effectiveness of these remedies in the context of manufacturing. We present a comprehensive comparative analysis in which we apply our proposed framework to benchmark the performance of different combinations of algorithm components using a real-world manufacturing dataset. We draw key insights into the effectiveness of each component and inter-relatedness between the dataset, the application context, and the design of the ML algorithm.";2021;Not health related;Not health related
"Kim, K; Chun, C; Moon, SY";Conformer-Based Dental AI Patient Clinical Diagnosis Simulation Using Korean Synthetic Data Generator for Multiple Standardized Patient Scenarios;The goal of clinical practice education is to develop the ability to apply theoretical knowledge in a clinical setting and to foster growth as a professional healthcare provider. One effective method of achieving this is through the utilization of Standardized Patients (SP) in education, which familiarizes students with real patient interviews and allows educators to assess their clinical performance skills. However, SP education faces challenges such as the cost of hiring actors and the shortage of professional educators to train them. In this paper, we aim to alleviate these issues by utilizing deep learning models to replace the actors. We employ the Conformer model for the implementation of the AI patient, and we develop a Korean SP scenario data generator to collect data for training responses to diagnostic questions. Our Korean SP scenario data generator is devised to generate SP scenarios based on the provided patient information, using pre-prepared questions and answers. In the AI patient training process, two types of data are employed: common data and personalized data. The common data are employed to develop natural general conversation skills, while personalized data, from the SP scenario, are utilized to learn specific clinical information relevant to a patient's role. Based on these data, to evaluate the learning efficiency of the Conformer structure, a comparison was conducted with the Transformer using the BLEU score and WER as evaluation metrics. Experimental results showed that the Conformer-based model demonstrated a 3.92% and 6.74% improvement in BLEU and WER performance compared to the Transformer-based model, respectively. The dental AI patient for SP simulation presented in this paper has the potential to be applied to other medical and nursing fields, provided that additional data collection processes are conducted.;2023;Health related;Health related
"Ferraretto, F; Laitz, T; Lotufo, R; Nogueira, R";ExaRanker: Synthetic Explanations Improve Neural Rankers;Recent work has shown that incorporating explanations into the output generated by large language models (LLMs) can significantly enhance performance on a broad spectrum of reasoning tasks. Our study extends these findings by demonstrating the benefits of explanations for neural rankers. By utilizing LLMs such as GPT-3.5 to enrich retrieval datasets with explanations, we trained a sequence-to-sequence ranking model, dubbed ExaRanker, to generate relevance labels and explanations for query-document pairs. The ExaRanker model, finetuned on a limited number of examples and synthetic explanations, exhibits performance comparable to models finetuned on three times more examples, but without explanations. Moreover, incorporating explanations imposes no additional computational overhead into the reranking step and allows for on-demand explanation generation. The codebase and datasets used in this study will be available at https://github.com/unicamp-dl/ExaRanker;2023;Not health related;Not health related
"Zhang, JW; Liu, HD; Xia, CK";Transformer Based Feature Pyramid Network for Transparent Objects Grasp;Transparent objects like glass bottles and plastic cups are common in daily life, while few works show good performance on grasping transparent objects due to their unique optic properties. Besides the difficulties of this task, there is no dataset for transparent objects grasp. To address this problem, we propose an efficient dataset construction pipeline to label grasp pose for transparent objects. With Blender physics engines, our pipeline could generate numerous photo-realistic images and label grasp poses in a short time. We also propose TTG-Net - a transformer-based feature pyramid network for generating planar grasp pose, which utilizes features pyramid network with residual module to extract features and use transformer encoder to refine features for better global information. TTG-Net is fully trained on the virtual dataset generated by our pipeline and it shows 80.4% validation accuracy on the virtual dataset. To prove the effectiveness of TTG-Net on real-world data, we also test TTG-Net with photos randomly captured in our lab. TTG-Net shows 73.4% accuracy on real-world benchmark which shows remarkable sim2real generalization. We also evaluate other main-stream methods on our dataset, TTG-Net shows better generalization ability.;2022;Not health related;Not health related
"Dziubliuk, V; Zlotnyk, M; Viatchaninov, O";Sequence Learning Model for Syllables Recognition Arranged in Two Dimensions;The handwritten text recognition from images is a challenging task due to the unique features of human handwriting styles, numerous overlaps and interrupting characters. It is especially difficult for languages where syllables are written by alphabetic letters arranged in two dimensions. Sequence learning architectures have a lot of potential to be applied for solving this type of tasks because they can access global and local contextual information. In this paper, we propose a multi-dimensional sequence learning model for handwriting recognition with residual connections between and inside Separable Blocks and self-attention along horizontal and vertical image directions instead of recurrence. The performance of recurrent and attention-based Directional Blocks on synthetic multi-line MNIST-based datasets is explored. We generated such data to force the model to learn local and global context during recognition. It is shown that a pre-trained model on MNIST-based datasets along with a syllable decomposition can successfully tackle Hangul handwriting recognition. To the best of our knowledge, our approach surpasses state-of-the-art results by achieving accuracy of 97.90% on PE92 and 97.76% on SERI95 for the syllable recognition tasks.;2021;Not health related;Not health related
"Kleinebrahm, M; Torriti, J; McKenna, R; Ardone, A; Fichtner, W";Using neural networks to model long-term dependencies in occupancy behavior;Models simulating household energy demand based on different occupant and household types and their behavioral patterns have received increasing attention over the last years due the need to better under -stand fundamental characteristics that shape the demand side. Most of the models described in the lit-erature are based on Time Use Survey data and Markov chains. Due to the nature of the underlying data and the Markov property, it is not sufficiently possible to consider long-term dependencies over sev-eral days in occupant behavior. An accurate mapping of long-term dependencies in behavior is of increas-ing importance, e.g. for the determination of flexibility potentials of individual households urgently needed to compensate supply-side fluctuations of renewable based energy systems. The aim of this study is to bridge the gap between social practice theory, energy related activity modelling and novel machine learning approaches. The weaknesses of existing approaches are addressed by combining time use survey data with mobility data, which provide information about individual mobility behavior over periods of one week. In social practice theory, emphasis is placed on the sequencing and repetition of practices over time. This suggests that practices have a memory. Transformer models based on the attention mechanism and Long short-term memory (LSTM) based neural networks define the state of the art in the field of nat-ural language processing (NLP) and are for the first time introduced in this paper for the generation of weekly activity profiles. In a first step an autoregressive model is presented, which generates synthetic weekly mobility schedules of individual occupants and thereby captures long-term dependencies in mobility behavior. In a second step, an imputation model enriches the weekly mobility schedules with detailed information about energy relevant at home activities. The weekly activity profiles build the basis for multiple use cases one of which is modelling consistent electricity, heat and mobility demand profiles of households. The approach developed provides the basis for making high-quality weekly activity data available to the general public without having to carry out complex application procedures. (c) 2021 Elsevier B.V. All rights reserved.;2021;Not health related;Not health related
"Hou, Y; Zhang, SH; Ma, R; Jia, HZ; Xie, XD";Frame-Recurrent Video Crowd Counting;Since video data contains temporal information, video crowd counting demonstrates more potential than single-frame crowd counting for scenarios requiring high accuracy. However, learning robust relationships among frames efficiently and cheaply is very challenging. Existing methods for video crowd counting lack explicit temporal correlation modeling and robustness, and they are complex. In this paper, we propose the Frame-Recurrent Video Crowd Counting (FRVCC) framework to solve these issues. Specifically, we design a frame-recurrent manner to recursively relate the density maps in the temporal dimension, which efficiently explores long-term inter-frame knowledge and ensures the continuity of feature map responses. FRVCC consists of three plug-in modules: an optical flow estimation module, a single-frame counting module, and a density map fusion module. For the fusion module, we propose the ResTrans network to robustly learn complementary features between visual-based and correlation-based feature maps through residual strategy and vision transformer. To constrain the output distribution to be consistent with the ground truth distribution, we introduce an adversarial loss to rectify the training process. Additionally, we release a large-scale synthetic video crowd-counting dataset, CrowdXV, to evaluate the proposed method and further improve its performance. We have conducted extensive experiments on several video-counting datasets. The results demonstrate that FRVCC achieves state-of-the-art performance and, concurrently, high generalization, high flexibility, and less complexity.;2023;Not health related;Not health related
"Lin, N; Wu, SJ; Wu, ZY; Ji, SB";Efficient Generation of Pretraining Samples for Developing a Deep Learning Brain Injury Model via Transfer Learning;"The large amount of training samples required to develop a deep learning brain injury model demands enormous computational resources. Here, we study how a transformer neural network ( TNN) of high accuracy can be used to efficiently generate pretraining samples for a convolutional neural network (CNN) brain injury model to reduce computational cost. The samples use synthetic impacts emulating real-world events or augmented impacts generated from limited measured impacts. First, we verify that the TNN remains highly accurate for the two impact types (N = 100 each; R-2 of 0.948-0.967 with root mean squared error, RMSE, similar to 0.01, for voxelized peak strains). The TNN-estimated samples (1000-5000 for each data type) are then used to pretrain a CNN, which is further finetuned using directly simulated training samples (250- 5000). An independent measured impact dataset considered of complete capture of impact event is used to assess estimation accuracy (N = 191). We find that pretraining can significantly improve CNN accuracy via transfer learning compared to a baseline CNN without pretraining. It is most effective when the finetuning dataset is relatively small (e.g., 2000-4000 pretraining synthetic or augmented samples improves success rate from 0.72 to 0.81 with 500 finetuning samples). When finetuning samples reach 3000 or more, no obvious improvement occurs from pretraining. These results support using the TNN to rapidly generate pretraining samples to facilitate a more efficient training strategy for future deep learning brain models, by limiting the number of costly direct simulations from an alternative baseline model. This study could contribute to a wider adoption of deep learning brain injury models for large-scale predictive modeling and ultimately, enhancing safety protocols and protective equipment.";2023;Health related;Not health related
"Zhang, SQ; Xu, LC; Li, SW; Oliveira, JCA; Li, X; Ackermann, L; Hong, X";Bridging Chemical Knowledge and Machine Learning for Performance Prediction of Organic Synthesis;Recent years have witnessed a boom of machine learning (ML) applications in chemistry, which reveals the potential of data-driven prediction of synthesis performance. Digitalization and ML modelling are the key strategies to fully exploit the unique potential within the synergistic interplay between experimental data and the robust prediction of performance and selectivity. A series of exciting studies have demonstrated the importance of chemical knowledge implementation in ML, which improves the model's capability for making predictions that are challenging and often go beyond the abilities of human beings. This Minireview summarizes the cutting-edge embedding techniques and model designs in synthetic performance prediction, elaborating how chemical knowledge can be incorporated into machine learning until June 2022. By merging organic synthesis tactics and chemical informatics, we hope this Review can provide a guide map and intrigue chemists to revisit the digitalization and computerization of organic chemistry principles.;2023;Not health related;Not health related
"Yu, TZ; Bidulka, L; McKeown, MJ; Wang, ZJ";PA-Tran: Learning to Estimate 3D Hand Pose with Partial Annotation;"This paper tackles a novel and challenging problem-3D hand pose estimation (HPE) from a single RGB image using partial annotation. Most HPE methods ignore the fact that the keypoints could be partially visible (e.g., under occlusions). In contrast, we propose a deep-learning framework, PA-Tran, that jointly estimates the keypoints status and 3D hand pose from a single RGB image with two dependent branches. The regression branch consists of a Transformer encoder which is trained to predict a set of target keypoints, given an input set of status, position, and visual features embedding from a convolutional neural network (CNN); the classification branch adopts a CNN for estimating the keypoints status. One key idea of PA-Tran is a selective mask training (SMT) objective that uses a binary encoding scheme to represent the status of the keypoints as observed or unobserved during training. In addition, by explicitly encoding the label status (observed/unobserved), the proposed PA-Tran can efficiently handle the condition when only partial annotation is available. Investigating the annotation percentage ranging from 50-100%, we show that training with partial annotation is more efficient (e.g., achieving the best 6.0 PA-MPJPE when using about 85% annotations). Moreover, we provide two new datasets. APDM-Hand, is for synthetic hands with APDM sensor accessories, which is designed for a specific hand task. PD-APDM-Hand, is a real hand dataset collected from Parkinson's Disease (PD) patients with partial annotation. The proposed PA-Tran can achieve higher estimation accuracy when evaluated on both proposed datasets and a more general hand dataset.";2023;Not health related;Health related