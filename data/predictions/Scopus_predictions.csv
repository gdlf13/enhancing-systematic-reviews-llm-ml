Authors;Title;Year;Abstract;GPT4 Review;Predicted Label"Alcaraz J.M.L.; Strodthoff N.";Diffusion-based conditional ECG generation with structured state space models;2023;Generating synthetic data is a promising solution for addressing privacy concerns that arise when distributing sensitive health data. In recent years, diffusion models have become the new standard for generating various types of data, while structured state space models have emerged as a powerful approach for capturing long-term dependencies in time series. Our proposed solution, SSSD-ECG, combines these two technologies to generate synthetic 12-lead electrocardiograms (ECGs) based on over 70 ECG statements. As reliable baselines are lacking, we also propose conditional variants of two state-of-the-art unconditional generative models. We conducted a thorough evaluation of the quality of the generated samples by assessing pre-trained classifiers on the generated data and by measuring the performance of a classifier trained only on synthetic data. SSSD-ECG outperformed its GAN-based competitors. Our approach was further validated through experiments that included conditional class interpolation and a clinical Turing test, which demonstrated the high quality of SSSD-ECG samples across a wide range of conditions. © 2023 Elsevier Ltd;Health related;1"Yu C.; Chang Y.; Liang X.; Liang C.; Xie Z.";Deep learning for particle image velocimetry with attentional transformer and cross-correlation embedded;2024;Deep learning-powered methodologies have realized remarkable advancements in the fluid mechanics community, including applications in the particle image velocimetry (PIV) task. However, previous deep learning-based methods still lack robustness and generalization in the real flow scenarios. To solve this problem, we put forward a deep learning architecture called DeepST-CC for PIV estimation, which embeds an attentional transformer and cross-correlation strategy. Specifically, we introduce the Swin Transformer into the optical flow model Recurrent All-pairs Field Transforms (RAFT) to enhance the features of flow images. Then, the global matching between features is efficiently computed by applying a 4D correlation volume. Afterwards, the conventional cross-correlation method derives the initial velocity field from a coarse correlation, which is fed to the GRU-based flow update module. This approach enhances the robustness of the proposed model by incorporating coarse velocity information. Finally, a supervised learning strategy is performed to guide the model training on the synthetic dataset. Extensive experimental are conducted to demonstrate that our proposed approach delivers exceptional performance on the public dataset. In addition, DeepST-CC exhibits good generalization ability towards complex experimental PIV images. © 2023;Not health related;0"Chen Q.; Ye A.; Zhang Y.; Chen J.; Huang C.";An intra-class distribution-focused generative adversarial network approach for imbalanced tabular data learning;2024;Data imbalance is a critical factor that adversely affects the performance of machine learning algorithms. It leads to deviations in decision boundaries, resulting in biased predictions towards the majority class and inaccurate classification of the minority class. Although oversampling the minority class using deep generative models is a popular strategy, many existing methods focus solely on enhancing data for the minority class while overlooking the distribution relationship within and between classes. Therefore, we propose an oversampling method that merges unsupervised clustering and generative adversarial network (GAN) to facilitate the imbalanced tabular data learning. First, we perform preprocessing (clustering) on the original data, remove clusters that do not require sampling and generate more samples for sparsely distributed minority class clusters to achieve sample balance within the minority class. Moreover, we design a CTGAN-based auxiliary classifier GAN (ACCTGAN) to generate the minority class. It enhances the semantic integrity of the synthetic data and avoids generating noisy samples. We conducted validation experiments comparing our approach to 7 typical methods on 12 real tabular datasets. Our method shows excellent performance in F1-measure and area under the curve (AUC), obtaining 19 and 20 best results on the three classifiers, respectively. It significantly enhances classification results and demonstrates good robustness and stability. © 2024, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Kayisu A.K.; Kambale W.V.; Benarbia T.; Bokoro P.N.; Kyamakya K.";A Comprehensive Literature Review on Artificial Dataset Generation for Repositioning Challenges in Shared Electric Automated and Connected Mobility †;2024;"In the near future, the incorporation of shared electric automated and connected mobility (SEACM) technologies will significantly transform the landscape of transportation into a sustainable and efficient mobility ecosystem. However, these technological advances raise complex scientific challenges. Problems related to safety, energy efficiency, and route optimization in dynamic urban environments are major issues to be resolved. In addition, the unavailability of realistic and various data of such systems makes their deployment, design, and performance evaluation very challenging. As a result, to avoid the constraints of real data collection, using generated artificial datasets is crucial for simulation to test and validate algorithms and models under various scenarios. These artificial datasets are used for the training of ML (Machine Learning) models, allowing researchers and operators to evaluate performance and predict system behavior under various conditions. To generate artificial datasets, numerous elements such as user behavior, vehicle dynamics, charging infrastructure, and environmental conditions must be considered. In all these elements, symmetry is a core concern; in some cases, asymmetry is more realistic; however, in others, reaching/maintaining as much symmetry as possible is a core requirement. This review paper provides a comprehensive literature survey of the most relevant techniques generating synthetic datasets in the literature, with a particular focus on the shared electric automated and connected mobility context. Furthermore, this paper also investigates central issues of these complex and dynamic systems regarding how artificial datasets could be used in the training of ML models to address the repositioning problem. Hereby, symmetry is undoubtedly a crucial consideration for ML models. In the case of datasets, it is imperative that they accurately emulate the symmetry or asymmetry observed in real-world scenarios to be effectively represented by the generated datasets. Then, this paper investigates the current challenges and limitations of synthetic datasets, such as the reliability of simulations to the real world, and the validation of generative models. Additionally, it explores how ML-based algorithms can be used to optimize vehicle routing, charging infrastructure usage, demand forecasting, and other important operational elements. In conclusion, this paper outlines a series of interesting new research avenues concerning the generation of artificial data for SEACM systems. © 2024 by the authors.";Not health related;0"Alsafadi F.; Wu X.";Deep generative modeling-based data augmentation with demonstration using the BFBT benchmark void fraction datasets;2023;Deep learning (DL) has achieved remarkable successes in many disciplines such as computer vision and natural language processing due to the availability of “big data”. However, such success cannot be easily replicated in many nuclear engineering problems because of the limited amount of training data, especially when the data comes from high-cost experiments. To overcome such a data scarcity issue, this paper explores the applications of deep generative models (DGMs) that have been widely used for image data generation to scientific data augmentation. DGMs, such as generative adversarial networks (GANs), normalizing flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can be trained to learn the underlying probabilistic distribution of the training dataset. Once trained, they can be used to generate synthetic data that are similar to the training data and significantly expand the dataset size. By employing DGMs to augment TRACE simulated data of the steady-state void fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have comparable generative performance with similar errors in the synthetic data, with CVAEs achieving the smallest errors. The findings shows that DGMs have a great potential to augment scientific data in nuclear engineering, which proves effective for expanding the training dataset and enabling other DL models to be trained more accurately. © 2023 Elsevier B.V.;Not health related;0"Liu H.; Wei D.; Lu D.; Tang X.; Wang L.; Zheng Y.";Simultaneous alignment and surface regression using hybrid 2D–3D networks for 3D coherent layer segmentation of retinal OCT images with full and sparse annotations;2024;Layer segmentation is important to quantitative analysis of retinal optical coherence tomography (OCT). Recently, deep learning based methods have been developed to automate this task and yield remarkable performance. However, due to the large spatial gap and potential mismatch between the B-scans of an OCT volume, all of them were based on 2D segmentation of individual B-scans, which may lose the continuity and diagnostic information of the retinal layers in 3D space. Besides, most of these methods required dense annotation of the OCT volumes, which is labor-intensive and expertise-demanding. This work presents a novel framework based on hybrid 2D–3D convolutional neural networks (CNNs) to obtain continuous 3D retinal layer surfaces from OCT volumes, which works well with both full and sparse annotations. The 2D features of individual B-scans are extracted by an encoder consisting of 2D convolutions. These 2D features are then used to produce the alignment displacement vectors and layer segmentation by two 3D decoders coupled via a spatial transformer module. Two losses are proposed to utilize the retinal layers’ natural property of being smooth for B-scan alignment and layer segmentation, respectively, and are the key to the semi-supervised learning with sparse annotation. The entire framework is trained end-to-end. To the best of our knowledge, this is the first work that attempts 3D retinal layer segmentation in volumetric OCT images based on CNNs. Experiments on a synthetic dataset and three public clinical datasets show that our framework can effectively align the B-scans for potential motion correction, and achieves superior performance to state-of-the-art 2D deep learning methods in terms of both layer segmentation accuracy and cross-B-scan 3D continuity in both fully and semi-supervised settings, thus offering more clinical values than previous works. © 2023 Elsevier B.V.;Health related;1"Shah D.; Khan M.A.U.; Abrar M.; Amin F.; Alkhamees B.F.; Alsalman H.";Enhancing the Quality and Authenticity of Synthetic Mammogram Images for Improved Breast Cancer Detection;2024;Breast cancer is widespread throughout the world and can be cured if diagnosed early. Mammography is an irreplaceable and critical technique in modern medicine that serves as a foundation for the detection of breast cancer. In medical imaging, the reliability of synthetic mammogram images is produced by deep convolutional generative adversarial networks (DCGAN). Human validation to assess the quality of synthetic images to examine and calculate the perceptual variations between synthetic images and their real-world counterparts is a difficult task. Thus, this research focused on improving the quality and authenticity of synthetic mammogram images. For this, we explored and identified a new research gap because radiologists consistently expressed much higher confidence levels in real mammogram images in their assessment process. This research highlights the key difference between synthetic and real mammograms by defining mean scores. The defined mean identifies a large gap, with real mammographic images receiving an average score of 0.73 and a synthetic score of 0.31. A statistical analysis was performed, which produced a T-statistic of -6.35, a p-value less than 0.001, and a 95% confidence interval ranging from -0.50 to -0.28. These results have a wide range of implications. It emphasizes the urgent need for further improvements in the generative model, improving the legitimacy and caliber of synthetic mammogram images. Our research highlights how crucial it is to incorporate synthetic images into clinical practice with caution and thought. Ethical considerations must encompass the potential consequences of relying on synthetic data in medical decision-making, along with concerns related to diagnostic accuracy and patient safety.  © 2013 IEEE.;Health related;1"Sun L.; Chen H.; Li J.; Wang C.";Offset flow-guide transformer network for semisupervised real-world video denoising;2024;Video denoising is a fundamental task in low-level computer vision. Most existing denoising algorithms use synthetic data learning. However, there is a significant difference between the noise distributions of synthetic and natural data, which leads to poor generalization performance of the model in actual scenes. Hence, a video method based on an offset optical flow-guided transformer is proposed. The proposed method adopts a semisupervised framework to improve the model's generalization performance, designs the offset optical flow to guide the transformer in capturing critical information, and performs global self-similarity modeling using neighboring spatiotemporal domain features to improve the denoising performance. In addition, contrastive learning is introduced in the supervised branch to prevent the fitting of wrong labels, imaging prior information to mine sequence features in the unsupervised branch, and a two-branch memory loss is introduced to reduce the difference of double branch training. Experimental results on synthetic and real videos demonstrate that our method has obvious quantitative and qualitative improvements over state-of-the-art methods with fewer parameters. © The Authors. Published by SPIE under a Creative Commons Attribution 4.0 International License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its.;Not health related;0"Zhou H.; Guo R.; Li M.; Yang F.; Xu S.; Abubakar A.";Feature-based magnetotelluric inversion by variational autoencoder using a subdomain encoding scheme;2023;Magnetotelluric (MT) data inversion aims to reconstruct a subsurface resistivity model that minimizes the discrepancy between inverted and measured electromagnetic data. Conventional pixel-based minimum-structure inversion often yields a smoothed-out reconstruction with a relatively low resolution. A priori geophysical knowledge can be embedded into inversion and improve the reconstruction resolution through proper reparameterization. However, existing reparameterization approaches, such as model-based and parametric transform-based inversion, have limited ability to incorporate various a priori information. The effectiveness of existing deep generative model-based inversion algorithms is still debatable when applied to scenarios with complex backgrounds. We develop a feature-based MT data inversion method based on a variational autoencoder (VAE) with a subdomain encoding scheme. Instead of encoding the entire domain of an investigation, we adopt a 1D subdomain encoding scheme to encode the 1D resistivity-depth models using a single VAE. The latent variables for the 2D model are a combination of the latent variables for 1D models, and the encoded region of interest (ROI) can be flexibly determined. The latent variables of ROI and the pixels outside the ROI are simultaneously inverted using the gradient-descent method. Our 1D subdomain encoding scheme reduces the complexity and diversity of the data set, and it can flexibly embed a priori knowledge with various uncertainties. Synthetic data inversion and inversion of the Southern African Magnetotelluric Experiment field data validate our method's ability to effectively improve inversion accuracy and resolution. © 2023 Society of Exploration Geophysicists.;Not health related;0"Li C.; Feng G.; Li Y.; Liu R.; Miao Q.; Chang L.";DiffTAD: Denoising diffusion probabilistic models for vehicle trajectory anomaly detection;2024;Vehicle trajectory anomaly detection plays an essential role in the fields of traffic video surveillance, autonomous driving navigation, and taxi fraud detection. Deep generative models have been shown to be promising solutions for anomaly detection, avoiding the costs involved in manual labeling. However, existing popular generative models such as Generative Adversarial Networks (GANs) and Variational AutoEncoders (VAEs) are often plagued by training instability, mode collapse, and poor sample quality. To resolve the dilemma, we present DiffTAD, a novel vehicle trajectory anomaly detection framework based on the emerging diffusion models. DiffTAD formalizes anomaly detection as a noisy-to-normal process that progressively adds noise to the vehicle trajectory until the path is corrupted to pure Gaussian noise. The core idea of our framework is to devise deep neural networks to learn the reverse of the diffusion process and to detect anomalies by comparing the difference between a query trajectory and its reconstruction. DiffTAD is a parameterized Markov chain trained with variational inference and allows the mean square error to optimize the reweighted variational lower bound. In addition, DiffTAD integrates decoupled Transformer-based temporal and spatial encoders to model the temporal dependencies and spatial interactions among vehicles in the diffusion models. Experiments on the real-world trajectory dataset TRAFFIC demonstrate that our DiffTAD achieves significant improvements over existing state-of-the-art methods, with the maximum enhancements reaching 25.87% and 35.59% in terms of AUC and F1. While on the synthetic datasets CROSS, SynTra, and MAAD, the maximum improvements in AUC/F1 are 27.47%/38.56%, 25.38%/31.42%, and 58.22%/50.04%, respectively. © 2024 Elsevier B.V.;Not health related;0"Wu Z.; Lau C.Y.; Zhou Q.; Wu J.; Wang Y.; Liu Q.; Lei Z.; Liu H.";Surgivisor: Transformer-based semi-supervised instrument segmentation for endoscopic surgery;2024;Precise instrument segmentation helps tracking of instruments in surgery. The most of the existing instrument segmentation methods are fully supervised, which are based on 100% labeled data. However, the annotation for instrument segmentation are really expensive, which need the skilled professionals who can identify the parts and types of the surgical instruments. In this work, we propose a transformer-based semi-supervised instrument segmentation for endoscopic surgery, called Surgivisor. First, we present a data augmentation technique to generate synthetic data from endoscopic images to overcome the complex background and instrument collision problem, by fully using the information of unlabeled data and pseudo labels. Second, we propose a mutual prototype loss and a dual structural similarity loss to address illumination reflection and bloody condition issues in the training phase. With the two improvements, the effectiveness of proposed method is validated by the experiments on EndoVis Challenges. It exceeds the state-of-the-art results on the sub-tasks of binary, part, and type. © 2023 Elsevier Ltd;Health related;0"Zhuang Z.; Li T.; Wang H.; Sun J.";Blind Image Deblurring with Unknown Kernel Size and Substantial Noise;2024;Blind image deblurring (BID) has been extensively studied in computer vision and adjacent fields. Modern methods for BID can be grouped into two categories: single-instance methods that deal with individual instances using statistical inference and numerical optimization, and data-driven methods that train deep-learning models to deblur future instances directly. Data-driven methods can be free from the difficulty in deriving accurate blur models, but are fundamentally limited by the diversity and quality of the training data—collecting sufficiently expressive and realistic training data is a standing challenge. In this paper, we focus on single-instance methods that remain competitive and indispensable. However, most such methods do not prescribe how to deal with unknown kernel size and substantial noise, precluding practical deployment. Indeed, we show that several state-of-the-art (SOTA) single-instance methods are unstable when the kernel size is overspecified, and/or the noise level is high. On the positive side, we propose a practical BID method that is stable against both, the first of its kind. Our method builds on the recent ideas of solving inverse problems by integrating physical models and structured deep neural networks, without extra training data. We introduce several crucial modifications to achieve the desired stability. Extensive empirical tests on standard synthetic datasets, as well as real-world NTIRE2020 and RealBlur datasets, show the superior effectiveness and practicality of our BID method compared to SOTA single-instance as well as data-driven methods. The code of our method is available at https://github.com/sun-umn/Blind-Image-Deblurring . © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.;Not health related;0"Kwak S.; Jeong J.; Lee H.; Kim W.; Seo D.; Yun W.; Lee W.; Shin J.";Few-Shot Anomaly Detection via Personalization;2024;Even with a plenty amount of normal samples, anomaly detection has been considered as a challenging machine learning task due to its one-class nature, i. e., the lack of anomalous samples in training time. It is only recently that a few-shot regime of anomaly detection became feasible in this regard, e. g., with a help from large vision-language pre-trained models such as CLIP, despite its wide applicability. In this paper, we explore the potential of large text-to-image generative models in performing few-shot industrial anomaly detection. Specifically, recent text-to-image models have shown unprecedented ability to generalize from few images to extract their common and unique concepts, and even encode them into a textual token to 'personalize' the model: so-called textual inversion. Here, we question whether this personalization is specific enough to discriminate the given images from their potential anomalies, which are often, e. g., open-ended, local, and hard-to-detect. We observe that standard textual inversion exhibits a weaker understanding in localized details within objects, which is not enough for detecting industrial anomalies accurately. Thus, we explore the utilization of model personalization to address anomaly detection and propose Anomaly Detection via Personalization (ADP). ADP enables extracting fine-grained local details shared in the images with simple-yet an effective regularization scheme from the zero-shot transferability of CLIP. We also propose a self-tuning scheme to further optimize the performance of our detection pipeline, leveraging synthetic data generated from the personalized generative model. Our experiments show that the proposed inversion scheme could achieve state-of-the-art results on two industrial anomaly benchmarks, MVTec-AD and VisA, in the regime of few normal samples.  © 2013 IEEE.;Not health related;0"Li J.; Cairns B.J.; Li J.; Zhu T.";Generating synthetic mixed-type longitudinal electronic health records for artificial intelligent applications;2023;The recent availability of electronic health records (EHRs) have provided enormous opportunities to develop artificial intelligence (AI) algorithms. However, patient privacy has become a major concern that limits data sharing across hospital settings and subsequently hinders the advances in AI. Synthetic data, which benefits from the development and proliferation of generative models, has served as a promising substitute for real patient EHR data. However, the current generative models are limited as they only generate single type of clinical data for a synthetic patient, i.e., either continuous-valued or discrete-valued. To mimic the nature of clinical decision-making which encompasses various data types/sources, in this study, we propose a generative adversarial network (GAN) entitled EHR-M-GAN that simultaneously synthesizes mixed-type timeseries EHR data. EHR-M-GAN is capable of capturing the multidimensional, heterogeneous, and correlated temporal dynamics in patient trajectories. We have validated EHR-M-GAN on three publicly-available intensive care unit databases with records from a total of 141,488 unique patients, and performed privacy risk evaluation of the proposed model. EHR-M-GAN has demonstrated its superiority over state-of-the-art benchmarks for synthesizing clinical timeseries with high fidelity, while addressing the limitations regarding data types and dimensionality in the current generative models. Notably, prediction models for outcomes of intensive care performed significantly better when training data was augmented with the addition of EHR-M-GAN-generated timeseries. EHR-M-GAN may have use in developing AI algorithms in resource-limited settings, lowering the barrier for data acquisition while preserving patient privacy. © 2023, The Author(s).;Health related;1"Zaballa O.; Pérez A.; Gómez-Inhiesto E.; Acaiturri-Ayesta T.; Lozano J.A.";A probabilistic generative model to discover the treatments of coexisting diseases with missing data;2024;"Background and Objective: Comorbidities, defined as the presence of co-existing diseases, progress through complex temporal patterns among patients. Learning such dynamics from electronic health records is crucial for understanding the coevolution of diseases. In general, medical records are represented through temporal sequences of clinical variables together with their diagnosis. However, we consider the specific problem where most of the diagnoses are missing. We present a novel probabilistic generative model with a three-fold objective: (i) identify and segment the medical history of patients into treatments associated with comorbidities; (ii) learn the model associated with each identified disease treatment; and (iii) discover subtypes of patients with similar coevolution of comorbidities. Methods: To this end, the model considers a latent structure for the sequences, where patients are modeled by a latent class defined by the evolution of their comorbidities, and each observed medical event of their clinical history is associated with a latent disease. The learning process is performed using an Expectation-Maximization algorithm that considers the exponential number of configurations of the latent variables and is efficiently solved with dynamic programming. Results: The evaluation of the method is carried out both on synthetic and real world data: the experiments on synthetic data show that the learning procedure allows the generative model underlying the data to be recovered; the experiments on real medical data show accurate results in the segmentation of sequences into different treatments, subtyping of patients and diagnosis imputation. Conclusion: We present an interpretable generative model that handles the incompleteness of EHRs and describes the different joint evolution of coexisting diseases depending on the active comorbidities of the patient at each moment. © 2023 Elsevier B.V.";Health related;1"Yan K.; Lu C.; Ma X.; Ji Z.; Huang J.";Intelligent fault diagnosis for air handing units based on improved generative adversarial network and deep reinforcement learning;2024;Data-driven Automatic fault detection and diagnosis (AFDD) for air handling units (AHUs) is crucial for ensuring the stable operation and energy consumption of the heating ventilation air-conditioning (HVAC) system. However, traditional machine learning methods often underperform when confronted with insufficient training sample data, especially when lacking samples from the fault types. Based on the issues of insufficient samples from the fault types and imbalanced training dataset, this study proposes a novel AFDD approach using transformer integrated conditional Wasserstein generative adversarial network and deep reinforcement learning (TCWGAN-DRL) to synthesize the fault data and select high quality synthetic data samples. Firstly, we utilize the proposed TransCWGAN to synthesize fault samples. Then, reinforcement learning is utilized to select high quality synthetic samples. Finally, the filtered samples and the real fault samples are merged to form the training dataset for conventional supervised learning classifiers. Experimental results demonstrate that the enriched training dataset can effectively improve the AFDD results and outperforms recently published existing methods, for instance, compared to the suboptimal model, our method exhibits an increase in fault recognition accuracy of 4.9%, 3.66%, and 4.02% when the number of real fault samples is 15, 20, and 30, respectively. © 2023 Elsevier Ltd;Health related;0"Yin M.; Zou Z.; Zhang E.; Cavinato C.; Humphrey J.D.; Karniadakis G.E.";A generative modeling framework for inferring families of biomechanical constitutive laws in data-sparse regimes;2023;Quantifying biomechanical properties of the human vasculature could deepen our understanding of cardiovascular diseases. Standard nonlinear regression in constitutive modeling requires considerable high-quality data and an explicit form of the constitutive model as prior knowledge. By contrast, we propose a novel approach that combines generative deep learning with Bayesian inference to efficiently infer families of constitutive relationships in data-sparse regimes. Inspired by the concept of functional priors, we develop a generative adversarial network (GAN) that incorporates a neural operator as the generator and a fully-connected neural network as the discriminator. The generator takes a vector of noise conditioned on measurement data as input and yields the predicted constitutive relationship, which is scrutinized by the discriminator in the following step. We demonstrate that this framework can accurately estimate means and standard deviations of the constitutive relationships of the murine aorta using data collected either from model-generated synthetic data or ex vivo experiments for mice with genetic deficiencies. In addition, the framework learns priors of constitutive models without explicitly knowing their functional form, providing a new model-agnostic approach to learning hidden constitutive behaviors from data. © 2023 Elsevier Ltd;Health related;0"Liu W.; Wang H.; Xi Z.; Wang L.";Physics-Informed Deep Learning Inversion with Application to Noisy Magnetotelluric Measurements;2024;"Despite demonstrating exceptional inversion production for synthetic data, the application of deep learning (DL) inversion methods to invert realistic magnetotelluric (MT) measurements, which are inevitably contaminated by noise in acquisition, poses a significant challenge. Hence, to facilitate DL inversion for realistic MT measurements, this work explores developing a noise-robust MT DL inversion method by generating targeted noisy training datasets and constructing a physics-informed neural network. Different from most previous works that only considered the noise of one fixed distribution and level, we propose three noise injection strategies and compare their combinations to mitigate the adverse effect of measurement noise on MT DL inversion results: (1) add synthetic relative noise obeying Gaussian distribution; (2) propose a multiwindow Savitzky–Golay (MWSG) filtering scheme to extract potential and possible noise from the target field data and then introduce them into training data; (3) create an augmented training dataset based on the former two strategies. Moreover, we employ the powerful Swin Transformer as the backbone network to construct a U-shaped DL model (SwinTUNet), based on which a physics-informed SwinTUNet (PISwinTUNet) is implemented to further enhance its generalization ability. In synthetic examples, the proposed noise injection strategies demonstrate impressive inversion effects, regardless of whether they are contaminated by familiar or unfamiliar noise. In a field example, the combination of three strategies drives PISwinTUNet to produce considerably faithful reconstructions for subsurface resistivity structures and outperform the classical deterministic Occam inversions. The experimental results show that the proposed noise-robust DL inversion method based on the noise injection strategies and physics-informed DL architecture holds great promise in processing MT field data. © 2023 by the authors.";Not health related;0"El Kababji S.; Mitsakakis N.; Fang X.; Beltran-Bless A.-A.; Pond G.; Vandermeer L.; Radhakrishnan D.; Mosquera L.; Paterson A.; Shepherd L.; Chen B.; Barlow W.E.; Gralow J.; Savard M.-F.; Clemons M.; El Emam K.";Evaluating the Utility and Privacy of Synthetic Breast Cancer Clinical Trial Data Sets;2023;PURPOSE: There is strong interest from patients, researchers, the pharmaceutical industry, medical journal editors, funders of research, and regulators in sharing clinical trial data for secondary analysis. However, data access remains a challenge because of concerns about patient privacy. It has been argued that synthetic data generation (SDG) is an effective way to address these privacy concerns. There is a dearth of evidence supporting this on oncology clinical trial data sets, and on the utility of privacy-preserving synthetic data. The objective of the proposed study is to validate the utility and privacy risks of synthetic clinical trial data sets across multiple SDG techniques. METHODS: We synthesized data sets from eight breast cancer clinical trial data sets using three types of generative models: sequential synthesis, conditional generative adversarial network, and variational autoencoder. Synthetic data utility was evaluated by replicating the published analyses on the synthetic data and assessing concordance of effect estimates and CIs between real and synthetic data. Privacy was evaluated by measuring attribution disclosure risk and membership disclosure risk. RESULTS: Utility was highest using the sequential synthesis method where all results were replicable and the CI overlap most similar or higher for seven of eight data sets. Both types of privacy risks were low across all three types of generative models. DISCUSSION: Synthetic data using sequential synthesis methods can act as a proxy for real clinical trial data sets, and simultaneously have low privacy risks. This type of generative model can be one way to enable broader sharing of clinical trial data.;Health related;1"Krepelka M.; Vrany J.";Synthesizing Vehicle Speed-Related Features with Neural Networks;2023;In today’s automotive industry, digital technology trends such as Big Data, Digital Twin, and Hardware-in-the-loop simulations using synthetic data offer opportunities that have the potential to transform the entire industry towards being more software-oriented and thus more effective and environmentally friendly. In this paper, we propose generative models to synthesize car features related to vehicle speed: brake pressure, percentage of the pressed throttle pedal, engaged gear, and engine RPM. Synthetic data are essential to digitize Hardware-in-the-loop integration testing of the vehicle’s dashboard, navigation, or infotainment and for Digital Twin simulations. We trained models based on Multilayer Perceptron and bidirectional Long-Short Term Memory neural network for each feature. These models were evaluated on a real-world dataset and demonstrated sufficient accuracy in predicting the desired features. Combining our current research with previous work on generating a speed profile for an arbitrary trip, where Open Street Map data and elevation data are available, allows us to digitally drive this trip. At the time of writing, we are unaware of any similar data-driven approach for generating desired speed-related features. © 2023 by the authors.;Not health related;0"Nguyen T.T.; Ren Z.; Nguyen T.T.; Jo J.; Nguyen Q.V.H.; Yin H.";Portable graph-based rumour detection against multi-modal heterophily;2024;The propagation of rumours on social media poses an important threat to societies, so that various techniques for graph-based rumour detection have been proposed recently. Existing works, however, are based on homophilic graphs: entities that are connected to each other often have the same label. However, recent studies found that heterophily is more common in real-world social networks, i.e., entities with different labels are also often linked to each other due to ‘innocent’ retweets or camouflage behaviours by malicious users. Especially, the heterophily problem is even more challenging in multi-modal social graphs, in which neighbouring entities might differ in terms of both labels and modalities. To cope with multi-modal homophily in graph-based rumour detection, we propose a Portable Graph Transformer-based Rumour Detection model (PHAROS) with novel multi-modal homophily measures. It integrates label information in the learning process, which enables us to generate discriminative neighbourhoods of entities. Our model can handle multiple modalities (a natural characteristic of social graphs) and is portable to be combined with existing graph-based models. Extensive experiments on real and synthetic data show the superiority, efficiency, robustness, and portability of PHAROS and its heterophily resilience. © 2023;Not health related;0"Li Y.; Cao J.; Xu Y.; Zhu L.; Dong Z.Y.";Deep learning based on Transformer architecture for power system short-term voltage stability assessment with class imbalance;2024;Most existing data-driven power system short-term voltage stability assessment (STVSA) approaches presume class-balanced input data. However, in practical applications, the occurrence of short-term voltage instability following a disturbance is minimal, leading to a significant class imbalance problem and a consequent decline in classifier performance. This work proposes a Transformer-based STVSA method to address this challenge. By utilizing the basic Transformer architecture, a stability assessment Transformer (StaaT) is developed as a classification model to reflect the correlation between the operational states of the system and the resulting stability outcomes. To combat the negative impact of imbalanced datasets, this work employs a conditional Wasserstein generative adversarial network with gradient penalty (CWGAN-GP) for synthetic data generation, aiding in the creation of a balanced, representative training set for the classifier. Semi-supervised clustering learning is implemented to enhance clustering quality, addressing the lack of a unified quantitative criterion for short-term voltage stability. Numerical tests on the IEEE 39-bus test system extensively demonstrate that the proposed method exhibits robust performance under class imbalances up to 100:1 and noisy environments, and maintains consistent effectiveness even with an increased penetration of renewable energy. Comparative results reveal that the CWGAN-GP generates more balanced datasets than traditional oversampling methods and that the StaaT outperforms other deep learning algorithms. This study presents a compelling solution for real-world STVSA applications that often face class imbalance and data noise challenges. © 2023 Elsevier Ltd;Not health related;0"Razghandi M.; Zhou H.; Erol-Kantarci M.; Turgut D.";Smart Home Energy Management: VAE-GAN Synthetic Dataset Generator and Q-Learning;2024;In recent years, there has been a growing interest in academia and industry in the analysis of electrical consumption in residential buildings and the implementation of smart home energy management systems (HEMS) to reduce household energy usage and costs. HEMS have been designed to emulate the statistical and functional characteristics of real smart grids. However, a major challenge in this research area is the limited availability of publicly accessible datasets. To address this challenge and further leverage the potential of artificial HEMS applications, it is crucial to develop time series that accurately represent diverse operating conditions of synthetic systems. This paper introduces a novel approach based on the combination of variational auto-encoder-generative adversarial network (VAE-GAN) techniques to generate time-series data of energy consumption in smart homes. Additionally, we investigate the performance of the generative model when integrated with a Q-learning based HEMS. The effectiveness of the Q-learning based HEMS is assessed through online experiments using real-world smart home data. To evaluate the quality of the generated dataset, we employ various metrics including Kullback-Leibler (KL) divergence, maximum mean discrepancy (MMD), and the Wasserstein distance, which quantify the disparities between probability distributions of the real and synthetic data. Our experimental results demonstrate that the synthetic data generated by VAE-GAN closely aligns with the distribution of real data. Furthermore, we demonstrate that the utilization of the generated data facilitates the training of a more efficient Q-learning based HEMS, surpassing the performance achieved with datasets generated using baseline approaches.  © 2010-2012 IEEE.;Not health related;0"Picard C.; Ahmed F.";Untrained and Unmatched: Fast and Accurate Zero-Training Classification for Tabular Engineering Data;2024;In engineering design, navigating complex decision-making landscapes demands a thorough exploration of the design, performance, and constraint spaces, often impeded by resource-intensive simulations. Data-driven methods can mitigate this challenge by harnessing historical data to delineate feasible domains, accelerate optimization, or evaluate designs. However, the implementation of these methods usually demands machine learning expertise and multiple trials to choose the right method and hyperparameters. This makes them less accessible for numerous engineering situations. Additionally, there is an inherent trade-off between training speed and accuracy, with faster methods sometimes compromising precision. In our paper, we demonstrate that a recently released general-purpose transformer-based classification model, TabPFN, is both fast and accurate. Notably, it requires no dataset-specific training to assess new tabular data. TabPFN is a prior-data fitted network, which undergoes a one-time offline training across a broad spectrum of synthetic datasets and performs in-context learning. We evaluated TabPFN’s efficacy across eight engineering design classification problems, contrasting it with seven other algorithms, including a state-of-the-art automated machine learning (AutoML) method. For these classification challenges, TabPFN consistently outperforms in speed and accuracy. It is also the most data-efficient and provides the added advantage of being differentiable and giving uncertainty estimates. Our findings advocate for the potential of pre-trained models that learn from synthetic data and require no domain-specific tuning to make data-driven engineering design accessible to a broader community and open ways to efficient general-purpose models valid across applications. Furthermore, we share a benchmark problem set for evaluating new classification algorithms in engineering design. [DOI: 10.1115/1.4064811] Copyright © 2024 by ASME.;Not health related;0"Wang L.; Zhang X.; Zhang J.; Dong H.; Meng H.; Jiao L.";Pixel-to-Abundance Translation: Conditional Generative Adversarial Networks Based on Patch Transformer for Hyperspectral Unmixing;2024;Spectral unmixing is a significant challenge in hyperspectral image processing. Existing unmixing methods utilize prior knowledge about the abundance distribution to solve the regularization optimization problem, where the difficulty lies in choosing appropriate prior knowledge and solving the complex regularization optimization problem. To solve these problems, we propose a hyperspectral conditional generative adversarial network (HyperGAN) method as a generic unmixing framework based on the following assumption: the unmixing process from pixel to abundance can be regarded as a transformation of two modalities with an internal specific relationship. The proposed HyperGAN is composed of a generator and a discriminator, the former completes the modal conversion from mixed hyperspectral pixel patch to the abundance of corresponding endmember of the central pixel and the latter is used to distinguish whether the distribution and structure of generated abundance are the same as the true ones. Additionally, we propose hyperspectral image (HSI) Patch Transformer as the main component of the generator, which utilizes adaptive attention score to capture the internal pixels correlation of the HSI patch and leverages the spatial-spectral information in a fine-grained way to achieve optimization of the unmixing process. Furthermore, we propose a data synthesis method based on superpixel segmentation and random split to get synthetic data with a spatial structure to further evaluate the effectiveness of our model for unmixing. Experiments on synthetic data and real hyperspectral data achieve impressive results compared to state-of-the-art competitors. Authors;Not health related;0"Wang Y.; Liu Y.; Zhou P.; Geng G.; Zhang Q.";SparseFormer: Sparse transformer network for point cloud classification;2023;Compared to the traditional self-attention structure of Transformers, the MLP-like structure offers advantages such as simplicity and improved performance. However, effectively and efficiently learning features from sparse, irregular, and unordered 3D point cloud data remains a challenge. To address this issue, we propose SparseFormer, a sparse transformer network designed specifically for point cloud processing tasks. SparseFormer incorporates a sparse MLP module that enables accurate feature learning while considering the unique characteristics of 3D point cloud data. Additionally, we enhance the context information by utilizing a multi-scale feature aggregation module. Experimental results demonstrate the superior performance of SparseFormer on classification tasks using benchmark datasets, including the ModelNet40 synthetic dataset and the ScanObjectNN real-world dataset. In the classification experiment on the ScanObjectNN dataset, SparseFormer achieves a mean accuracy of 84.1% and an overall accuracy of 85.5%. © 2023 Elsevier Ltd;Not health related;0"Chen J.; Yang C.; Zhang L.; Yang L.; Bian L.; Luo Z.; Wang J.";TCCU-Net: Transformer and CNN Collaborative Unmixing Network for Hyperspectral image;2024;In recent years, deep learning-based hyperspectral unmixing techniques have garnered increasing attention and made significant advancements. However, relying solely on the use of CNN or Transformer approaches is insufficient for effectively capturing both global and fine-grained information, thereby compromising the accuracy of unmixing tasks. In order to fully harness the information contained within HSIs, this study explores a dual-stream collaborative network, referred to as TCCU-Net. It end-to-end learns information in four dimensions: spectral, spatial, global, and local, to achieve more effective unmixing. The network comprises two core encoders: one is a Transformer encoder, which includes squeeze-launch modules, DSSCR-VIT modules, and stripe pooling modules, while the other one is a CNN encoder, which is composed of 2D pyramid convolutions and 3D pyramid convolutions. By fusing the outputs of these two encoders, the semantic gap between the encoder and decoder is bridged, resulting in improved feature mapping and unmixing outcomes. This study extensively evaluates TCCU-Net and seven hyperspectral unmixing methods on four datasets (Samson, Apex, Jasper Ridge and Synthetic dataset). The experimental results firmly demonstrate that the proposed approach surpasses others in terms of accuracy, holding the potential to effectively address hyperspectral unmixing tasks. Authors;Not health related;0"Kayatas Z.; Bestle D.; Bestle P.; Reick R.";Generation of Realistic Cut-In Maneuvers to Support Safety Assessment of Advanced Driver Assistance Systems;2023;Advanced Driver Assistance Systems (ADASs) attract constantly growing attention from academics and industry as more and more vehicles are equipped with such technology. Level-3 ADASs, like the DRIVE PILOT from Mercedes-Benz AG, are expected to appear more and more on the market in the next few years. However, automated driving raises new challenges for the system validation required for series approval. The replacement of a human driver as control instance expands the range of variants to be validated and verified. The scenario-based validation approach meets these challenges by simulating only specific safety-critical driving scenarios using software-in-the-loop simulation. According to the current state of the art, various safety-relevant driving scenarios are parameterized as idealized maneuvers which, however, requires a great modeling effort, and at the same time, such simplifications may bias the safety assessment. Therefore, a novel approach using artificial intelligence methods is taken here to generate more realistic driving scenarios. Namely, a generative model based on a variational autoencoder is trained with real-world data and then used to generate trajectories for a specific driving maneuver. Through a comprehensive analysis of the synthetic trajectories, it becomes clear that the generative model can learn and replicate relevant properties of real driving data as well as their probabilistics much better than the mathematical models used so far. Furthermore, it is proven that both the statistical properties and the time characteristics are almost equal to those of the input data. © 2023 by the authors.;Not health related;0"Gao L.; Shen H.; Min F.";Swin Transformer for simultaneous denoising and interpolation of seismic data;2024;Seismic data are often characterized by low quality due to noise contamination or missing traces. Convolutional neural networks are popular in dealing with denoising and interpolation. However, fixed-size convolution kernels have limited feature extraction range, and popular networks aim at either denoising or interpolating. In this paper, we propose a Swin Transformer convolutional residual network (SCRN) for simultaneous denoising and interpolation. We step-by-step show on synthetic datasets that SCRN can effectively denoise, interpolate, or denoise and interpolate simultaneously. Following this, the trained simultaneous denoising and interpolation model is directly used to handle multi-tasks on the field datasets. We assess the reconstruction effect of SCRN based on synthetic and field datasets. Comparison methods include both supervised ones (DnCNN, Unet and RIDNet) and unsupervised ones (DDUL, MultiResUNet and DL-POCS). Experimental results show that SCRN outperforms the counterparts in terms of (1) quantitative evaluation indices, (2) event continuity and weak signal retention, (3) generalization seismic data ability to suppress various noise levels and interpolate different sampling rates, and (4) preservation of first-arriving edge signals. These results indicate that SCRN can effectively reconstruct seismic data. © 2023 Elsevier Ltd;Not health related;0"Hu Y.; Li Y.; Song L.; Lee H.P.; Rehm P.J.; Makdad M.; Miller E.; Lu N.";MultiLoad-GAN: A GAN-Based Synthetic Load Group Generation Method Considering Spatial-Temporal Correlations;2024;This paper presents a deep-learning framework, Multi-load Generative Adversarial Network (MultiLoad-GAN), for generating a group of synthetic load profiles (SLPs) simultaneously. The main contribution of MultiLoad-GAN is the capture of spatial-temporal correlations among a group of loads that are served by the same distribution transformer. This enables the generation of a large amount of correlated SLPs required for microgrid and distribution system studies. The novelty and uniqueness of the MultiLoad-GAN framework are three-fold. First, to the best of our knowledge, this is the first method for generating a group of load profiles bearing realistic spatial-temporal correlations simultaneously. Second, two complementary realisticness metrics for evaluating generated load profiles are developed: computing statistics based on domain knowledge and comparing high-level features via a deep-learning classifier. Third, to tackle data scarcity, a novel iterative data augmentation mechanism is developed to generate training samples for enhancing the training of both the classifier and the MultiLoad-GAN model. Simulation results show that MultiLoad-GAN can generate more realistic load profiles than existing approaches, especially in group level characteristics. With little finetuning, MultiLoad-GAN can be readily extended to generate a group of load or PV profiles for a feeder or a service area.  © 2010-2012 IEEE.;Not health related;0"Chundawat V.S.; Tarun A.K.; Mandal M.; Lahoti M.; Narang P.";A Universal Metric for Robust Evaluation of Synthetic Tabular Data;2024;Synthetic tabular data generation becomes crucial when real data are limited, expensive to collect, or simply cannot be used due to privacy concerns. However, producing good quality synthetic data is challenging. Several probabilistic, statistical, generative adversarial networks and variational autoencoder-based approaches have been presented for synthetic tabular data generation. Once generated, evaluating the quality of the synthetic data is quite challenging. Some of the traditional metrics have been used in the literature, but there is lack of a common, robust, and single metric. This makes it difficult to properly compare the effectiveness of different synthetic tabular data generation methods. In this article, we propose a new universal metric, TabSynDex, for the robust evaluation of synthetic data. The proposed metric assesses the similarity of synthetic data with real data through different component scores, which evaluate the characteristics that are desirable for 'high-quality' synthetic data. Being a single score metric and having an implicit bound, TabSynDex can also be used to observe and evaluate the training of neural network-based approaches. This would help in obtaining insights that was not possible earlier. We present several baseline models for comparative analysis of the proposed evaluation metric with existing generative models. We also give a comparative analysis between TabSynDex and existing synthetic tabular data evaluation metrics. This shows the effectiveness and universality of our metric over the existing metrics.  © 2020 IEEE.;Not health related;0"Zhang H.; Hai L.; Sun H.; Wang X.; Li R.; Geng G.; Zhou M.";GTGMM: geometry transformer and Gaussian Mixture Models for robust point cloud registration;2024;Due to different acquisition time, viewpoint, and sensor noise during the process of point cloud data acquisition, the captured point clouds typically exhibit partial overlapped and contain large amounts of noise and outliers. However, this circumstance tends to diminish the accuracy of point-to-point correspondence searches. Existing point-level methods rely on idealized point-to-point correspondences, which cannot be guaranteed in practical applications. To address above limitations, a noval network based on a geometry transformer and a Gaussian Mixture Model (GMM) is proposed, called GTGMM. Specifically, we formulate the registration problem as the problem of aligning the two Gaussian mixtures, leveraging the advantages of the statistic model and learned robust features to overcome the noise and outliers variants. We utilize a Local Feature Extractor (LFE) to extract structural features of point clouds, while the Transformer encoders establish global relations among the point clouds. Additionally, a geometry transformer network is introduced to capture geometric relations within the point cloud, and overlap scores are learned to reject non-overlapping regions. Utilizing overlap scores, point cloud features, and 3D point cloud coordinates, the matching parameters of GMM to calculate to guide the alignment of two point clouds. Experimental results on synthetic datasets and the real Terracotta Warriors data demonstrate that our method achieves high accuracy and robustness under various registration conditions. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.;Not health related;0"Melícias F.S.; Ribeiro T.F.R.; Rabadão C.; Santos L.; Costa R.L.D.C.";GPT and Interpolation-Based Data Augmentation for Multiclass Intrusion Detection in IIoT;2024;The absence of essential security protocols in Industrial Internet of Things (IIoT) networks introduces cybersecurity vulnerabilities and turns them into potential targets for various attack types. Although machine learning has been used for intrusion detection in the IIoT, datasets with representative data of common attacks of IIoT network traffic are limited and often imbalanced. Data augmentation techniques address these problems by creating artificial data in classes with fewer samples. In this work, we evaluate the use of data augmentation when training intrusion detection models based on IIoT traffic data. We compare Generative Pre-trained Transformers (GPT) and variations on the Synthetic Minority Over-sampling TEchnique (SMOTE) and evaluate their capability to enhance intrusion detection performance. We examine the performance of five intrusion detection algorithms when trained with augmented datasets to models trained with the original non-augmented dataset. To ensure a fair comparison, we evaluated the algorithms' performance in the different scenarios using the same test dataset, which does not contain synthetic data. The results show the need for a systematic evaluation before employing data augmentation, as its impact on classification performance depends on the algorithm, data, and used technique. While deep neural networks benefit from data augmentation, the eXtreme Gradient Boosting (XGBoost), which achieved superior performance in intrusion detection between all evaluated classifiers (with F1-Score over 91%), didn't have any performance improvement when trained with augmented data. The evaluation of data generated by GPT-based methods shows such methods (especially GReaT) generate invalid data for both numerical and categorical features in a way that leads to performance degradation in multiclass classification. © 2013 IEEE.;Not health related;0"Benabdallah Benarmas R.; Beghdad Bey K.";Improving Road Traffic Speed Prediction Using Data Augmentation: A Deep Generative Models-based Approach;2024;Deep learning prediction models have emerged as the most widely used for the development of intelligent transportation systems (ITS), and their success is strongly reliant on the volume and quality of training data. However, traffic datasets are often small due to the limitations of the resources used to collect and store traffic flow data. Data Augmentation (DA) is a key method to improve the amount of the training dataset before applying a prediction model. In this paper, we demonstrate the effectiveness of data augmentation for predicting traffic speed by using a Deep Generative Model-based approach (DGM). We empirically evaluate the ability of time series-appropriate architectures to improve traffic prediction over a Train on Synthetic Test on Real(TSTR) process. A Time Series-based Generative Adversarial Network model is used to transform an original road traffic dataset into a synthetic dataset to improve traffic prediction. Experiments were carried out using the 6th Beijing and PeMS datasets to show that the transformation improves the prediction model’s accuracy using both parametric and non-parametric methods. Original datasets are compared with the generated ones using statistical analysis methods to measure the fidelity and behavior of the produced data. © 2024, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Elaziz E.A.; Fathalla R.; Shaheen M.";Deep reinforcement learning for data-efficient weakly supervised business process anomaly detection;2023;The detection of anomalous behavior in business process data is a crucial task for preventing failures that may jeopardize the performance of any organization. Supervised learning techniques are impracticable because of the difficulties of gathering huge amounts of labeled business process anomaly data. For this reason, unsupervised learning techniques and semi-supervised learning approaches trained on entirely labeled normal data have dominated this domain for a long time. However, these methods do not work well because of the absence of prior knowledge of true anomalies. In this study, we propose a deep weakly supervised reinforcement learning-based approach to identify anomalies in business processes by leveraging limited labeled anomaly data. The proposed approach is intended to use a small collection of labeled anomalous data while exploring a huge set of unlabeled data to find new classes of anomalies that are outside the scope of the labeled anomalous data. We created a unique reward function that combined the supervisory signal supplied by a variational autoencoder trained on unlabeled data with the supervisory signal provided by the environment’s reward. To further reduce data deficiency, we introduced a sampling method to allow the effective exploration of the unlabeled data and to address the imbalanced data problem, which is a common problem in the anomaly detection field. This approach depends on the proximity between the data samples in the latent space of the variational autoencoder. Furthermore, to efficiently model the sequential nature of business process data and to handle the long-term dependences, we used a long short-term memory network combined with a self-attention mechanism to develop the agent of our reinforcement learning model. Multiple scenarios were used to test the proposed approach on real-world and synthetic datasets. The findings revealed that the proposed approach outperformed five competing approaches by efficiently using the few available anomalous examples. © 2023, The Author(s).;Not health related;0"Long N.M.H.; Chung W.-Y.";Reconstruction of Corrupted Photoplethysmography Signals Using Recursive Generative Adversarial Networks;2024;This article explores how motion artifacts (MAs) affect photoplethysmography (PPG) signals measured from the radial artery of the wrist through our wearable system called WrisTee. We propose a recursive generative adversarial network (GAN) model that reconstructs corrupted PPG signals across a wide range of signal-to-noise ratios (SNRs) from -33 to 25 dB. To train and evaluate the model's performance, we constructed a dataset of PPG signals obtained from 15 subjects and developed an algorithm for generating synthetic noisy data. The proposed GAN model enables the measurement of heart rate (HR) from synthetic data with a mean absolute error (MAE) of 1.7 bpm. Finally, our model successfully processed 77% of PPG segments from real noisy data. This method provides a foundation for developing generative models aimed at reconstructing noisy PPG data affected by MAs, therefore enhancing the accuracy of personal health monitoring devices.  © 1963-2012 IEEE.;Health related;1"Zhang Z.; Meng L.; Gu Y.";SageFormer: Series-Aware Framework for Long-Term Multivariate Time Series Forecasting;2024;In the burgeoning ecosystem of Internet of Things, multivariate time series (MTS) data has become ubiquitous, highlighting the fundamental role of time series forecasting across numerous applications. The crucial challenge of long-term MTS forecasting requires adept models capable of capturing both intra-and inter-series dependencies. Recent advancements in deep learning, notably Transformers, have shown promise. However, many prevailing methods either marginalize inter-series dependencies or overlook them entirely. To bridge this gap, this paper introduces a novel series-aware framework, explicitly designed to emphasize the significance of such dependencies. At the heart of this framework lies our specific implementation: the SageFormer. As a Series-aware Graph-enhanced Transformer model, SageFormer proficiently discerns and models the intricate relationships between series using graph structures. Beyond capturing diverse temporal patterns, it also curtails redundant information across series. Notably, the series-aware framework seamlessly integrates with existing Transformer-based models, enriching their ability to comprehend inter-series relationships. Extensive experiments on real-world and synthetic datasets validate the superior performance of SageFormer against contemporary state-of-the-art approaches. IEEE;Not health related;0"Lo P.-C.; Lim E.-P.";A transformer framework for generating context-aware knowledge graph paths;2023;Contextual Path Generation (CPG) refers to the task of generating knowledge path(s) between a pair of entities mentioned in an input textual context to determine the semantic connection between them. Such knowledge paths, also called contextual paths, can be very useful in many advanced information retrieval applications. Nevertheless, CPG involves several technical challenges, namely, sparse and noisy input context, missing relations in knowledge graphs, and generation of ill-formed and irrelevant knowledge paths. In this paper, we propose a transformer-based model architecture. In this approach, we leverage a mixture of pre-trained word and knowledge graph embeddings to encode the semantics of input context, a transformer decoder to perform path generation controlled by encoded input context and head entity to stay relevant to the context, and scaling methods to sample a well-formed path. We evaluate our proposed CPG models derived using the above architecture on two real datasets, both consisting of Wikinews articles as input context documents and ground truth contextual paths, as well as a large synthetic dataset to conduct larger-scale experiments. Our experiments show that our proposed models outperform the baseline models, and the scaling methods contribute to better quality contextual paths. We further analyze how CPG accuracy can be affected by different amount of context data, and missing relations in the knowledge graph. Finally, we demonstrate that an answer model for knowledge graph questions adapted for CPG could not perform well due to the lack of an effective path generation module. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.;Not health related;0"Gurevich A.; Bamani E.; Sintov A.";Learning a data-efficient model for a single agent in homogeneous multi-agent systems;2023;Training Reinforcement Learning (RL) policies for a robot requires an extensive amount of data recorded while interacting with the environment. Acquiring such a policy on a real robot is a tedious and time-consuming task. This is more challenging in a multi-agent system where individual data may be required from each agent. While training in simulations is the common approach due to efficiency and low-cost, they rarely describe the real world. Consequently, policies trained in simulations and transferred to the real robot usually perform poorly. In this paper, we present a novel real-to-sim-to-real framework to bridge the reality gap for an agent in collective motion of a homogeneous multi-agent system. First, we propose a novel deep neural-network architecture termed Convolutional-Recurrent Network (CR-Net) to capture the complex state transition of an agent and simulate its motion. Once trained with data from one agent, we show that the CR-Net can accurately predict motion of all agents in the group. Second, we propose to invest a limited amount of real data from the agent in a generative model. Then, training the CR-Net with synthetic data sampled from the generative model is shown to be at least equivalent to real data. Hence, the proposed approach provides a sufficiently accurate model with significantly less real data. The generative model can also be disseminated along with open-source hardware for easier usage. We show experiments on ground and underwater vehicles in which multi-agent RL policies are trained in the simulation for collective motion and successfully transferred to the real-world. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.;Not health related;0"Schaudt D.; Späte C.; von Schwerin R.; Reichert M.; von Schwerin M.; Beer M.; Kloth C.";A Critical Assessment of Generative Models for Synthetic Data Augmentation on Limited Pneumonia X-ray Data;2023;In medical imaging, deep learning models serve as invaluable tools for expediting diagnoses and aiding specialized medical professionals in making clinical decisions. However, effectively training deep learning models typically necessitates substantial quantities of high-quality data, a resource often lacking in numerous medical imaging scenarios. One way to overcome this deficiency is to artificially generate such images. Therefore, in this comparative study we train five generative models to artificially increase the amount of available data in such a scenario. This synthetic data approach is evaluated on a a downstream classification task, predicting four causes for pneumonia as well as healthy cases on 1082 chest X-ray images. Quantitative and medical assessments show that a Generative Adversarial Network (GAN)-based approach significantly outperforms more recent diffusion-based approaches on this limited dataset with better image quality and pathological plausibility. We show that better image quality surprisingly does not translate to improved classification performance by evaluating five different classification models and varying the amount of additional training data. Class-specific metrics like precision, recall, and F1-score show a substantial improvement by using synthetic images, emphasizing the data rebalancing effect of less frequent classes. However, overall performance does not improve for most models and configurations, except for a DreamBooth approach which shows a +0.52 improvement in overall accuracy. The large variance of performance impact in this study suggests a careful consideration of utilizing generative models for limited data scenarios, especially with an unexpected negative correlation between image quality and downstream classification improvement. © 2023 by the authors.;Health related;1"Zhang Q.; Guo M.; Zhao L.; Li Y.; Zhang X.; Han M.";Transformer-based structural seismic response prediction;2024;Seismic response prediction is a crucial aspect of evaluating the performance of civil structures. Accurate and efficient response prediction is of significance owing to its application ranging from structural design to structural performance evaluation. Nonlinear time history analysis offers precise and deterministic predictions of seismic response. However, its practical application is limited by the significant computational costs and low modeling efficiency associated with this method. Therefore, a novel Deep Learning (DL) based deterministic structural seismic response prediction method is proposed as an alternative to nonlinear time history analysis. This framework adopts the Encoder-Decoder architecture of Transformer, with the Encoder encoding the seismic wave and the Decoder, coupled with a Long Short-Term Memory (LSTM) neural network, decoding seismic wave encoding features and obtaining preliminary seismic response. Additionally, Moving Average (MA) operation is embedded into the proposed framework, aiming to adjust the preliminary prediction and acquire the final seismic response. Experimental results on four synthetic datasets and one real dataset show that the proposed TLM method has excellent prediction accuracy for both linear and nonlinear systems as well as for linear-elastic and elastoplastic response prediction of structures. Meanwhile, the TLM method is more computationally efficient than traditional numerical methods for solving relatively refined models. © 2024 Institution of Structural Engineers;Not health related;0"Schultz K.; Bej S.; Hahn W.; Wolfien M.; Srivastava P.; Wolkenhauer O.";ConvGeN: A convex space learning approach for deep-generative oversampling and imbalanced classification of small tabular datasets;2024;Oversampling is commonly used to improve classifier performance for small tabular imbalanced datasets. State-of-the-art linear interpolation approaches can be used to generate synthetic samples from the convex space of the minority class. Generative networks are common deep learning approaches for synthetic sample generation. However, their scope on synthetic tabular data generation in the context of imbalanced classification is not adequately explored. In this article, we show that existing deep generative models perform poorly compared to linear interpolation-based approaches for imbalanced classification problems on small tabular datasets. To overcome this, we propose a deep generative model, ConvGeN that combines the idea of convex space learning with deep generative models. ConvGeN learns coefficients for the convex combinations of the minority class samples, such that the synthetic data is distinct enough from the majority class. Our benchmarking experiments demonstrate that our proposed model ConvGeN improves imbalanced classification on such small datasets, as compared to existing deep generative models, while being on par with the existing linear interpolation approaches. Moreover, we discuss how our model can be used for synthetic tabular data generation in general, even outside the scope of data imbalance, and thus improves the overall applicability of convex space learning. © 2023 Elsevier Ltd;Not health related;0"Zhang Z.; Wang Z.";Multi-Objective Prediction of Integrated Energy System Using Generative Tractive Network;2023;Accurate load forecasting can bring economic benefits and scheduling optimization. The complexity and uncertainty arising from the coupling of different energy sources in integrated energy systems pose challenges for simultaneously predicting multiple target load sequences. Existing data-driven methods for load forecasting in integrated energy systems use multi-task learning to address these challenges. When determining the input data for multi-task learning, existing research primarily relies on data correlation analysis and considers the influence of external environmental factors in terms of feature engineering. However, such feature engineering methods lack the utilization of the characteristics of multi-target sequences. In leveraging the characteristics of multi-target sequences, language generation models trained on textual logic structures and other sequence features can generate synthetic data that can even be applied to self-training to improve model performance. This provides an idea for feature engineering in data-driven time-series forecasting models. However, because time-series data are different from textual data, existing transformer-based language generation models cannot be directly applied to generating time-series data. In order to consider the characteristics of multi-target load sequences in integrated energy system load forecasting, this paper proposed a generative tractive network (GTN) model. By selectively utilizing appropriate autoregressive feature data for temporal data, this model facilitates feature mining from time-series data. This model is capable of analyzing temporal data variations, generating novel synthetic time-series data that align with the intrinsic temporal patterns of the original sequences. Moreover, the model can generate synthetic samples that closely mimic the variations in the original time series. Subsequently, through the integration of the GTN and autoregressive feature data, various prediction models are employed in case studies to affirm the effectiveness of the proposed methodology. © 2023 by the authors.;Not health related;0Sufi F.;Generative Pre-Trained Transformer (GPT) in Research: A Systematic Review on Data Augmentation;2024;GPT (Generative Pre-trained Transformer) represents advanced language models that have significantly reshaped the academic writing landscape. These sophisticated language models offer invaluable support throughout all phases of research work, facilitating idea generation, enhancing drafting processes, and overcoming challenges like writer’s block. Their capabilities extend beyond conventional applications, contributing to critical analysis, data augmentation, and research design, thereby elevating the efficiency and quality of scholarly endeavors. Strategically narrowing its focus, this review explores alternative dimensions of GPT and LLM applications, specifically data augmentation and the generation of synthetic data for research. Employing a meticulous examination of 412 scholarly works, it distills a selection of 77 contributions addressing three critical research questions: (1) GPT on Generating Research data, (2) GPT on Data Analysis, and (3) GPT on Research Design. The systematic literature review adeptly highlights the central focus on data augmentation, encapsulating 48 pertinent scholarly contributions, and extends to the proactive role of GPT in critical analysis of research data and shaping research design. Pioneering a comprehensive classification framework for “GPT’s use on Research Data”, the study classifies existing literature into six categories and 14 sub-categories, providing profound insights into the multifaceted applications of GPT in research data. This study meticulously compares 54 pieces of literature, evaluating research domains, methodologies, and advantages and disadvantages, providing scholars with profound insights crucial for the seamless integration of GPT across diverse phases of their scholarly pursuits. © 2024 by the author.;Not health related;0"Jafari S.M.; Cevik M.; Basar A.";Improved _-GAN architecture for generating 3D connected volumes with an application to radiosurgery treatment planning;2023;Generative Adversarial Networks (GANs) have gained significant attention in several computer vision tasks for generating high-quality synthetic data. Various medical applications including diagnostic imaging and radiation therapy can benefit greatly from synthetic data generation due to data scarcity in the domain. However, medical image data is typically kept in 3D space, and generative models suffer from the curse of dimensionality issues in generating such synthetic data. In this paper, we investigate the potential of GANs for generating connected 3D volumes. We propose an improved version of 3D _-GAN by incorporating various architectural enhancements. On a synthetic dataset of connected 3D spheres and ellipsoids, our model can generate fully connected 3D shapes with similar geometrical characteristics to that of training data. We also show that our 3D GAN model can successfully generate high-quality 3D tumor volumes and associated treatment specifications (e.g., isocenter locations). Similar moment invariants to the training data as well as fully connected 3D shapes confirm that improved 3D _-GAN implicitly learns the training data distribution, and generates realistic-looking samples. The capability of improved 3D _-GAN makes it a valuable source for generating synthetic medical image data that can help future research in this domain. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.;Health related;1"Filatov N.; Kindulov M.";Low Rank Adaptation for Stable Domain Adaptation of Vision Transformers;2023;Abstract: Unsupervised domain adaptation plays a crucial role in semantic segmentation tasks due to the high cost of annotating data. Existing approaches often rely on large transformer models and momentum networks to stabilize and improve the self-training process. In this study, we investigate the applicability of low-rank adaptation (LoRA) to domain adaptation in computer vision. Our focus is on the unsupervised domain adaptation task of semantic segmentation, which requires adapting models from a synthetic dataset (GTA5) to a real-world dataset (City-scapes). We employ the Swin Transformer as the feature extractor and TransDA domain adaptation framework. Through experiments, we demonstrate that LoRA effectively stabilizes the self-training process, achieving similar training dynamics to the exponentially moving average (EMA) mechanism. Moreover, LoRA provides comparable metrics to EMA under the same limited computation budget. In GTA5 _ Cityscapes experiments, the adaptation pipeline with LoRA achieves a mIoU of 0.515, slightly surpassing the EMA baseline’s mIoU of 0.513, while also offering an 11% speedup in training time and video memory saving. These re-sults highlight LoRA as a promising approach for domain adaptation in computer vision, offering a viable alternative to momentum networks which also saves computational resources. © 2023, Allerton Press, Inc.;Not health related;0"Pavez V.; Hermosilla G.; Silva M.; Farias G.";Advanced Deep Learning Techniques for High-Quality Synthetic Thermal Image Generation;2023;In this paper, we introduce a cutting-edge system that leverages state-of-the-art deep learning methodologies to generate high-quality synthetic thermal face images. Our unique approach integrates a thermally fine-tuned Stable Diffusion Model with a Vision Transformer (ViT) classifier, augmented by a Prompt Designer and Prompt Database for precise image generation control. Through rigorous testing across various scenarios, the system demonstrates its capability in producing accurate and superior-quality thermal images. A key contribution of our work is the development of a synthetic thermal face image database, offering practical utility for training thermal detection models. The efficacy of our synthetic images was validated using a facial detection model, achieving results comparable to real thermal face images. Specifically, a detector fine-tuned with real thermal images achieved a 97% accuracy rate when tested with our synthetic images, while a detector trained exclusively on our synthetic data achieved an accuracy of 98%. This research marks a significant advancement in thermal image synthesis, paving the way for its broader application in diverse real-world scenarios. © 2023 by the authors.;Not health related;0"Wang R.; Fung J.C.H.; Lau A.K.H.";Physical-Dynamic-Driven AI-Synthetic Precipitation Nowcasting Using Task-Segmented Generative Model;2023;Precise and timely rainfall nowcasting plays a critical role in ensuring public safety amid disasters triggered by heavy precipitation. While deep-learning models have exhibited superior performance over traditional nowcasting methods in recent years, their efficacy is still hampered by limited forecasting skill, insufficient training data, and escalating blurriness in forecasts. To address these challenges, we present the Synthetic-data Task-segmented Generative Model (STGM), an innovative physical-dynamic-driven heavy rainfall nowcasting model. The STGM encompasses three key components: the Long Video Generation (LVG) model generating synthetic radar data from observed radar images and data provided by the Weather Research and Forecasting (WRF) model, MaskPredNet predicting the spatial coverage of various rainfall intensities, and SPADE determining rainfall intensity based on the coverage provided by MaskPredNet. The STGM has demonstrated promising skill for precipitation forecasts for up to six hours, and significantly reduce the blurriness of predicted images, thus showcasing advances in rainfall nowcasting. © 2023 The Authors.;Not health related;0"Hou Y.; Zhang S.; Ma R.; Jia H.; Xie X.";Frame-Recurrent Video Crowd Counting;2023;Since video data contains temporal information, video crowd counting demonstrates more potential than single-frame crowd counting for scenarios requiring high accuracy. However, learning robust relationships among frames efficiently and cheaply is very challenging. Existing methods for video crowd counting lack explicit temporal correlation modeling and robustness, and they are complex. In this paper, we propose the Frame-Recurrent Video Crowd Counting (FRVCC) framework to solve these issues. Specifically, we design a frame-recurrent manner to recursively relate the density maps in the temporal dimension, which efficiently explores long-term inter-frame knowledge and ensures the continuity of feature map responses. FRVCC consists of three plug-in modules: an optical flow estimation module, a single-frame counting module, and a density map fusion module. For the fusion module, we propose the ResTrans network to robustly learn complementary features between visual-based and correlation-based feature maps through residual strategy and vision transformer. To constrain the output distribution to be consistent with the ground truth distribution, we introduce an adversarial loss to rectify the training process. Additionally, we release a large-scale synthetic video crowd-counting dataset, CrowdXV, to evaluate the proposed method and further improve its performance. We have conducted extensive experiments on several video-counting datasets. The results demonstrate that FRVCC achieves state-of-the-art performance and, concurrently, high generalization, high flexibility, and less complexity.  © 1991-2012 IEEE.;Not health related;0"Sadder B.; Sadder R.; Abandah G.; Jafar I.";MULTI-DOMAIN MACHINE LEARNING APPROACH OF NAMED ENTITY RECOGNITION FOR ARABIC BOOKING CHATBOT ENGINES USING PRE-TRAINED BIDIRECTIONAL TRANSFORMERS;2024;Chatbots have recently become essential in various fields, ranging from customer service and information acquisition to entertainment. The use of chatbots reduces operational costs and human errors while providing services at any time. This work presents a Named Entity Recognition (NER) model for the Arabic booking chatbot, focusing on booking tickets and appointments across multiple domains. This research paves the way for the development of chatbots that can support multiple booking domains, contributing to the advancement of the Arabic language in this field. We adopt deep machine-learning and transfer-learning approaches to solve this task. Specifically, we utilized and fine-tuned the AraBERTv0.2 base model to develop the Named Entity Recognition for Booking Queries (NERB) model. Furthermore, we extended it to the Domain-Aware Named Entity Recognition for Booking Queries (DA-NERB) model by adding an additional input for domain type and an embedding layer. The input to our proposed model consists of text sequences of reservation requests, while the output includes sequences of tags representing entities within the input sequences. For training and testing, we synthesized the Arabic Booking Chatbot-Synthetic Dataset (ABC-S Dataset), comprising 76,117 reservation samples that span seven different domains and encompassing 26 categories of named entities. Additionally, we collected the Arabic Booking Chatbot-Collected Dataset (ABC-C Dataset) from volunteers to evaluate our model using various samples. It's worth noting that these datasets are written in informal Arabic, specifically the Levantine dialect. The proposed model achieves 100% and 96.9% accuracy scores on ABC-S (test set) and ABC-C, respectively. Both the datasets and the code for our model are publicly available to support research in the field of Arabic chatbots. © 2024, Scientific Research Support Fund of Jordan. All rights reserved.;Not health related;0"Liu J.; Yuan H.; Yuan Z.; Liu L.; Lu B.; Yu M.";Visual transformer with stable prior and patch-level attention for single image dehazing;2023;Single-image dehazing aims to recover blurred image details and improve image quality, which is a challenging ill-posed problem due to severe information degradation. In the image dehazing task, extracting local features from adjacent regions is particularly important. However, Transformer-based methods lack relative awareness of patch-level features. Furthermore, due to the sensitivity of self-attention to textcolorreddata distribution, the model suffers severe performance degradation when migrating from synthetic domain to real domain. To alleviate the above problems, we propose visual transformer with stable prior and patch-level attention (VSPPA) for image dehazing. Firstly, we propose a region-aware patch-level attention module to obtain the positional correlation between local patches and contexts, which can enhance the concentration of local patch-related features. Next, due to the instability problem caused by distribution shifts, we introduce dataset-independent prior to guide the transformer model, thereby preventing feature drift thus to improve the robustness of the model. Finally, domain-drift leads to insufficient dehazing when the model trained on synthetic data while migrates to the real environment, we come up with a introduce a patch filling strategy (PFS) for fuzzy data to narrow the domain gap and realize the generalization in real scenes. Extensive experiments show that the model achieves State-of-the-Art on the SOTS synthetic dataset and effective generalization to real-world scenarios. © 2023 Elsevier B.V.;Not health related;0"Liu X.; Xie Y.; Diao S.; Tan S.; Liang X.";Unsupervised CT Metal Artifact Reduction by Plugging Diffusion Priors in Dual Domains;2024;During the process of computed tomography (CT), metallic implants often cause disruptive artifacts in the reconstructed images, impeding accurate diagnosis. Many supervised deep learning-based approaches have been proposed for metal artifact reduction (MAR). However, these methods heavily rely on training with paired simulated data, which are challenging to acquire. This limitation can lead to decreased performance when applying these methods in clinical practice. Existing unsupervised MAR methods, whether based on learning or not, typically work within a single domain, either in the image domain or the sinogram domain. In this paper, we propose an unsupervised MAR method based on the diffusion model, a generative model with a high capacity to represent data distributions. Specifically, we first train a diffusion model using CT images without metal artifacts. Subsequently, we iteratively introduce the diffusion priors in both the sinogram domain and image domain to restore the degraded portions caused by metal artifacts. Besides, we design temporally dynamic weight masks for the image-domian fusion. The dual-domain processing empowers our approach to outperform existing unsupervised MAR methods, including another MAR method based on diffusion model. The effectiveness has been qualitatively and quantitatively validated on synthetic datasets. Moreover, our method demonstrates superior visual results among both supervised and unsupervised methods on clinical datasets. Codes are available in github.com/DeepXuan/DuDoDp-MAR. IEEE;Health related;0"Janssen A.; Smalbil L.; Bennis F.C.; Cnossen M.H.; Mathôt R.A.A.";A Generative and Causal Pharmacokinetic Model for Factor VIII in Hemophilia A: A Machine Learning Framework for Continuous Model Refinement;2024;In rare diseases, such as hemophilia A, the development of accurate population pharmacokinetic (PK) models is often hindered by the limited availability of data. Most PK models are specific to a single recombinant factor VIII (rFVIII) concentrate or measurement assay, and are generally unsuited for answering counterfactual (“what-if”) queries. Ideally, data from multiple hemophilia treatment centers are combined but this is generally difficult as patient data are kept private. In this work, we utilize causal inference techniques to produce a hybrid machine learning (ML) PK model that corrects for differences between rFVIII concentrates and measurement assays. Next, we augment this model with a generative model that can simulate realistic virtual patients as well as impute missing data. This model can be shared instead of actual patient data, resolving privacy issues. The hybrid ML-PK model was trained on chromogenic assay data of lonoctocog alfa and predictive performance was then evaluated on an external data set of patients who received octocog alfa with FVIII levels measured using the one-stage assay. The model presented higher accuracy compared with three previous PK models developed on data similar to the external data set (root mean squared error = 14.6 IU/dL vs. mean of 17.7 IU/dL). Finally, we show that the generative model can be used to accurately impute missing data (< 18% error). In conclusion, the proposed approach introduces interesting new possibilities for model development. In the context of rare disease, the introduction of generative models facilitates sharing of synthetic data, enabling the iterative improvement of population PK models. © 2024 The Authors. Clinical Pharmacology & Therapeutics published by Wiley Periodicals LLC on behalf of American Society for Clinical Pharmacology and Therapeutics.;Not health related;1"Cao H.; Zhang Y.; Shan D.; Liu X.; Zhao J.";TRF-Net: a transformer-based RGB-D fusion network for desktop object instance segmentation;2023;To perform object-specific tasks on the desktop, robots need to perceive different objects. The challenge is to calculate the pixel-wise mask for each object, even in the presence of occlusions and unseen objects. We take a step toward this problem by proposing a metric learning-based network called TRF-Net to perform desktop object instance segmentation. We design two ResNet-based branches to process the RGB and depth images separately. Then, we propose a Transformer-based fusion module called TranSE to fuse the features from both branches. This module also transfers the fused features to the decoder part, which helps generate fine-grained decoder features. After that, we propose a multi-scale feature embedding loss function called MFE loss to reduce the intra-class distance and increase the inter-class distance, which contributes to the feature clustering in embedding space. Due to the lack of large-scale real-world datasets for desktop objects, the proposed TRF-Net is trained with the synthetic dataset and tested with the small-scale real-world dataset. The target objects in the testing dataset do not present in the training dataset, ensuring the novelty of testing objects. We demonstrate that our method can produce accurate instance segmentation masks, outperforming other state-of-the-art methods on desktop object instance segmentation. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.;Not health related;0"Ahn W.-J.; Kang G.; Choi H.-D.; Lim M.-T.";Domain adaptation for complex shadow removal with shadow transformer network;2023;Shadows observed in practical scenes have complex shapes, and removing them is a very challenging task in computer vision. In particular, previous studies on complex shadow removal have limitations in that they can be learned only on paired datasets. Taking the issues into consideration, we present a new domain-adaptive shadow removal framework. The proposed approach includes domain adaptation, detection, and removal stages. The shadow-preserving domain translator in the first stage compensates for the lack of real data through domain transformation of the synthetic data. In the second stage, efficient shadow detection is performed through the domain adaptive mean teacher network. Last, a novel attention network removes complex shadows using detected shadows as a query, effectively removing complex shadows. The feasibility and effectiveness of the proposed framework are validated through the newly collected Grand Theft Auto-Road Shadow dataset. The proposed method outperforms existing methods for quantitative and qualitative metrics related to shadow detection and removal. © 2023 Elsevier B.V.;Not health related;0"Osuala R.; Skorupko G.; Lazrak N.; Garrucho L.; García E.; Joshi S.; Jouide S.; Rutherford M.; Prior F.; Kushibar K.; Díaz O.; Lekadir K.";Medigan: A Python library of pretrained generative models for medical image synthesis;2023;Purpose: Deep learning has shown great promise as the backbone of clinical decision support systems. Synthetic data generated by generative models can enhance the performance and capabilities of data-hungry deep learning models. However, there is (1) limited availability of (synthetic) datasets and (2) generative models are complex to train, which hinders their adoption in research and clinical applications. To reduce this entry barrier, we explore generative model sharing to allow more researchers to access, generate, and benefit from synthetic data. Approach: We propose medigan, a one-stop shop for pretrained generative models implemented as an open-source framework-agnostic Python library. After gathering end-user requirements, design decisions based on usability, technical feasibility, and scalability are formulated. Subsequently, we implement medigan based on modular components for generative model (i) execution, (ii) visualization, (iii) search & ranking, and (iv) contribution. We integrate pretrained models with applications across modalities such as mammography, endoscopy, x-ray, and MRI. Results: The scalability and design of the library are demonstrated by its growing number of integrated and readily-usable pretrained generative models, which include 21 models utilizing nine different generative adversarial network architectures trained on 11 different datasets. We further analyze three medigan applications, which include (a) enabling community-wide sharing of restricted data, (b) investigating generative model evaluation metrics, and (c) improving clinical downstream tasks. In (b), we extract Fr chet inception distances (FID) demonstrating FID variability based on image normalization and radiology-specific feature extractors. Conclusion: medigan allows researchers and developers to create, increase, and domain-adapt their training data in just a few lines of code. Capable of enriching and accelerating the development of clinical machine learning models, we show medigan's viability as platform for generative model sharing. Our multimodel synthetic data experiments uncover standards for assessing and reporting metrics, such as FID, in image synthesis studies.  © The Authors. Published by SPIE under a Creative Commons Attribution 4.0 International License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.;Health related;1"Walton N.; Brown J.; Fritsch W.; Brown D.; Nobre G.; Sobes V.";Methodology for physics-informed generation of synthetic neutron time-of-flight measurement data;2024;Accurate neutron cross section data are a vital input to the simulation of nuclear systems for a wide range of applications from energy production to national security. The evaluation of experimental data is a key step in producing accurate cross sections. There is a widely recognized lack of reproducibility in the evaluation process due to its artisanal nature and therefore there is a call for improvement within the nuclear data community. This can be realized by automating/standardizing viable parts of the process, namely, parameter estimation by fitting theoretical models to experimental data. There are numerous candidate methods to approach this type of problem, but many rely on large, labeled datasets that are not accessible to the nuclear data evaluator. For a reaction cross-section, there are usually just a handful of datasets, none of which can be considered labeled because evaluators never have access to the exact solution (cross section). This work leverages problem-specific physics, Monte Carlo sampling, and a general methodology for data synthesis to generate unlimited, labeled experimental cross-section data of high-utility. The synthesized data is said to be of high-utility because it is statistically similar to the observed data. Heuristic and, where applicable, rigorous statistical comparisons to observed data support this claim. The methodology is split into two generative models. The first generates a realization of an energy-differential cross section for a given isotope. The second takes the output from the first as a determined input and generates noisy experimental observables (radiation detector signals) from the determined cross section realization. The latter is the primary development of this article and is based/limited to transmission measurements at Rensselaer Polytechnic Institute (RPI). The former leverages an existing method for model parameter sampling in the resolved resonance region (RRR), thus limiting the current demonstration to the RRR of incident neutron energies. An open-source software is published alongside this article that executes the complete methodology to produce high-utility synthetic datasets. The goal of this work is to provide an approach and corresponding tool that will allow the evaluation community to begin exploring more data-driven, ML-based solutions to long-standing challenges in the field. © 2023 Elsevier B.V.;Not health related;0"Yang G.; Kang G.; Lee J.; Cho Y.";Joint-ID: Transformer-Based Joint Image Enhancement and Depth Estimation for Underwater Environments;2024;Underwater imaging is a challenging task due to factors such as scattering, absorption, and turbulence, which degrade image quality and limit visibility. In this article, we propose a novel approach for enhancing underwater images that leverages the benefits of joint learning for simultaneous image enhancement and depth estimation. We introduce Joint-ID, a transformer-based neural network that can obtain high-perceptual image quality and depth information from raw underwater images. Our approach formulates a multimodal objective function that addresses invalid depth, lack of sharpness, and image degradation based on color and local texture. We design an end-to-end training pipeline that enables joint restoration and depth estimation in a shared hierarchical feature space. In addition, we propose a synthetic dataset with various distortions and scene depths for multitask learning. We evaluate Joint-ID on synthetic and standard datasets, as well as real underwater images with diverse spectra and harsh turbidity, demonstrating its effectiveness for underwater image enhancement (UIE) and depth estimation. Furthermore, we demonstrate the ability of Joint-ID to perform feature matching and saliency detection for visually guided underwater robots. Our proposed method has the potential to improve the visual perception of underwater environments and benefit applications such as oceanography and underwater robotics. Supplements are available at https://sites.google.com/view/joint-id/home.  © 2001-2012 IEEE.;Not health related;0"Dai M.; Zheng E.; Feng Z.; Qi L.; Zhuang J.; Yang W.";Vision-Based UAV Self-Positioning in Low-Altitude Urban Environments;2024;Unmanned Aerial Vehicles (UAVs) rely on satellite systems for stable positioning. However, due to limited satellite coverage or communication disruptions, UAVs may lose signals for positioning. In such situations, vision-based techniques can serve as an alternative, ensuring the self-positioning capability of UAVs. However, most of the existing datasets are developed for the geo-localization task of the objects captured by UAVs, rather than UAV self-positioning. Furthermore, the existing UAV datasets apply discrete sampling to synthetic data, such as Google Maps, neglecting the crucial aspects of dense sampling and the uncertainties commonly experienced in practical scenarios. To address these issues, this paper presents a new dataset, DenseUAV, that is the first publicly available dataset tailored for the UAV self-positioning task. DenseUAV adopts dense sampling on UAV images obtained in low-altitude urban areas. In total, over 27K UAV- and satellite-view images of 14 university campuses are collected and annotated. In terms of methodology, we first verify the superiority of Transformers over CNNs for the proposed task. Then we incorporate metric learning into representation learning to enhance the model's discriminative capacity and to reduce the modality discrepancy. Besides, to facilitate joint learning from both the satellite and UAV views, we introduce a mutually supervised learning approach. Last, we enhance the Recall@K metric and introduce a new measurement, SDM@K, to evaluate both the retrieval and localization performance for the proposed task. As a result, the proposed baseline method achieves a remarkable Recall@1 score of 83.01% and an SDM@1 score of 86.50% on DenseUAV. The dataset and code have been made publicly available on https://github.com/Dmmm1997/DenseUAV.  © 1992-2012 IEEE.;Not health related;0"Gwon H.; Ahn I.; Kim Y.; Kang H.J.; Seo H.; Choi H.; Cho H.N.; Kim M.; Han J.; Kee G.; Park S.; Lee K.H.; Jun T.J.; Kim Y.-H.";LDP-GAN : Generative adversarial networks with local differential privacy for patient medical records synthesis;2024;Electronic medical records(EMR) have considerable potential to advance healthcare technologies, including medical AI. Nevertheless, due to the privacy issues associated with the sharing of patient's personal information, it is difficult to sufficiently utilize them. Generative models based on deep learning can solve this problem by creating synthetic data similar to real patient data. However, the data used for training these deep learning models run into the risk of getting leaked because of malicious attacks. This means that traditional deep learning-based generative models cannot completely solve the privacy issues. Therefore, we suggested a method to prevent the leakage of training data by protecting the model from malicious attacks using local differential privacy(LDP). Our method was evaluated in terms of utility and privacy. Experimental results demonstrated that the proposed method can generate medical data with reasonable performance while protecting training data from malicious attacks. © 2023 Elsevier Ltd;Health related;1"Li P.; Quan W.; Guo J.; Yan D.-M.";Layout-aware Single-image Document Flattening;2023;Single image rectification of document deformation is a challenging task. Although some recent deep learning-based methods have attempted to solve this problem, they cannot achieve satisfactory results when dealing with document images with complex deformations. In this article, we propose a new efficient framework for document flattening. Our main insight is that most layout primitives in a document have rectangular outline shapes, making unwarping local layout primitives essentially homogeneous with unwarping the entire document. The former task is clearly more straightforward to solve than the latter due to the more consistent texture and relatively smooth deformation. On this basis, we propose a layout-aware deep model working in a divide-and-conquer manner. First, we employ a transformer-based segmentation module to obtain the layout information of the input document. Then a new regression module is applied to predict the global and local UV maps. Finally, we design an effective merging algorithm to correct the global prediction with local details. Both quantitative and qualitative experimental results demonstrate that our framework achieves favorable performance against state-of-the-art methods. In addition, the current publicly available document flattening datasets have limited 3D paper shapes without layout annotation and also lack a general geometric correction metric. Therefore, we build a new large-scale synthetic dataset by utilizing a fully automatic rendering method to generate deformed documents with diverse shapes and exact layout segmentation labels. We also propose a new geometric correction metric based on our paired document UV maps. Code and dataset will be released at https://github.com/BunnySoCrazy/LA-DocFlatten.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.;Not health related;0"Boelts J.; Harth P.; Gao R.; Udvary D.; Yáñez F.; Baum D.; Hege H.-C.; Oberlaender M.; Macke J.H.";Simulation-based inference for efficient identification of generative models in computational connectomics;2023;Recent advances in connectomics research enable the acquisition of increasing amounts of data about the connectivity patterns of neurons. How can we use this wealth of data to efficiently derive and test hypotheses about the principles underlying these patterns? A common approach is to simulate neuronal networks using a hypothesized wiring rule in a generative model and to compare the resulting synthetic data with empirical data. However, most wiring rules have at least some free parameters, and identifying parameters that reproduce empirical data can be challenging as it often requires manual parameter tuning. Here, we propose to use simulation-based Bayesian inference (SBI) to address this challenge. Rather than optimizing a fixed wiring rule to fit the empirical data, SBI considers many parametrizations of a rule and performs Bayesian inference to identify the parameters that are compatible with the data. It uses simulated data from multiple candidate wiring rule parameters and relies on machine learning methods to estimate a probability distribution (the ‘posterior distribution over parameters conditioned on the data’) that characterizes all data-compatible parameters. We demonstrate how to apply SBI in computational connectomics by inferring the parameters of wiring rules in an in silico model of the rat barrel cortex, given in vivo connectivity measurements. SBI identifies a wide range of wiring rule parameters that reproduce the measurements. We show how access to the posterior distribution over all data-compatible parameters allows us to analyze their relationship, revealing biologically plausible parameter interactions and enabling experimentally testable predictions. We further show how SBI can be applied to wiring rules at different spatial scales to quantitatively rule out invalid wiring hypotheses. Our approach is applicable to a wide range of generative models used in connectomics, providing a quantitative and efficient way to constrain model parameters with empirical connectivity data. Copyright: © 2023 Boelts et al.;Not health related;0"Chen D.; Qi X.; Zheng Y.; Lu Y.; Huang Y.; Li Z.";Synthetic data augmentation by diffusion probabilistic models to enhance weed recognition;2024;Weed management plays an important role in crop yield and quality protection. Conventional weed control methods largely rely on intensive, blanket herbicide application, which incurs significant management costs and poses hazards to the environment and human health. Machine vision-based automated weeding has gained increasing attention for sustainable weed management through weed recognition and site-specific treatments. However, it remains a challenging task to reliably recognize weeds in variable field conditions, in part due to the difficulty curating large-scale, expert-labeled weed image datasets for supervised training of weed recognition algorithms. Data augmentation methods, including traditional geometric/color transformations and more advanced generative adversarial networks (GANs) can supplement data collection and labeling efforts by algorithmically expanding the scale of datasets. Recently, diffusion models have emerged in the field of image synthesis, providing a new means for augmenting image datasets to power machine vision systems. This study presents a novel investigation of the efficacy of diffusion models for generating weed images to enhance weed identification. Experiments on two public multi-class large weed datasets showed that diffusion models yielded the best trade-off between sample fidelity and diversity and obtained the highest Fréchet Inception Distance, compared to GANs (BigGAN, StyleGAN2, StyleGAN3). For instance, on a ten-class weed dataset (CottonWeedID10), the inclusion of synthetic weed images led to improvements by 1.17% (97.30% to 98.47), 1.21% (97.92% to 99.13%), and 2.30% (96.06% to 98.27%) in accuracy, precision, and recall, respectively, in weed classification by four deep learning models (i.e., VGG16, Inception-v3, Inception-v3, and ResNet50). Models trained using only 10% of real images with the remainder being synthetic data resulted in testing accuracy exceeding 94%. © 2023;Health related;0"Boutros F.; Huber M.; Luu A.T.; Siebke P.; Damer N.";SFace2: Synthetic-Based Face Recognition With w-Space Identity-Driven Sampling;2024;The use of synthetic data for training neural networks has recently received increased attention, especially in the area of face recognition. This was mainly motivated by the increase of privacy, ethical, and legal concerns of using privacy-sensitive authentic data to train face recognition models. Many authentic datasets such as MS-Celeb-1M or VGGFace2 that have been widely used to train state-of-the-art deep face recognition models are retracted and officially no longer maintained or provided by official sources as they often have been collected without explicit consent. Toward this end, we first propose a synthetic face generation approach, SFace which utilizes a class-conditional generative adversarial network to generate class-labeled synthetic face images. To evaluate the privacy aspect of using such synthetic data in face recognition development, we provide an extensive evaluation of the identity relation between the generated synthetic dataset and the original authentic dataset used to train the generative model. The investigation proved that the associated identity of the authentic dataset to the one with the same class label in the synthetic dataset is hardly possible, strengthening the possibility for privacy-aware face recognition training. We then propose three different learning strategies to train the face recognition model on our privacy-friendly dataset, SFace, and report the results on five authentic benchmarks, demonstrating its high potential. Noticing the relatively low (in comparison to authentic data) identity discrimination in SFace, we started by analysing the w-space of the class-conditional generator, finding identity information that is highly correlated to that in the embedding space. Based on this finding, we proposed an approach that performs the sampling in the w-space driven to generate data with higher identity discrimination, the SFace2. Our experiments showed the disentanglement of the latent w-space and the benefit of training face recognition models on the more identity-discriminated synthetic dataset SFace2. IEEE;Not health related;0"Ghanadian H.; Nejadgholi I.; Osman H.A.";Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models;2024;Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation. © 2013 IEEE.;Not health related;0"Neo E.R.K.; Low J.S.C.; Goodship V.; Coles S.R.; Debattista K.";Cross-modal generative models for multi-modal plastic sorting;2023;Automated sorting through chemometric analysis of plastic spectral data could be a key strategy towards improving plastic waste management. Deep learning is a promising chemometric tool, but further development through multi-modal deep learning has been limited by lack of data availability. A new Multi-modal Plastic Spectral Database (MMPSD) consisting of Fourier Transform Infrared (FTIR), Raman and Laser-induced Breakdown Spectroscopy (LIBS) data for each sample in the database is introduced in this work. MMPSD serves as the basis for novel cross-modality generative model technique termed Spectral Conversion Autoencoders (SCAE), which generates synthetic data from data of another modality. SCAE is advantageous over traditional generative models like Variational Autoencoders (VAE), as it can generate class specific synthetic data without the need to train multiple models for each data class. MMPSD also facilitated the exploration of multi-modal deep learning, which improved the classification accuracy as compared to an uni-modal approach from 0.933 to 0.970. SCAE can further be combined with multi-modal methods to achieve a higher accuracy of 0.963 while still using a single sensor to reduce costs, which can be applied for multi-modal augmentation from FTIR sensors used in industrial sorting. © 2023 The Authors;Not health related;0"Qin D.; Amariucai G.T.; Qiao D.; Guan Y.; Fu S.";A comprehensive and reliable feature attribution method: Double-sided remove and reconstruct (DoRaR);2024;The limited transparency of the inner decision-making mechanism in deep neural networks (DNN) and other machine learning (ML) models has hindered their application in several domains. In order to tackle this issue, feature attribution methods have been developed to identify the crucial features that heavily influence decisions made by these black box models. However, many feature attribution methods have inherent downsides. For example, one category of feature attribution methods suffers from the artifacts problem, which feeds out-of-distribution masked inputs directly through the classifier that was originally trained on natural data points. Another category of feature attribution method finds explanations by using jointly trained feature selectors and predictors. While avoiding the artifacts problem, this new category suffers from the Encoding Prediction in the Explanation (EPITE) problem, in which the predictor's decisions rely not on the features, but on the masks that selects those features. As a result, the credibility of attribution results is undermined by these downsides. In this research, we introduce the Double-sided Remove and Reconstruct (DoRaR) feature attribution method based on several improvement methods that addresses these issues. By conducting thorough testing on MNIST, CIFAR10 and our own synthetic dataset, we demonstrate that the DoRaR feature attribution method can effectively bypass the above issues and can aid in training a feature selector that outperforms other state-of-the-art feature attribution methods. Our code is available at https://github.com/dxq21/DoRaR. © 2024 Elsevier Ltd;Not health related;0"He B.; Jahed Armaghani D.; Hin Lai S.; Samui P.; Tonnizam Mohamad E.";Applying data augmentation technique on blast-induced overbreak prediction: Resolving the problem of data shortage and data imbalance;2024;"Blast-induced overbreak in tunnels can cause severe damage and has therefore been a main concern in tunnel blasting. Researchers have developed many machine learning-based models to predict overbreak. Collecting overbreak data manually, however, can be challenging and might obtain insufficient or poorly structured data. Thus, this study aims to utilise a deep generative model, namely the Conditional Tabular Generative Adversarial Network (CTGAN), to establish an acceptable dataset for overbreak prediction. The CTGAN model was applied to overbreak data collected from paired tunnels: a left-line tunnel and a right-line tunnel. The overbreak dataset collected from the left-line tunnel—nominated as the true dataset—served to train the CTGAN model. Then the well-trained CTGAN model generated a synthetic overbreak dataset. Statistical-based approaches verified the similarity between the true and synthetic datasets; machine learning-based approaches verified the feasibility of using the synthetic dataset to train overbreak prediction model. Lastly, this study clarified how to resolve the problem of data shortage and data imbalance by leveraging the CTGAN model. The results evidence that the CTGAN model can effectively generate a high-quality synthetic overbreak dataset. The synthetic overbreak dataset not only greatly retains the properties of the true dataset but also effectively enhances its diversity. The way, integrating the true and synthetic overbreak datasets, can dramatically resolve the problem of data shortage and data imbalance in overbreak prediction. The findings in this study, therefore, highlight it as a promising perspective to resolve such a particular engineering problem. © 2023 Elsevier Ltd";Not health related;0"Barrere K.; Soullard Y.; Lemaitre A.; Coüasnon B.";Training transformer architectures on few annotated data: an application to historical handwritten text recognition;2024;Transformer-based architectures show excellent results on the task of handwritten text recognition, becoming the standard architecture for modern datasets. However, they require a significant amount of annotated data to achieve competitive results. They typically rely on synthetic data to solve this problem. Historical handwritten text recognition represents a challenging task due to degradations, specific handwritings for which few examples are available and ancient languages that vary over time. These limitations also make it difficult to generate realistic synthetic data. Given sufficient and appropriate data, Transformer-based architectures could alleviate these concerns, thanks to their ability to have a global view of textual images and their language modeling capabilities. In this paper, we propose the use of a lightweight Transformer model to tackle the task of historical handwritten text recognition. To train the architecture, we introduce realistic looking synthetic data reproducing the style of historical handwritings. We present a specific strategy, both for training and prediction, to deal with historical documents, where only a limited amount of training data are available. We evaluate our approach on the ICFHR 2018 READ dataset which is dedicated to handwriting recognition in specific historical documents. The results show that our Transformer-based approach is able to outperform existing methods. © 2024, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Zhu D.; Fu L.; Kazei V.; Li W.";Diffusion Model for DAS-VSP Data Denoising;2023;Distributed acoustic sensing (DAS) has emerged as a transformational technology for seismic data acquisition. However, noise remains a major impediment, necessitating advanced denoising techniques. This study pioneers the application of diffusion models, a type of generative model, for DAS vertical seismic profile (VSP) data denoising. The diffusion network is trained on a new generated synthetic dataset that accommodates variations in the acquisition parameters. The trained model is applied to suppress noise in synthetic and field DAS-VSP data. The results demonstrate the model's effectiveness in removing various noise types with minimal signal leakage, outperforming conventional methods. This research signifies diffusion models' potential for DAS processing.;Not health related;0"Khosravi B.; Rouzrokh P.; Mickley J.P.; Faghani S.; Mulford K.; Yang L.; Larson A.N.; Howe B.M.; Erickson B.J.; Taunton M.J.; Wyles C.C.";Few-shot biomedical image segmentation using diffusion models: Beyond image generation;2023;"Background: Medical image analysis pipelines often involve segmentation, which requires a large amount of annotated training data, which is time-consuming and costly. To address this issue, we proposed leveraging generative models to achieve few-shot image segmentation. Methods: We trained a denoising diffusion probabilistic model (DDPM) on 480,407 pelvis radiographs to generate 256 _ 256 px synthetic images. The DDPM was conditioned on demographic and radiologic characteristics and was rigorously validated by domain experts and objective image quality metrics (Frechet inception distance [FID] and inception score [IS]). For the next step, three landmarks (greater trochanter [GT], lesser trochanter [LT], and obturator foramen [OF]) were annotated on 45 real-patient radiographs; 25 for training and 20 for testing. To extract features, each image was passed through the pre-trained DDPM at three timesteps and for each pass, features from specific blocks were extracted. The features were concatenated with the real image to form an image with 4225 channels. The feature-set was broken into random patches, which were fed to a U-Net. Dice Similarity Coefficient (DSC) was used to compare the performance with a vanilla U-Net trained on radiographs. Results: Expert accuracy was 57.5 % in determining real versus generated images, while the model reached an FID = 7.2 and IS = 210. The segmentation UNet trained on the 20 feature-sets achieved a DSC of 0.90, 0.84, and 0.61 for OF, GT, and LT segmentation, respectively, which was at least 0.30 points higher than the naively trained model. Conclusion: We demonstrated the applicability of DDPMs as feature extractors, facilitating medical image segmentation with few annotated samples. © 2023 Elsevier B.V.";Health related;1"Li D.; Zhang Y.; Yang Z.; Jin Y.; Xu Y.";Sensing anomaly of photovoltaic systems with sequential conditional variational autoencoder;2024;The market for urban distributed photovoltaics (DPV) is expected to take off in the next decade. However, these systems are often subject to complex urban contexts and sub-optimal conditions, requiring scalable and comprehensive solutions to detect their underperformances. In recent years, deep generative models (DGMs) have exhibited outstanding performance in the anomaly detection domain, dealing with generic high-dimensional time series data. Nevertheless, the existing applications of DGMs in the photovoltaic (PV) sector are still unable to account for environmental information, limiting their performance under various environmental conditions. This study proposes the Sequential Conditional Variational Autoencoder (SCVAE), which can cope with the sequential impacts of the environment on PV power generation. Using real-world data collected from 30 rooftop PV sites located across China, a data processing pipeline is developed to construct the training datasets which contain mostly normal samples for unsupervised SCVAE model training. This work also constructs a synthetic dataset with a wide variety of artificial anomalies in reference to the domain insights and engineering practice of DPV systems. After checking and refining by experts, the synthetic dataset can finally be used to validate the anomaly detection models. The results demonstrate that the SCVAE model outperforms existing state-of-the-art unsupervised anomaly detection models and can be effectively generalized to unseen PV sites. Moreover, the latent variables of SCVAE could be used to identify the type of DPV failure, thereby enabling more targeted diagnostics of anomaly mechanisms. © 2023 Elsevier Ltd;Not health related;0"Dudas D.; Dilling T.J.; El Naqa I.";Improved outcome models with denoising diffusion;2024;Purpose: Radiotherapy outcome modelling often suffers from class imbalance in the modelled endpoints. One of the main options to address this issue is by introducing new synthetically generated datapoints, using generative models, such as Denoising Diffusion Probabilistic Models (DDPM). In this study, we implemented DDPM to improve performance of a tumor local control model, trained on imbalanced dataset, and compare this approach with other common techniques. Methods: A dataset of 535 NSCLC patients treated with SBRT (50 Gy/5 fractions) was used to train a deep learning outcome model for tumor local control prediction. The dataset included complete treatment planning data (planning CT images, 3D planning dose distribution and patient demographics) with sparsely distributed endpoints (6–7 % experiencing local failure). Consequently, we trained a novel conditional 3D DDPM model to generate synthetic treatment planning data. Synthetically generated treatment planning datapoints were used to supplement the real training dataset and the improvement in the model's performance was studied. Obtained results were also compared to other common techniques for class imbalanced training, such as Oversampling, Undersampling, Augmentation, Class Weights, SMOTE and ADASYN. Results: Synthetic DDPM-generated data were visually trustworthy, with Fréchet inception distance (FID) below 50. Extending the training dataset with the synthetic data improved the model's performance by more than 10%, while other techniques exhibited only about 4% improvement. Conclusions: DDPM introduces a novel approach to class-imbalanced outcome modelling problems. The model generates realistic synthetic radiotherapy planning data, with a strong potential to increase performance and robustness of outcome models. © 2024 Associazione Italiana di Fisica Medica e Sanitaria;Not health related;0"Sapai S.; Loo J.Y.; Ding Z.Y.; Tan C.P.; Baskaran V.M.; Nurzaman S.G.";A Deep Learning Framework for Soft Robots with Synthetic Data;2023;Data-driven methods with deep neural networks demonstrate promising results for accurate modeling in soft robots. However, deep neural network models rely on voluminous data in discovering the complex and nonlinear representations inherent in soft robots. Consequently, while it is not always possible, a substantial amount of effort is required for data acquisition, labeling, and annotation. This article introduces a data-driven learning framework based on synthetic data to circumvent the exhaustive data collection process. More specifically, we propose a novel time series generative adversarial network with a self-attention mechanism, Transformer TimeGAN (TTGAN) to precisely learn the complex dynamics of a soft robot. On top of that, the TTGAN is incorporated with a conditioning network that enables it to produce synthetic data for specific soft robot behaviors. The proposed framework is verified on a widely used pneumatic-based soft gripper as an exemplary experimental setup. Experimental results demonstrate that the TTGAN generates synthetic time series data with realistic soft robot dynamics. Critically, a combination of the synthetic and only partially available original data produces a data-driven model with estimation accuracy comparable to models obtained from using complete original data. © Mary Ann Liebert, Inc.;Not health related;0"Yang A.; Lu C.; Yu W.; Hu J.; Nakanishi Y.; Wu M.";Data Augmentation Considering Distribution Discrepancy for Fault Diagnosis of Drilling Process With Limited Samples;2023;The fault diagnosis during drilling is necessary to prevent the accidents develop to more serious status. Data-driven diagnosis methods have great advantages in nonlinear industrial process, however, the problem of limited samples restricts its further application. This article proposes a data augmentation method based on synthetic data generation and updating for drilling fault diagnosis with limited samples. First, the generator is trained with generative adversarial nets (GAN), and the GAN is improved by the design of parameter selection module, and loss function in generative model. Then, sufficient samples are obtained, and a balanced dataset is constructed for modeling. Meanwhile, by considering the distribution discrepancy, the self-organizing incremental neural network-based synthetic data updating is realized to track the changes of data distribution when the data drift appears. Finally, the actual data acquired from two wells are employed for the method validation. The experimental results illustrate that the proposed method is helpful for improving the performance of diagnosis model with limited samples, and the negative impact to diagnosis model due to the distribution discrepancy also can be overcome. © 1982-2012 IEEE.;Health related;0"Annys A.; Jannis D.; Verbeeck J.";Deep learning for automated materials characterisation in core-loss electron energy loss spectroscopy;2023;Electron energy loss spectroscopy (EELS) is a well established technique in electron microscopy that yields information on the elemental content of a sample in a very direct manner. One of the persisting limitations of EELS is the requirement for manual identification of core-loss edges and their corresponding elements. This can be especially bothersome in spectrum imaging, where a large amount of spectra are recorded when spatially scanning over a sample area. This paper introduces a synthetic dataset with 736,000 labeled EELS spectra, computed from available generalized oscillator strength tables, that represents 107 K, L, M or N core-loss edges and 80 chemical elements. Generic lifetime broadened peaks are used to mimic the fine structure due to band structure effects present in experimental core-loss edges. The proposed dataset is used to train and evaluate a series of neural network architectures, being a multilayer perceptron, a convolutional neural network, a U-Net, a residual neural network, a vision transformer and a compact convolutional transformer. An ensemble of neural networks is used to further increase performance. The ensemble network is used to demonstrate fully automated elemental mapping in a spectrum image, both by directly mapping the predicted elemental content and by using the predicted content as input for a physical model-based mapping. © 2023, Springer Nature Limited.;Not health related;0"Park H.; Li B.; Liu Y.; Nelson M.S.; Wilson H.M.; Sifakis E.; Eliceiri K.W.";Collagen fiber centerline tracking in fibrotic tissue via deep neural networks with variational autoencoder-based synthetic training data generation;2023;The role of fibrillar collagen in the tissue microenvironment is critical in disease contexts ranging from cancers to chronic inflammations, as evidenced by many studies. Quantifying fibrillar collagen organization has become a powerful approach for characterizing the topology of collagen fibers and studying the role of collagen fibers in disease progression. We present a deep learning-based pipeline to quantify collagen fibers’ topological properties in microscopy-based collagen images from pathological tissue samples. Our method leverages deep neural networks to extract collagen fiber centerlines and deep generative models to create synthetic training data, addressing the current shortage of large-scale annotations. As a part of this effort, we have created and annotated a collagen fiber centerline dataset, with the hope of facilitating further research in this field. Quantitative measurements such as fiber orientation, alignment, density, and length can be derived based on the centerline extraction results. Our pipeline comprises three stages. Initially, a variational autoencoder is trained to generate synthetic centerlines possessing controllable topological properties. Subsequently, a conditional generative adversarial network synthesizes realistic collagen fiber images from the synthetic centerlines, yielding a synthetic training set of image–centerline pairs. Finally, we train a collagen fiber centerline extraction network using both the original and synthetic data. Evaluation using collagen fiber images from pancreas, liver, and breast cancer samples collected via second-harmonic generation microscopy demonstrates our pipeline's superiority over several popular fiber centerline extraction tools. Incorporating synthetic data into training further enhances the network's generalizability. Our code is available at https://github.com/uw-loci/collagen-fiber-metrics. © 2023 Elsevier B.V.;Health related;1"Boutin R.; Bouveyron C.; Latouche P.";Embedded topics in the stochastic block model;2023;Communication networks such as emails or social networks are now ubiquitous and their analysis has become a strategic field. In many applications, the goal is to automatically extract relevant information by looking at the nodes and their connections. Unfortunately, most of the existing methods focus on analysing the presence or absence of edges and textual data is often discarded. However, all communication networks actually come with textual data on the edges. In order to take into account this specificity, we consider in this paper networks for which two nodes are linked if and only if they share textual data. We introduce a deep latent variable model allowing embedded topics to be handled called ETSBM to simultaneously perform clustering on the nodes while modelling the topics used between the different clusters. ETSBM extends both the stochastic block model (SBM) and the embedded topic model (ETM) which are core models for studying networks and corpora, respectively. The inference is done using a variational-Bayes expectation-maximisation algorithm combined with a stochastic gradient descent. The methodology is evaluated on synthetic data and on a real world dataset. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.;Not health related;0"Alshantti A.; Varagnolo D.; Rasheed A.; Rahmati A.; Westad F.";CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis;2024;Generative adversarial networks (GANs) have drawn considerable attention in recent years for their proven capability in generating synthetic data which can be utilised for multiple purposes. While GANs have demonstrated tremendous successes in producing synthetic data samples that replicate the dynamics of the original datasets, the validity of the synthetic data and the underlying privacy concerns represent major challenges which are not sufficiently addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN) for generating realistic tabular data with a specific focus on the validity of the output. In this context, validity refers to the the dependency between features that can be found in the real data, but is typically misrepresented by traditional generative models. Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data. Our experimental results demonstrate that our model is capable of generating synthetic tabular data that can be used for fitting machine learning models, as CasTGAN's classification performance only falls under the real training data's PR-AUC score by 4.88% on average for classification datasets, and exhibits an average reduction of the real training data's $R^{2}$ score by 0.139 for regression datasets. In addition, our model captures well the constraints and the correlations between the features of the real data, especially the high dimensional datasets. Assessing the generation of invalid records demonstrates that CasTGAN reduces the number of invalid data observations by up to 622% in comparison to the second best performing baseline tabular GAN model. Furthermore, we evaluate the risk of white-box privacy attacks on our model and subsequently show that applying some perturbations to the auxiliary learners in CasTGAN increases the overall robustness of our model against targeted attacks.  © 2013 IEEE.;Not health related;0"Yan A.; Hou R.; Yan H.; Liu X.";Explanation-based data-free model extraction attacks;2023;Deep learning (DL) has dramatically pushed the previous limits of various tasks, ranging from computer vision to natural language processing. Despite its success, the lack of model explanations thwarts the usage of these techniques in life-critical domains, e.g., medical diagnosis and self-driving systems. To date, the core technology to solve the explainable issue is explainable artificial intelligence (XAI). XAI methods have been developed to produce human-understandable explanations by leveraging intermediate results of the DL models, e.g., gradients and model parameters. While the effectiveness of XAI methods has been demonstrated in benign environments, their privacy against model extraction attacks (i.e., attacks at the model confidentially) requires to be studied. To this end, this paper proposes DMEAE, a data-free model extraction attack using explanation-guided, to explore XAI privacy threats. Compared with previous works, DMEAE does not require collecting any data and utilizes model explanation loss. Specifically, DMEAE creates synthetic data using a generative model with model explanation loss items. Extensive evaluations verify the effectiveness and efficiency of the proposed attack strategy on SVHN and CIFAR-10 datasets. We hope that our research can provide insights for the development of practical tools to trade off the relationship between privacy and model explanations. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.;Health related;0"Wang Y.; Xiong J.; Yan X.; Wei M.";USCFormer: Unified Transformer With Semantically Contrastive Learning for Image Dehazing;2023;Haze severely degrades the visibility of scene objects and deteriorates the performance of autonomous driving, traffic monitoring, and other vision-based intelligent transportation systems. As a potential remedy, we propose a novel unified Transformer with semantically contrastive learning for image dehazing, dubbed USCFormer. USCFormer has three key contributions. First, USCFormer absorbs the respective strengths of CNN and Transformer by incorporating them into a unified Transformer format. Thus, it allows the simultaneous capture of global-local dependency features for better image dehazing. Second, by casting clean/hazy images as the positive/negative samples, the contrastive constraint encourages the restored image to be closer to the ground-truth images (positives) and away from the hazy ones (negatives). Third, we regard the semantic information as important prior knowledge to help USCFormer mitigate the effects of haze on the scene and preserve image details and colors by leveraging intra-object semantic correlation. Experiments on synthetic datasets and real-world hazy photos fully validate the superiority of USCFormer in both perceptual quality assessment and subjective evaluation. Code is available at https://github.com/yz-wang/USCFormer.  © 2000-2011 IEEE.;Not health related;0"Silva W.N.; Bandória L.H.T.; Dias B.H.; de Almeida M.C.; de Oliveira L.W.";Generating realistic load profiles in smart grids: An approach based on nonlinear independent component estimation (NICE) and convolutional layers;2023;The utilization of energy consumption data is crucial for efficient operation and planning in smart grids. Nonetheless, certain obstacles need to be addressed, such as high computational costs, data security and privacy concerns, and significant expenses associated with installing smart meters across the electrical grid. To address these challenges, generating synthetic data has emerged as a promising approach, providing an opportunity to enhance energy efficiency, demand flexibility, and power grid operation. Therefore, this study proposes a nonlinear model of independent component estimation (NICE) with convolutional layers to produce realistic load profiles. This research aims to evaluate the potential of deep generative models (DGMs) through the characterization and quantification of electricity consumption profiles obtained from an actual smart grid on a university campus. The Kullback–Leibler divergence is used to evaluate the performance of the proposed model. Simulation results show that the proposed model can accurately capture the spatiotemporal correlation of actual samples, leading to synthetic load profiles that closely resemble actual profiles. The performance of the proposed NICE model is compared with a NICE model with dense layers, as well as with Generative Adversarial Networks (GAN) with dense layers, and GAN with convolutional layers (cGAN), all methods previously used in the literature to generate synthetic load profiles. It was observed that the proposed NICE model with convolutional layers leads to better results. This model produces more significant similarity between the probability distributions of actual and synthetic data, in addition to a more extraordinary ability to reproduce more realistic load variability curves. © 2023 Elsevier Ltd;Not health related;0"Yuan Y.; Xia G.; Zhang X.; Zhou C.";Synthesis-Style Auto-Correlation-Based Transformer: A Learner on Ionospheric TEC Series Forecasting;2023;Accurate 1-day global total electron content (TEC) forecasting is essential for ionospheric monitoring and satellite communications. However, it faces challenges due to limited data and difficulty in modeling long-term dependencies. This study develops a highly accurate model for 1-day global TEC forecasting. We utilized generative TEC data augmentation based on the International Global Navigation Satellite Service (IGS) data set from 1998 to 2017 to enhance the model's prediction ability. Our model takes the TEC sequence of the previous 2 days as input and predicts the global TEC value for each hourly step of the next day. We compared the performance of our model with 1-day predicted ionospheric products provided by both the Center for Orbit Determination in Europe (C1PG) and Beihang University (B1PG). We proposed a two-step framework: (a) a time series generative model to produce realistic synthetic TEC data for training, and (b) an auto-correlation-based transformer model designed to capture long-range dependencies in the TEC sequence. Experiments demonstrate that our model significantly improves 1-day forecast accuracy over prior approaches. On the 2018 benchmark data set, the global root mean squared error (RMSE) of our model is reduced to 1.17 TEC units (TECU), while the RMSE of the C1PG model is 2.07 TECU. Reliability is higher in middle and high latitudes but lower in low latitudes (RMSE < 2.5 TECU), indicating room for improvement. This study highlights the potential of using data augmentation and auto-correlation-based transformer models trained on synthetic data to achieve high-quality 1-day global TEC forecasting. © 2023 The Authors.;Not health related;0"Hemateja A.V.N.M.; Kondakath G.; Das S.; Kothandaraman M.; Shoba S.; Pandey A.; Babu R.; Jain A.";Novel data augmentation for named entity recognition;2023;Named entity recognition (NER) is a crucial Natural language processing (NLP) task used in applications like voice assistants, search engines, customer support, etc. A lack of entities relevant to the use case makes the available datasets insufficient for training. Data augmentation is a method in which synthetic data is fabricated from existing data to enhance the existing dataset. The existing data augmentation methods do not consider the grammatical and logical correctness of the fabricated sentences, resulting in a decrease in the performance of transformer-based NER models. This paper proposes a novel data augmentation method with a sanity-checker that checks the correctness of the augmented sentences and produces augmented data that improves the performance of transformer-based NER models. When the proposed augmentation algorithm was tested with the CoNLL-2003 dataset, a significant increase in the F1 score of BERT based NER from 94.73 to 95.37% and RoBERTa based NER from 94.13 to 95.14% was observed. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.;Not health related;0"Yoon J.; Mizrahi M.; Ghalaty N.F.; Jarvinen T.; Ravi A.S.; Brune P.; Kong F.; Anderson D.; Lee G.; Meir A.; Bandukwala F.; Kanal E.; Arık S.Ö.; Pfister T.";EHR-Safe: generating high-fidelity and privacy-preserving synthetic electronic health records;2023;Privacy concerns often arise as the key bottleneck for the sharing of data between consumers and data holders, particularly for sensitive data such as Electronic Health Records (EHR). This impedes the application of data analytics and ML-based innovations with tremendous potential. One promising approach for such privacy concerns is to instead use synthetic data. We propose a generative modeling framework, EHR-Safe, for generating highly realistic and privacy-preserving synthetic EHR data. EHR-Safe is based on a two-stage model that consists of sequential encoder-decoder networks and generative adversarial networks. Our innovations focus on the key challenging aspects of real-world EHR data: heterogeneity, sparsity, coexistence of numerical and categorical features with distinct characteristics, and time-varying features with highly-varying sequence lengths. Under numerous evaluations, we demonstrate that the fidelity of EHR-Safe is almost-identical with real data (<3% accuracy difference for the models trained on them) while yielding almost-ideal performance in practical privacy metrics. © 2023, Springer Nature Limited.;Health related;1"Buoy R.; Iwamura M.; Srun S.; Kise K.";Explainable Connectionist-Temporal-Classification-Based Scene Text Recognition;2023;Connectionist temporal classification (CTC) is a favored decoder in scene text recognition (STR) for its simplicity and efficiency. However, most CTC-based methods utilize one-dimensional (1D) vector sequences, usually derived from a recurrent neural network (RNN) encoder. This results in the absence of explainable 2D spatial relationship between the predicted characters and corresponding image regions, essential for model explainability. On the other hand, 2D attention-based methods enhance recognition accuracy and offer character location information via cross-attention mechanisms, linking predictions to image regions. However, these methods are more computationally intensive, compared with the 1D CTC-based methods. To achieve both low latency and model explainability via character localization using a 1D CTC decoder, we propose a marginalization-based method that processes 2D feature maps and predicts a sequence of 2D joint probability distributions over the height and class dimensions. Based on the proposed method, we newly introduce an association map that aids in character localization and model prediction explanation. This map parallels the role of a cross-attention map, as seen in computationally-intensive attention-based architectures. With the proposed method, we consider a ViT-CTC STR architecture that uses a 1D CTC decoder and a pretrained vision Transformer (ViT) as a 2D feature extractor. Our ViT-CTC models were trained on synthetic data and fine-tuned on real labeled sets. These models outperform the recent state-of-the-art (SOTA) CTC-based methods on benchmarks in terms of recognition accuracy. Compared with the baseline Transformer-decoder-based models, our ViT-CTC models offer a speed boost up to 12 times regardless of the backbone, with a maximum 3.1% reduction in total word recognition accuracy. In addition, both qualitative and quantitative assessments of character locations estimated from the association map align closely with those from the cross-attention map and ground-truth character-level bounding boxes. © 2023 by the authors.;Not health related;0"Pahari N.; Shimada K.";Layer Configurations of BERT for Multitask Learning and Data Augmentation;2024;Multitask learning (MTL) and data augmentation are becoming increasingly popular in natural language processing (NLP). These techniques are particularly useful when data are scarce. In MTL, knowledge learned from one task is applied to another. To address data scarcity, data augmentation facilitates by providing additional synthetic data during model training. In NLP, the bidirectional encoder representations from transformers (BERT) model is the default candidate for various tasks. MTL and data augmentation using BERT have yielded promising results. However, a detailed study regarding the effect of using MTL in different layers of BERT and the benefit of data augmentation in these configurations has not been conducted. In this study, we investigate the use of MTL and data augmentation from generative models, specifically for category classification, sentiment classification, and aspect-opinion sequence-labeling using BERT. The layers of BERT are categorized into top, middle, and bottom layers, which are frozen, shared, or unshared. Experiments are conducted to identify the optimal layer configuration for improved performance compared with that of single-task learning. Generative models are used to generate augmented data, and experiments are performed to reveal their effectiveness. The results indicate the effectiveness of the MTL configuration compared with single-task learning as well as the effectiveness of data augmentation using generative models for classification tasks. © 2024 Fuji Technology Press. All rights reserved.;Not health related;0"Skondras P.; Zervas P.; Tzimas G.";Generating Synthetic Resume Data with Large Language Models for Enhanced Job Description Classification †;2023;In this article, we investigate the potential of synthetic resumes as a means for the rapid generation of training data and their effectiveness in data augmentation, especially in categories marked by sparse samples. The widespread implementation of machine learning algorithms in natural language processing (NLP) has notably streamlined the resume classification process, delivering time and cost efficiencies for hiring organizations. However, the performance of these algorithms depends on the abundance of training data. While selecting the right model architecture is essential, it is also crucial to ensure the availability of a robust, well-curated dataset. For many categories in the job market, data sparsity remains a challenge. To deal with this challenge, we employed the OpenAI API to generate both structured and unstructured resumes tailored to specific criteria. These synthetically generated resumes were cleaned, preprocessed and then utilized to train two distinct models: a transformer model (BERT) and a feedforward neural network (FFNN) that incorporated Universal Sentence Encoder 4 (USE4) embeddings. While both models were evaluated on the multiclass classification task of resumes, when trained on an augmented dataset containing 60 percent real data (from Indeed website) and 40 percent synthetic data from ChatGPT, the transformer model presented exceptional accuracy. The FFNN, albeit predictably, achieved lower accuracy. These findings highlight the value of augmented real-world data with ChatGPT-generated synthetic resumes, especially in the context of limited training data. The suitability of the BERT model for such classification tasks further reinforces this narrative. © 2023 by the authors.;Not health related;0"Qiu S.; Cai B.; Wang W.; Wang J.; Zaheer Q.; Liu X.; Hu W.; Peng J.";Automated detection of railway defective fasteners based on YOLOv8-FAM and synthetic data using style transfer;2024;Fastener damage detection is an integral component of track safety inspections. The lack of balanced dataset caused by insufficient data on defective fasteners poses a significant challenge to the current development of robust fastener detection models. This study proposes the YOLOv8-FAM detection model algorithm, which combines the enhanced capabilities of YOLOv8, and generates realistic images of defective fasteners by performing style transfer on masked images of non-defective fasteners, thereby creating a balanced dataset for training the detection model. Experimental results show that the defect detection accuracy of YOLOv8-FAM improves by 8% compared to the original model, while also reducing the data acquisition cost by 40%. The YOLOv8-FAM model surpasses existing models in detecting defective fasteners while minimizing inference costs to the maximum extent. The proposed style transfer data synthesis method drives the practical deployment of deep learning, offering an efficient and cost-effective solution for the transportation infrastructure industry. © 2024 Elsevier B.V.;Not health related;0"Helmer M.; Warrington S.; Mohammadi-Nejad A.-R.; Ji J.L.; Howell A.; Rosand B.; Anticevic A.; Sotiropoulos S.N.; Murray J.D.";On the stability of canonical correlation analysis and partial least squares with application to brain-behavior associations;2024;"Associations between datasets can be discovered through multivariate methods like Canonical Correlation Analysis (CCA) or Partial Least Squares (PLS). A requisite property for interpretability and generalizability of CCA/PLS associations is stability of their feature patterns. However, stability of CCA/PLS in high-dimensional datasets is questionable, as found in empirical characterizations. To study these issues systematically, we developed a generative modeling framework to simulate synthetic datasets. We found that when sample size is relatively small, but comparable to typical studies, CCA/PLS associations are highly unstable and inaccurate; both in their magnitude and importantly in the feature pattern underlying the association. We confirmed these trends across two neuroimaging modalities and in independent datasets with n ≈ 1000 and n = 20,000, and found that only the latter comprised sufficient observations for stable mappings between imaging-derived and behavioral features. We further developed a power calculator to provide sample sizes required for stability and reliability of multivariate analyses. Collectively, we characterize how to limit detrimental effects of overfitting on CCA/PLS stability, and provide recommendations for future studies. © The Author(s) 2024.";Not health related;0"Yuan J.; Chen T.; Shen Z.; Li B.; Xue X.";Unsupervised Object-Centric Learning From Multiple Unspecified Viewpoints;2024;"Visual scenes are extremely diverse, not only because there are infinite possible combinations of objects and backgrounds but also because the observations of the same scene may vary greatly with the change of viewpoints. When observing a multi-object visual scene from multiple viewpoints, humans can perceive the scene compositionally from each viewpoint while achieving the so-called &#x201C;object constancy&#x201D; across different viewpoints, even though the exact viewpoints are untold. This ability is essential for humans to identify the same object while moving and to learn from vision efficiently. It is intriguing to design models that have a similar ability. In this paper, we consider a novel problem of learning compositional scene representations from multiple unspecified (i.e., unknown and unrelated) viewpoints without using any supervision and propose a deep generative model which separates latent representations into a viewpoint-independent part and a viewpoint-dependent part to solve this problem. During the inference, latent representations are randomly initialized and iteratively updated by integrating the information in different viewpoints with neural networks. Experiments on several specifically designed synthetic datasets have shown that the proposed method can effectively learn from multiple unspecified viewpoints. IEEE";Not health related;0"Hou Y.; Kang B.; Mitchell A.; Wang W.; Kang J.; Botteldooren D.";Cooperative Scene-Event Modelling for Acoustic Scene Classification;2024;Acoustic scene classification (ASC) can be helpful for creating context awareness for intelligent robots. Humans naturally use the relations between acoustic scenes (AS) and audio events (AE) to understand and recognize their surrounding environments. However, in most previous works, ASC and audio event classification (AEC) are treated as independent tasks, with a focus primarily on audio features shared between scenes and events, but not their implicit relations. To address this limitation, we propose a cooperative scene-event modelling (cSEM) framework to automatically model the intricate scene-event relation by an adaptive coupling matrix to improve ASC. Compared with other scene-event modelling frameworks, the proposed cSEM offers the following advantages. First, it reduces the confusion between similar scenes by aligning the information of coarse-grained AS and fine-grained AE in the latent space, and reducing the redundant information between the AS and AE embeddings. Second, it exploits the relation information between AS and AE to improve ASC, which is shown to be beneficial, even if the information of AE is derived from unverified pseudo-labels. Third, it uses a regression-based loss function for cooperative modelling of scene-event relations, which is shown to be more effective than classification-based loss functions. Instantiated from four models based on either Transformer or convolutional neural networks, cSEM is evaluated on real-life and synthetic datasets. Experiments show that cSEM-based models work well in real-life scene-event analysis, offering competitive results on ASC as compared with other multi-feature or multi-model ensemble methods. The ASC accuracy achieved on the TUT2018, TAU2019, and JSSED datasets is 81.0%, 88.9% and 97.2%, respectively. © 2023 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.;Not health related;0"Dedhia B.; Balasubramanian R.; Jha N.K.";SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for Actionable Healthcare;2023;The synthetic control method has pioneered a class of powerful data-driven techniques to estimate the counterfactual reality of a unit from donor units. At its core, the technique involves a linear model fitted on the pre-intervention period that combines donor outcomes to yield the counterfactual. However, linearly combining spatial information at each time instance using time-agnostic weights fails to capture important inter-unit and intra-unit temporal contexts and complex nonlinear dynamics of real data. We instead propose an approach to use local spatiotemporal information before the onset of the intervention as a promising way to estimate the counterfactual sequence. To this end, we suggest a Transformer model that leverages particular positional embeddings, a modified decoder attention mask, and a novel pre-training task to perform spatiotemporal sequence-to-sequence modeling. Our experiments on synthetic data demonstrate the efficacy of our method in the typical small donor pool setting and its robustness against noise. We also generate actionable healthcare insights at the population and patient levels by simulating a state-wide public health policy to evaluate its effectiveness, an in silico trial for asthma medications to support randomized controlled trials, and a medical intervention for patients with Friedreich's ataxia to improve clinical decision making and promote personalized therapy (code is available at https://github.com/JHA-Lab/scout).  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.;Health related;1"Loizillon S.; Bottani S.; Maire A.; Ströer S.; Dormont D.; Colliot O.; Burgos N.";Automatic motion artefact detection in brain T1-weighted magnetic resonance images from a clinical data warehouse using synthetic data;2024;Containing the medical data of millions of patients, clinical data warehouses (CDWs) represent a great opportunity to develop computational tools. Magnetic resonance images (MRIs) are particularly sensitive to patient movements during image acquisition, which will result in artefacts (blurring, ghosting and ringing) in the reconstructed image. As a result, a significant number of MRIs in CDWs are corrupted by these artefacts and may be unusable. Since their manual detection is impossible due to the large number of scans, it is necessary to develop tools to automatically exclude (or at least identify) images with motion in order to fully exploit CDWs. In this paper, we propose a novel transfer learning method from research to clinical data for the automatic detection of motion in 3D T1-weighted brain MRI. The method consists of two steps: a pre-training on research data using synthetic motion, followed by a fine-tuning step to generalise our pre-trained model to clinical data, relying on the labelling of 4045 images. The objectives were both (1) to be able to exclude images with severe motion, (2) to detect mild motion artefacts. Our approach achieved excellent accuracy for the first objective with a balanced accuracy nearly similar to that of the annotators (balanced accuracy>80 %). However, for the second objective, the performance was weaker and substantially lower than that of human raters. Overall, our framework will be useful to take advantage of CDWs in medical imaging and highlight the importance of a clinical validation of models trained on research data. © 2023;Health related;1"Li P.; Zhao J.; Wu J.; Deng C.; Han Y.; Wang H.; Yu T.";OPAL: Occlusion Pattern Aware Loss for Unsupervised Light Field Disparity Estimation;2024;Light field disparity estimation is an essential task in computer vision. Currently, supervised learning-based methods have achieved better performance than both unsupervised and optimization-based methods. However, the generalization capacity of supervised methods on real-world data, where no ground truth is available for training, remains limited. In this paper, we argue that unsupervised methods can achieve not only much stronger generalization capacity on real-world data but also more accurate disparity estimation results on synthetic datasets. To fulfill this goal, we present the Occlusion Pattern Aware Loss, named OPAL, which successfully extracts and encodes general occlusion patterns inherent in the light field for calculating the disparity loss. OPAL enables: i) accurate and robust disparity estimation by teaching the network how to handle occlusions effectively and ii) significantly reduced network parameters required for accurate and efficient estimation. We further propose an EPI transformer and a gradient-based refinement module for achieving more accurate and pixel-aligned disparity estimation results. Extensive experiments demonstrate our method not only significantly improves the accuracy compared with SOTA unsupervised methods, but also possesses stronger generalization capacity on real-world data compared with SOTA supervised methods. Last but not least, the network training and inference efficiency are much higher than existing learning-based methods. Our code will be made publicly available.  © 1979-2012 IEEE.;Not health related;0"Liu B.; Fang S.";Multi-level wavelet network based on CNN-Transformer hybrid attention for single image deraining;2023;Removing rain streaks from rainy images can improve the accuracy of computer vision applications such as object detection. In order to make full use of the frequency domain analysis characteristics of wavelet and combine the advantages of Convolutional Neural Network (CNN) and Transformer, a Multi-level Wavelet Network Based on CNN-Transformer Hybrid Attention (MWN-CTHA) for single image deraining is proposed. MWN-CTHA obtains multi-scale low-frequency and high-frequency images through multi-level non-separable lifting wavelet transform and uses CNN-Transformer Hybrid Attention Block (CTHAB) to learn global structure and detail information from low-frequency and high-frequency, respectively. CTHAB consists of CA-SA Layer (CSL) and Detail-enhanced Attention Feed-forward Layer (DAFL). CSL uses the non-local modeling ability of self-attention to capture long-range rain streaks and uses convolutional attention to enhance the search ability for local rain streaks, where convolution can assist self-attention to achieve better feature representation. DAFL utilizes Depth-wise Convolutional Layer to supplement detailed features and filters the information of feed-forward layer through Dual-branch Attention. The experimental results on the four synthetic datasets demonstrate that the proposed method achieves higher PSNR and SSIM than the state-of-the-art method DANet, with an improvement of 1.07 dB and 0.0098, respectively. The code is available at https://github.com/fashyon/MWN-CTHA . © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.;Not health related;0"Vasylechko S.D.; Warfield S.K.; Kurugol S.; Afacan O.";Improved myelin water fraction mapping with deep neural networks using synthetically generated 3D data;2024;We introduce a generative model for synthesis of large scale 3D datasets for quantitative parameter mapping of myelin water fraction (MWF). Our model combines a MR physics signal decay model with an accurate probabilistic multi-component parametric T2 model. We synthetically generate a wide variety of high quality signals and corresponding parameters from a wide range of naturally occurring prior parameter values. To capture spatial variation, the generative signal decay model is combined with a generative spatial model conditioned on generic tissue segmentations. Synthesized 3D datasets can be used to train any convolutional neural network (CNN) based architecture for MWF estimation. Our source code is available at: https://github.com/quin-med-harvard-edu/synthmap Reduction of acquisition time at the expense of lower SNR, as well as accuracy and repeatability of MWF estimation techniques, are key factors that affect the adoption of MWF mapping in clinical practice. We demonstrate that the synthetically trained CNN provides superior accuracy over the competing methods under the constraints of naturally occurring noise levels as well as on the synthetically generated images at low SNR levels. Normalized root mean squared error (nRMSE) is less than 7% on synthetic data, which is significantly lower than competing methods. Additionally, the proposed method yields a coefficient of variation (CoV) that is at least 4x better than the competing method on intra-session test-retest reference dataset. © 2023 Elsevier B.V.;Health related;1"Ferede F.A.; Balasubramanian M.";SSTM: Spatiotemporal recurrent transformers for multi-frame optical flow estimation;2023;Inaccurate optical flow estimates in and near occluded regions, and out-of-boundary regions are two of the current significant limitations of optical flow estimation algorithms. Recent state-of-the-art optical flow estimation algorithms are two-frame based methods where optical flow is estimated sequentially for each consecutive image pair in a sequence. While this approach gives good flow estimates, it fails to generalize optical flows in occluded regions mainly due to limited local evidence regarding moving elements in a scene. In this work, we propose a learning-based multi-frame optical flow estimation method that estimates two or more consecutive optical flows in parallel from multi-frame image sequences. Our underlying hypothesis is that by understanding temporal scene dynamics from longer sequences with more than two frames, we can characterize pixel-wise dependencies in a larger spatiotemporal domain, generalize complex motion patterns and thereby improve the accuracy of optical flow estimates in occluded regions. We present learning-based spatiotemporal recurrent transformers for multi-frame based optical flow estimation (SSTMs). Our method utilizes 3D Convolutional Gated Recurrent Units (3D-ConvGRUs) and spatiotemporal transformers to learn recurrent space–time motion dynamics and global dependencies in the scene and provide a generalized optical flow estimation. When compared with recent state-of-the-art two-frame and multi-frame methods on real world and synthetic datasets, performance of the SSTMs were significantly higher in occluded and out-of-boundary regions. Among all published state-of-the-art multi-frame methods, SSTM achieved state-of the-art results on the Sintel Final and KITTI2015 benchmark datasets. Software code, data and instructions: https://github.com/Computational-Ocularscience/SSTM. © 2023 Elsevier B.V.;Not health related;0"Mennella C.; Maniscalco U.; De Pietro G.; Esposito M.";Generating a novel synthetic dataset for rehabilitation exercises using pose-guided conditioned diffusion models: A quantitative and qualitative evaluation;2023;Machine learning has emerged as a promising approach to enhance rehabilitation therapy monitoring and evaluation, providing personalized insights. However, the scarcity of data remains a significant challenge in developing robust machine learning models for rehabilitation. This paper introduces a novel synthetic dataset for rehabilitation exercises, leveraging pose-guided person image generation using conditioned diffusion models. By processing a pre-labeled dataset of class movements for 6 rehabilitation exercises, the described method generates realistic human movement images of elderly subjects engaging in home-based exercises. A total of 22,352 images were generated to accurately capture the spatial consistency of human joint relationships for predefined exercise movements. This novel dataset significantly amplified variability in the physical and demographic attributes of the main subject and the background environment. Quantitative metrics used for image assessment revealed highly favorable results. The generated images successfully maintained intra-class and inter-class consistency in motion data, producing outstanding outcomes with distance correlation values exceeding the 0.90. This innovative approach empowers researchers to enhance the value of existing limited datasets by generating high-fidelity synthetic images that precisely augment the anthropometric and biomechanical attributes of individuals engaged in rehabilitation exercises. © 2023;Health related;1"Kapp A.; Hansmeyer J.; Mihaljevi_ H.";Generative Models for Synthetic Urban Mobility Data: A Systematic Literature Review;2023;Although highly valuable for a variety of applications, urban mobility data are rarely made openly available, as it contains sensitive personal information. Synthetic data aims to solve this issue by generating artificial data that resembles an original dataset in structural and statistical characteristics, but omits sensitive information. For mobility data, a large number of corresponding models have been proposed in the past decade. This systematic review provides a structured comparative overview of the current state of this heterogeneous, active field of research. A special focus is put on the applicability of the reviewed models in practice. © 2023 held by the owner/author(s).;Not health related;0"Huang J.; Sullivan N.P.; Zakutayev A.; O'Hayre R.";How reliable is distribution of relaxation times (DRT) analysis? A dual regression-classification perspective on DRT estimation, interpretation, and accuracy;2023;The distribution of relaxation times (DRT) has gained increasing attention and adoption in recent years as a versatile method for analyzing electrochemical impedance spectroscopy (EIS) data obtained from complex devices like fuel cells, electrolyzers, and batteries. The DRT deconvolutes the impedance without a priori specification of a generative model, which is especially useful for interpretation and model selection when the governing principles of the system under study are not fully understood. However, DRT estimation is an ill-posed inversion problem that must be addressed with a subjective choice of regularization and tuning, which leaves substantial risk of misleading interpretations of EIS data. In this work, we suggest a new classification view of the DRT inversion to clarify DRT estimation and interpretation. We introduce a dual regression-classification framework that unifies the classification and regression views of the DRT inversion with wide-reaching implications for DRT analysis. The dual framework is employed to demonstrate a new kind of DRT inversion algorithm and develop novel evaluation metrics that capture previously ignored aspects of DRT accuracy. These approaches are applied to both synthetic data and experimental spectra collected from a protonic ceramic fuel cell and a lithium-ion battery to illustrate their broad utility. The dual inversion algorithm shows promising performance for accurate DRT estimation and autonomous model identification, while the dual evaluation approach produces metrics that meaningfully assess the strengths and risks of DRT algorithms. This work provides valuable insight for both practical application of the DRT to experimental data and further development of EIS analysis methods. © 2023 Elsevier Ltd;Not health related;0"Wang W.; Feng H.; Zhou W.; Liao Z.; Li H.";Model-Aware Pre-Training for Radial Distortion Rectification;2023;Camera lenses often suffer from optical aberrations, causing radial distortion in the captured images. In those images, there exists a clear and general physical distortion model. However, in existing solutions, such rich geometric prior is under-utilized, and the formulation of an effective prediction target is under-explored. To this end, we introduce Radial Distortion TRansformer (RDTR), a new framework for radial distortion rectification. Our RDTR includes a model-aware pre-training stage for distortion feature extraction and a deformation estimation stage for distortion rectification. Technically, on the one hand, we formulate the general radial distortion (i.e., barrel distortion and pincushion distortion) in camera-captured images with a shared geometric distortion model and perform a unified model-aware pre-training for its learning. With the pre-training, the network is capable of encoding the specific distortion pattern of a radially distorted image. After that, we transfer the learned representations to the learning of distortion rectification. On the other hand, we introduce a new prediction target called backward warping flow for rectifying images with any resolution while avoiding image defects. Extensive experiments are conducted on our synthetic dataset, and the results demonstrate that our method achieves state-of-the-art performance while operating in real-time. Besides, we also validate the generalization of RDTR on real-world images. Our source code and the proposed dataset are publicly available at https://github.com/wwd-ustc/RDTR.  © 2023 IEEE.;Not health related;0"Li Y.; Alkhalifah T.; Huang J.; Li Z.";Self-Supervised Pretraining Vision Transformer With Masked Autoencoders for Building Subsurface Model;2023;Building subsurface models is a very important but challenging task in hydrocarbon exploration and development. The subsurface elastic properties are usually sourced from seismic data and well logs. Thus, we design a deep learning (DL) framework using vision transformer (ViT) as the backbone architecture to build the subsurface model using well log information as we apply full waveform inversion (FWI) on the seismic data. However, training a ViT network from scratch with limited well log data can be difficult to achieve good generalization. To overcome this, we implement an efficient self-supervised pretraining process using a masked autoencoder (MAE) architecture to learn important feature representations in seismic volumes. The seismic volumes required by the pretraining are randomly extracted from a seismic inversion, such as an FWI result. We can also incorporate reverse time migration (RTM) image into the seismic volumes to provide additional structure information. The pretraining task of MAE is to reconstruct the original image from the masked image with a masking ratio of 75%. This pretraining task enables the network to learn the high-level latent representations. After the pretraining process, we then fine-tune the ViT network to build the optimal mapping relationship between 2-D seismic volumes and 1-D well segments. Once the fine-tuning process is finished, we apply the trained ViT network to the whole seismic inversion domain to predict the subsurface model. At last, we use one synthetic dataset and two field datasets to test the performance of the proposed method. The test results demonstrate that the proposed method effectively integrates seismic and well information to improve the resolution and accuracy of the velocity model.  © 1980-2012 IEEE.;Not health related;0"Bian W.; Li C.; Hou H.; Liu X.";Iterative convolutional enhancing self-attention Hawkes process with time relative position encoding;2023;Modeling Hawkes process using deep learning is superior to traditional statistical methods in the goodness of fit. However, methods based on RNN or self-attention are deficient in long-time dependence and recursive induction, respectively. Universal Transformer (UT) is an advanced framework to integrate these two requirements simultaneously due to its continuous transformation of self-attention in the depth of the position. In addition, migration of the UT framework involves the problem of effectively matching Hawkes process modeling. Thus, in this paper, an iterative convolutional enhancing self-attention Hawkes process with time relative position encoding (ICAHP-TR) is proposed, which is based on improved UT. First, the embedding maps from dense layers are carried out on sequences of arrival time points and markers to enrich event representation. Second, the deep network composed of UT extracts hidden historical information from event expression with the characteristics of recursion and the global receptive field. Third, two designed mechanics, including the relative positional encoding on the time step and the convolution enhancing perceptual attention are adopted to avoid losing dependencies between relative and adjacent positions in the Hawkes process. Finally, the hidden historical information is mapped by Dense layers as parameters in Hawkes process intensity function, thereby obtaining the likelihood function as the network loss. The experimental results show that the proposed methods demonstrate the effectiveness of synthetic datasets and real-world datasets from the perspective of both the goodness of fit and predictive ability compared with other baseline methods. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Ye X.; Zhao J.";Heterogeneous clustering via adversarial deep Bayesian generative model;2023;This paper aims to study the deep clustering problem with heterogeneous features and unknown cluster number. To address this issue, a novel deep Bayesian clustering framework is proposed. In particular, a heterogeneous feature metric is first constructed to measure the similarity between different types of features. Then, a feature metric-restricted hierarchical sample generation process is established, in which sample with heterogeneous features is clustered by generating it from a similarity constraint hidden space. When estimating the model parameters and posterior probability, the corresponding variational inference algorithm is derived and implemented. To verify our model capability, we demonstrate our model on the synthetic dataset and show the superiority of the proposed method on some real datasets. Our source code is released on the website: Github.com/yexlwh/Heterogeneousclustering. © 2023, Higher Education Press.;Not health related;0"Tekin S.F.; Kozat S.S.";Crime prediction with graph neural networks and multivariate normal distributions;2023;We study high-resolution crime prediction and introduce a new generative model applicable to any spatiotemporal data with graph convolutional gated recurrent units (Graph-ConvGRU) and multivariate Gaussian distributions. We introduce a subdivision algorithm and create a graph representation to tackle the sparsity and complexity problem in high-resolution spatiotemporal data. By leveraging the flexible structure of graph representation, we model the spatial, temporal, and categorical relations of crime events and produce state vectors for each region. We create a multivariate probability distribution from the state vectors and train the distributions by minimizing the KL divergence between the generated and the actual distribution of the crime events. After creating the distributions, crime can be predicted in any resolution as the first time in the literature. In our experiments on real-life and synthetic datasets, our model obtains the best score with respect to the state-of-the-art models with statistically significant improvements. Hence, our model is not only generative but also precise. We also provide the source code of our algorithm for reproducibility. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.;Not health related;0"Moreu E.; Arazo E.; McGuinness K.; O'Connor N.E.";Joint one-sided synthetic unpaired image translation and segmentation for colorectal cancer prevention;2023;Deep learning has shown excellent performance in analysing medical images. However, datasets are difficult to obtain due privacy issues, standardization problems, and lack of annotations. We address these problems by producing realistic synthetic images using a combination of 3D technologies and generative adversarial networks. We propose CUT-seg, a joint training where a segmentation model and a generative model are jointly trained to produce realistic images while learning to segment polyps. We take advantage of recent one-sided translation models because they use significantly less memory, allowing us to add a segmentation model in the training loop. CUT-seg performs better, is computationally less expensive, and requires less real images than other memory-intensive image translation approaches that require two stage training. Promising results are achieved on five real polyp segmentation datasets using only one real image and zero real annotations. As a part of this study we release Synth-Colon, an entirely synthetic dataset that includes 20,000 realistic colon images and additional details about depth and 3D geometry: https://enric1994.github.io/synth-colon. © 2022 John Wiley & Sons Ltd.;Health related;1"Qin X.; Song H.; Fan J.; Zhang K.";Spatio-spectral Cross-Attention Transformer for Hyperspectral image and Multispectral image fusion;2023;This paper presents a novel Spatio-spectral Cross-Attention Transformer (SCAformer) for HyperSpectral Image and MultiSpectral Image (HSI/MSI) fusion. Specifically, we first design a Parallel Spatio-spectral Cross-Attention (P-SCA) module composed of a Spectral-wise Multi-head Cross-Attention (S-MCA) and a Window-based MCA (W-MCA), to yield more effective global spectra and local texture feature transferring between the HSI-MSI pairs. Afterwards, we develop a Spatial Fusion Module (SFM) that encodes rich local texture details to fuse the pairwise outputs of P-SCA in the pixel space. Finally, we construct a High-frequency Extraction Module (HEM) to further complement the edge details. The HEM first spatially-wise modulates the features to preserve spatial details, and then leverages Discrete Wavelet Transform (DWT) to decompose the modulated representation into a set of high-frequency components to complement the edge details in the fused image. Extensive experiments on three synthetic datasets (i.e. CAVE, Harvard and Pavia Centre) and a real dataset demonstrate that the proposed SCAformer outperforms the state-of-the-art methods in terms of all evaluation metrics. © 2023 Informa UK Limited, trading as Taylor & Francis Group.;Not health related;0"Zou Q.; Priya S.; Nagpal P.; Jacob M.";Joint Cardiac T1 Mapping and Cardiac Cine Using Manifold Modeling;2023;The main focus of this work is to introduce a single free-breathing and ungated imaging protocol to jointly estimate cardiac function and myocardial (Formula presented.) maps. We reconstruct a time series of images corresponding to k-space data from a free-breathing and ungated inversion recovery gradient echo sequence using a manifold algorithm. We model each image in the time series as a non-linear function of three variables: cardiac and respiratory phases and inversion time. The non-linear function is realized using a convolutional neural networks (CNN) generator, while the CNN parameters, as well as the phase information, are estimated from the measured k-t space data. We use a dense conditional auto-encoder to estimate the cardiac and respiratory phases from the central multi-channel k-space samples acquired at each frame. The latent vectors of the auto-encoder are constrained to be bandlimited functions with appropriate frequency bands, which enables the disentanglement of the latent vectors into cardiac and respiratory phases, even when the data are acquired with intermittent inversion pulses. Once the phases are estimated, we pose the image recovery as the learning of the parameters of the CNN generator from the measured k-t space data. The learned CNN generator is used to generate synthetic data on demand by feeding it with appropriate latent vectors. The proposed approach capitalizes on the synergies between cine MRI and (Formula presented.) mapping to reduce the scan time and improve patient comfort. The framework also enables the generation of synthetic breath-held cine movies with different inversion contrasts, which improves the visualization of the myocardium. In addition, the approach also enables the estimation of the (Formula presented.) maps with specific phases, which is challenging with breath-held approaches. © 2023 by the authors.;Not health related;1"Yang Z.; Xu M.; Liu S.; Sheng H.; Wan J.";UST-Net: A U-Shaped Transformer Network Using Shifted Windows for Hyperspectral Unmixing;2023;Autoencoders (AEs) are commonly utilized for acquiring low-dimensional data representations and performing data reconstruction, which makes them suitable for hyperspectral unmixing (HU). However, AE networks trained pixel by pixel and those employing localized convolutional filters disregard the global material distribution and distant interdependencies, resulting in the loss of necessary spatial feature information essential for the unmixing process. To overcome this limitation, we propose an innovative deep neural network model named U-shaped transformer network using shifted windows (UST-Net). UST-Net prioritizes spatial information in the scene that is more discriminative and significant by using multihead self-attention blocks based on shifted windows. Unlike patch-based unmixing networks, UST-Net operates on the complete image, eliminating inconsistencies associated with patches. Moreover, the downsampling and upsampling stages are used to extract hyperspectral image (HSI) feature maps at different scales. This process generates a context-rich and spatially accurate abundance map without losing local details. The experimental results of one synthetic dataset and three real datasets demonstrate that UST-Net significantly outperforms both traditional and several other advanced neural network methods. Our code is publicly available at https://github.com/UPCGIT/UST-Net.  © 1980-2012 IEEE.;Not health related;0"Deveshwar N.; Rajagopal A.; Sahin S.; Shimron E.; Larson P.E.Z.";Synthesizing Complex-Valued Multicoil MRI Data from Magnitude-Only Images;2023;Despite the proliferation of deep learning techniques for accelerated MRI acquisition and enhanced image reconstruction, the construction of large and diverse MRI datasets continues to pose a barrier to effective clinical translation of these technologies. One major challenge is in collecting the MRI raw data (required for image reconstruction) from clinical scanning, as only magnitude images are typically saved and used for clinical assessment and diagnosis. The image phase and multi-channel RF coil information are not retained when magnitude-only images are saved in clinical imaging archives. Additionally, preprocessing used for data in clinical imaging can lead to biased results. While several groups have begun concerted efforts to collect large amounts of MRI raw data, current databases are limited in the diversity of anatomy, pathology, annotations, and acquisition types they contain. To address this, we present a method for synthesizing realistic MR data from magnitude-only data, allowing for the use of diverse data from clinical imaging archives in advanced MRI reconstruction development. Our method uses a conditional GAN-based framework to generate synthetic phase images from input magnitude images. We then applied ESPIRiT to derive RF coil sensitivity maps from fully sampled real data to generate multi-coil data. The synthetic data generation method was evaluated by comparing image reconstruction results from training Variational Networks either with real data or synthetic data. We demonstrate that the Variational Network trained on synthetic MRI data from our method, consisting of GAN-derived synthetic phase and multi-coil information, outperformed Variational Networks trained on data with synthetic phase generated using current state-of-the-art methods. Additionally, we demonstrate that the Variational Networks trained with synthetic k-space data from our method perform comparably to image reconstruction networks trained on undersampled real k-space data. © 2023 by the authors.;Health related;1"Liao H.; Xia J.; Yang Z.; Pan F.; Liu Z.; Liu Y.";Meta-learning based Domain Prior with Application to Optical-ISAR Image Translation;2023;This paper focuses on generating Inverse Synthetic Aperture Radar (ISAR) images from optical images, in particular, for orbit space targets. ISAR images are widely applied in space target observation and classification tasks, whereas, limited to the expensive cost of ISAR sample collection, training deep learning-based ISAR image classifiers with insufficient samples and generating ISAR samples from emulation optical images via image translation techniques have attracted increasing attention. Image translation has highlighted significant success and popularity in computer vision, remote sensing and data generation societies. However, most of the existing methods are implemented under the discipline of extracting the explicit pixel-level features and do not perform effectively while entailing translation to domains with specific implicit features, such as ISAR image does. We propose a meta-learning based domain prior to implicit feature modelling and apply it to CycleGAN and UNIT models to realize effective translations between the ISAR and optical domains. Two representative implicit features, ISAR scattering distribution feature from the physical domain and the classification identifying feature from the task domain, are elaborately formulated with explicit modelling in statistic form. A meta-learning based training scheme is introduced to leverage the mutual knowledge of domain priors across different samples, and thus allows few-shot learning capacity with dramatically reduced training samples. Extensive simulations validate that the obtained ISAR images have better visible-authenticity and training-effectiveness than the existing image translation approaches on various synthetic datasets. Source codes are available at. IEEE;Not health related;0"Sboev A.G.; Gryaznov A.V.; Rybka R.B.; Skorokhodov M.S.; Moloshnikov I.A.";"A deep learning method based on language models for processingnatural language Russian commands in human robot interaction; [______ III. _____________ _________ _____ _ _________ _____________ _____]";2023;The development of high performance human-machine interface systems for controlling robotic platforms by natural language is a relevant task in interdisciplinary field «Human-Robot Interaction». In particular, it is in demand, when the robotic platform is controlled by an operator without any skills necessary to use specialized control tools. The paper describes a complex Russian language commands processing into a formalized RDF graph format to control a robotic platform. In this processing, neural network models are consistently used to search and replace pronouns in commands, restore missing verbs-actions, decompose a complex command with several actions into simple commands with only one action and classify simple command attribute. State-of-the-art solutions are applied as neural network models in this work. It is language models based on deep neural networks transformer architecture. The previous our papers show synthetic datasets based on developed generator of Russian language text commands, data based on crowdsourcing technologies and data from open sources for each of the described stages of processing. These datasets were used to fine-tune the language models of the neural networks. In this work, the resulting fine-tuned language models are implemented into the interface. The impact of the stage of searching and replacing pronouns on the efficiency of command conversion are evaluated. Using the virtual three-dimensional robotic platform simulator created at the National Research Center «Kurchatov Institute», the high efficiency of complex Russian language commands processing as part of a human-machine interface system is demonstrated. © 2023 Japan Society of Logopedics and Phoniatrics. All rights reserved.;Not health related;0"Bai N.; Wang X.; Han R.; Wang Q.; Liu Z.";PAFormer: Anomaly Detection of Time Series With Parallel-Attention Transformer;2023;Time-series anomaly detection is a critical task with significant impact as it serves a pivotal role in the field of data mining and quality management. Current anomaly detection methods are typically based on reconstruction or forecasting algorithms, as these methods have the capability to learn compressed data representations and model time dependencies. However, most methods rely on learning normal distribution patterns, which can be difficult to achieve in real-world engineering applications. Furthermore, real-world time-series data is highly imbalanced, with a severe lack of representative samples for anomalous data, which can lead to model learning failure. In this article, we propose a novel end-to-end unsupervised framework called the parallel-attention transformer (PAFormer), which discriminates anomalies by modeling both the global characteristics and local patterns of time series. Specifically, we construct parallel-attention (PA), which includes two core modules: the global enhanced representation module (GERM) and the local perception module (LPM). GERM consists of two pattern units and a normalization module, with attention weights that indicate the relationship of each data point to the whole series (global). Due to the rarity of anomalous points, they have strong associations with adjacent data points. LPM is composed of a learnable Laplace kernel function that learns the neighborhood relevancies through the distributional properties of the kernel function (local). We employ the PA to learn the global-local distributional differences for each data point, which enables us to discriminate anomalies. Finally, we propose a two-stage adversarial loss to optimize the model. We conduct experiments on five public benchmark datasets (real-world datasets) and one synthetic dataset. The results show that PAFormer outperforms state-of-the-art baselines. IEEE;Not health related;0"Ishiwatari T.; Saito S.; Nakahara Y.; Iikubo Y.; Matsushima T.";Bayes optimal estimation and its approximation algorithm for difference with and without treatment under IRSLC model;2023;We consider verifying the effect of the treatment under the situation in which a response is given when a treatment is applied to units with features. In estimating the effect, there are problems such as the treatment can be given only once to the unit and the features of the unit cannot be controlled. For such problems, conventional studies have some mathematical models. However, in this paper, we propose the different data generative model in which there are latent classes of units with the same response, each latent class contains units with similar features. We call this model the identical response structure latent class model (IRSLC model). Under the proposed model, we calculate the Bayes optimal decision and its approximation algorithm for the difference with and without the treatment for the entire population. We conducted experiments using the synthetic data of the model assumed by the proposed method or the conventional method. Then, we compared our method with previous studies to confirm the characteristics of the proposed model. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.;Health related;0"Carrle F.P.; Hollenbenders Y.; Reichenbach A.";Generation of synthetic EEG data for training algorithms supporting the diagnosis of major depressive disorder;2023;Introduction: Major depressive disorder (MDD) is the most common mental disorder worldwide, leading to impairment in quality and independence of life. Electroencephalography (EEG) biomarkers processed with machine learning (ML) algorithms have been explored for objective diagnoses with promising results. However, the generalizability of those models, a prerequisite for clinical application, is restricted by small datasets. One approach to train ML models with good generalizability is complementing the original with synthetic data produced by generative algorithms. Another advantage of synthetic data is the possibility of publishing the data for other researchers without risking patient data privacy. Synthetic EEG time-series have not yet been generated for two clinical populations like MDD patients and healthy controls. Methods: We first reviewed 27 studies presenting EEG data augmentation with generative algorithms for classification tasks, like diagnosis, for the possibilities and shortcomings of recent methods. The subsequent empirical study generated EEG time-series based on two public datasets with 30/28 and 24/29 subjects (MDD/controls). To obtain baseline diagnostic accuracies, convolutional neural networks (CNN) were trained with time-series from each dataset. The data were synthesized with generative adversarial networks (GAN) consisting of CNNs. We evaluated the synthetic data qualitatively and quantitatively and finally used it for re-training the diagnostic model. Results: The reviewed studies improved their classification accuracies by between 1 and 40% with the synthetic data. Our own diagnostic accuracy improved up to 10% for one dataset but not significantly for the other. We found a rich repertoire of generative models in the reviewed literature, solving various technical issues. A major shortcoming in the field is the lack of meaningful evaluation metrics for synthetic data. The few studies analyzing the data in the frequency domain, including our own, show that only some features can be produced truthfully. Discussion: The systematic review combined with our own investigation provides an overview of the available methods for generating EEG data for a classification task, their possibilities, and shortcomings. The approach is promising and the technical basis is set. For a broad application of these techniques in neuroscience research or clinical application, the methods need fine-tuning facilitated by domain expertise in (clinical) EEG research. Copyright © 2023 Carrle, Hollenbenders and Reichenbach.;Health related;1"Guo E.; Fu H.; Zhou L.; Xu D.";Bridging Synthetic and Real Images: A Transferable and Multiple Consistency Aided Fundus Image Enhancement Framework;2023;Deep learning based image enhancement models have largely improved the readability of fundus images in order to decrease the uncertainty of clinical observations and the risk of misdiagnosis. However, due to the difficulty of acquiring paired real fundus images at different qualities, most existing methods have to adopt synthetic image pairs as training data. The domain shift between the synthetic and the real images inevitably hinders the generalization of such models on clinical data. In this work, we propose an end-to-end optimized teacher-student framework to simultaneously conduct image enhancement and domain adaptation. The student network uses synthetic pairs for supervised enhancement, and regularizes the enhancement model to reduce domain-shift by enforcing teacher-student prediction consistency on the real fundus images without relying on enhanced ground-truth. Moreover, we also propose a novel multi-stage multi-attention guided enhancement network (MAGE-Net) as the backbones of our teacher and student network. Our MAGE-Net utilizes multi-stage enhancement module and retinal structure preservation module to progressively integrate the multi-scale features and simultaneously preserve the retinal structures for better fundus image quality enhancement. Comprehensive experiments on both real and synthetic datasets demonstrate that our framework outperforms the baseline approaches. Moreover, our method also benefits the downstream clinical tasks.  © 1982-2012 IEEE.;Health related;0"Ta N.; Chen H.; Lyu Y.; Wang X.; Shi Z.; Liu Z.";A complementary and contrastive network for stimulus segmentation and generalization;2023;Existing convolutional neural networks (CNNs) have achieved remarkable performance in medical image segmentation tasks. However, they still fail to generalize well to unseen datasets due to the limited size and diversity of training data as well as distribution shifts. Meanwhile, CNN-based methods have inherent limitations in capturing global contexts and suffer semantic dilution issues in the decoder stage, which leads to suboptimal predictions especially under low inter-class discrepancy and complex backgrounds. In this paper, we propose a novel framework named CCNet that learns complementary and contrastive features for accurate segmentation. Firstly, a novel complementary feature extraction module is formulated to learn global–local features by coordinating Transformer and CNN-style parallel branches. Secondly, a global context refinement module is constructed to adaptively generate a set of layer-specific global maps, so as to remedy semantic dilution. Thirdly, a mutual attentive module is designed to alleviate background confusion, in which contrastive cues are mutually captured from the foreground and background view by cascaded dual attention blocks. Moreover, we implement synthetic data augmentation to deal with training data scarcity and distribution shifts, thereby improving the out-of-distribution generalization of our model. Extensive experiments demonstrate that our CCNet achieves outstanding performance in polyp, skin lesion, and nuclei segmentation tasks, outperforming the state-of-the-arts. © 2023;Health related;0"Shin Y.; Chun C.";Sound Event Localization and Detection Using Imbalanced Real and Synthetic Data via Multi-Generator;2023;This study proposes a sound event localization and detection (SELD) method using imbalanced real and synthetic data via a multi-generator. The proposed method is based on a residual convolutional neural network (RCNN) and a transformer encoder for real spatial sound scenes. SELD aims to classify the sound event, detect the onset and offset of the classified event, and estimate the direction of the sound event. In Detection and Classification of Acoustic Scenes and Events (DCASE) 2022 Task 3, SELD is performed with a few real spatial sound scene data and a relatively large number of synthetic data. When a model is trained using imbalanced data, it can proceed by focusing only on a larger number of data. Thus, a multi-generator that samples real and synthetic data at a specific rate in one batch is proposed to prevent this problem. We applied the data augmentation technique SpecAugment and used time-frequency masking to the dataset. Furthermore, we propose a neural network architecture to apply the RCNN and transformer encoder. Several models were trained with various structures and hyperparameters, and several ensemble models were obtained by “cherry-picking” specific models. Based on the experiment, the single model of the proposed method and the model applied with the ensemble exhibited improved performance compared with the baseline model. © 2023 by the authors.;Not health related;0"Espinosa E.; Figueira A.";On the Quality of Synthetic Generated Tabular Data;2023;Class imbalance is a common issue while developing classification models. In order to tackle this problem, synthetic data have recently been developed to enhance the minority class. These artificially generated samples aim to bolster the representation of the minority class. However, evaluating the suitability of such generated data is crucial to ensure their alignment with the original data distribution. Utility measures come into play here to quantify how similar the distribution of the generated data is to the original one. For tabular data, there are various evaluation methods that assess different characteristics of the generated data. In this study, we collected utility measures and categorized them based on the type of analysis they performed. We then applied these measures to synthetic data generated from two well-known datasets, Adults Income, and Liar+. We also used five well-known generative models, Borderline SMOTE, DataSynthesizer, CTGAN, CopulaGAN, and REaLTabFormer, to generate the synthetic data and evaluated its quality using the utility measures. The measurements have proven to be informative, indicating that if one synthetic dataset is superior to another in terms of utility measures, it will be more effective as an augmentation for the minority class when performing classification tasks. © 2023 by the authors.;Not health related;0"Cai H.; Song Y.; Ji Y.; Li Z.; He A.";Displacement extraction of background-oriented schlieren images using Swin Transformer;2023;Displacement extraction of background-oriented schlieren (BOS) is an essential step in BOS reconstruction, which directly determines the accuracy of the results. Typically, the displacement is calculated from the background images with and without inhomogeneous flow using the cross-correlation (CC) or optical flow (OF) method. This paper discusses the disadvantages of the CC and OF methods, and an end-to-end deep neural network was designed to estimate the BOS displacement. The proposed network is based on a Swin Transformer, which can build long-range correlations. A synthetic dataset used for training was generated using the simulated flow field by computational fluid dynamics. After training, the displacement can be obtained using the BOS image pair without additional parameters. Finally, the effectiveness of the proposed network was verified through experiments. The experiments illustrate that the proposed method performs stably on synthetic and real experimental images and outperforms conventional CC or OF methods and classic convolutional neural networks for OF tasks. © 2023 Optica Publishing Group.;Not health related;0"Sánchez-Gutiérrez M.E.; González-Pérez P.P.";Addressing the class imbalance in tabular datasets from a generative adversarial network approach in supervised machine learning;2023;One common issue with datasets used for supervised classification tasks is data imbalance or the unequal distribution of classes within a dataset. The class imbalance may cause biased machine learning models to favor the dominant class, misclassifying the minority class. Specific techniques can be employed to deal with the issue of class imbalance, including resampling by oversampling or undersampling and ensemble approaches. Besides, generative adversarial networks, a deep learning technique for building generative models, offer an alternative machine learning technique that is particularly well suited to address the class imbalance problem. This work introduces a machine learning-based approach to deal with the class imbalance in a cancer intracellular signaling dataset produced by a verified and validated computer simulation. Specifically, we use synthetic data generation to increase and balance the dataset generated by the computational simulation. The used approach simulates the oversampling method by employing a generative adversarial network to produce new examples for the minority class. Subsequently, we applied supervised machine learning methods, such as the K-NN algorithm, to assess whether or not the classification accuracy improved relative to the unbalanced dataset. The results presented in this work have shown an accuracy increase in the classification of patterns belonging to the minority class, with an improvement of (Formula presented.). © The Author(s) 2023.;Health related;0"Trevithick A.; Chan M.; Stengel M.; Chan E.; Liu C.; Yu Z.; Khamis S.; Chandraker M.; Ramamoorthi R.; Nagano K.";Real-Time Radiance Fields for Single-Image Portrait View Synthesis;2023;We present a one-shot method to infer and render a photorealistic 3D representation from a single unposed image (e.g., face portrait) in real-time. Given a single RGB input, our image encoder directly predicts a canonical triplane representation of a neural radiance field for 3D-aware novel view synthesis via volume rendering. Our method is fast (24 fps) on consumer hardware, and produces higher quality results than strong GAN-inversion baselines that require test-time optimization. To train our triplane encoder pipeline, we use only synthetic data, showing how to distill the knowledge from a pretrained 3D GAN into a feedforward encoder. Technical contributions include a Vision Transformer-based triplane encoder, a camera data augmentation strategy, and a well-designed loss function for synthetic data training. We benchmark against the state-of-the-art methods, demonstrating significant improvements in robustness and image quality in challenging real-world settings. We showcase our results on portraits of faces (FFHQ) and cats (AFHQ), but our algorithm can also be applied in the future to other categories with a 3D-aware image generator.  © 2023 Owner/Author(s).;Not health related;0"Nikbakht M.; Gazi A.H.; Zia J.; An S.; Lin D.J.; Inan O.T.; Kamaleswaran R.";Synthetic seismocardiogram generation using a transformer-based neural network;2023;"Objective: To design and validate a novel deep generative model for seismocardiogram (SCG) dataset augmentation. SCG is a noninvasively acquired cardiomechanical signal used in a wide range of cardivascular monitoring tasks; however, these approaches are limited due to the scarcity of SCG data. Methods: A deep generative model based on transformer neural networks is proposed to enable SCG dataset augmentation with control over features such as aortic opening (AO), aortic closing (AC), and participant-specific morphology. We compared the generated SCG beats to real human beats using various distribution distance metrics, notably Sliced-Wasserstein Distance (SWD). The benefits of dataset augmentation using the proposed model for other machine learning tasks were also explored. Results: Experimental results showed smaller distribution distances for all metrics between the synthetically generated set of SCG and a test set of human SCG, compared to distances from an animal dataset (1.14x SWD), Gaussian noise (2.5x SWD), or other comparison sets of data. The input and output features also showed minimal error (95% limits of agreement for pre-ejection period [PEP] and left ventricular ejection time [LVET] timings are 0.03 6 3.81 ms and -0.28 6 6.08 ms, respectively). Experimental results for data augmentation for a PEP estimation task showed 3.3% accuracy improvement on an average for every 10% augmentation (ratio of synthetic data to real data). Conclusion: The model is thus able to generate physiologically diverse, realistic SCG signals with precise control over AO and AC features. This will uniquely enable dataset augmentation for SCG processing and machine learning to overcome data scarcity. © The Author(s) 2023. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.";Not health related;1"Boutros F.; Struc V.; Fierrez J.; Damer N.";Synthetic data for face recognition: Current state and future prospects;2023;Over the past years, deep learning capabilities and the availability of large-scale training datasets advanced rapidly, leading to breakthroughs in face recognition accuracy. However, these technologies are foreseen to face a major challenge in the next years due to the legal and ethical concerns about using authentic biometric data in AI model training and evaluation along with increasingly utilizing data-hungry state-of-the-art deep learning models. With the recent advances in deep generative models and their success in generating realistic and high-resolution synthetic image data, privacy-friendly synthetic data has been recently proposed as an alternative to privacy-sensitive authentic data to overcome the challenges of using authentic data in face recognition development. This work aims at providing a clear and structured picture of the use-cases taxonomy of synthetic face data in face recognition along with the recent emerging advances of face recognition models developed on the bases of synthetic data. We also discuss the challenges facing the use of synthetic data in face recognition development and several future prospects of synthetic data in the domain of face recognition. © 2023 Elsevier B.V.;Not health related;0"Billot B.; Greve D.N.; Puonti O.; Thielscher A.; Van Leemput K.; Fischl B.; Dalca A.V.; Iglesias J.E.";SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining;2023;Despite advances in data augmentation and transfer learning, convolutional neural networks (CNNs) difficultly generalise to unseen domains. When segmenting brain scans, CNNs are highly sensitive to changes in resolution and contrast: even within the same MRI modality, performance can decrease across datasets. Here we introduce SynthSeg, the first segmentation CNN robust against changes in contrast and resolution. SynthSeg is trained with synthetic data sampled from a generative model conditioned on segmentations. Crucially, we adopt a domain randomisation strategy where we fully randomise the contrast and resolution of the synthetic training data. Consequently, SynthSeg can segment real scans from a wide range of target domains without retraining or fine-tuning, which enables straightforward analysis of huge amounts of heterogeneous clinical data. Because SynthSeg only requires segmentations to be trained (no images), it can learn from labels obtained by automated methods on diverse populations (e.g., ageing and diseased), thus achieving robustness to a wide range of morphological variability. We demonstrate SynthSeg on 5,000 scans of six modalities (including CT) and ten resolutions, where it exhibits unparallelled generalisation compared with supervised CNNs, state-of-the-art domain adaptation, and Bayesian segmentation. Finally, we demonstrate the generalisability of SynthSeg by applying it to cardiac MRI and CT scans. © 2023 The Author(s);Health related;1"Marco R.; Ahmad S.S.S.; Ahmad S.";Improving Conditional Variational Autoencoder with Resampling Strategies for Regression Synthetic Project Generation;2023;"The uncertainty inherent in the predictive environment of software effort estimation, is due to the limited availability of data information and the expensive costs associated with data collection. Consequently, there is difficulty in making accurate predictions with insufficient software effort estimation data, due to the limited information in the data. The probabilistic deep generative model conditional variational autoencoder (CVAE) is capable of producing synthetic data and modeling complex data distribution characteristics that is similarity to the real Unfortunately, because the method was previously developed for the classification task, the application of the technique to the regression task has received little attention. This study aims to construct a CVAE model combined with the relevance function contained in the re-sampling method. Relevance function method aims to create a label on the target. Statistical tests, such as the Levene test, t-test, and Kolmogrove Smirnov test, are utilized to compare the results to the real data. This study considers seven popular algorithms for comparison, such as synthetic minority oversampling technique regression (SMOTER), generative adversarial networks (GAN), conditional tabular generative adversarial networks (CTGAN), gaussian-copula (GC), copula GAN (CGAN), and variational autoencoder (VAE). CVAE approach has the best augmentation performance quality with accuracy values (MAE; RMSE; RAE; R2) compared to existing models in each china dataset (923.330; 1470.536; 0.436; 0.848) and desharnais dataset (9.540; 11.694; 0.041; 0.978), respectively. The proposed model generates synthetic data which is similarity to real data in the software effort estimation context. In addition, synthetic data improves the quality of performance on baseline machine learning in software effort estimation contexts rather than using real data. © 2023, International Journal of Intelligent Engineering and Systems. All Rights Reserved.";Not health related;0"Eigenschink P.; Reutterer T.; Vamosi S.; Vamosi R.; Sun C.; Kalcher K.";Deep Generative Models for Synthetic Data: A Survey;2023;A growing interest in synthetic data has stimulated the development and advancement of a large variety of deep generative models for a wide range of applications. However, as this research has progressed, its streams have become more specialized and disconnected from one another. This is why models for synthesizing text data for natural language processing cannot readily be compared to models for synthesizing health records anymore. To mitigate this isolation, we propose a data-driven evaluation framework for generative models for synthetic sequential data, an important and challenging sub-category of synthetic data, based on five high-level criteria: representativeness, novelty, realism, diversity and coherence of a synthetic data-set relative to the original data-set regardless of the models' internal structures. The criteria reflect requirements different domains impose on synthetic data and allow model users to assess the quality of synthetic data across models. In a critical review of generative models for sequential data, we examine and compare the importance of each performance criterion in numerous domains. We find that realism and coherence are more important for synthetic data natural language, speech and audio processing tasks. At the same time, novelty and representativeness are more important for healthcare and mobility data. We also find that measurement of representativeness is often accomplished using statistical metrics, realism by using human judgement, and novelty using privacy tests.  © 2013 IEEE.;Health related;1"Wang Z.; You J.; Liu W.; Wang X.";Transformer assisted dual U-net for seismic fault detection;2023;Automatic seismic fault identification for seismic data is essential for oil and gas resource exploration. The traditional manual method cannot accommodate the needs of processing massive seismic data. With the development of artificial intelligence technology, deep learning techniques based on pattern recognition have become a popular research area for seismic fault identification. Despite the progress made with U-shaped neural networks (Unet), they still fall short in meeting the stringent requirements of fault prediction in complex structures. We propose a novel approach by combining a standard Unet with a transformer Unet to create a parallel dual Unet model, called Dual Unet with Transformer. To improve the accuracy of fault prediction, we compare six loss functions (including Binary Cross Entropy loss, Dice coefficient loss, Tversky loss, Local Tversky loss, Multi-scale Structural Similarity and Intersection over Union loss) using synthetic data, based on three evolution metrics involving Dice coefficient, Sensitivity and Specificity, find that the binary cross entropy loss function is the most robust one. An example comparing the prediction performance of different Unet models on synthetic data demonstrates the superior performance of our Dual Unet model, verifying the practical application value. To further validate the practical feasibility of our proposed method, we use real seismic data with a complex fault system and find that our proposed model is more accurate in predicting the fault system compared to well-developed Unet models such as the classical Unet and classical coherence cube algorithm, without transfer learning. This confirms the potential for wide-scale application of our proposed model. Copyright © 2023 Wang, You, Liu and Wang.;Not health related;0"Haleem M.S.; Ekuban A.; Antonini A.; Pagliara S.; Pecchia L.; Allocca C.";Deep-Learning-Driven Techniques for Real-Time Multimodal Health and Physical Data Synthesis;2023;With the advent of Artificial Intelligence for healthcare, data synthesis methods present crucial benefits in facilitating the fast development of AI models while protecting data subjects and bypassing the need to engage with the complexity of data sharing and processing agreements. Existing technologies focus on synthesising real-time physiological and physical records based on regular time intervals. Real health data are, however, characterised by irregularities and multimodal variables that are still hard to reproduce, preserving the correlation across time and different dimensions. This paper presents two novel techniques for synthetic data generation of real-time multimodal electronic health and physical records, (a) the Temporally Correlated Multimodal Generative Adversarial Network and (b) the Document Sequence Generator. The paper illustrates the need and use of these techniques through a real use case, the H2020 GATEKEEPER project of AI for healthcare. Furthermore, the paper presents the evaluation for both individual cases and a discussion about the comparability between techniques and their potential applications of synthetic data at the different stages of the software development life-cycle. © 2023 by the authors.;Health related;1"Allahyani M.; Alsulami R.; Alwafi T.; Alafif T.; Ammar H.; Sabban S.; Chen X.";DivGAN: A diversity enforcing generative adversarial network for mode collapse reduction;2023;Generative Adversarial Networks (GANs) are one of the most efficient generative models to generate data. They have made breakthroughs in many computer vision tasks. However, the generic GAN suffers from a mode collapse problem. To alleviate this problem, the present work proposes a new GAN framework called diversified GAN (DivGAN). DivGAN can be incorporated into any existing GAN. It includes a new network called DivNet that aims at enforcing the GANs to produce diverse data. One advantage of the proposed network is that it does not alter the architectures of the GANs and hence can be easily incorporated into them. Extensive experiments on synthetic and real datasets show that the proposed framework significantly contributes to mode collapse reduction and performs better than recent state-of-the-art GANs. © 2023 Elsevier B.V.;Not health related;0"Puchalski A.; Komorska I.";APPLICATIONS OF GENERATIVE MODELS WITH A LATENT OBSERVATION SUBSPACE IN VIBRODIAGNOSTICS;2023;The vibration signal is one of the most essential diagnostic signals, the analysis of which allows for determining the dynamic state of the monitored machine set. In the era of cyber-physical industrial systems, making diagnostic decisions involves the study of large databases from previous registers and data downloaded from machines in real-time. However, the recorded signals mainly concern the operational status of the monitored object. Insufficient training data regarding failure states hinders the operation of classification algorithms. Progress in machine learning has created a new avenue for the advancement of diagnostic methods based on models. These methods now have the capability to produce signals through random sampling from a hidden space or generate fresh instances of input data from noise. The article suggests the use of a Generative Adversarial Network (GAN) model as a tool to create synthetic measurement observations for vibration monitoring. The effectiveness of the synthetic data generation algorithm was verified on the example of the vibration signal recorded during tests of the drive system of a motor vehicle. © 2023 Polish Society of Technical Diagnostics. All rights reserved.;Not health related;0"Derus N.; Curti N.; Giampieri E.; Dall'olio D.; Sala C.; Castellani G.";Synthetic Data Generation And Classification Of Histopathological Images;2023;Histopathology involves the analysis of microscopic tissue images for diagnosing and studying the progress of diseases, such as cancers. Recently, Artificial Intelligence algorithms reached encouraging success in diagnosing diseases related to these medical images. However, research in this area can be hampered by several problems. Indeed, due to the sensitive nature of medical data, it is challenging to access real datasets, making it impossible to train Deep Learning models. Moreover, real datasets often contain biases or imbalances that hinder the generalization of the results on new unseen data. Variational Autoencoders are a popular class of probabilistic generative models that enable consistent training and a useful latent representation of the original input. However, there are theoretical and practical obstacles that hinder their generative potential. Here, we consider different approaches to address the challenges of synthetic data generation of histopathology images and discuss the potential impact in improving the performance of diagnosis models.  © 2023 World Scientific Publishing Company.;Health related;1"Ergün O.; Sahillioglu Y.";3D point cloud classification with ACGAN-3D and VACWGAN-GP;2023;Machine learning and deep learning techniques are widely used to make sense of 3D point cloud data which became ubiquitous and important due to the recent advances in 3D scanning technologies and other sensors. In this work, we propose two networks to predict the class of the input 3D point cloud: 3D Auxiliary Classifier Generative Adversarial Network (ACGAN-3D) and Versatile Auxiliary Conditional Wasserstein Generative Adversarial Network with Gradient Penalty (VACWGAN-GP). Unlike other classifiers, we are able to enlarge the limited data set with the data produced by generative models. We consequently aim to increase the success of the model by training it with more data. As suggested by the conventional ACGAN models, in addition to the real dataset, we train the Discriminator with synthetic data generated by the Generator using the class label. By doing so, we ensure that Discriminator can discriminate between the real data and the synthetic data. Thus, as the training evolves, the Generator is trained to produce more realistic synthetic data, which in turn forces Discriminator to classify or discriminate better. Defined originally on 2D images, our ACGAN-3D modifies this conventional ACGAN model in order to classify 3D point clouds by updating the neural network layers. Our second model VACWGAN-GP, on the other hand, demonstrates similar abilities with more stable training by replacing its Discriminator with Critic and by modifying its loss function. In this model, we managed to merge Wasserstein GAN-GP with conditional GAN in order to improve the classifier's performance. The proposed models ACGAN-3D and VACWGAN-GP were tested extensively on 3D datasets and comparisons with the other state-of-the-art studies have revealed our clear advantages on various aspects. While ACGAN-3D can be preferred with its compact design, our second method VACWGAN-GP stands out for higher performance.  © 2023 TÜB_TAK.;Not health related;0"Pan S.; Wang T.; Qiu R.L.J.; Axente M.; Chang C.-W.; Peng J.; Patel A.B.; Shelton J.; Patel S.A.; Roper J.; Yang X.";2D medical image synthesis using transformer-based denoising diffusion probabilistic model;2023;Objective. Artificial intelligence (AI) methods have gained popularity in medical imaging research. The size and scope of the training image datasets needed for successful AI model deployment does not always have the desired scale. In this paper, we introduce a medical image synthesis framework aimed at addressing the challenge of limited training datasets for AI models. Approach. The proposed 2D image synthesis framework is based on a diffusion model using a Swin-transformer-based network. This model consists of a forward Gaussian noise process and a reverse process using the transformer-based diffusion model for denoising. Training data includes four image datasets: chest x-rays, heart MRI, pelvic CT, and abdomen CT. We evaluated the authenticity, quality, and diversity of the synthetic images using visual Turing assessments conducted by three medical physicists, and four quantitative evaluations: the Inception score (IS), Fréchet Inception Distance score (FID), feature similarity and diversity score (DS, indicating diversity similarity) between the synthetic and true images. To leverage the framework value for training AI models, we conducted COVID-19 classification tasks using real images, synthetic images, and mixtures of both images. Main results. Visual Turing assessments showed an average accuracy of 0.64 (accuracy converging to 50 % indicates a better realistic visual appearance of the synthetic images), sensitivity of 0.79, and specificity of 0.50. Average quantitative accuracy obtained from all datasets were IS = 2.28, FID = 37.27, FDS = 0.20, and DS = 0.86. For the COVID-19 classification task, the baseline network obtained an accuracy of 0.88 using a pure real dataset, 0.89 using a pure synthetic dataset, and 0.93 using a dataset mixed of real and synthetic data. Significance. A image synthesis framework was demonstrated for medical image synthesis, which can generate high-quality medical images of different imaging modalities with the purpose of supplementing existing training sets for AI model deployment. This method has potential applications in many data-driven medical imaging research. © 2023 The Author(s). Published on behalf of Institute of Physics and Engineering in Medicine by IOP Publishing Ltd.;Health related;1"Tong B.; Kong F.; Kang T.; Luo T.; Shi Z.";A dual-stream hybrid model for blind image quality assessment;2023;Blind image quality assessment (BIQA) is a fundamental task in computer vision. Humans can evaluate image quality from local and global aspects without information on reference images. Inspired by this, we propose a BIQA method named DS-IQA by mimicking human visual system (HVS). A dual-stream hybrid module is established to get dual-stream quality-aware features. A CNN branch is used to mimic the active inference process of HVS to extract local quality-aware features. An enhanced Transformer-branch is used to extract global quality-aware features by modeling nonlocal relations of image patches. Finally, a quality evaluator based on Transformer layers is developed to map the dual-stream features and output the final quality score. The proposed approach is evaluated on five databases. The PLCC of DS-IQA reaches 0.975, 0.938, and 0.963 respectively on synthetic databases (LIVE, TID2013, CSIQ), and individual distortion experimental on TID2013 shows that DS-IQA outperforms in 8 of the 24 distortion categories on TID2013. On authentic databases (LIVEC, KonIQ-10k), the PLCC of DS-IQA reaches 0.887, 0.918, experiments show the superiority of the proposed method over other state-of-the-art BIQA metrics. © 2023 Elsevier Inc.;Not health related;0"Tai C.-Y.; Wang W.-J.; Huang Y.-M.";Using Time-Series Generative Adversarial Networks to Synthesize Sensing Data for Pest Incidence Forecasting on Sustainable Agriculture;2023;"A sufficient amount of data is crucial for high-performance and accurate trend prediction. However, it is difficult and time-consuming to collect agricultural data over long periods of time; the consequence of such difficulty is datasets that are characterized by missing data. In this study we use a time-series generative adversarial network (TimeGAN) to synthesize multivariate agricultural sensing data and train RNN (Recurrent Neural Network), LSTM (Long Short-Term Memory), and GRU (Gated Recurrent Unit) neural network prediction models on the original and generated data to predict future pest populations. After our experiment, the data generated using TimeGAN and the original data have the smallest EC value in the GRU model, which is 9.86. The results show that the generative model effectively synthesizes multivariate agricultural sensing data and can be used to make up for the lack of actual data. The pest prediction model trained on synthetic data using time-series data generation yields results that are similar to that of the model trained on actual data. Accurate prediction of pest populations would represent a breakthrough in allowing for accurate and timely pest control. © 2023 by the authors.";Not health related;0"Ghosheh G.O.; Thwaites C.L.; Zhu T.";Synthesizing Electronic Health Records for Predictive Models in Low-Middle-Income Countries (LMICs);2023;The spread of machine learning models, coupled with by the growing adoption of electronic health records (EHRs), has opened the door for developing clinical decision support systems. However, despite the great promise of machine learning for healthcare in low-middle-income countries (LMICs), many data-specific limitations, such as the small size and irregular sampling, hinder the progress in such applications. Recently, deep generative models have been proposed to generate realistic-looking synthetic data, including EHRs, by learning the underlying data distribution without compromising patient privacy. In this study, we first use a deep generative model to generate synthetic data based on a small dataset (364 patients) from a LMIC setting. Next, we use synthetic data to build models that predict the onset of hospital-acquired infections based on minimal information collected at patient ICU admission. The performance of the diagnostic model trained on the synthetic data outperformed models trained on the original and oversampled data using techniques such as SMOTE. We also experiment with varying the size of the synthetic data and observe the impact on the performance and interpretability of the models. Our results show the promise of using deep generative models in enabling healthcare data owners to develop and validate models that serve their needs and applications, despite limitations in dataset size. © 2023 by the authors.;Health related;1"Duan Y.; Xu X.; Li T.; Pan B.; Shi Z.";UnDAT: Double-Aware Transformer for Hyperspectral Unmixing;2023;Deep-learning-based methods have attracted increasing attention on hyperspectral unmixing, where the transformer models have shown promising performance. However, recently proposed deep-learning-based hyperspectral unmixing methods usually tend to directly apply visual models, while ignoring the characteristics of hyperspectral imagery. In this article, we propose a novel double-aware transformer for hyperspectral Unmixing (UnDAT), which aims at simultaneously exploiting the region homogeneity and spectral correlation of hyperspectral imagery. One of the major assumptions of UnDAT is that hyperspectral remote-sensing images involve many homogeneous regions. Pixels inside a homogeneous region usually present similar spectral features, and the edge pixels are just the reverse. Another observation is that the pixel spectra are continuous and correlated. Based on the above assumption and observation, we construct the UnDAT by developing two modules: Score-based homogeneous-aware (SHA) module and the spectral group-aware (SGA) module. In the SHA module, a feature map rearrangement (FMR) approach is proposed to split the shallow feature maps from a linear encoder into an ordered homogeneous map (HomoMap) and an edge map and develop a homogenous region-aware strategy for deep feature representation. In the SGA module, the dependency among neighboring bands is described by dividing the hyperspectral image into multiple spectral groups and calculating the spectral similarity among bands within each group. Experiments on both real and synthetic datasets indicate the effectiveness of our model. We will publish the code of our approach if the article has the honor to be accepted.  © 1980-2012 IEEE.;Not health related;0"Yang Z.; Xu M.; Liu S.; Sheng H.; Zheng H.";Spatial-Spectral Attention Bilateral Network for Hyperspectral Unmixing;2023;Autoencoders (AEs) are widely utilized in hyperspectral unmixing (HU) as an unsupervised learning model. In particular, convolutional AE networks are popular for processing multidimensional hyperspectral features. Nonetheless, the traditional convolutional AE network's receptive field is constrained in the unmixing task, and establishing the connection between the local spatial neighborhood and the local spectrum fails to improve unmixing performance significantly. To address these limitations, a bilateral global attention network based on both spatial and spectral information is proposed. It enables the network to obtain respective feature dependencies in the two dimensions and achieve optimal fusion of both features. The network comprises two information extraction branches. The spatial information extraction branch uses the Swin Transformer block to acquire the global spatial attention of the overall image, while the spectral information extraction branch designates a simplified spectral channel attention mechanism to gain spectral attention weight maps. The network's efficacy is demonstrated through a comparative study using a synthetic dataset and two real datasets. The code of this work is available at https://github.com/UPCGIT/SSABN.  © 2004-2012 IEEE.;Not health related;0"Suroso D.J.; Cherntanomwong P.; Sooraksa P.";Synthesis of a Small Fingerprint Database through a Deep Generative Model for Indoor Localisation;2023;In deep learning (DL), the deep generative model is helpful for data augmentation objectives to tackle the lack of datasets that have a significant impact on learning performance. Data augmentation or synthesis is expected to solve the issue in a small/sparse database. The problem of databasing also exists in the fingerprint-based indoor localisation system. The dense offline fingerprint database must be constructed with the accuracy requirement. However, this will affect the high cost, massive laborious work, and increase the complexity of the system. Therefore, this paper proposes to address these issues by generating synthetic data via a deep generative model. The generative adversarial network (GAN) is selected to generate the synthetic fingerprint database for indoor localisation. Our database consideration consists of power-based parameters, i.e., the received signal strength indicator (RSSI) from Wi-Fi devices obtained from the actual measurement campaign. Some of the literature mainly discusses how GAN works in a vast and complex dataset. Here, we consider applying GAN in a relatively small dataset and for a simple setup. Our results show that by only using the 20 % fraction of actual RSSI data combined with the synthetic RSSI, the accuracy validation performance is slightly higher than when using all actual data usage. Moreover, in only 60 % of actual data usage and in combination with 625 samples of synthetic data, the accuracy performance is improved to 0.73 (1.37 times higher than the use of all actual data, 0.53). Thus, this result proves that the challenges of offline fingerprint databases can be alleviated by data synthesis through GAN by using only a small dataset. © 2023 Kauno Technologijos Universitetas. All rights reserved.;Not health related;0"Kim K.; Chun C.; Moon S.-Y.";Conformer-Based Dental AI Patient Clinical Diagnosis Simulation Using Korean Synthetic Data Generator for Multiple Standardized Patient Scenarios;2023;The goal of clinical practice education is to develop the ability to apply theoretical knowledge in a clinical setting and to foster growth as a professional healthcare provider. One effective method of achieving this is through the utilization of Standardized Patients (SP) in education, which familiarizes students with real patient interviews and allows educators to assess their clinical performance skills. However, SP education faces challenges such as the cost of hiring actors and the shortage of professional educators to train them. In this paper, we aim to alleviate these issues by utilizing deep learning models to replace the actors. We employ the Conformer model for the implementation of the AI patient, and we develop a Korean SP scenario data generator to collect data for training responses to diagnostic questions. Our Korean SP scenario data generator is devised to generate SP scenarios based on the provided patient information, using pre-prepared questions and answers. In the AI patient training process, two types of data are employed: common data and personalized data. The common data are employed to develop natural general conversation skills, while personalized data, from the SP scenario, are utilized to learn specific clinical information relevant to a patient’s role. Based on these data, to evaluate the learning efficiency of the Conformer structure, a comparison was conducted with the Transformer using the BLEU score and WER as evaluation metrics. Experimental results showed that the Conformer-based model demonstrated a 3.92% and 6.74% improvement in BLEU and WER performance compared to the Transformer-based model, respectively. The dental AI patient for SP simulation presented in this paper has the potential to be applied to other medical and nursing fields, provided that additional data collection processes are conducted. © 2023 by the authors.;Health related;1"Han Y.; Nanda G.; Moghaddam M.";Attribute-Sentiment-Guided Summarization of User Opinions From Online Reviews;2023;Eliciting informative user opinions from online reviews is a key success factor for innovative product design and development. The unstructured, noisy, and verbose nature of user reviews, however, often complicate large-scale need finding in a format useful for designers without losing important information. Recent advances in abstractive text summarization has created the opportunity to systematically generate opinion summaries from online reviews to inform the early stages of product design and development. However, two knowledge gaps hinder the applicability of opinion summarization methods in practice. First, there is a lack of formal mechanisms to guide the generative process with respect to different categories of product attributes and user sentiments. Second, the annotated training datasets needed for supervised training of abstractive summarization models are often difficult and costly to create. This article addresses these gaps by (1) devising an efficient computational framework for abstractive opinion summarization guided by specific product attributes and sentiment polarities, and (2) automatically generating a synthetic training dataset that captures various degrees of granularity and polarity. A hierarchical multi-instance attribute-sentiment inference mode is developed for assembling a high-quality synthetic dataset, which is utilized to fine-tune a pretrained language model for abstractive summary generation. Numerical experiments conducted on a large dataset scraped from three major e-Commerce retail store for apparel and footwear products indicate the performance, feasibility, and potentials of the developed framework. Several directions are provided for future exploration in the area of automated opinion summarization for user-centered design. © 2023 American Society of Mechanical Engineers (ASME). All rights reserved.;Not health related;0"Klokov A.A.; Pak D.U.; Khorin A.; Yudin D.A.; Kochiev L.; Luchinskiy V.D.; Bezuglyj V.D.";DAPS3D: Domain Adaptive Projective Segmentation of 3D LiDAR Point Clouds;2023;LiDARs are one of the key sources of reliable environmental ranging information for autonomous vehicles. However, segmentation of 3D scene elements (roads, buildings, people, cars, etc.) based on LiDAR point clouds has limitations. On the one hand, point- and voxel-based segmentation neural networks do not offer sufficiently high speed. On the other hand, modern labeled datasets primarily consist of street scenes recorded for driverless cars and contain little data for mobile delivery robots or cleaners that must work in parks and yards with heavy pedestrian traffic. This article aims to overcome these limitations. We have proposed a novel approach called DAPS3D to train deep neural networks for 3D semantic segmentation. This approach is based on a spherical projection of a point cloud and LiDAR-specific masks, enabling the model to adapt to different types of LiDAR. First of all, we have introduced various high-speed multi-scale spherical projection segmentation models, including convolutional, recurrent, and transformer architectures. Among them, the SalsaNextRecLSTM architecture with recurrent blocks showed the best results. In particular, this model achieved the 83.5% mIoU metric for the SemanticKitti dataset with joint categories. Secondly, we have proposed several original augmentations for spherical projections of LiDAR data, including FoV, flip, and rotation augmentation, as well as a special T-Zone cutout. These augmentations increase the model's invariance when dealing with changes in the data domain. Finally, we introduce a new method to generate synthetic datasets for domain adaptation problems. We have developed two new datasets for validating 3D scene outdoor segmentation algorithms: the DAPS-1 dataset, which is based on the augmentation of the reconstructed 3D semantic map, and the DAPS-2 LiDAR dataset, collected by the on-board sensors of a cleaning robot in a park area. Particular attention is given to the performance of the developed models, demonstrating their ability to function in real-time. The code and datasets used in this study are publicly available at: github.com/subake/DAPS3D.  © 2013 IEEE.;Not health related;0"Yang M.; Svirsky Y.; Cheng Z.; Sharf A.";Self-Supervised Fragment Alignment With Gaps;2023;"Image alignment and registration methods typically rely on visual correspondences across common regions and boundaries to guide the alignment process. Without them, the problem becomes significantly more challenging. Nevertheless, in real world, image fragments may be corrupted with no common boundaries and little or no overlap. In this work, we address the problem of learning the alignment of image fragments with gaps (i.e., without common boundaries or overlapping regions). Our setting is unsupervised, having only the fragments at hand with no ground truth to guide the alignment process. This is usually the situation in the restoration of unique archaeological artifacts such as frescoes and mosaics. Hence, we suggest a self-supervised approach utilizing <italic>self-examples</italic> which we generate from the existing data and then feed into an adversarial neural network. Our idea is that available information inside fragments is often sufficiently rich to guide their alignment with good accuracy. Following this observation, our method splits the initial fragments into sub-fragments yielding a set of aligned pieces. Thus, sub-fragmentation allows exposing new alignment relations and revealing inner structures and feature statistics. In fact, the new sub-fragments construct true and false alignment relations between fragments. We feed this data to a spatial transformer GAN which learns to predict the alignment between fragments gaps. We test our technique on various synthetic datasets as well as large scale frescoes and mosaics. Results demonstrate our method&#x0027;s capability to learn the alignment of deteriorated image fragments in a self-supervised manner, by examining inner image statistics for both synthetic and real data. IEEE";Not health related;0"Sadad T.; Aurangzeb R.A.; Safran M.; Imran; Alfarhood S.; Kim J.";Classification of Highly Divergent Viruses from DNA/RNA Sequence Using Transformer-Based Models;2023;Viruses infect millions of people worldwide each year, and some can lead to cancer or increase the risk of cancer. As viruses have highly mutable genomes, new viruses may emerge in the future, such as COVID-19 and influenza. Traditional virology relies on predefined rules to identify viruses, but new viruses may be completely or partially divergent from the reference genome, rendering statistical methods and similarity calculations insufficient for all genome sequences. Identifying DNA/RNA-based viral sequences is a crucial step in differentiating different types of lethal pathogens, including their variants and strains. While various tools in bioinformatics can align them, expert biologists are required to interpret the results. Computational virology is a scientific field that studies viruses, their origins, and drug discovery, where machine learning plays a crucial role in extracting domain- and task-specific features to tackle this challenge. This paper proposes a genome analysis system that uses advanced deep learning to identify dozens of viruses. The system uses nucleotide sequences from the NCBI GenBank database and a BERT tokenizer to extract features from the sequences by breaking them down into tokens. We also generated synthetic data for viruses with small sample sizes. The proposed system has two components: a scratch BERT architecture specifically designed for DNA analysis, which is used to learn the next codons unsupervised, and a classifier that identifies important features and understands the relationship between genotype and phenotype. Our system achieved an accuracy of 97.69% in identifying viral sequences. © 2023 by the authors.;Health related;1"Yang C.; Du J.; Xue M.; Zhang J.";"An encoder-decoder based generation model for online handwritten mathematical expressions; [________________]";2023;Objective The emerging digitization and intelligence techniques have facilitated the path to accept and recognize text content originated from paper documents_photos_or contexts nowadasys. Recent online mathematical expression recognition is widely used for such domain of portable devices like mobile phones and tablet PCs. The devices are required for converting the online handwritten trajectory into mathematical expression text and indicate symbols-between logical relationship in relevance to such of power_subscript and matrix. Online math calculator can be used to receive handwritten mathematical expressions in terms of online mathematical expression recognition_which makes input easier beyond LaTeX mathematical expressions with symbols of complex mathematical relation. At the same time_instant electric recording in complex scenarios becomes feasible for such scenarios like classes and academic meetings. Current encoder-decoder based mathematical expression recognition methods have been developing intensively. The quality and quantity of training data have a great impact on the performance of deep neural network. The lack of data has threatened the optimization of generalization and robustness of the model in consistency. The input form of the mathematical expression in the online scene is recognized as the track point sequence_which needs to be collected on the annotation-before real time handwriting device further. Therefore_cost of online data collection is higher than offline data. The model still has poor performance due to insufficient data. Method To resolve the problems mentioned above_we develop an encoder-decoder based generation model for online handwritten mathematical expressions. The model can generate the corresponding online trajectory point sequence in terms of the given mathematical expression text. We also can synthesize different-writing-style mathematical expressions by different style symbols input. A large amount of near real handwriting data is obtained at a very low cost_which expands the scale of training data flexibly and avoids lacked data fitting or over fitting of the model. For generation tasks_the ability of representation and discrimination of the encoder often affect the performance directly. The encoder aims to model the input text effectively. In detail_sufficient difference is needed between the representations of different inputs_and certain similarity is required between the ones of similar inputs as well. Intuitively_the representation of tree structure can well reflect expressions-between similarities and differences to some extent. Therefore_we design a tree representation-based text feature extraction module for the generation model in the encoder_which makes full use of the two-dimensional structure information. In addition_there is no corresponding relationship between each character of input text and the output track points. Therefore_to align the input text sequence with the output track points_we introduce a location-based attention model into the decoder. Simutaneously_to generate multiple handwriting style samples_we also integrate different handwriting style features into the decoder. The decoder can be used to synthesize the skeleton of the track through the input text_and writing style feature-related can be rendered into different styles. Result The method proposed is evaluated from two aspects_visual effect of generated results and the improvement of recognition tasks. First_we illustrate generation results of different difficulty_including simple sequence_complex fraction_multi-line expression and long text. Second_we select and display the generated data with similar and different writing styles. Next_we generate a large number of mathematical expression texts and synthesize online data randomly based on the generation model. Finally_we use these synthetic data as data augmentation to train the Transformer-TAP _track_attend_and parse)_TAP and Densetap-TD _DenseNet TAP with tree decoder_as well. The performance of these three models is significantly improved beneficial from synthetic data. The additional data enriches the training set and the model is mutual-benefited for more symbol combinations with different writing styles. The results show that each of the absolute recognition rates is increased by 0. 98%_1. 55% and 1. 06%_as well as each of the relative recognition rates is increased by 9. 9%_12. 37% and 9. 81%. Conclu_ sion An online mathematical expression generation method is introduced based on encoder-decoder model. The method can be used to realize the generation of on-line trajectory point sequence from given expression text. It can expand the original data set more flexibly to a certain extent. Experimental result demonstrates that the synthetic data can improve the accuracy of online handwriting mathematical expression recognition effectively. It improves the generalization and robustness of the recognition model further. © 2022 Chinese Academy of Railway Sciences. All rights reserved.;Not health related;0"Zhang Q.; Lai J.; Xie X.; Chen H.";"A summary on group re-identification; [___________]";2023;Pedestrians-oriented group re-identification_GReID_analysis is focused on non-overlapped and multi-viewed small groups. To extract stable and robust feature representations_the challenge issue of GReID is to model the temporal changes and intra-group pedestrians. Our summary is reviewed on the growth of GReID critically. First_we review its research domain in related to its basic concepts_technologies and datasets in relevance. To optimize the surveillance in public security_the GReID can monitor and prevent group-based crimes accurately like women and children-oriented kid_ napping and trafficking. Due to pedestrians-targeted are severely occluded or even disappeared_it can leverage the appear_ ance features of pedestrians’partners as additional prior information for recognition. Specifically_GReID-based groups are composed of 2 to 8 members. First_the same group can be identified when the identified intersection-over-union_IoU_ratio of member is greater than 60% in the two group images. Then_a variety of GReID algorithms are introduced and tested in detail. The existing works can be categorized from three perspectives_1_data_2_method_and 3_label. For data types_the existing methods can be segmented into_real image-based_synthetic images-based_and real video-based methods. The real images-based method is basically focused on the datasets collected from real surveillance scenarios_such as CUHK-SYSU Group_CSG__RoadGroup_iLIDS-MCTS_and etc. These datasets can be used to collect several group images from different camera views of different groups and provide the elements of location information and identifica_ tion information of member. This supervision information can be used to design discriminative group feature representa_ tions. However_it is still more challenging to collect and label the real group datasets than the traditional pedestrian reidentification datasets because the consistent group identity is required to be judged between group images_including mem_ ber variations and layout variations. The following datasets are proposed based on 3D synthetic images. This type of datas_ ets can generate mass group images with high-quality labels efficiency and effectively. These methods can be used to improve the performances of the model in real datasets through massive synthetic data. The video-based datasets can pro_ vide several consecutive frames for each group from the surveillance videos. Researchers can extract the group features according to the potential patio-temporal or intra-group relationships. They can be mainly divided into_traditional methods and deep learning methods. The former one is to design group descriptors and extract group features derived of human expe_ rience. However_due to the high dependence on the prior knowledge of expertise_it is unable to describe and generalize all possible situations for group images. The model can construct the representations of group images automatically because the emerging deep learning based methods is beneficial for a large number of data samples_and the discrimination and robustness of the deep models have been significantly improved. Deep learning-based methods can be divided into 1_the feature learning-based_2_metric learning based_and 3_generative adversarial network_GAN_based. The deep feature learning based methods aim to design a discriminative network structure or a discriminative feature learning strategy. The features-extracted can reflect the group identification of the input images accurately_and it can be robust enough to sup_ press occlusion_illumination_number and layout variations of intra-group members. Metric learning based methods can be focused on a similarity criterion evaluation between two groups of images. To get high similarity under the designed mea_ surement criteria_even two group images from the same group class have great differences. To optimize small size of the dataset_GAN-based method attempts to expand the dataset scale of the GReID task by style transfer of samples from other related pedestrian re-identification datasets. For its label_the existing methods can be categorized into_supervised and unsupervised. Supervised learning based methods tend to be more competitive because the group labels or the member labels are participated in the entire training process. It often can learn the similarity only for the local area of the group images because labels are not be provided in the unsupervised learning_and cluster methods can be designed to extract the feature representations of the same group class. To sum up_1_the specific scenarios based GReID is required to be devel_ oped from the aspects of data collection and method design further_2_GReID is still not interrelated to other related visual tasks mutually. Therefore_multiple tasks-collaborated are called to resolve more industry needs_and the implementation of the industry is required to be accelerated for the domain of academia and industry. Furthermore_the data privacy policy-relevant ethic issue needs to be utilized for virtual data and real data in the future. © 2023 Editorial and Publishing Board of JIG;Not health related;0"Fu J.; Xiang Z.; Qiao C.; Bai T.";PT-FlowNet: Scene Flow Estimation on Point Clouds With Point Transformer;2023;As a low-level task of 3D perception, scene flow is a fundamental representation of dynamic scenes and provides non-rigid motion descriptions for the objects in the 3D environment, which can strongly support many upper-level applications. Inspired by the revolutionary success of deep learning, many attention-based neural networks have recently been proposed to estimate scene flow from consecutive point clouds. However, extracting effective features and estimating accurate point motions for irregular and occluded point clouds remains a challenging task. In this letter, we propose PT-FlowNet, the first end-to-end scene flow estimation network embedding the point transformer (PT) into all functional stages of the task. In particular, we design novel PT-based modules for point feature extraction, iterative flow update, and flow refinement stage to encourage effective point-level feature aggregation. Experimental results on FlyingThings3D and KITTI datasets show that our PT-FlowNet achieves state-of-the-art performance. Trained on synthetic data only, our PT-FlowNet can generalize to real-world scans and outperforms the existing methods by at least 36.2% for the EPE3D metric on the KITTI dataset. © 2016 IEEE.;Not health related;0"Chu Z.; He J.; Peng D.; Zhang X.; Zhu N.";Differentially Private Denoise Diffusion Probability Models;2023;Diffusion models and their variants have achieved high-quality image generation without adversarial training. These algorithms provide new ideas for data shortages in some fields. But the diffusion model also faces the same problem as other generative models: The learned probability density function will retain the characteristics of the training samples, which means that the high complexity of the deep network will make the model easily remember the training samples. When a diffusion model is applied to sensitive datasets, the distribution the model focuses on may reveal private information, and the security concerns described above become more pronounced. To address this challenge, this paper proposes a privacy diffusion model named DPDM (Differentially Private Denoise Diffusion Probability Models) that satisfies differential privacy by adding appropriate noise to the gradient during the training. Besides, this paper adopts a series of optimization strategies to improve model performance and training speed such as adaptive gradient clipping threshold and dynamic decay learning rate. Through the evaluation and analysis of the benchmark dataset, it is found that the attempt in this paper has promising usability, and the synthetic data has better performance.  © 2013 IEEE.;Not health related;0"Mahmoud Z.; Li C.; Zappatore M.; Solyman A.; Alfatemi A.; Ibrahim A.O.; Abdelmaboud A.";Semi-supervised learning and bidirectional decoding for effective grammar correction in low-resource scenarios;2023;The correction of grammatical errors in natural language processing is a crucial task as it aims to enhance the accuracy and intelligibility of written language. However, developing a grammatical error correction (GEC) framework for low-resource languages presents significant challenges due to the lack of available training data. This article proposes a novel GEC framework for low-resource languages, using Arabic as a case study. To generate more training data, we propose a semi-supervised confusion method called the equal distribution of synthetic errors (EDSE), which generates a wide range of parallel training data. Additionally, this article addresses two limitations of the classical seq2seq GEC model, which are unbalanced outputs due to the unidirectional decoder and exposure bias during inference. To overcome these limitations, we apply a knowledge distillation technique from neural machine translation. This method utilizes two decoders, a forward decoder right-to-left and a backward decoder left-to-right, and measures their agreement using Kullback-Leibler divergence as a regularization term. The experimental results on two benchmarks demonstrate that our proposed framework outperforms the Transformer baseline and two widely used bidirectional decoding techniques, namely asynchronous and synchronous bidirectional decoding. Furthermore, the proposed framework reported the highest F1 score, and generating synthetic data using the equal distribution technique for syntactic errors resulted in a significant improvement in performance. These findings demonstrate the effectiveness of the proposed framework for improving grammatical error correction for low-resource languages, particularly for the Arabic language. © 2023 Mahmoud et al. Distributed under Creative Commons CC-BY 4.0. All Rights Reserved.;Not health related;0"Dang Q.-V.; Lee G.-S.";Scene Text Segmentation via Multi-Task Cascade Transformer With Paired Data Synthesis;2023;The scene text segmentation task provides a wide range of practical applications. However, the number of images in the available datasets for scene text segmentation is not large enough to effectively train deep learning-based models, leading to limited performance. To solve this problem, we employ paired data generation to secure sufficient data samples for text segmentation via Text Image-conditional GANs. Furthermore, existing models implicitly model text attributes such as size, layout, font, and structure, which hinders their performance. To remedy this, we propose a Multi-task Cascade Transformer network that explicitly learns these attributes using large volumes of generated synthetic data. The transformer-based network includes two auxiliary tasks and one main task for text segmentation. The auxiliary tasks help the network learn text regions to focus on, as well as the structure of the text through different words and fonts, to support the main task. To bridge the gap between different datasets, we train the proposed network on paired synthetic data before fine-tuning it on real data. Our experiments on publicly available scene text segmentation datasets show that our method outperforms existing methods. © 2013 IEEE.;Not health related;0"Hamdan M.; Chaudhary H.; Bali A.; Cheriet M.";Refocus attention span networks for handwriting line recognition;2023;Recurrent neural networks have achieved outstanding recognition performance for handwriting identification despite the enormous variety observed across diverse handwriting structures and poor-quality scanned documents. We initially proposed a BiLSTM baseline model with a sequential architecture well-suited for modeling text lines due to its ability to learn probability distributions over character or word sequences. However, employing such recurrent paradigms prevents parallelization and suffers from vanishing gradients for long sequences during training. To alleviate these limitations, we propose four significant contributions to this work. First, we devised an end-to-end model composed of a split-attention CNN-backbone that serves as a feature extraction method and a self-attention Transformer encoder–decoder that serves as a transcriber method to recognize handwriting manuscripts. The multi-head self-attention layers in an encoder–decoder transformer-based enhance the model’s ability to tackle handwriting recognition and learn the linguistic dependencies of character sequences. Second, we conduct various studies on transfer learning (TL) from large datasets to a small database, determining which model layers require fine-tuning. Third, we attained an efficient paradigm by combining different strategies of TL with data augmentation (DA). Finally, since the robustness of the proposed model is lexicon-free and can recognize sentences not presented in the training phase, the model is only trained on a few labeled examples with no extra cost of generating and training on synthetic datasets. We recorded comparable and outperformed Character and Word Error Rates CER/WER on four benchmark datasets to the most recent (SOTA) models. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Sun C.; van Soest J.; Dumontier M.";Generating synthetic personal health data using conditional generative adversarial networks combining with differential privacy;2023;A large amount of personal health data that is highly valuable to the scientific community is still not accessible or requires a lengthy request process due to privacy concerns and legal restrictions. As a solution, synthetic data has been studied and proposed to be a promising alternative to this issue. However, generating realistic and privacy-preserving synthetic personal health data retains challenges such as simulating the characteristics of the patients’ data that are in the minority classes, capturing the relations among variables in imbalanced data and transferring them to the synthetic data, and preserving individual patients’ privacy. In this paper, we propose a differentially private conditional Generative Adversarial Network model (DP-CGANS) consisting of data transformation, sampling, conditioning, and network training to generate realistic and privacy-preserving personal data. Our model distinguishes categorical and continuous variables and transforms them into latent space separately for better training performance. We tackle the unique challenges of generating synthetic patient data due to the special data characteristics of personal health data. For example, patients with a certain disease are typically the minority in the dataset and the relations among variables are crucial to be observed. Our model is structured with a conditional vector as an additional input to present the minority class in the imbalanced data and maximally capture the dependency between variables. Moreover, we inject statistical noise into the gradients in the networking training process of DP-CGANS to provide a differential privacy guarantee. We extensively evaluate our model with state-of-the-art generative models on personal socio-economic datasets and real-world personal health datasets in terms of statistical similarity, machine learning performance, and privacy measurement. We demonstrate that our model outperforms other comparable models, especially in capturing the dependence between variables. Finally, we present the balance between data utility and privacy in synthetic data generation considering the different data structures and characteristics of real-world personal health data such as imbalanced classes, abnormal distributions, and data sparsity. © 2023;Health related;1"Lin N.; Wu S.; Wu Z.; Ji S.";Efficient Generation of Pretraining Samples for Developing a Deep Learning Brain Injury Model via Transfer Learning;2023;"The large amount of training samples required to develop a deep learning brain injury model demands enormous computational resources. Here, we study how a transformer neural network (TNN) of high accuracy can be used to efficiently generate pretraining samples for a convolutional neural network (CNN) brain injury model to reduce computational cost. The samples use synthetic impacts emulating real-world events or augmented impacts generated from limited measured impacts. First, we verify that the TNN remains highly accurate for the two impact types (N = 100 each; R2 of 0.948–0.967 with root mean squared error, RMSE, ~ 0.01, for voxelized peak strains). The TNN-estimated samples (1000–5000 for each data type) are then used to pretrain a CNN, which is further finetuned using directly simulated training samples (250–5000). An independent measured impact dataset considered of complete capture of impact event is used to assess estimation accuracy (N = 191). We find that pretraining can significantly improve CNN accuracy via transfer learning compared to a baseline CNN without pretraining. It is most effective when the finetuning dataset is relatively small (e.g., 2000–4000 pretraining synthetic or augmented samples improves success rate from 0.72 to 0.81 with 500 finetuning samples). When finetuning samples reach 3000 or more, no obvious improvement occurs from pretraining. These results support using the TNN to rapidly generate pretraining samples to facilitate a more efficient training strategy for future deep learning brain models, by limiting the number of costly direct simulations from an alternative baseline model. This study could contribute to a wider adoption of deep learning brain injury models for large-scale predictive modeling and ultimately, enhancing safety protocols and protective equipment. © 2023, The Author(s) under exclusive licence to Biomedical Engineering Society.";Not health related;1"Flanagan A.R.; Glavin F.G.";A Comparative Analysis of Data Synthesis Techniques to Improve Classification Accuracy of Raman Spectroscopy Data;2023;"Raman spectra are examples of high dimensional data that can often be limited in the number of samples. This is a primary concern when Deep Learning frameworks are developed for tasks such as chemical species identification, quantification, and diagnostics. Open-source data are difficult to obtain and often sparse; furthermore, the collecting and curating of new spectra require expertise and resources. Deep generative modeling utilizes Deep Learning architectures to approximate high dimensional distributions and aims to generate realistic synthetic data. The evaluation of the data and the performance of the deep models is usually conducted on a per-task basis and provides no indication of an increase to robustness, or generalization, on a wider scale. In this study, we compare the benefits and limitations of a standard statistical approach to data synthesis (weighted blending) with a popular deep generative model, the Variational Autoencoder. Two binary data sets are divided into 3-fold to simulate small, limited samples. Synthetic data distributions are created per fold using the two methods and then augmented into the training of two Deep Learning algorithms, a Convolutional Neural Network and a Fully-Connected Neural Network. The goal of this study is to observe the trends in learning as synthetic data are continually augmented to the training data in increasing batches. To determine the impact of each synthetic method, Principal Component Analysis and the discrete Fréchet distance are implemented to visualize and measure the distance between the source and synthetic distributions along with the Machine Learning metric balanced accuracy for evaluating performance on imbalanced data. © 2023 The Authors. Published by American Chemical Society.";Not health related;0"Clavijo J.J.; Martínez J.F.";Adversarial learning of permanent seismic deformation from GNSS coordinate timeseries;2023;Deformation produced by an earthquake has a wide variety of forms. Therefore, there are a variety of models for quantifying the amount of deformation observed on GNSS coordinate timeseries, each of them based on different assumptions about the underlying mechanism that generates the data. Hence, it is of interest to look for methods relying on minimal assumptions about the observed position series. In this work we propose a semiparametric method, based on adversarial learning, to perform inference of the permanent seismic deformation. The only assumption made is that the probability distributions of GNSS fixed-length coordinate series for periods with and without observable seismic deformation differs mainly in the permanent deformation, represented by an additive scaled heaviside function. A dataset based on the series of GNSS coordinates published by the Nevada Geodetic Laboratory was built, and an adversarial model was trained over this dataset. In order to train the algorithm, an initial labeling of the samples was conducted using time, position an magnitude information of seismic events from the USGS database. It was shown that learning was possible with the available real data, and multiple sanity checks were run, showing consistency of the offset estimations compared with a trajectory model based estimator and with published offsets for well studied events on the South American active margin. To assess the capabilities of the method in a more controlled environment, further experiments were conducted on synthetic data. Those experiments confirmed that the presence of postseismic transient signals does not impede learning. As a derivative, our proposal allows to refine imperfect initial estimations for the presence/absence of seismic deformation. © 2023 Elsevier Ltd;Not health related;0"Gao F.; Ji S.; Guo J.; Hou J.; Ouyang C.; Yang B.";"A Multi-Stage Transformer Network for Image Dehazing Based on Contrastive Learning; [__________Transformer______]";2023;A multi-stage Transformer network for image dehazing based on contrastive learning is proposed to solve the problem that existing image dehazing methods fail to achieve the desired results in local image dehazing and detail restoration, and the non-homogeneous haze cannot be removed completely all the way. First, the channel-wise Transformer block is utilized as the primary feature extraction block to adequately capture the mutual long-range dependencies among channels. Second, the multi-modality supervised contrastive learning is introduced to maximize the capturing efficiency of information from the contrastive samples, so that the restored image is closer to the clear image in the embedding space while staying as far away from the hazy image as possible. Finally, a hierarchical multi-patch structure and deformable Transformer blocks are employed to effectively integrate the local and global structural information of the hazy image. Moreover, a large number of tests have been conducted on the proposed method by using two synthetic data sets and the three real data sets. The results show that the proposed MSTCNet achieves a higher peak signal-to-noise ratio(PSNR)gain of 1.49, 1.45, 0.11, 1.45 and 0.22 dB on five datasets, respectively. It outperforms existing methods in both general and non-data sets, shows the best visual effect of dehazing in removing the dense, non-homogeneous and uniform haze, and achieves the highest objective evaluation index value. © 2023 Xi'an Jiaotong University. All rights reserved.;Not health related;0"Saitta S.; Maga L.; Armour C.; Votta E.; O'Regan D.P.; Salmasi M.Y.; Athanasiou T.; Weinsaft J.W.; Xu X.Y.; Pirola S.; Redaelli A.";Data-driven generation of 4D velocity profiles in the aneurysmal ascending aorta;2023;Background and Objective: Numerical simulations of blood flow are a valuable tool to investigate the pathophysiology of ascending thoratic aortic aneurysms (ATAA). To accurately reproduce in vivo hemodynamics, computational fluid dynamics (CFD) models must employ realistic inflow boundary conditions (BCs). However, the limited availability of in vivo velocity measurements, still makes researchers resort to idealized BCs. The aim of this study was to generate and thoroughly characterize a large dataset of synthetic 4D aortic velocity profiles sampled on a 2D cross-section along the ascending aorta with features similar to clinical cohorts of patients with ATAA. Methods: Time-resolved 3D phase contrast magnetic resonance (4D flow MRI) scans of 30 subjects with ATAA were processed through in-house code to extract anatomically consistent cross-sectional planes along the ascending aorta, ensuring spatial alignment among all planes and interpolating all velocity fields to a reference configuration. Velocity profiles of the clinical cohort were extensively characterized by computing flow morphology descriptors of both spatial and temporal features. By exploiting principal component analysis (PCA), a statistical shape model (SSM) of 4D aortic velocity profiles was built and a dataset of 437 synthetic cases with realistic properties was generated. Results: Comparison between clinical and synthetic datasets showed that the synthetic data presented similar characteristics as the clinical population in terms of key morphological parameters. The average velocity profile qualitatively resembled a parabolic-shaped profile, but was quantitatively characterized by more complex flow patterns which an idealized profile would not replicate. Statistically significant correlations were found between PCA principal modes of variation and flow descriptors. Conclusions: We built a data-driven generative model of 4D aortic inlet velocity profiles, suitable to be used in computational studies of blood flow. The proposed software system also allows to map any of the generated velocity profiles to the inlet plane of any virtual subject given its coordinate set. © 2023 The Authors;Health related;0"Azadmanesh M.; Shahgholi Ghahfarokhi B.; Ashouri Talouki M.";An Auto-Encoder based Membership Inference Attack against Generative Adversarial Network;2023;Using generative models to produce unlimited synthetic samples is a popular replacement for database sharing. Generative Adversarial Network (GAN) is a popular class of generative models which generates synthetic data samples very similar to real training datasets. However, GAN models do not necessarily guarantee training privacy as these models may memorize details of training data samples. When these models are built using sensitive data, the developers should ensure that the training dataset is appropriately protected against privacy leakage. Hence, quantifying the privacy risk of these models is essential. To this end, this paper focuses on evaluating the privacy risk of publishing the generator network of GAN models. Specially, we conduct a novel generator white-box membership inference attack against GAN models that exploits accessible information about the victim model, i.e., the generator’s weights and synthetic samples, to conduct the attack. In the proposed attack, an auto-encoder is trained to determine member and non-member training records. This attack is applied to various kinds of GANs. We evaluate our attack accuracy with respect to various model types and training configurations. The results demonstrate the superior performance of the proposed attack on non-private GANs compared to previous attacks in white-box generator access. The accuracy of the proposed attack is 19% higher on average than similar work. The proposed attack, like previous attacks, has better performance for victim models that are trained with small training sets. © 2020 ISC. All rights reserved.;Not health related;0"Lin J.; Michailidis G.";A multi-task encoder-dual-decoder framework for mixed frequency data prediction;2023;"Mixed-frequency data prediction tasks are pertinent in various application domains, in which one leverages progressively available high-frequency data to forecast/nowcast the low-frequency ones. Existing methods in the literature tailored to such tasks are mostly linear in nature; depending on the specific formulation, they largely rely on the assumption that the (latent) processes that govern the dynamics of the high- and low-frequency blocks of variables evolve at the same frequency, either the low or the high one. This paper develops a neural network-based multi-task shared-encoder-dual-decoder framework for joint multi-horizon prediction of both the low- and high-frequency blocks of variables, wherein the encoder/decoder modules can be either long short-term memory or transformer ones. It addresses forecast/nowcast tasks in a unified manner, leveraging the encoder–decoder structure that can naturally accommodate the mixed-frequency nature of the data. The proposed framework exhibited competitive performance when assessed on both synthetic data experiments and two real datasets of US macroeconomic indicators and electricity data. © 2023 The Authors";Not health related;0"Zhu Y.; Shen X.; Du P.";Denoising-Based Decoupling-Contrastive Learning for Ubiquitous Synthetic Face Images;2023;With the improvement of generative models such as GPT-4, GANs, and diffusion models, synthetic face images are increasingly pervading the current digital environment. Various face editing software based on generative models is already commercially available, which can edit face image attributes, including changing age, makeup, hair, scars, gender, etc. Existing face recognition methods tend to employ synthetic face images to augment datasets during large-scale training. However, the involvement of low-quality synthetic data can impair the feature extraction ability, consequently affecting recognition performance. Furthermore, face editing can potentially be applied for illegal or criminal purposes, such as criminals uploading edited face images to disguise themselves, thereby reducing the accuracy of face recognition models. To mitigate the negative impact of synthetic face images, we propose a denoising-based decoupling-contrastive learning (DDCL) method for extracting more benign features from synthetic data. By designing a siamese network structure with two branches, the framework extracts robust features from natural and synthetic images with the contrastive learning mechanism. Subsequently, the bi-directional coding-based feature decoupling module filters out features of synthetic images before proceeding to identity recognition. Experimental results demonstrate that our method can alleviate the negative impact of synthetic face images and achieve the highest recognition accuracy for both synthetic and natural data.  © 2013 IEEE.;Not health related;0"Solyman A.; Zappatore M.; Zhenyu W.; Mahmoud Z.; Alfatemi A.; Ibrahim A.O.; Gabralla L.A.";Optimizing the impact of data augmentation for low-resource grammatical error correction;2023;Grammatical Error Correction (GEC) refers to the automatic identification and amendment of grammatical, spelling, punctuation, and word-positioning errors in monolingual texts. Neural Machine Translation (NMT) is nowadays one of the most valuable techniques used for GEC but it may suffer from scarcity of training data and domain shift, depending on the addressed language. However, current techniques (e.g., tuning pre-trained language models or developing spell-confusion methods without focusing on language diversity) tackling the data sparsity problem associated with NMT create mismatched data distributions. This paper proposes new aggressive transformation approaches to augment data during training that extend the distribution of authentic data. In particular, it uses augmented data as auxiliary tasks to provide new contexts when the target prefix is not helpful for the next word prediction. This enhances the encoder and steadily increases its contribution by forcing the GEC model to pay more attention to the text representations of the encoder during decoding. The impact of these approaches was investigated using the Transformer-based for low-resource GEC task, and Arabic GEC was used as a case study. GEC models trained with our data tend more to source information, are more domain shift robustness, and have less hallucinations with tiny training datasets and domain shift. Experimental results showed that the proposed approaches outperformed the baseline, the most common data augmentation methods, and classical synthetic data approaches. In addition, a combination of the three best approaches Misspelling, Swap, and Reverse achieved the best F1 score in two benchmarks and outperformed previous Arabic GEC approaches. © 2023 The Authors;Not health related;0"Zhou T.; Huang J.; Yu T.; Shao R.; Li K.";HDhuman: High-quality Human Novel-view Rendering from Sparse Views;2023;In this paper, we aim to address the challenge of novel view rendering of human performers that wear clothes with complex texture patterns using a sparse set of camera views. Although some recent works have achieved remarkable rendering quality on humans with relatively uniform textures using sparse views, the rendering quality remains limited when dealing with complex texture patterns as they are unable to recover the high-frequency geometry details that are observed in the input views. To this end, we propose HDhuman, which uses a human reconstruction network with a pixel-aligned spatial transformer and a rendering network with geometry-guided pixel-wise feature integration to achieve high-quality human reconstruction and rendering. The designed pixel-aligned spatial transformer calculates the correlations between the input views and generates human reconstruction results with high-frequency details. Based on the surface reconstruction results, the geometry-guided pixel-wise visibility reasoning provides guidance for multi-view feature integration, enabling the rendering network to render high-quality images at 2k resolution on novel views. Unlike previous neural rendering works that always need to train or fine-tune an independent network for a different scene, our method is a general framework that is able to generalize to novel subjects. Experiments show that our approach outperforms all the prior generic or specific methods on both synthetic data and real-world data. Source code and test data will be made publicly available for research purposes. IEEE;Not health related;0"Kholgh D.K.; Kostakos P.";PAC-GPT: A Novel Approach to Generating Synthetic Network Traffic With GPT-3;2023;The application of machine learning models, particularly in cybersecurity, has surged significantly in the past few years. However, the effectiveness of these models is predominantly tethered to the quality and breadth of the training data they ingest. The scarcity of realistic datasets within the cybersecurity field constitutes a considerable challenge to the development of industry-grade tools intended for real-world application scenarios. Specifically, current datasets are either significantly outdated or fall short on both qualitative and quantitative fronts, primarily because many organizations exhibit reluctance in data sharing, stemming from privacy concerns or the potential threat to trade secrets. To address this challenge, the paper introduces PAC-GPT, a novel framework to generate reliable synthetic data for machine learning methods based on Open AI's Generative Pre-trained Transformer 3 (GPT-3). The core components of this framework are two modules, namely a Flow Generator, which is responsible for capturing and regenerating patterns in a series of network packets, and Packet Generator, which can generate individual network packets given the network flow. We also propose a packet generator based on LLM chaining and then proceed to assess, compare, and evaluate its performance using metrics such as loss, accuracy and success rate, concluding that transformers are a suitable approach for synthetic packet generation with minimal fine-tuning performed. Lastly, a streamlined command line interface (CLI) tool has been devised to facilitate the seamless access of this innovative data generation strategy by professionals from various disciplines. © 2013 IEEE.;Not health related;0"Luo Y.; Huang Q.; Ling J.; Lin K.; Zhou T.";Local and global knowledge distillation with direction-enhanced contrastive learning for single-image deraining;2023;Single image deraining (SID) is a challenging problem since the rainy images contain a variety of backgrounds with rain streaks of different directions and densities. Though previous convolutional neural network based methods for SID have shown promising performance, their characterization ability is limited as they suffer from the local receptive fields and ignore long-range dependencies. Some methods try to solve it by designing complicated network architectures, which yields high computational costs. To address these problems, we consider both local and global features in the proposed recurrent attention-distilling network (RADN). Specifically, in the shallow layer, the local contextual information is extracted by a local extract module with channel and pixel attention blocks to focus on features of important channels and spatial locations. In the deep layer, the global intrinsic features are characterized by a refined transformer block with a self-attention (SA) mechanism to capture the long-range dependencies. Meanwhile, a teacher network is pre-trained by a rain-to-rain mapping to supervise the proposed RADN learning the rain intrinsic features quicker with lightweight. Moreover, we propose a direction-enhanced contrastive learning (DeCL) strategy which incorporates the potential rainy images into negative contrastive pairs to improve the model generalization ability. Extensive experiments show that the proposed method can achieve a competitive performance to state-of-the-art methods on both real and synthetic datasets. The source code is available at https://github.com/Meky-hqd/RADN. © 2023 Elsevier B.V.;Not health related;0"Strelcenia E.; Prakoonwit S.";A Survey on GAN Techniques for Data Augmentation to Address the Imbalanced Data Issues in Credit Card Fraud Detection;2023;Data augmentation is an important procedure in deep learning. GAN-based data augmentation can be utilized in many domains. For instance, in the credit card fraud domain, the imbalanced dataset problem is a major one as the number of credit card fraud cases is in the minority compared to legal payments. On the other hand, generative techniques are considered effective ways to rebalance the imbalanced class issue, as these techniques balance both minority and majority classes before the training. In a more recent period, Generative Adversarial Networks (GANs) are considered one of the most popular data generative techniques as they are used in big data settings. This research aims to present a survey on data augmentation using various GAN variants in the credit card fraud detection domain. In this survey, we offer a comprehensive summary of several peer-reviewed research papers on GAN synthetic generation techniques for fraud detection in the financial sector. In addition, this survey includes various solutions proposed by different researchers to balance imbalanced classes. In the end, this work concludes by pointing out the limitations of the most recent research articles and future research issues, and proposes solutions to address these problems. © 2023 by the authors.;Not health related;0"Park C.; Lee J.; Kim Y.; Park J.-G.; Kim H.; Hong D.";An Enhanced AI-Based Network Intrusion Detection System Using Generative Adversarial Networks;2023;As communication technology advances, various and heterogeneous data are communicated in distributed environments through network systems. Meanwhile, along with the development of communication technology, the attack surface has expanded, and concerns regarding network security have increased. Accordingly, to deal with potential threats, research on network intrusion detection systems (NIDSs) has been actively conducted. Among the various NIDS technologies, recent interest is focused on artificial intelligence (AI)-based anomaly detection systems, and various models have been proposed to improve the performance of NIDS. However, there still exists the problem of data imbalance, in which AI models cannot sufficiently learn malicious behavior and thus fail to detect network threats accurately. In this study, we propose a novel AI-based NIDS that can efficiently resolve the data imbalance problem and improve the performance of the previous systems. To address the aforementioned problem, we leveraged a state-of-the-art generative model that could generate plausible synthetic data for minor attack traffic. In particular, we focused on the reconstruction error and Wasserstein distance-based generative adversarial networks, and autoencoder-driven deep learning models. To demonstrate the effectiveness of our system, we performed comprehensive evaluations over various data sets and demonstrated that the proposed systems significantly outperformed the previous AI-based NIDS.  © 2014 IEEE.;Not health related;0"Hu H.; Liu J.; Chen G.; Zhao Y.; Gao Z.; Zheng R.";Driver Identification Using Deep Generative Model With Limited Data;2023;"The scarcity of driving data constrains the accuracy of deep learning (DL)-based driver identification methods in practical application scenarios. To address this issue, this study proposes a novel unsupervised deep generative model called the convolution condition variant autoencoder (CCVAE) for driving data augmentation. In CCVAE, aided by driver identification information, the condition variant autoencoder can learn the real driving data distribution of each driver through an unsupervised learning paradigm; and aiming for better feature representation ability, convolutional neural network and deconvolution are leveraged, respectively. Therefore, a large number of synthetic samples can be generated by the generative part of the CCVAE. We demonstrate the effectiveness of the CCVAE through extensive experimental analysis using a real dataset collected from a vehicular CAN bus; the improvement of the DL-based driver identification results is demonstrated using synthetic samples. For instance, when only using 2% of the original data, approximately 20% improvement is achieved in terms of four evaluation indicators for two commonly used DL-based driver identification methods, namely, 1-D CNN and LSTM. Furthermore, several comparable experiments with state-of-the-art deep generative methods reveal the superior performance of the proposed CCVAE with respect to identification results, synthetic data quality, and model computation time. Therefore, the proposed model accomplishes a breakthrough in driver identification with limited data and shows great potential in data-driven applications of intelligent vehicles.  © 2000-2011 IEEE.";Not health related;0"Forgione M.; Pura F.; Piga D.";From System Models to Class Models: An In-Context Learning Paradigm;2023;Is it possible to understand the intricacies of a dynamical system not solely from its input/output pattern, but also by observing the behavior of other systems within the same class? This central question drives the study presented in this letter. In response to this query, we introduce a novel paradigm for system identification, addressing two primary tasks: one-step-ahead prediction and multi-step simulation. Unlike conventional methods, we do not directly estimate a model for the specific system. Instead, we learn a meta model that represents a class of dynamical systems. This meta model is trained on a potentially infinite stream of synthetic data, generated by simulators whose settings are randomly extracted from a probability distribution. When provided with a context from a new system-specifically, an input/output sequence-the meta model implicitly discerns its dynamics, enabling predictions of its behavior. The proposed approach harnesses the power of Transformers, renowned for their in-context learning capabilities. For one-step prediction, a GPT-like decoder-only architecture is utilized, whereas the simulation problem employs an encoder-decoder structure. Initial experimental results affirmatively answer our foundational question, opening doors to fresh research avenues in system identification.  © 2017 IEEE.;Not health related;0"Yu T.; Bidulka L.; McKeown M.J.; Wang Z.J.";PA-Tran: Learning to Estimate 3D Hand Pose with Partial Annotation;2023;"This paper tackles a novel and challenging problem—3D hand pose estimation (HPE) from a single RGB image using partial annotation. Most HPE methods ignore the fact that the keypoints could be partially visible (e.g., under occlusions). In contrast, we propose a deep-learning framework, PA-Tran, that jointly estimates the keypoints status and 3D hand pose from a single RGB image with two dependent branches. The regression branch consists of a Transformer encoder which is trained to predict a set of target keypoints, given an input set of status, position, and visual features embedding from a convolutional neural network (CNN); the classification branch adopts a CNN for estimating the keypoints status. One key idea of PA-Tran is a selective mask training (SMT) objective that uses a binary encoding scheme to represent the status of the keypoints as observed or unobserved during training. In addition, by explicitly encoding the label status (observed/unobserved), the proposed PA-Tran can efficiently handle the condition when only partial annotation is available. Investigating the annotation percentage ranging from 50–100%, we show that training with partial annotation is more efficient (e.g., achieving the best 6.0 PA-MPJPE when using about 85% annotations). Moreover, we provide two new datasets. APDM-Hand, is for synthetic hands with APDM sensor accessories, which is designed for a specific hand task. PD-APDM-Hand, is a real hand dataset collected from Parkinson’s Disease (PD) patients with partial annotation. The proposed PA-Tran can achieve higher estimation accuracy when evaluated on both proposed datasets and a more general hand dataset. © 2023 by the authors.";Not health related;0"Zhao Z.; Kunar A.; Birke R.; Van der Scheer H.; Chen L.Y.";CTAB-GAN+: enhancing tabular data synthesis;2023;"The usage of synthetic data is gaining momentum in part due to the unavailability of original data due to privacy and legal considerations and in part due to its utility as an augmentation to the authentic data. Generative adversarial networks (GANs), a paragon of generative models, initially for images and subsequently for tabular data, has contributed many of the state-of-the-art synthesizers. As GANs improve, the synthesized data increasingly resemble the real data risking to leak privacy. Differential privacy (DP) provides theoretical guarantees on privacy loss but degrades data utility. Striking the best trade-off remains yet a challenging research question. In this study, we propose CTAB-GAN+ a novel conditional tabular GAN. CTAB-GAN+ improves upon state-of-the-art by (i) adding downstream losses to conditional GAN for higher utility synthetic data in both classification and regression domains; (ii) using Wasserstein loss with gradient penalty for better training convergence; (iii) introducing novel encoders targeting mixed continuous-categorical variables and variables with unbalanced or skewed data; and (iv) training with DP stochastic gradient descent to impose strict privacy guarantees. We extensively evaluate CTAB-GAN+ on statistical similarity and machine learning utility against state-of-the-art tabular GANs. The results show that CTAB-GAN+ synthesizes privacy-preserving data with at least 21.9% higher machine learning utility (i.e., F1-Score) across multiple datasets and learning tasks under given privacy budget. Copyright © 2024 Zhao, Kunar, Birke, Van der Scheer and Chen.";Not health related;0"Liu J.; Liu H.; Fu H.; Ye Y.; Chen K.; Lu Y.; Mao J.; Xu R.X.; Sun M.";Edge-Guided Contrastive Adaptation Network for Arteriovenous Nicking Classification Using Synthetic Data;2024;Retinal arteriovenous nicking (AVN) manifests as a reduced venular caliber of an arteriovenous crossing. AVNs are signs of many systemic, particularly cardiovascular diseases. Studies have shown that people with AVN are twice as likely to have a stroke. However, AVN classification faces two challenges. One is the lack of data, especially AVNs compared to the normal arteriovenous (AV) crossings. The other is the significant intra-class variations and minute inter-class differences. AVNs may look different in shape, scale, pose, and color. On the other hand, the AVN could be different from the normal AV crossing only by slight thinning of the vein. To address these challenges, first, we develop a data synthesis method to generate AV crossings, including normal and AVNs. Second, to mitigate the domain shift between the synthetic and real data, an edge-guided unsupervised domain adaptation network is designed to guide the transfer of domain invariant information. Third, a semantic contrastive learning branch (SCLB) is introduced and a set of semantically related images, as a semantic triplet, are input to the network simultaneously to guide the network to focus on the subtle differences in venular width and to ignore the differences in appearance. These strategies effectively mitigate the lack of data, domain shift between synthetic and real data, and significant intra- but minute inter-class differences. Extensive experiments have been performed to demonstrate the outstanding performance of the proposed method.  © 1982-2012 IEEE.;Health related;0"Kothari P.; Alahi A.";Safety-Compliant Generative Adversarial Networks for Human Trajectory Forecasting;2023;Human trajectory forecasting in crowds presents the challenges of modelling social interactions and outputting collision-free multimodal distribution. Following the success of Social Generative Adversarial Networks (SGAN), recent works propose various GAN-based designs to better model human motion in crowds. Despite superior performance in reducing distance-based metrics, current networks fail to output socially acceptable trajectories, as evidenced by high collisions in model predictions. To counter this, we introduce SGANv2: an improved safety-compliant SGAN architecture equipped with spatio-temporal interaction modelling and a transformer-based discriminator. The spatio-temporal modelling ability helps to learn the human social interactions better while the transformer-based discriminator design improves temporal sequence modelling. Additionally, SGANv2 utilizes the learned discriminator even at test-time via a collaborative sampling strategy that not only refines the colliding trajectories but also prevents mode collapse, a common phenomenon in GAN training. Through extensive experimentation on multiple real-world and synthetic datasets, we demonstrate the efficacy of SGANv2 to provide socially-compliant multimodal trajectories.  © 2000-2011 IEEE.;Not health related;0"Achddou R.; Gousseau Y.; Ladjal S.";Fully synthetic training for image restoration tasks;2023;In this work, we show that neural networks aimed at solving various image restoration tasks can be successfully trained on fully synthetic data. In order to do so, we rely on a generative model of images, the scaling dead leaves model, which is obtained by superimposing disks whose size distribution is scale-invariant. Pairs of clean and corrupted synthetic images can then be obtained by a careful simulation of the degradation process. We show on various restoration tasks that such a synthetic training yields results that are only slightly inferior to those obtained when the training is performed on large natural image databases. This implies that, for restoration tasks, the geometric contents of natural images can be nailed down to only a simple generative model and a few parameters. This prior can then be used to train neural networks for specific modality, without having to rely on demanding campaigns of natural images acquisition. We demonstrate the feasibility of this approach on difficult restoration tasks, including the denoising of smartphone RAW images and the full development of low-light images. © 2023 Elsevier Inc.;Not health related;0"Xiong Y.; Xiao X.; Yao M.; Liu H.; Yang H.; Fu Y.";MarsFormer: Martian Rock Semantic Segmentation with Transformer;2023;"Semantic segmentation of Mars scenes has a crucial role in Mars rovers science missions. Current convolutional neural network (CNN)-based composition of U-Net has powerful information extraction capabilities; however, convolutional localization suffers from the limited global context modeling capability. Although transformer global modeling has performed well, it still encounters obstacles in the extraction and retention of low-level features. This issue is particularly relevant for Martian rocks with their varying shapes, textures, and sizes in Mars scenes. In this article, we propose a novel transformer semantic segmentation framework for Martian rock images, called MarsFormer, that consists of an encoder-decoder structure connected through a feature enhancement module (FEM) and a window transformer block (WTB). Specifically, multiscale hierarchical features are generated by the mix transformer (MiT) encoders, upgraded-FFN decoder (UFD) fuse and filter features at different scales, preserving the rich local and global contextual information. FEM enhances the inter-multiscale feature correlation from both spatial and channel perspectives. WTB captures the long-range contexts and preserves the local features. We built two datasets of synthetic and real Martian rocks. The synthetic dataset is SynMars, referencing data from the ZhuRong rover taken from its virtual terrain engine. The other dataset is MarsData-V2, from real Mars scenes, and published recently in our previous study. Extensive experiments conducted on both datasets showed that MarsFormer achieves superiority in Martian rock segmentation, obtaining state-of-the-art performance with favorable computational simplicity. The data are available at: https://github.com/CVIR-Lab/SynMars.  © 1980-2012 IEEE.";Not health related;0"Li Y.; Guo J.; Qiu H.; Chen F.; Zhang J.";Denoising Diffusion Probabilistic Models and Transfer Learning for citrus disease diagnosis;2023;Problems: Plant Disease diagnosis based on deep learning mechanisms has been extensively studied and applied. However, the complex and dynamic agricultural growth environment results in significant variations in the distribution of state samples, and the lack of sufficient real disease databases weakens the information carried by the samples, posing challenges for accurately training models. Aim: This paper aims to test the feasibility and effectiveness of Denoising Diffusion Probabilistic Models (DDPM), Swin Transformer model, and Transfer Learning in diagnosing citrus diseases with a small sample. Methods: Two training methods are proposed: The Method 1 employs the DDPM to generate synthetic images for data augmentation. The Swin Transformer model is then used for pre-training on the synthetic dataset produced by DDPM, followed by fine-tuning on the original citrus leaf images for disease classification through transfer learning. The Method 2 utilizes the pre-trained Swin Transformer model on the ImageNet dataset and fine-tunes it on the augmented dataset composed of the original and DDPM synthetic images. Results and conclusion: The test results indicate that Method 1 achieved a validation accuracy of 96.3%, while Method 2 achieved a validation accuracy of 99.8%. Both methods effectively addressed the issue of model overfitting when dealing with a small dataset. Additionally, when compared with VGG16, EfficientNet, ShuffleNet, MobileNetV2, and DenseNet121 in citrus disease classification, the experimental results demonstrate the superiority of the proposed methods over existing approaches to a certain extent. Copyright © 2023 Li, Guo, Qiu, Chen and Zhang.;Health related;0"Fan Z.; Liu X.-J.; Li X.-B.; Cui Y.-C.";A homography estimation method robust to illumination and occlusion;2023;Homography estimation is a basic task in the field of computer vision. In order to improve the robustness of homography estimation to illumination and occlusion, a homography estimation model based on unsupervised learning was proposed. This model took two stacked images as input and the estimated homography matrix as output. The bidirectional homography was proposed to estimate the average photometric loss. Then, in order to increase the receptive field and improve the resistance of the network model to deformation and position change, we introduced the spatial transformer networks (STN) module and deformation convolution to the network model. Finally, by inserting random occlusion shapes, the occlusion factors were introduced into the synthetic dataset of the homography estimation task for the first time, thus making the trained model robust to occlusion. Compared with the traditional methods, the proposed method could maintain the same or achieve better accuracy, and give superior performance in estimating the homography of image pairs with low texture or large illumination changes. Compared with the learning-based homography estimation method, the proposed method is robust to occlusion and performs better on real datasets. © 2023, Editorial of Board of Journal of Graphics. All rights reserved.;Not health related;0"Ali M.; Prakash K.; Macana C.; Raza M.Q.; Bashir A.K.; Pota H.";Modeling synthetic power distribution network and datasets with industrial validation;2023;Creating synthetic networks and datasets for power distribution network is challenging due to continuous expansion of networks, integration of new low carbon technologies and large penetration of renewable energy resources in network. In this paper, a practical approach for generating synthetic distribution networks and datasets using public databases and data synthesis algorithms is proposed. A synthetic power distribution network is developed by leveraging the open-data from local government databases, OpenStreetMaps and mapping engines such as Google Street View. New data synthesis algorithms are proposed to obtain the missing network datasets. The proposed algorithms include a topology for designing power lines, a method for computing the lengths of power lines, a hub-line algorithm for determining the number of consumers connected to a single transformer, a virtual layer approach based on FromNode and ToNode for establishing electrical connectivity, and a technique for ingesting raw data into industrial data platforms. The practical feasibility of the proposed solutions is demonstrated by an illustrative case study of the Colac region in Australia. Synthetic network and datasets are created for the distribution feeder, and then evaluated in industry servers. The results are compared using a three-step validation procedure: comparing the synthetic and actual network datasets using geo-based visualizations, by including feedback from industry experts familiar with the analysis, and by testing the generic applicability of the proposed techniques to other regions. The paper compares network elements that include 4714 power lines, 48 distribution transformers, 4155 energy consumers, 609 electrical nodes, and 1 substation. The comparison results demonstrate the efficacy of developed networks and datasets as they show resemblance to real network and datasets while providing the geographical validation of distribution network models. © 2022 Elsevier Inc.;Not health related;0"Kundu S.; Maulik U.; Sheshanarayana R.; Ghosh S.";Vehicle Smoke Synthesis and Attention-Based Deep Approach for Vehicle Smoke Detection;2023;Third world countries are suffering from extreme vehicular air pollution due to dominating number of fossil fuel-driven vehicles on the road. Therefore, in these countries, automatic surveillance systems are in high demand for close monitoring to identify and penalize vehicles emitting excessive smoke. In recent times, deep learning-based computer vision systems are rigorously working on the same. Their accuracy strongly depends on the number of the training images taken under various imaging conditions. However, there are very few publicly available vehicle smoke datasets that could be used for training purposes. To capture on-road videos for the creation of a dataset is another challenging and time-consuming task. To aid and enhance the vehicular smoke monitoring system, in this article, we propose, a holistic dual-level framework for dataset enhancement by smoke generation along with a transformer network for efficient identification. We have created a realistic vehicle smoke generation algorithm using a range of mask patterns and filtering, which helps us to train our deep neural model by generating sufficient synthetic data. We have also proposed a transformer network on the YOLOv5 backbone, which efficiently identifies the smoke region and the smoky vehicle from the image frame simultaneously. We have shown that the lambda-implemented attention-based detection network outperforms the other state-of-the-art techniques on three baseline datasets. Sample demo videos are available at the link https://github.com/srimantacse/VehicleSmoke. © 1972-2012 IEEE.;Not health related;0"Liu W.; Wang H.; Xi Z.; Zhang R.";Smooth Deep Learning Magnetotelluric Inversion Based on Physics-Informed Swin Transformer and Multiwindow Savitzky-Golay Filter;2023;Despite exhibiting excellent inversion results for synthetic data in magnetotelluric (MT) inversion, applying deep learning (DL) to directly inverting MT field data remains challenging. In this study, different from most previous works that mainly focus on generating massive representative resistivity models to cover the solutions of the field data or constructing a strong network by employing advanced DL techniques, we provide a new perspective in that a multiwindow Savitzky-Golay (MWSG) filter is proposed to first smooth the apparent resistivity and phase derived from the MT field measurements before network prediction. This smoothing operation aims to promote the actual apparent resistivity and phase to be close in morphology and smoothness to the training input data, i.e., to adapt the field data to the training sample data. Then, the smoothed apparent resistivity and phase, instead of the original ones, are fed into the well-trained network for instantaneous inversion. Because we create a set of layered resistivity models with gradual-changing resistivity to act as desired output during network training, it together with the proposed MWSG filter enables this work to achieve smooth inversion. Besides, we introduce Swin Transformer (SwinT) to improve the efficiency of MT DL inversion, based on which a physics-informed SwinT (PISwinT) is implemented to enhance the generalization capability. We demonstrate the proposed PISwinT-MWSG smooth inversion method in both synthetic and field MT cases, and it is expected to improve the adaptability and practicability of the DL method to directly solve the inverse problems in MT surveys. © 1980-2012 IEEE.;Not health related;0"Xiong Z.; Huang W.; Hu J.; Zhu X.X.";THE Benchmark: Transferable Representation Learning for Monocular Height Estimation;2023;Generating 3-D city models rapidly is crucial for many applications. Monocular height estimation (MHE) is one of the most efficient and timely ways to obtain large-scale geometric information. However, existing works focus primarily on training and testing models using unbiased datasets, which does not align well with real-world applications. Therefore, we propose a new benchmark dataset to study the transferability of height estimation models in a cross-dataset setting. To this end, we first design and construct a large-scale benchmark dataset for cross-dataset transfer learning on the height estimation task. This benchmark dataset includes a newly proposed large-scale synthetic dataset, a newly collected real-world dataset, and four existing datasets from different cities. Next, a new experimental protocol, few-shot cross-dataset transfer, is designed. Furthermore, in this article, we propose a scale-deformable convolution (SDC) module to enhance the window-based Transformer for handling the scale-variation problem in the height estimation task. Experimental results have demonstrated the effectiveness of the proposed methods in traditional and cross-dataset transfer settings. The datasets and codes are publicly available at https://mediatum.ub.tum.de/1662763 and https://thebenchmarkh.github.io/.  © 1980-2012 IEEE.;Not health related;0"Paepae T.; Bokoro P.N.; Kyamakya K.";Data Augmentation for a Virtual-Sensor-Based Nitrogen and Phosphorus Monitoring;2023;To better control eutrophication, reliable and accurate information on phosphorus and nitrogen loading is desired. However, the high-frequency monitoring of these variables is economically impractical. This necessitates using virtual sensing to predict them by utilizing easily measurable variables as inputs. While the predictive performance of these data-driven, virtual-sensor models depends on the use of adequate training samples (in quality and quantity), the procurement and operational cost of nitrogen and phosphorus sensors make it impractical to acquire sufficient samples. For this reason, the variational autoencoder, which is one of the most prominent methods in generative models, was utilized in the present work for generating synthetic data. The generation capacity of the model was verified using water-quality data from two tributaries of the River Thames in the United Kingdom. Compared to the current state of the art, our novel data augmentation—including proper experimental settings or hyperparameter optimization—improved the root mean squared errors by 23–63%, with the most significant improvements observed when up to three predictors were used. In comparing the predictive algorithms’ performances (in terms of the predictive accuracy and computational cost), k-nearest neighbors and extremely randomized trees were the best-performing algorithms on average. © 2023 by the authors.;Not health related;0"Aetesam H.; Maji S.K.";Perceptually Motivated Generative Model for Magnetic Resonance Image Denoising;2023;Image denoising is an important preprocessing step in low-level vision problems involving biomedical images. Noise removal techniques can greatly benefit raw corrupted magnetic resonance images (MRI). It has been discovered that the MR data is corrupted by a mixture of Gaussian-impulse noise caused by detector flaws and transmission errors. This paper proposes a deep generative model (GenMRIDenoiser) for dealing with this mixed noise scenario. This work makes four contributions. To begin, Wasserstein generative adversarial network (WGAN) is used in model training to mitigate the problem of vanishing gradient, mode collapse, and convergence issues encountered while training a vanilla GAN. Second, a perceptually motivated loss function is used to guide the training process in order to preserve the low-level details in the form of high-frequency components in the image. Third, batch renormalization is used between the convolutional and activation layers to prevent performance degradation under the assumption of non-independent and identically distributed (non-iid) data. Fourth, global feature attention module (GFAM) is appended at the beginning and end of the parallel ensemble blocks to capture the long-range dependencies that are often lost due to the small receptive field of convolutional filters. The experimental results over synthetic data and MRI stack obtained from real MR scanners indicate the potential utility of the proposed technique across a wide range of degradation scenarios. © 2022, The Author(s) under exclusive licence to Society for Imaging Informatics in Medicine.;Health related;1"Zhu K.; Cheng S.; Kovalchuk N.; Simmons M.; Guo Y.-K.; Matar O.K.; Arcucci R.";Analyzing drop coalescence in microfluidic devices with a deep learning generative model;2023;Predicting drop coalescence based on process parameters is crucial for experimental design in chemical engineering. However, predictive models can suffer from the lack of training data and more importantly, the label imbalance problem. In this study, we propose the use of deep learning generative models to tackle this bottleneck by training the predictive models using generated synthetic data. A novel generative model, named double space conditional variational autoencoder (DSCVAE) is developed for labelled tabular data. By introducing label constraints in both the latent and the original space, DSCVAE is capable of generating consistent and realistic samples compared to the standard conditional variational autoencoder (CVAE). Two predictive models, namely random forest and gradient boosting classifiers, are enhanced on synthetic data and their performances are evaluated based on real experimental data. Numerical results show that a considerable improvement in prediction accuracy can be achieved by using synthetic data and the proposed DSCVAE clearly outperforms the standard CVAE. This research clearly provides more insights into handling imbalanced data for classification problems, especially in chemical engineering. © 2023 The Royal Society of Chemistry.;Not health related;0"Wu Y.; Pan S.; Chen Y.; Chen J.; Yi S.; Zhang D.; Song G.";An Unsupervised Inversion Method for Seismic Brittleness Parameters Driven by the Physical Equation;2023;Brittleness is an important parameter characterizing the fracturing properties of shale reservoir, which can be predicted by the prestack seismic inversion. In order to overcome the low efficiency and ill-posed problems of the traditional prestack brittleness inversion, we propose a new unsupervised deep learning (DL) inversion method for seismic brittleness parameters based on the physical equation. This method integrates DL framework and the physical equation and provides a DL inversion strategy without actual labels. We first input the original seismic data into the Fastformer network and use the low-frequency model as the physical constraint to predict the brittle parameters. Then, the prediction results of brittleness parameters are sent to the forward modeling module (a linear approximation equation) to calculate the synthetic seismic data. Next, the error between the calculated seismic data and original seismic data is used to update the network prediction results. The network parameters are iteratively optimized to minimize the error, and the brittle prediction parameters are finally output. In the whole training process, it is not necessary to use the real brittle parameters as the labels. Through this method, the effect of approximate unsupervised learning is obtained. Finally, we apply the proposed method to the synthetic data and field data and compared with the results inverted by the traditional L1 method. The experimental results show that the proposed method has higher inversion accuracy and efficiency than the traditional L1 method, which has a great potential in the practical application. © 1980-2012 IEEE.;Not health related;0"Tang Z.; Wu B.; Wu W.; Ma D.";Fault Detection via 2.5D Transformer U-Net with Seismic Data Pre-Processing;2023;Seismic fault structures are important for the detection and exploitation of hydrocarbon resources. Due to their development and popularity in the geophysical community, deep-learning-based fault detection methods have been proposed and achieved SOTA results. Due to the efficiency and benefits of full spatial information extraction, 3D convolutional neural networks (CNNs) are used widely to directly detect faults on seismic data volumes. However, using 3D data for training requires expensive computational resources and can be limited by hardware facilities. Although 2D CNN methods are less computationally intensive, they lead to the loss of correlation between seismic slices. To mitigate the aforementioned problems, we propose to predict a 2D fault section using multiple neighboring seismic profiles, that is, 2.5D fault detection. In CNNs, convolution layers mainly extract local information and pooling layers may disrupt the edge features in seismic data, which tend to cause fault discontinuities. To this end, we incorporate the Transformer module in U-net for feature extraction to enhance prediction continuity. To reduce the data discrepancies between synthetic and different real seismic datasets, we apply a seismic data standardization workflow to improve the prediction stability on real datasets. Netherlands F3 real data tests show that, when training on synthetic data labels, the proposed 2.5D Transformer U-net-based method predicts more subtle faults and faults with higher spatial continuity than the baseline full 3D U-net model. © 2023 by the authors.;Not health related;0"Yang Z.; Li Y.; Zhou G.";TS-GAN: Time-series GAN for Sensor-based Health Data Augmentation;2023;Deep learning has achieved significant success on intelligent medical treatments, such as automatic diagnosis and analysis of medical data. To train an automatic diagnosis system with high accuracy and strong robustness in healthcare, sufficient training data are required when using deep learning-based methods. However, given that the data collected by sensors that are embedded in medical or mobile devices are inadequate, it is challenging to train an effective and efficient classification model with state-of-The-Art performance. Inspired by generative adversarial networks (GANs), we propose TS-GAN, a Time-series GAN architecture based on long short-Term memory (LSTM) networks for sensor-based health data augmentation, thereby improving the performance of deep learning-based classification models. TS-GAN aims to learn a generative model that creates time-series data with the same space and time dependence as the real data. Specifically, we design an LSTM-based generator for creating realistic data and an LSTM-based discriminator for determining how similar the generated data are to real data. In particular, we design a sequential-squeeze-And-excitation module in the LSTM-based discriminator to better understand space dependence of real data, and apply the gradient penalty originated from Wasserstein GANs in the training process to stabilize the optimization. We conduct comparative experiments to evaluate the performance of TS-GAN with TimeGAN, C-RNN-GAN and Conditional Wasserstein GANs through discriminator loss, maximum mean discrepancy, visualization methods and classification accuracy on health datasets of ECG_200, NonInvasiveFatalECG_Thorax1, and mHealth, respectively. The experimental results show that TS-GAN exceeds other state-of-The-Art time-series GANs in almost all the evaluation metrics, and the classifier trained on synthetic datasets generated by TS-GAN achieves the highest classification accuracy of 97.50% on ECG_200, 94.12% on NonInvasiveFatalECG_Thorax1, and 98.12% on mHealth, respectively.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.;Health related;1"Kang P.; Jiang S.; Shull P.B.";Synthetic EMG Based on Adversarial Style Transfer Can Effectively Attack Biometric-Based Personal Identification Models;2023;"Biometric-based personal identification models are generally considered to be accurate and secure because biological signals are too complex and person-specific to be fabricated, and EMG signals, in particular, have been used as biological identification tokens due to their high dimension and non-linearity. We investigate the possibility of effectively attacking EMG-based identification models with adversarial biological input via a novel EMG signal individual-style transformer based on a generative adversarial network and tiny leaked data segments. Since two same EMG segments do not exist in nature; the leaked data can't be used to attack the model directly or it will be easily detected. Therefore, it is necessary to extract the style with the leaked personal signals and generate the attack signals with different contents. With our proposed method and tiny leaked personal EMG fragments, numerous EMG signals with different content can be generated in that person's style. EMG hand gesture data from eighteen subjects and three well-recognized deep EMG classifiers were used to demonstrate the effectiveness of the proposed attack methods. The proposed methods achieved an average of 99.41% success rate on confusing identification models and an average of 91.51% success rate on manipulating identification models. These results demonstrate that EMG classifiers based on deep neural networks can be vulnerable to synthetic data attacks. The proof-of-concept results reveal that synthetic EMG biological signals must be considered in biological identification system design across a vast array of relevant biometric systems to ensure personal identification security for individuals and institutions.  © 2023 IEEE.";Not health related;0"Qiao M.; Wang S.; Qiu H.; De Marvao A.; O'Regan D.P.; Rueckert D.; Bai W.";CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy;2024;"Two key questions in cardiac image analysis are to assess the anatomy and motion of the heart from images; and to understand how they are associated with non-imaging clinical factors such as gender, age and diseases. While the first question can often be addressed by image segmentation and motion tracking algorithms, our capability to model and answer the second question is still limited. In this work, we propose a novel conditional generative model to describe the 4D spatio-temporal anatomy of the heart and its interaction with non-imaging clinical factors. The clinical factors are integrated as the conditions of the generative modelling, which allows us to investigate how these factors influence the cardiac anatomy. We evaluate the model performance in mainly two tasks, anatomical sequence completion and sequence generation. The model achieves high performance in anatomical sequence completion, comparable to or outperforming other state-of-the-art generative models. In terms of sequence generation, given clinical conditions, the model can generate realistic synthetic 4D sequential anatomies that share similar distributions with the real data. The code and the trained generative model are available at https://github.com/MengyunQ/CHeart.  © 1982-2012 IEEE.";Not health related;1"Buoy R.; Iwamura M.; Srun S.; Kise K.";Toward a Low-Resource Non-Latin-Complete Baseline: An Exploration of Khmer Optical Character Recognition;2023;"Many existing text recognition methods rely on the structure of Latin characters and words. Such methods may not be able to deal with non-Latin scripts that have highly complex features, such as character stacking, diacritics, ligatures, non-uniform character widths, and writing without explicit word boundaries. In addition, from a natural language processing (NLP) perspective, most non-Latin languages are considered low-resource due to the scarcity of large-scale data. This paper presents a convolutional Transformer-based text recognition method for low-resource non-Latin scripts, which uses local two-dimensional (2D) feature maps. The proposed method can handle images of arbitrarily long textlines, which may occur with non-Latin writing without explicit word boundaries, without resizing them to a fixed size by using an improved image chunking and merging strategy. It has a low time complexity in self-attention layers and allows efficient training. The Khmer script is used as the representative of non-Latin scripts because it shares many features with other non-Latin scripts, which makes the construction of an optical character recognition (OCR) method for Khmer as hard as that for other non-Latin scripts. Thus, by analogy with the AI-complete concept, a Khmer OCR method can be considered as one of the non-Latin-complete methods and can be used as a low-resource non-Latin baseline method. The proposed 2D method was trained on synthetic datasets and outperformed the baseline models on both synthetic and real datasets. Fine-tuning experiments using Khmer handwritten palm leaf manuscripts and other non-Latin scripts demonstrated the feasibility of transfer learning from the Khmer OCR method. To contribute to the low-resource language community, the training and evaluation datasets will be made publicly available.  © ; 2023 The Authors.";Not health related;0"Bavirisetti D.P.; Martinsen H.R.; Kiss G.H.; Lindseth F.";A Multi-Task Vision Transformer for Segmentation and Monocular Depth Estimation for Autonomous Vehicles;2023;In this paper, we investigate the use of Vision Transformers for processing and understanding visual data in an autonomous driving setting. Specifically, we explore the use of Vision Transformers for semantic segmentation and monocular depth estimation using only a single image as input. We present state-of-the-art Vision Transformers for these tasks and combine them into a multitask model. Through multiple experiments on four different street image datasets, we demonstrate that the multitask approach significantly reduces inference time while maintaining high accuracy for both tasks. Additionally, we show that changing the size of the Transformer-based backbone can be used as a trade-off between inference speed and accuracy. Furthermore, we investigate the use of synthetic data for pre-training and show that it effectively increases the accuracy of the model when real-world data is limited.  © 2020 IEEE.;Not health related;0"Zakharov K.; Stavinova E.; Boukhanovsky A.";Synthetic Financial Time Series Generation with Regime Clustering;2023;"Methods for synthetic data generation are extremely valuable nowadays since they allow researchers and practitioners to develop and test their models without the risk and cost associated with using real data. In this paper, we propose a method for the generation of synthetic financial time series. The method adopts time series regimes clustering to perform generative models training on the data from each cluster separately. Also, we suggest the modification of Quantum Generative Adversarial Networks (QuantGAN) architecture that is able to produce synthetic data with frequency characteristics closer to the corresponding real-world time series ones. Our experiments show that (1) synthetic financial time series can be effectively generated by our method; (2) the distribution characteristics of synthetic time series generated by the method are closer to the initial ones in comparison with Fourier Flows and QuantGAN; (3) training the forecasting model on the synthetics generated by the proposed method (Fourier Flows model is used within it) can reduce the forecasting error on the real-world series. © 2023 by the authors.";Not health related;0"Zhou Y.; Ma X.; Wu D.; Li X.";Communication-Efficient and Attack-Resistant Federated Edge Learning with Dataset Distillation;2023;Federated Edge Learning considers a large amount of distributed edge nodes collectively train a global gradient-based model for edge computing in the Artificial Internet of Things, which significantly promotes the development of cloud computing. However, current federated learning algorithms take tens of communication rounds transmitting unwieldy model weights under ideal circumstances and hundreds when data is poorly distributed. This drawback directly results in expensive communication overhead for edge devices. Inspired by recent work on dataset distillation and distributed one-shot learning, we propose Distilled One-Shot Federated Learning (DOSFL) to significantly reduce the communication cost while achieving comparable performance. In just one round, each client distills their private dataset, sends the synthetic data to the server, and collectively trains a global model. The distilled data look like noise and are only useful to the specific model weights, i.e., become useless after the model updates. With this weight-less and gradient-less design, the total communication cost of DOSFL is up to three orders of magnitude less than FedAvg while preserving up to 99% performance of centralized training on both vision and language tasks with different models including CNN, LSTM, Transformer, etc. We demonstrate that an eavesdropping attacker cannot properly train a good model using the leaked distilled data, without knowing the initial model weights. DOSFL serves as an inexpensive method to quickly converge on a performant pre-trained model with less than 0.1% communication cost of traditional methods.  © 2013 IEEE.;Not health related;0"Yu S.; Zhai D.; Guan Y.; Xia Y.";Category-Level 6-D Object Pose Estimation With Shape Deformation for Robotic Grasp Detection;2023;Category-level 6-D object pose estimation plays a crucial role in achieving reliable robotic grasp detection. However, the disparity between synthetic and real datasets hinders the direct transfer of models trained on synthetic data to real-world scenarios, leading to ineffective results. Additionally, creating large-scale real datasets is a time-consuming and labor-intensive task. To overcome these challenges, we propose CatDeform, a novel category-level object pose estimation network trained on synthetic data but capable of delivering good performance on real datasets. In our approach, we introduce a transformer-based fusion module that enables the network to leverage multiple sources of information and enhance prediction accuracy through feature fusion. To ensure proper deformation of the prior point cloud to align with scene objects, we propose a transformer-based attention module that deforms the prior point cloud from both geometric and feature perspectives. Building upon CatDeform, we design a two-branch network for supervised learning, bridging the gap between synthetic and real datasets and achieving high-precision pose estimation in real-world scenes using predominantly synthetic data supplemented with a small amount of real data. To minimize reliance on large-scale real datasets, we train the network in a self-supervised manner by estimating object poses in real scenes based on the synthetic dataset without manual annotation. We conduct training and testing on CAMERA25 and REAL275 datasets, and our experimental results demonstrate that the proposed method outperforms state-of-the-art (SOTA) techniques in both self-supervised and supervised training paradigms. Finally, we apply CatDeform to object pose estimation and robotic grasp experiments in real-world scenarios, showcasing a higher grasp success rate. IEEE;Not health related;0"Lv J.; Zhang L.; Xu J.; Li W.; Li G.; Zhou H.";Automatic segmentation of mandibular canal using transformer based neural networks;2023;Accurate 3D localization of the mandibular canal is crucial for the success of digitally-assisted dental surgeries. Damage to the mandibular canal may result in severe consequences for the patient, including acute pain, numbness, or even facial paralysis. As such, the development of a fast, stable, and highly precise method for mandibular canal segmentation is paramount for enhancing the success rate of dental surgical procedures. Nonetheless, the task of mandibular canal segmentation is fraught with challenges, including a severe imbalance between positive and negative samples and indistinct boundaries, which often compromise the completeness of existing segmentation methods. To surmount these challenges, we propose an innovative, fully automated segmentation approach for the mandibular canal. Our methodology employs a Transformer architecture in conjunction with cl-Dice loss to ensure that the model concentrates on the connectivity of the mandibular canal. Additionally, we introduce a pixel-level feature fusion technique to bolster the model’s sensitivity to fine-grained details of the canal structure. To tackle the issue of sample imbalance and vague boundaries, we implement a strategy founded on mandibular foramen localization to isolate the maximally connected domain of the mandibular canal. Furthermore, a contrast enhancement technique is employed for pre-processing the raw data. We also adopt a Deep Label Fusion strategy for pre-training on synthetic datasets, which substantially elevates the model’s performance. Empirical evaluations on a publicly accessible mandibular canal dataset reveal superior performance metrics: a Dice score of 0.844, click score of 0.961, IoU of 0.731, and HD95 of 2.947 mm. These results not only validate the efficacy of our approach but also establish its state-of-the-art performance on the public mandibular canal dataset. Copyright © 2023 Lv, Zhang, Xu, Li, Li and Zhou.;Health related;1"Li M.; Zhuang D.; Chang J.M.";MC-GEN: Multi-level clustering for private synthetic data generation;2023;With the development of machine learning and data science, data sharing is very common between companies and research institutes to avoid data scarcity. However, sharing original datasets that contain private information can cause privacy leakage. A reliable solution is to utilize private synthetic datasets which preserve statistical information from original datasets. In this paper, we propose MC-GEN, a privacy-preserving synthetic data generation method under differential privacy guarantee for machine learning classification tasks. MC-GEN applies multi-level clustering and differential private generative model to improve the utility of synthetic data. In the experimental evaluation, we evaluated the effects of parameters and the effectiveness of MC-GEN. The results showed that MC-GEN can achieve significant effectiveness under certain privacy guarantees on multiple classification tasks. Moreover, we compare MC-GEN with three existing methods. The results showed that MC-GEN outperforms other methods in terms of utility. © 2023 Elsevier B.V.;Not health related;0"Kafunah J.; Verma P.; Ali M.I.; Breslin J.G.";Out-of-Distribution Data Generation for Fault Detection and Diagnosis in Industrial Systems;2023;The emergence of Industry 4.0 has transformed modern-day factories into high-tech industrial sites through rapid automation and increased access to real-time data. Deep learning approaches possessing superior capabilities for intelligent, data-driven fault diagnosis have become critical in ensuring process safety and reliability in these industrial sites. However, such applications trained exclusively on in-distribution process data face challenges in the wake of previously unseen out-of-distribution (OOD) data in the real world. This paper addresses the challenge of out-of-distribution data detection for deep learning-based fault diagnosis models by generating synthetic data to simulate real-world anomalies not present in the training set. We propose Manifold Guided Sampling (MGS), a data-driven method for generating synthetic OOD samples from the in-distribution data-supporting manifold estimated through a deep generative model. Synthetic data from MGS enhances the model capacity for prediction uncertainty quantification, resulting in safe and reliable models for real-world industrial process monitoring. Furthermore, the MGS algorithm maintains the in-distribution data feature space as a reference point during data generation to ensure the resulting synthetic OOD data is realistic. We analyze the effectiveness of MGS through experiments conducted on the steel plates faults dataset and demonstrate that augmenting training data with synthetic data from MGS enhances the model performance in OOD detection tasks and provides robustness against dataset distributional shifts. The findings underscore the effectiveness of utilizing synthetic MGS-generated OOD data in scenarios where real-world OOD data is limited, enabling better generalization and more reliable fault detection in practical applications.  © 2023 The Authors.;Health related;0"Yuan Y.; Wu Y.; Fan X.; Gong M.; Ma W.; Miao Q.";EGST: Enhanced Geometric Structure Transformer for Point Cloud Registration;2023;We explore the effect of geometric structure descriptors on extracting reliable correspondences and obtaining accurate registration for point cloud registration. The point cloud registration task involves the estimation of rigid transformation motion in unorganized point cloud, hence it is crucial to capture the contextual features of the geometric structure in point cloud. Recent coordinates-only methods ignore numerous geometric information in the point cloud which weaken ability to express the global context. We propose <italic>Enhanced Geometric Structure Transformer</italic> to learn enhanced contextual features of the geometric structure in point cloud and model the structure consistency between point clouds for extracting reliable correspondences, which encodes three explicit enhanced geometric structures and provides significant cues for point cloud registration. More importantly, we report empirical results that <italic>Enhanced Geometric Structure Transformer</italic> can learn meaningful geometric structure features using none of the following: (i) explicit positional embeddings, (ii) additional feature exchange module such as cross-attention, which can simplify network structure compared with plain Transformer. Extensive experiments on the synthetic dataset and real-world datasets illustrate that our method can achieve competitive results. IEEE;Not health related;0"Semenoglou A.-A.; Spiliotis E.; Assimakopoulos V.";Data augmentation for univariate time series forecasting with neural networks;2023;Neural networks have been proven particularly accurate in univariate time series forecasting settings, requiring however a significant number of training samples to be effectively trained. In machine learning applications where available data are limited, data augmentation techniques have been successfully used to generate synthetic data that resemble and complement the original train set. Since the potential of data augmentation has been largely neglected in univariate time series forecasting, in this study we investigate nine data augmentation techniques, ranging from simple transformations and adjustments to sophisticated generative models and a novel upsampling approach. We empirically evaluate the impact of data augmentation on forecasting accuracy considering both shallow and deep feed-forward neural networks and time series data sets of different sizes from the M4 and the Tourism competitions. Our results suggest that certain data augmentation techniques that build on upsampling and time series combinations can improve forecasting performance, especially when deep networks are used. However, these improvements become less significant as the initial size of the train set increases. © 2022 Elsevier Ltd;Not health related;0"El Emam K.; Mosquera L.; Fang X.";Validating a membership disclosure metric for synthetic health data;2022;Background: One of the increasingly accepted methods to evaluate the privacy of synthetic data is by measuring the risk of membership disclosure. This is a measure of the F1 accuracy that an adversary would correctly ascertain that a target individual from the same population as the real data is in the dataset used to train the generative model, and is commonly estimated using a data partitioning methodology with a 0.5 partitioning parameter. Objective: Validate the membership disclosure F1 score, evaluate and improve the parametrization of the partitioning method, and provide a benchmark for its interpretation. Materials and methods: We performed a simulated membership disclosure attack on 4 population datasets: an Ontario COVID-19 dataset, a state hospital discharge dataset, a national health survey, and an international COVID-19 behavioral survey. Two generative methods were evaluated: sequential synthesis and a generative adversarial network. A theoretical analysis and a simulation were used to determine the correct partitioning parameter that would give the same F1 score as a ground truth simulated membership disclosure attack. Results: The default 0.5 parameter can give quite inaccurate membership disclosure values. The proportion of records from the training dataset in the attack dataset must be equal to the sampling fraction of the real dataset from the population. The approach is demonstrated on 7 clinical trial datasets. Conclusions: Our proposed parameterization, as well as interpretation and generative model training guidance provide a theoretically and empirically grounded basis for evaluating and managing membership disclosure risk for synthetic data.  © 2022 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association.;Health related;1"Ramesh L.; Murthy C.R.; Tyagi H.";Multiple Support Recovery Using Very Few Measurements Per Sample;2022;In the problem of multiple support recovery, we are given access to linear measurements of multiple sparse samples in Rd. These samples can be partitioned into_ groups, with samples having the same support belonging to the same group. For a given budget of m measurements per sample, the goal is to recover the _ underlying supports, in the absence of the knowledge of group labels. We study this problem with a focus on the measurement-constrained regime where m is smaller than the support size k of each sample. We design a two-step procedure that estimates the union of the underlying supports first, and then uses a spectral algorithm to estimate the individual supports. Our proposed estimator can recover the supports with m< k measurements per sample, from Ok4_ 4/m4 samples. Our guarantees hold for a general, generative model assumption on the samples and measurement matrices. We also provide results from experiments conducted on synthetic data and on the MNIST dataset. © 1991-2012 IEEE.;Not health related;0"Delgado A.; Hamilton K.E.";Unsupervised quantum circuit learning in high energy physics;2022;Unsupervised training of generative models is a machine learning task that has many applications in scientific computing. In this work we evaluate the efficacy of using quantum circuit-based generative models to generate synthetic data of high energy physics processes. We use nonadversarial, gradient-based training of quantum circuit Born machines to generate joint distributions over two and three variables.  © 2022 American Physical Society.;Not health related;0Endo Y.;User-Controllable Latent Transformer for StyleGAN Image Layout Editing;2022;Latent space exploration is a technique that discovers interpretable latent directions and manipulates latent codes to edit various attributes in images generated by generative adversarial networks (GANs). However, in previous work, spatial control is limited to simple transformations (e.g., translation and rotation), and it is laborious to identify appropriate latent directions and adjust their parameters. In this paper, we tackle the problem of editing the StyleGAN image layout by annotating the image directly. To do so, we propose an interactive framework for manipulating latent codes in accordance with the user inputs. In our framework, the user annotates a StyleGAN image with locations they want to move or not and specifies a movement direction by mouse dragging. From these user inputs and initial latent codes, our latent transformer based on a transformer encoder-decoder architecture estimates the output latent codes, which are fed to the StyleGAN generator to obtain a result image. To train our latent transformer, we utilize synthetic data and pseudo-user inputs generated by off-the-shelf StyleGAN and optical flow models, without manual supervision. Quantitative and qualitative evaluations demonstrate the effectiveness of our method over existing methods. © 2022 The Author(s) Computer Graphics Forum © 2022 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.;Not health related;0"Qamar R.; Bajao N.; Suwarno I.; Jokhio F.A.";Survey on Generative Adversarial Behavior in Artificial Neural Tasks;2022;Generative opposing networking is a technique for learning deep representations in the absence of a large amount of annotated training data. This competitive technique employs two networks to generate background signals. Generative adversarial networks (GANs) use learned representations for a variety of applications, including image synthesis, semantic imaging, style transfer, super magnification, and segmentation. Images can be utilized in many ways. GANs are a unique class that has recently received considerable interest because of the popularity of deep generative models. GANs implicitly distribute complex and high-resolution images, sounds, and data. However, given inadvertently built network architecture, objective function usage, and optimization algorithm selection, significant difficulties, such as mode collapse, inconsistencies, and instability, develop while training GANs. This study conducts a thorough examination of the developments in GANs design and optimization strategies presented to address GANs’ difficulties. We provide intriguing study possibilities in this rapidly evolving area. GANs are a popular study topic because of their ability to generate synthetic data and the benefits of representations that can be understood regardless of the application. While various reviews for GANs in the image processing arena have been undertaken to date, none have focused on the review of GANs in multi-disciplinary domains. Thus, this study investigates the utilization of GANs in interdisciplinary application fields and their implementation issues by thoroughly searching for research articles connected to GAN. © 2022 Autoctonía. Revista de Ciencias Sociales e Historia. All rights reserved.;Not health related;0"Wang H.; Tao G.; Ma J.; Jia S.; Chi L.; Yang H.; Zhao Z.; Tao J.";Predicting the Epidemics Trend of COVID-19 Using Epidemiological-Based Generative Adversarial Networks;2022;The Coronavirus disease 2019 (COVID-19) is a respiratory illness that can spread from person to person. Since the COVID-19 pandemic is spreading rapidly over the world and its outbreak has affected different people in different ways, it is significant to study or predict the evolution of its epidemic trend. However, most of the studies focused solely on either classical epidemiological models or machine learning models for COVID-19 pandemic forecasting, which either suffer from the limitation of the generalization ability and scalability or the lack of surveillance data. In this work, we propose T-SIRGAN that integrates the strengths of the epidemiological theories and deep learning models to be able to represent complex epidemic processes and model the non-linear relationship for more accurate prediction of the growth of COVID-19. T-SIRGAN first adopts the Susceptible-Infectious-Recovered (SIR) model to generate epidemiological-based simulation data, which are then fed into a generative adversarial network (GAN) as adversarial examples for data augmentation. Then, Transformers are used to predict the future trends of COVID-19 based on the generated synthetic data. Extensive experiments on real-world datasets demonstrate the superiority of our method. We also discuss the effectiveness of vaccine based on the difference between the predicted and the reported number of COVID-19 cases.  © 2007-2012 IEEE.;Health related;0"Zeraati R.; Engel T.A.; Levina A.";A flexible Bayesian framework for unbiased estimation of timescales;2022;Timescales characterize the pace of change for many dynamic processes in nature. They are usually estimated by fitting the exponential decay of data autocorrelation in the time or frequency domain. Here we show that this standard procedure often fails to recover the correct timescales due to a statistical bias arising from the finite sample size. We develop an alternative approach to estimate timescales by fitting the sample autocorrelation or power spectrum with a generative model based on a mixture of Ornstein–Uhlenbeck processes using adaptive approximate Bayesian computations. Our method accounts for finite sample size and noise in data and returns a posterior distribution of timescales that quantifies the estimation uncertainty and can be used for model selection. We demonstrate the accuracy of our method on synthetic data and illustrate its application to recordings from the primate cortex. We provide a customizable Python package that implements our framework via different generative models suitable for diverse applications. © 2022, The Author(s).;Not health related;0"Liang Y.; Han Z.; Nie X.; Ohkura K.";Improving generative adversarial network with multiple generators by evolutionary algorithms;2022;Generative Adversarial Network (GAN) is a novel class of deep generative models that has recently gained significant attention. However, the original GAN with one generator can easily get trapped into the mode collapsing problem, which could cause the generator only to produce similar images. This paper proposed a combination of GAN and an evolutionary algorithm to overcome the mode collapsing problem. In our approach, multiple generator networks are trained with the evolutionary strategy (ES), an evolution algorithm. The discriminator network distinguishes if the image comes from the real dataset or not. An additional classifier network is implemented to distinguish different generators. The mutations in the evolutionary strategy and the additional classifier network keep the diversity among generators. We term our approach the Evolution-GAN. In this paper, we conduct experiments on 2D synthetic data to verify that the Evolution-GAN overcomes the mode collapsing problem. Furthermore, experiments on MNIST datasets are implemented to compare the performance of Evolution-GAN, the original GAN, and Deep Convolutional GAN(DCGAN) and Evolutionary GAN. © 2022, International Society of Artificial Life and Robotics (ISAROB).;Not health related;0"González-Prieto Á.; Mozo A.; Gómez-Canaval S.; Talavera E.";Improving the quality of generative models through Smirnov transformation;2022;Solving the convergence issues of Generative Adversarial Networks (GANs) is one of the most outstanding problems in generative models. In this work, we propose a novel activation function to be used as output of the generator agent. This activation function is based on the Smirnov probabilistic transformation and it is specifically designed to improve the quality of the generated data. In sharp contrast to previous works, our activation function provides a more general approach that deals not only with the replication of categorical variables but with any type of data distribution (continuous or discrete). Moreover, our activation function is derivable and therefore, it can be seamlessly integrated in the backpropagation computations during the GAN training processes. To validate this approach, we firstly evaluate our proposal on two different data sets: a) an artificially rendered data set containing a mixture of discrete and continuous variables, and b) a real data set of flow-based network traffic data containing both normal connections and cryptomining attacks. In addition, three publicly available data sets were added to the evaluation to generalize the obtained results. To evaluate the fidelity of the generated data, we analyze their results both in terms of quality measures of statistical nature and regarding the use of these synthetic data to feed a nested machine learning-based classifier. The experimental results evince a clear outperformance of a Wasserstein GAN network (WGAN) tuned with this new activation function with respect to both a naïve mean-based generator and a standard WGAN. The quality of the generated data allows to fully substitute real data with synthetic data for training the nested classifier without a significant fall in the obtained accuracy. © 2022 The Authors;Not health related;0"Xu X.; Geng G.; Cao X.; Li K.; Zhou M.";TDNet: transformer-based network for point cloud denoising;2022;This study proposes a novel, to the best of our knowledge, transformer-based end-to-end network (TDNet) for point cloud denoising based on encoder–decoder architecture. The encoder is based on the structure of a transformer in natural language processing (NLP). Even though points and sentences are different types of data, the NLP transformer can be improved to be suitable for a point cloud because the point can be regarded as a word. The improved model facilitates point cloud feature extraction and transformation of the input point cloud into the underlying high-dimensional space, which can characterize the semantic relevance between points. Subsequently, the decoder learns the latent manifold of each sampled point from the high-dimensional features obtained by the encoder, finally achieving a clean point cloud. An adaptive sampling approach is introduced during denoising to select points closer to the clean point cloud to reconstruct the surface. This is based on the view that a 3D object is essentially a 2D manifold. Extensive experiments demonstrate that the proposed network is superior in terms of quantitative and qualitative results for synthetic data sets and real-world terracotta warrior fragments. © 2021 Optical Society of America;Not health related;0"Pavez V.; Hermosilla G.; Pizarro F.; Fingerhuth S.; Yunge D.";Thermal Image Generation for Robust Face Recognition;2022;This article shows how to create a robust thermal face recognition system based on the FaceNet architecture. We propose a method for generating thermal images to create a thermal face database with six different attributes (frown, glasses, rotation, normal, vocal, and smile) based on various deep learning models. First, we use StyleCLIP, which oversees manipulating the latent space of the input visible image to add the desired attributes to the visible face. Second, we use the GANs N’ Roses (GNR) model, a multimodal image-to-image framework. It uses maps of style and content to generate thermal imaging from visible images, using generative adversarial approaches. Using the proposed generator system, we create a database of synthetic thermal faces composed of more than 100k images corresponding to 3227 individuals. When trained and tested using the synthetic database, the Thermal-FaceNet model obtained a 99.98% accuracy. Furthermore, when tested with a real database, the accuracy was more than 98%, validating the proposed thermal images generator system. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.;Not health related;0"Juraev S.; Ghimire A.; Alikhanov J.; Kakani V.; Kim H.";Exploring Human Pose Estimation and the Usage of Synthetic Data for Elderly Fall Detection in Real-World Surveillance;2022;The world's elderly population continues to grow at an unprecedented rate, creating a need to monitor the safety of an aging population. One of the current problems is accurately classifying elderly physical activities, especially falling down, and delivering prompt assistance to someone in need. Owing to the advancements in deep learning research, vision based solutions are employed for action recognition. One such popular approach is human pose estimation based action recognition or fall detection. Nevertheless, due to a lack of large-scale elderly fall datasets and the continuation of numerous challenges such as varying camera angles, illumination, and occlusion accurately classifying falls has been a problematic. To address these problems, this research first carried out a comprehensive study of the AI Hub dataset collected from real lives of elderly people in order to benchmark the performance of state-of-the-art human pose estimation methods. Secondly, owing to the limited number of real datasets, augmentation with synthetic data was applied and performance improvement was validated based on changes in the degree of accuracy. Third, this study shows that a Transformer network applied to elderly action recognition outperforms LSTM-based networks by a noticeable margin. Lastly, by observing the quantitative and qualitative performances of different networks, this paper proposes an efficient solution for elderly activity recognition and fall detection in the context of surveillance cameras.  © 2013 IEEE.;Not health related;0"Saraskanroud F.M.; Jeffrey I.";Hybrid Approaches in Microwave Imaging Using Quantitative Time- and Frequency-Domain Algorithms;2022;In this work we propose two hybrid time-and frequency-domain microwave imagingschemes aimed to improve time-to-solution of quantitative time-domain imaging algorithms and image resolution of quantitative frequency-domain imaging algorithms. The proposed hybrid methods combine discontinuous Galerkin method (DGM) implementations of the time-domain (TD) forward-backward time-stepping (FBTS) algorithm and the frequency-domain (FD) contrast source inversion (CSI) or Gauss Newton Inversion (GNI). Simply put, an initial inversion in one domain (time or frequency) is used as prior information for the other. These schemes, referred to as FD-TD when FD prior is used in a TD algorithm, and TD-FD when TD prior is used in a FD algorithm, are applied to experimental and synthetic data. The results of the hybrid imaging approaches manifest an appreciable improvement relative to the stand-alone of FD and TD algorithms. Specifically, this study demonstrates that low-resolution frequency-domain prior information improves TD convergence. Additionally, we show that early-iteration time-domain solutions improves FD algorithm performance. We hope that these hybridization techniques pave the way for future investigations of optimal strategies for combining TD and FD schemes. © 2015 IEEE.;Not health related;0"Gelencsér-Horváth A.; Kopácsi L.; Varga V.; Keller D.; Dobolyi Á.; Karacs K.; L_rincz A.";Tracking Highly Similar Rat Instances under Heavy Occlusions: An Unsupervised Deep Generative Pipeline;2022;"Identity tracking and instance segmentation are crucial in several areas of biological re-search. Behavior analysis of individuals in groups of similar animals is a task that emerges frequently in agriculture or pharmaceutical studies, among others. Automated annotation of many hours of surveillance videos can facilitate a large number of biological studies/experiments, which otherwise would not be feasible. Solutions based on machine learning generally perform well in tracking and instance segmentation; however, in the case of identical, unmarked instances (e.g., white rats or mice), even state-of-the-art approaches can frequently fail. We propose a pipeline of deep generative models for identity tracking and instance segmentation of highly similar instances, which, in contrast to most region-based approaches, exploits edge information and consequently helps to resolve ambiguity in heavily occluded cases. Our method is trained by synthetic data generation techniques, not requiring prior human annotation. We show that our approach greatly outperforms other state-of-the-art unsupervised methods in identity tracking and instance segmentation of unmarked rats in real-world laboratory video recordings. © 2022 by the author. Licensee MDPI, Basel, Switzerland.";Not health related;0"Aleardi M.; Vinciguerra A.; Stucchi E.; Hojat A.";Stochastic electrical resistivity tomography with ensemble smoother and deep convolutional autoencoders;2022;To reduce both the computational cost of probabilistic inversions and the ill-posedness of geophysical problems, model and data spaces can be reparameterized into low-dimensional domains where the inverse solution can be computed more efficiently. Among the many compression methods, deep learning algorithms based on deep generative models provide an efficient approach for model and data space reduction. We present a probabilistic electrical resistivity tomography inversion in which the data and model spaces are compressed through deep convolutional variational autoencoders, while the optimization procedure is driven by the ensemble smoother with multiple data assimilation, an iterative ensemble-based algorithm. This method iteratively updates an initial ensemble of models that are generated according to a previously defined prior model. The inversion outcome consists of the most likely solution and a set of realizations of the variables of interest from which the posterior uncertainties can be numerically evaluated. We test the method on synthetic data computed over a schematic subsurface model, and then we apply the inversion to field measurements. The model predictions and the uncertainty assessments provided by the presented approach are also compared with the results of a Markov Chain Monte Carlo sampling working in the compressed domains, a gradient-based algorithm and with the outcomes of an ensemble-based inversion running in the uncompressed spaces. A finite-element code constitutes the forward operator. Our experiments show that the implemented inversion provides most likely solutions and uncertainty quantifications comparable to those yielded by the ensemble-based inversion running in the full model and data spaces, and the Markov Chain Monte Carlo sampling, but with a significant reduction of the computational cost. © 2021 European Association of Geoscientists & Engineers;Not health related;0"Tiwary K.; Patro S.K.; Gandomi A.H.; Sahoo K.S.";Model updating using causal information: a case study in coupled slab;2022;Problems like improper sampling (sampling on unnecessary variables) and undefined prior distribution (or taking random priors) often occur in model updating. Any such limitations on model parameters can lead to lower accuracy and higher experimental costs (due to more iterations) of structural optimisation. In this work, we explored the effective dimensionality of the model updating problem by leveraging the causal information. In order to utilise the causal structure between the parameters, we used Causal Bayesian Optimisation (CBO), a recent variant of Bayesian Optimisation, to integrate observational and intervention data. We also employed generative models to generate synthetic observational data, which helps in creating a better prior for surrogate models. This case study of a coupled slab structure in a recreational building resulted in the modal updated frequencies which were extracted from the finite element of the structure and compared to measured frequencies from ambient vibration tests found in the literature. The results of mode shapes between experimental and predicted values were also compared using modal assurance criterion (MAC) percentages. The updated frequency and MAC number that was obtained using the proposed model was found in least number of iterations (impacts experimental budget) as compared to previous approaches which optimise the same parameters using same data. This also shows how the causal information has impact on experimental budget. © 2022, The Author(s).;Not health related;0"Wang Z.; Deng Y.; Yang J.; Yu J.; Tong X.";Generative Deformable Radiance Fields for Disentangled Image Synthesis of Topology-Varying Objects;2022;3D-aware generative models have demonstrated their superb performance to generate 3D neural radiance fields (NeRF) from a collection of monocular 2D images even for topology-varying object categories. However, these methods still lack the capability to separately control the shape and appearance of the objects in the generated radiance fields. In this paper, we propose a generative model for synthesizing radiance fields of topology-varying objects with disentangled shape and appearance variations. Our method generates deformable radiance fields, which builds the dense correspondence between the density fields of the objects and encodes their appearances in a shared template field. Our disentanglement is achieved in an unsupervised manner without introducing extra labels to previous 3D-aware GAN training. We also develop an effective image inversion scheme for reconstructing the radiance field of an object in a real monocular image and manipulating its shape and appearance. Experiments show that our method can successfully learn the generative model from unstructured monocular images and well disentangle the shape and appearance for objects (e.g., chairs) with large topological variance. The model trained on synthetic data can faithfully reconstruct the real object in a given single image and achieve high-quality texture and shape editing results. © 2022 The Author(s) Computer Graphics Forum © 2022 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.;Not health related;0"Kar P.; Tiruvadi-Krishnan S.; Männik J.; Männik J.; Amir A.";Distinguishing different modes of growth using single-cell data;2021;Collection of high-throughput data has become prevalent in biology. Large datasets allow the use of statistical constructs such as binning and linear regression to quantify relationships between variables and hypothesize underlying biological mechanisms based on it. We discuss several such examples in relation to single-cell data and cellular growth. In particular, we show instances where what appears to be ordinary use of these statistical methods leads to incorrect conclusions such as growth being non-exponential as opposed to exponential and vice versa. We propose that the data analysis and its interpretation should be done in the context of a generative model, if possible. In this way, the statistical methods can be validated either analytically or against synthetic data generated via the use of the model, leading to a consistent method for inferring biological mechanisms from data. On applying the validated methods of data analysis to infer cellular growth on our experimental data, we find the growth of length in E. coli to be non-exponential. Our analysis shows that in the later stages of the cell cycle the growth rate is faster than exponential. © 2021, eLife Sciences Publications Ltd. All rights reserved.;Not health related;0"Sun C.; Xu K.; Fiore M.; Marina M.K.; Wang Y.; Ziemlicki C.";AppShot: A Conditional Deep Generative Model for Synthesizing Service-Level Mobile Traffic Snapshots at City Scale;2022;Service-level mobile traffic data enables research studies and innovative applications with a potential to shape future service-oriented communication systems and beyond. However, real-world datasets reporting measurements at the individual service level are hard to access as such data is deemed commercially sensitive by operators. APPSHOT is a model for generating synthetic high-fidelity city-scale snapshots of service level mobile traffic. It can operate in any geographical region and relies solely on easily available spatial context information such as population density, thus allowing the generation of new and open traffic datasets for the research community. The design of APPSHOT is informed by an original characterization of service-level mobile traffic data. APPSHOT is a novel conditional GAN design instantiated by a convolutional neural network generator and two discriminators. The model features several other innovative mechanisms including multi-channel and overlapping patch based generation to address the unique challenges involved in generating mobile service traffic snapshots. Experiments with ground-truth data collected by a major European operator in multiple metropolitan areas show that APPSHOT can produce realistic network loads at the service level for areas where it has no prior traffic knowledge, and that such data can reliably support service-oriented networking studies. © 2004-2012 IEEE.;Not health related;0"Chiesa S.; Taraglio S.";Traffic Request Generation through a Variational Auto Encoder Approach;2022;Traffic and transportation forecasting is a key issue in urban planning aimed to provide a greener and more sustainable environment to residents. Their privacy is a second key issue that requires synthetic travel data. A possible solution is offered by generative models. Here, a variational autoencoder architecture has been trained on a floating car dataset in order to grasp the statistical features of the traffic demand in the city of Rome. The architecture is based on multilayer dense neural networks for encoding and decoding parts. A brief analysis of parameter influence is conducted. The generated trajectories are compared with those in the dataset. The resulting reconstructed synthetic data are employed to compute the traffic fluxes and geographic distribution of parked cars. Further work directions are provided. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.;Not health related;0"Kawashima T.; Hino H.";Gaussian Process Koopman Mode Decomposition;2023;We propose a nonlinear probabilistic generative model of Koopman mode decomposition based on an unsupervised gaussian process. Existing data-driven methods for Koopman mode decomposition have focused on estimating the quantities specified by Koopman mode decomposition: eigenvalues, eigenfunctions, and modes. Our model enables the simultaneous estimation of these quantities and latent variables governed by an unknown dynamical system. Furthermore, we introduce an efficient strategy to estimate the parameters of our model by low-rank approximations of covariance matrices. Applying the proposed model to both synthetic data and a real-world epidemiological data set, we show that various analyses are available using the estimated parameters. © 2022 Massachusetts Institute of Technology.;Not health related;0"Song Z.-Y.; Liu J.-W.; Yang J.; Zhang L.-N.";Linear normalization attention neural Hawkes process;2023;"With the development of the Internet and the formal arrival of the era of big data, people record, store and process data in electronic form, while the bulk of the data in the real life are asynchronous event sequence data. For modeling the asynchronous event sequence, neural point process is one of the most mainstream solutions. With the more and more in-depth study of neural point process, in order to boost the prediction accuracy of the model, the complexity of the model cannot be overestimated, or the selected model itself has more nonlinearity. For example, the neural point process based on attention mechanism will lead to great complexity of the model. Meanwhile, with the development of deep learning, people find that the traditional multi-layer perceptron has great potential. Now many model architectures built with pure multi-layer perceptron without attention have been proposed, and the effect is better than the attention mechanism. Therefore, the multi-layer perceptron has been ""reborn"" and has attracted extensive attention. Inspired by this, we propose the Linear Normalization Attention Hawkes Process (LNAHP), which substitutes the multi-head dot-product attention from the transformer for linear normalization attention, and learns the hidden representation through two linear transformation layers and normalization operation, which markedly reduces the complexity of the model. The performance for different evaluation metrics for the LNAHP is verified and compared to the current baselines on real datasets from different fields and synthetic datasets, which proves the effectiveness of the LNAHP. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.";Not health related;0"Xin B.; Geng Y.; Hu T.; Chen S.; Yang W.; Wang S.; Huang L.";Federated synthetic data generation with differential privacy;2022;Distributed machine learning has attracted much attention in the last decade with the widespread use of the Internet of Things. As a generative model, Generative Adversarial Network (GAN) has excellent empirical performance. However, the distributed storage of data and the fact that data cannot be shared for privacy reasons in a federated learning setting bring new challenges to training GAN. To address this issue, we propose private FL-GAN, a differentially private GAN based on federated learning. By strategically combining the Lipschitz condition with differential privacy sensitivity, our model can generate high-quality synthetic data without sacrificing the training data's privacy. When communication between clients becomes the main bottleneck for federated learning, we propose to use a serialized model-training paradigm, which significantly reduces communication costs. Considering the distributed data is often non-IID in reality, which poses challenges to modeling, we further propose universal private FL-GAN to approach this problem. We not only theoretically prove that our algorithms can provide strict privacy guarantees with differential privacy, but also experimentally demonstrate that our models can generate satisfactory data while protecting the privacy of the training data, even if the data is non-IID. © 2021 Elsevier B.V.;Not health related;0"Bountos N.I.; Michail D.; Papoutsis I.";Learning from Synthetic InSAR with Vision Transformers: The Case of Volcanic Unrest Detection;2022;The detection of early signs of volcanic unrest preceding an eruption in the form of ground deformation in interferometric synthetic aperture radar (InSAR) data is critical for assessing volcanic hazard. In this work, we treat this as a binary classification problem of InSAR images and propose a novel deep learning methodology that exploits a rich source of synthetically generated interferograms to train quality classifiers that perform equally well in real interferograms. The imbalanced nature of the problem, with orders of magnitude fewer positive samples, coupled with the lack of a curated database with labeled InSAR data, sets a challenging task for conventional deep learning architectures. We propose a new framework for domain adaptation, in which we learn class prototypes from synthetic data with vision transformers. We report detection accuracy that amounts to the highest reported accuracy on a large test set for volcanic unrest detection. Moreover, we built upon this knowledge by learning a new, nonlinear, projection between the learned representations and prototype space, using pseudo-labels produced by our model from an unlabeled real InSAR dataset. This leads to the new state-of-the-art with 97.1% accuracy on our test set. We demonstrate the robustness of our approach by training a simple ResNet-18 convolutional neural network on the unlabeled real InSAR dataset with pseudo-labels generated from our top transformer prototype model. Our methodology provides a significant improvement in performance without the need of manually labeling any sample, opening the road for further exploitation of synthetic InSAR data in various remote sensing applications.  © 1980-2012 IEEE.;Not health related;0"Treppner M.; Salas-Bastos A.; Hess M.; Lenz S.; Vogel T.; Binder H.";Synthetic single cell RNA sequencing data from small pilot studies using deep generative models;2021;Deep generative models, such as variational autoencoders (VAEs) or deep Boltzmann machines (DBMs), can generate an arbitrary number of synthetic observations after being trained on an initial set of samples. This has mainly been investigated for imaging data but could also be useful for single-cell transcriptomics (scRNA-seq). A small pilot study could be used for planning a full-scale experiment by investigating planned analysis strategies on synthetic data with different sample sizes. It is unclear whether synthetic observations generated based on a small scRNA-seq dataset reflect the properties relevant for subsequent data analysis steps. We specifically investigated two deep generative modeling approaches, VAEs and DBMs. First, we considered single-cell variational inference (scVI) in two variants, generating samples from the posterior distribution, the standard approach, or the prior distribution. Second, we propose single-cell deep Boltzmann machines (scDBMs). When considering the similarity of clustering results on synthetic data to ground-truth clustering, we find that the scVIposterior variant resulted in high variability, most likely due to amplifying artifacts of small datasets. All approaches showed mixed results for cell types with different abundance by overrepresenting highly abundant cell types and missing less abundant cell types. With increasing pilot dataset sizes, the proportions of the cells in each cluster became more similar to that of ground-truth data. We also showed that all approaches learn the univariate distribution of most genes, but problems occurred with bimodality. Across all analyses, in comparing 10_ Genomics and Smart-seq2 technologies, we could show that for 10_ datasets, which have higher sparsity, it is more challenging to make inference from small to larger datasets. Overall, the results show that generative deep learning approaches might be valuable for supporting the design of scRNA-seq experiments. © 2021, The Author(s).;Not health related;0"Zheng R.; Lyzinski V.; Priebe C.E.; Tang M.";Vertex Nomination Between Graphs via Spectral Embedding and Quadratic Programming;2022;Given a network and a subset of interesting vertices whose identities are only partially known, the vertex nomination problem seeks to rank the remaining vertices in such a way that the interesting vertices are ranked at the top of the list. An important variant of this problem is vertex nomination in the multiple graphs setting. Given two graphs G 1, G 2 with common vertices and a vertex of interest (Formula presented.), we wish to rank the vertices of G 2 such that the vertices most similar to x are ranked at the top of the list. The current article addresses this problem and proposes a method that first applies adjacency spectral graph embedding to embed the graphs into a common Euclidean space, and then solves a penalized linear assignment problem to obtain the nomination lists. Since the spectral embedding of the graphs are only unique up to orthogonal transformations, we present two approaches to eliminate this potential nonidentifiability. One approach is based on orthogonal Procrustes and is applicable when there are enough vertices with known correspondence between the two graphs. Another approach uses adaptive point set registration and is applicable when there are few or no vertices with known correspondence. We show that our nomination scheme leads to accurate nomination under a generative model for pairs of random graphs that are approximately low-rank and possibly with pairwise edge correlations. We illustrate our algorithm’s performance through simulation studies on synthetic data as well as analysis of a high-school friendship network and analysis of transition rates between web pages on the Bing search engine. Supplementary materials for this article are available and include R code, data, and an appendix with detailed proofs. © 2022 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.;Not health related;0"Hasegawa K.; Moriwaki Y.; Terada T.; Wei C.; Shimizu K.";Feedback-AVPGAN: Feedback-guided generative adversarial network for generating antiviral peptides;2022;"In this study, we propose Feedback-AVPGAN, a system that aims to computationally generate novel antiviral peptides (AVPs). This system relies on the key premise of the Generative Adversarial Network (GAN) model and the Feedback method. GAN, a generative modeling approach that uses deep learning methods, comprises a generator and a discriminator. The generator is used to generate peptides; the generated proteins are fed to the discriminator to distinguish between the AVPs and non-AVPs. The original GAN design uses actual data to train the discriminator. However, not many AVPs have been experimentally obtained. To solve this problem, we used the Feedback method to allow the discriminator to learn from the existing as well as generated synthetic data. We implemented this method using a classifier module that classifies each peptide sequence generated by the GAN generator as AVP or non-AVP. The classifier uses the transformer network and achieves high classification accuracy. This mechanism enables the efficient generation of peptides with a high probability of exhibiting antiviral activity. Using the Feedback method, we evaluated various algorithms and their performance. Moreover, we modeled the structure of the generated peptides using AlphaFold2 and determined the peptides having similar physicochemical properties and structures to those of known AVPs, although with different sequences.  © 2022 The Author(s).";Not health related;0"Chen Y.-T.; Hsu C.-Y.; Yu C.-M.; Barhamgi M.; Perera C.";On the Private Data Synthesis Through Deep Generative Models for Data Scarcity of Industrial Internet of Things;2023;Due to the data-driven intelligence from the recent deep learning based approaches, the huge amount of data collected from various kinds of sensors from industrial devices have the potential to revolutionize the current technologies used in the industry. To improve the efficiency and quality of machines, the machine manufacturer needs to acquire the history of the machine operation process. However, due to the business secrecy, the factories are not willing to do so. One promising solution to the abovementioned difficulty is the synthetic dataset and an informatic network structure, both through deep generative models such as differentially private generative adversarial networks. Hence, this article initiates the study of the utility difference between the abovementioned two kinds. We carry out an empirical study and find that the classifier generated by private informatic network structure is more accurate than the classifier generated by private synthetic data, with approximately 0.31-7.66%.  © 2005-2012 IEEE.;Not health related;0"Dixit V.; Selvarajan R.; Aldwairi T.; Koshka Y.; Novotny M.A.; Humble T.S.; Alam M.A.; Kais S.";Training a Quantum Annealing Based Restricted Boltzmann Machine on Cybersecurity Data;2022;A restricted Boltzmann machine (RBM) is a generative model that could be used in effectively balancing a cybersecurity dataset because the synthetic data a RBM generates follows the probability distribution of the training data. RBM training can be performed using contrastive divergence (CD) and quantum annealing (QA). QA-based RBM training is fundamentally different from CD and requires samples from a quantum computer. We present a real-world application that uses a quantum computer. Specifically, we train a RBM using QA for cybersecurity applications. The D-Wave 2000Q has been used to implement QA. RBMs are trained on the ISCX data, which is a benchmark dataset for cybersecurity. For comparison, RBMs are also trained using CD. CD is a commonly used method for RBM training. Our analysis of the ISCX data shows that the dataset is imbalanced. We present two different schemes to balance the training dataset before feeding it to a classifier. The first scheme is based on the undersampling of benign instances. The imbalanced training dataset is divided into five sub-datasets that are trained separately. A majority voting is then performed to get the result. Our results show the majority vote increases the classification accuracy up from 90.24% to 95.68%, in the case of CD. For the case of QA, the classification accuracy increases from 74.14% to 80.04%. In the second scheme, a RBM is used to generate synthetic data to balance the training dataset. We show that both QA and CD-trained RBM can be used to generate useful synthetic data. Balanced training data is used to evaluate several classifiers. Among the classifiers investigated, K-Nearest Neighbor (KNN) and Neural Network (NN) perform better than other classifiers. They both show an accuracy of 93%. Our results show a proof-of-concept that a QA-based RBM can be trained on a 64-bit binary dataset. The illustrative example suggests the possibility to migrate many practical classification problems to QA-based techniques. Further, we show that synthetic data generated from a RBM can be used to balance the original dataset.  © 2017 IEEE.;Not health related;0"Tu L.; Talbot A.; Gallagher N.M.; Carlson D.E.";Supervising the Decoder of Variational Autoencoders to Improve Scientific Utility;2022;Probabilistic generative models are attractive for scientific modeling because their inferred parameters can be used to generate hypotheses and design experiments. This requires that the learned model accurately represents the input data and yields a latent space that effectively predicts outcomes relevant to the scientific question. Supervised Variational Autoencoders (SVAEs) have previously been used for this purpose, as a carefully designed decoder can be used as an interpretable generative model of the data, while the supervised objective ensures a predictive latent representation. Unfortunately, the supervised objective forces the encoder to learn a biased approximation to the generative posterior distribution, which renders the generative parameters unreliable. This issue has remained undetected as reconstruction losses commonly used to evaluate model performance do not detect bias in the encoder. We address this previously-unreported issue by developing a new framework (SOS-VAE) that updates the decoder parameters, rather than the encoder, to induce a predictive latent representation. This ensures that the encoder maintains a reliable posterior approximation and the decoder parameters can be effectively interpreted. We extend this technique to allow the user to trade-off the bias in the generative parameters for improved predictive performance, acting as an intermediate option between SVAEs and SOS-VAE. We also use this methodology to address missing data issues that often arise when combining recordings from multiple scientific experiments. We demonstrate the effectiveness of these developments using synthetic data and electrophysiological recordings with an emphasis on how our learned representations can be used to design scientific experiments. © 1991-2012 IEEE.;Not health related;0"Zaballa O.; Pérez A.; Gómez Inhiesto E.; Acaiturri Ayesta T.; Lozano J.A.";Learning the progression patterns of treatments using a probabilistic generative model;2023;"Modeling a disease or the treatment of a patient has drawn much attention in recent years due to the vast amount of information that Electronic Health Records contain. This paper presents a probabilistic generative model of treatments that are described in terms of sequences of medical activities of variable length. The main objective is to identify distinct subtypes of treatments for a given disease, and discover their development and progression. To this end, the model considers that a sequence of actions has an associated hierarchical structure of latent variables that both classifies the sequences based on their evolution over time, and segments the sequences into different progression stages. The learning procedure of the model is performed with the Expectation–Maximization algorithm which considers the exponential number of configurations of the latent variables and is efficiently solved with a method based on dynamic programming. The evaluation of the model is twofold: first, we use synthetic data to demonstrate that the learning procedure allows the generative model underlying the data to be recovered; we then further assess the potential of our model to provide treatment classification and staging information in real-world data. Our model can be seen as a tool for classification, simulation, data augmentation and missing data imputation. © 2022 Elsevier Inc.";Health related;1"Chalé M.; Bastian N.D.";Generating realistic cyber data for training and evaluating machine learning classifiers for network intrusion detection systems;2022;"Cyberspace operations, in conjunction with artificial intelligence and machine learning enhanced cyberspace infrastructure, make it possible to connect sensors directly to shooters independent of human control. These technologies serve as the pivot around which cyber data from the military's Internet of Battlefield Things, for example, will be turned into actionable insight and knowledge and, ultimately, an information advantage for the military. As such, network intrusion detection systems must detect, evaluate, and respond to malicious cyber traffic at machine speed. Generative adversarial networks and variational autoencoders are fit as generative models with labeled cyber data from a real military enterprise network. These generative models are used to create realistic, synthetic cyber data. A combination of real and synthetic cyber data sets are then used to train several machine learning models for network intrusion detection. Purely synthetic data is shown to be statistically similar to the real data. There is no statistically significant difference in the performance of classifiers trained with real data versus a combination of real and synthetic data; however, classifiers trained with only synthetic data underperformed. To avoid a decrease in intrusion detection performance, classifiers must be trained with at least 15% real data. © 2022";Not health related;0"Lenz S.; Hess M.; Binder H.";Deep generative models in DataSHIELD;2021;Background: The best way to calculate statistics from medical data is to use the data of individual patients. In some settings, this data is difficult to obtain due to privacy restrictions. In Germany, for example, it is not possible to pool routine data from different hospitals for research purposes without the consent of the patients. Methods: The DataSHIELD software provides an infrastructure and a set of statistical methods for joint, privacy-preserving analyses of distributed data. The contained algorithms are reformulated to work with aggregated data from the participating sites instead of the individual data. If a desired algorithm is not implemented in DataSHIELD or cannot be reformulated in such a way, using artificial data is an alternative. Generating artificial data is possible using so-called generative models, which are able to capture the distribution of given data. Here, we employ deep Boltzmann machines (DBMs) as generative models. For the implementation, we use the package “BoltzmannMachines” from the Julia programming language and wrap it for use with DataSHIELD, which is based on R. Results: We present a methodology together with a software implementation that builds on DataSHIELD to create artificial data that preserve complex patterns from distributed individual patient data. Such data sets of artificial patients, which are not linked to real patients, can then be used for joint analyses. As an exemplary application, we conduct a distributed analysis with DBMs on a synthetic data set, which simulates genetic variant data. Patterns from the original data can be recovered in the artificial data using hierarchical clustering of the virtual patients, demonstrating the feasibility of the approach. Additionally, we compare DBMs, variational autoencoders, generative adversarial networks, and multivariate imputation as generative approaches by assessing the utility and disclosure of synthetic data generated from real genetic variant data in a distributed setting with data of a small sample size. Conclusions: Our implementation adds to DataSHIELD the ability to generate artificial data that can be used for various analyses, e.g., for pattern recognition with deep learning. This also demonstrates more generally how DataSHIELD can be flexibly extended with advanced algorithms from languages other than R. © 2021, The Author(s).;Health related;1"Liu H.; Yao M.; Xiao X.; Xiong Y.";RockFormer: A U-Shaped Transformer Network for Martian Rock Segmentation;2023;Martian rock segmentation aims to separate rock pixels from background, which plays a crucial role in downstream tasks, such as traversing and geologic analysis by Mars rovers. The U-Nets have achieved certain results in rock segmentation. However, due to the inherent locality of convolution operations, U-Nets are inadequate in modeling global context and long-range spatial dependencies. Although emerging Transformers can solve this, they suffer from difficulties in extracting and retaining sufficient low-level local information. These shortcomings limit the performance of the existing networks for Martian rocks that are variable in shape, size, texture, and color. Therefore, we propose RockFormer, the first U-shaped Transformer framework for Mars rock segmentation, consisting of a hierarchical encoder-decoder architecture with a feature refining module (FRM) connected between them. Specifically, the encoder hierarchically generates multiscale features using an improved vision Transformer (improved-ViT), where both abundant local information and long-range contexts are exploited. The FRM removes less representative features and captures global dependencies between multiscale features, improving RockFormer's robustness to Martian rocks with diverse appearances. The decoder is responsible for aggregating these features for pixelwise rock prediction. For evaluation, we establish two Mars rock datasets, including both real and synthesized images. One is MarsData-V2, an extension of our previously published MarsData collected from real Mars rocks. The other is SynMars, a synthetic dataset sequentially photographed from a virtual terrain built referring to the TianWen-1 dataset. Extensive experiments on the two datasets show the superiority of RockFormer for Martian rock segmentation, achieving state-of-the-art performance with decent computational simplicity.  © 1980-2012 IEEE.;Not health related;0"Ramakrishna A.; Gupta R.; Narayanan S.";Joint Multi-Dimensional Model for Global and Time-Series Annotations;2022;Crowdsourcing is a popular approach to collect annotations for unlabeled data instances. It involves collecting a large number of annotations from several, often naive untrained annotators for each data instance which are then combined to estimate the ground truth. Further, annotations for constructs such as affect are often multi-dimensional with annotators rating multiple dimensions, such as valence and arousal, for each instance. Most annotation fusion schemes however ignore this aspect and model each dimension separately. In this article we address this by proposing a generative model for multi-dimensional annotation fusion, which models the dimensions jointly leading to more accurate ground truth estimates. The model we propose is applicable to both global and time series annotation fusion problems and treats the ground truth as a latent variable distorted by the annotators. The model parameters are estimated using the Expectation-Maximization algorithm and we evaluate its performance using synthetic data and real emotion corpora as well as on an artificial task with human annotations.  © 2010-2012 IEEE.;Not health related;0"Li W.; Ma P.; Wang H.; Fang C.";SAR-TSCC: A Novel Approach for Long Time Series SAR Image Change Detection and Pattern Analysis;2023;Change detection has played an increasingly important role in multitemporal remote sensing applications recently. Long time series analysis is providing new information of land cover changes and improving the quality and accuracy of the change information being derived from remote sensing. The purpose of this study is to dig for more change temporal information and change pattern information from synthetic aperture radar (SAR) image time series (ITS), which is of great significance for monitoring urban area changes, conducting land use surveys, and renovating illegal constructions. In the study, a novel unified framework for long time series SAR image change detection and change pattern analysis (SAR-TSCC) was proposed for land cover change mapping. To obtain the most notable change time rapidly, a fast SAR ITS change point search method based on pruned exact linear time (SAR-PELT) algorithm was adopted. Meanwhile, the deep time series classification network, named SAR time series transformer (SAR-TST), was implemented to recognize the change patterns, which is based on time series transformer (TST) architecture. Considering the lack of real training data, a novel synthetic data generation method is developed. The combination of the synthetic and real data enhanced the generalization of the classifiers. The proposed framework was used for monitoring a large urbanization area in the northwest of Hong Kong, China. The Cosmo Skymed (CSK) time series data acquired from 2013 to 2020 were exploited for land cover change analysis. Experiment results showed that our approach achieved the state-of-the-art performance, as the time accuracy reached 86% and the classification accuracy on the four main change patterns (impulse, step, cycle, and complex) is over 99%. In particular, the proposed SAR-TST model showed remarkable advantages in the presence of insufficient real data.  © 1980-2012 IEEE.;Not health related;0"Liu J.; Chen R.; An S.";"Reference prior and generative prior linked distorted old photos restoration; [_________________]";2022;"Objective: Distorted old photos restoration is a challenging issue in practice. Photos are severely eroded in harsh environments, resulting in unclear photo content or even permanent damage, such as scratches, noise, blur and color fading. First, distorted old photos are digitized and implemented (such as Adobe Photoshop) to harness pixel-level manual fine restoration via image processing software. However, manual restoration is time consuming and a batch of manual restoration is more challenged. Traditional methods restore distorted photos (such as digital filtering, edge detection, image patching, etc.) based on multiple restoration algorithms. However, incoherent or unclear restoration results are produced. A large number of deep learning methods have been facilitated nowadays. However, most of the deep learning methods originated from single degradation or several integrated degradations affect generalization ability because the synthesized artificial data cannot represent the real degradation process and data distribution. Based on the framework of generative adversarial network, our problem solving restores distorted old photos through introducing reference priors and generative priors, which improve the restoration quality and generalization performance of distorted old photos. Method: The reference image option is a key factor to implement our method. A high-quality reference image is linked to the following features: 1) Structure similarity: the reference image and the distorted old photos should be similar to image structure. 2) Feature similarity: the distorted old photos restoration focuses more on the restoration of portraits. The resolution of the previous camera was generally not high and portraits are the core of the photo. The portrait content of the reference image should be as similar as possible to the portrait content in the targeted photos, including gender, age, posture, etc. Theoretically, the closer the two images are, the better the similarity coupling between features, more effective prior information can be obtained. Our method picks potential reference images up based on 2 portrait datasets of CelebFaces Atributes Dataset(CelebA) and Flickr faces high quality(FFHQ), using structural similarity as an indicator. The image structural similarity is greater than 0.9 as an appropriated reference image; the reference image is further aligned with the distorted old photo through feature point detection. Our demonstration first extracts the shallow features of the reference image and the distorted old photos. The method uses a 3_3 convolution to extract the reference image features and uses 3 kernel sizes (7_7, 5_5, 3_3) convolutions to extract the shallow features of targeted photos. The shallow features of the reference image and the targeted photos are then encoded each to obtain deep semantics features in multiple-scales and latent semantic codes. Our 2 latent semantic codes are fused in latent space to obtain deep semantic codes through a series of overall interlinked layers. Deep semantic codes use the generative prior via compressed pre-trained generative model to generate generative prior features and guide spatial multi-feature (SMF) transformation condition attention block to fuse reference semantic features, generative prior features and distorted old photo features. Specifically, the distorted photo features are segmented into two sections, one section remains identity connection to ensure the fidelity of the restoration, and its copy is fused with generative prior features simultaneously. The other one is projected to affine transformation via the compressed reference semantic features. Finally, the 2 sections are interconnected and then the deep semantic codes are used for attention fusion. The fused features are related to the decoded features through the skip connection and residual connection, a following 3_3 convolution is used to reconstruct the restored photos. We build up a distorted old photo dataset excluded synthetic data. Result: Our quantitative illustrations compares the results of the method with 6 state-of-the-art methods on 4 evaluation metrics, including signal-to-noise ratio (PSNR), the structural similarity index (SSIM), the learned perceptual image patch similarity (LPIPS) and Fréchet inception distance (FID), which comprehensively consider the average pixel error, structural similarity, data distribution, and so on. Our demonstration is significantly better than other comparison methods in all evaluation metrics. The analyzed results of all numerical metrics are illustrated as mentioned below: the PSNR is 23.69 dB, the SSIM is 0.828 3, the LPIPS is 0.309 and the FID is 71.53, which are improved by 0.75 dB, 0.019 7, 13.69%, and 19.86%, respectively. Our qualitative method compares all the results of restoration methods. The best structured defects restoration quality is significantly better than other methods and the restoration results are more consistent and natural, such as missing, scratches, etc., our unstructured defects method also facilitates comparable and better restoration results. Fewer parameters (43.44 M) and faster inference time are obtained (mean 248 ms for 256_256 resolution distorted old photos). Conclusion: Our reference priors and generative priors' method restore distorted old photos. The semantic information of reference priors and generative model compressed portrait priors are facilitated to qualitative and quantitative restoration both. © 2022, Editorial Office of Journal of Image and Graphics. All right reserved.";Not health related;0"Li P.; Bai W.";"Automatic Hiding Method of Sensitive Targets in Remote Sensing Images Based on Transformer Structure; [__Transformer_________________]";2022;Objective Decryption is the key to ensure the safe sharing of remote sensing resources. To solve the problems of incomplete target detection, unreliable complementary results, high resource consumption and difficulty of training in the traditional methods of sensitive target hiding in remote sensing images, an automatic hiding method of sensitive targets in remote sensing images is proposed based on the ability of Transformer structure to deal with global information. Methods Firstly, the optimized Cascade Mask R-CNN instance segmentation model with Swin Transformer as the backbone network is used to detect sensitive targets and generate mask regions. After improving the generalization capability of the model, RSMosaic (remote sense Mosaic), a data synthesis method to reduce the dependence on manually labeled data is designed. Secondly, the mask region is expanded by using the shadow detection model based on HSV(hue-saturation-value) space, and the MAE(masked autoencoders) model is introduced to achieve target background generation. Finally, the generated images are spliced with the original images to obtain the decrypted images. Results The sub-meter remote sensing images collected by Google Earth are used as test data, and the results show that this proposed method generates reliable hiding results while reducing dataset dependence and training resource consumption. Compared with the traditional method, the AP (average precision) values of bounding box and pixel mask are improved by 13.2% and 11.2% respectively in sensitive target instance segmentation, and the AP values can be improved by another 9.39% and 14.16% respectively after using RSMosaic, which is better than other repair models in terms of objective index and index variance in the field of image repair, especially in mean absolute error and maximum mean discrepancy indexes which are improved by more than 80%. It achieves the effect of automatic hiding of sensitive targets with reasonable structure and clear texture. Conclusions The proposed method reduces manpower, data and computing resources, and achieves better results in both subjective visual effects and objective indexes, which can provide technical support for real remote sensing image sharing. © 2022 Wuhan University. All rights reserved.;Not health related;0"Perez-Bueno F.; Garcia L.; Macia-Fernandez G.; Molina R.";Leveraging a Probabilistic PCA Model to Understand the Multivariate Statistical Network Monitoring Framework for Network Security Anomaly Detection;2022;Network anomaly detection is a very relevant research area nowadays, especially due to its multiple applications in the field of network security. The boost of new models based on variational autoencoders and generative adversarial networks has motivated a reevaluation of traditional techniques for anomaly detection. It is, however, essential to be able to understand these new models from the perspective of the experience attained from years of evaluating network security data for anomaly detection. In this paper, we revisit anomaly detection techniques based on PCA from a probabilistic generative model point of view, and contribute a mathematical model that relates them. Specifically, we start with the probabilistic PCA model and explain its connection to the Multivariate Statistical Network Monitoring (MSNM) framework. MSNM was recently successfully proposed as a means of incorporating industrial process anomaly detection experience into the field of networking. We have evaluated the mathematical model using two different datasets. The first, a synthetic dataset created to better understand the analysis proposed, and the second, UGR'16, is a specifically designed real-traffic dataset for network security anomaly detection. We have drawn conclusions that we consider to be useful when applying generative models to network security detection. © 1993-2012 IEEE.;Not health related;0"Cheng Y.; Gong Y.; Liu Y.; Song B.; Zou Q.";Molecular design in drug discovery: a comprehensive review of deep generative models;2021;Deep generative models have been an upsurge in the deep learning community since they were proposed. These models are designed for generating new synthetic data including images, videos and texts by fitting the data approximate distributions. In the last few years, deep generative models have shown superior performance in drug discovery especially de novo molecular design. In this study, deep generative models are reviewed to witness the recent advances of de novo molecular design for drug discovery. In addition, we divide those models into two categories based on molecular representations in silico. Then these two classical types of models are reported in detail and discussed about both pros and cons. We also indicate the current challenges in deep generative models for de novo molecular design. De novo molecular design automatically is promising but a long road to be explored. © 2021 The Author(s). Published by Oxford University Press. All rights reserved.;Not health related;0"Fan C.; Li X.; Zhao Y.; Wang J.";Quantitative assessments on advanced data synthesis strategies for enhancing imbalanced AHU fault diagnosis performance;2021;The accurate and reliable fault diagnosis of air handling units (AHUs) has profound impacts on building energy efficiency and indoor thermal comforts. Data-driven fault diagnosis methods have gained increasing popularity considering the wide availabilities of operational data and advances in data analytics. In practice, the data-driven fault diagnosis performance can be severely degraded by the imbalanced nature of building operational data, i.e., the data samples of faulty operations are much smaller than that of normal operations. This study serves as a comprehensive study to investigate the potential of different data synthesis techniques in enhancing the performance of imbalanced AHU fault diagnosis. A variety of data synthesis strategies, ranging from conventional random sampling-based to advanced variational autoencoder-based techniques, have been developed for synthetic data generation. Data experiments have been designed to quantitatively evaluate the value of data synthesis in data scenarios considering various data amounts and imbalanced ratios. The research results indicate that synthetic data can significantly enhance the performance of imbalanced AHU fault diagnosis by up to 8.94%. Optimal data synthesis strategies have been identified in different data scenarios. The research outcomes are helpful for the development of reliable data-driven tools for practical tasks in building energy management. © 2021 Elsevier B.V.;Health related;0"Noguer J.; Contreras I.; Mujahid O.; Beneyto A.; Vehi J.";Generation of Individualized Synthetic Data for Augmentation of the Type 1 Diabetes Data Sets Using Deep Learning Models;2022;In this paper, we present a methodology based on generative adversarial network architecture to generate synthetic data sets with the intention of augmenting continuous glucose monitor data from individual patients. We use these synthetic data with the aim of improving the overall performance of prediction models based on machine learning techniques. Experiments were per-formed on two cohorts of patients suffering from type 1 diabetes mellitus with significant differences in their clinical outcomes. In the first contribution, we have demonstrated that the chosen methodology is able to replicate the intrinsic characteristics of individual patients following the statistical distributions of the original data. Next, a second contribution demonstrates the potential of synthetic data to improve the performance of machine learning approaches by testing and comparing different prediction models for the problem of predicting nocturnal hypoglycemic events in type 1 diabetic patients. The results obtained for both generative and predictive models are quite encouraging and set a precedent in the use of generative techniques to train new machine learning models. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.;Health related;1"Deshpande S.; Minhas F.; Graham S.; Rajpoot N.";SAFRON: Stitching Across the Frontier Network for Generating Colorectal Cancer Histology Images;2022;Automated synthesis of histology images has several potential applications including the development of data-efficient deep learning algorithms. In the field of computational pathology, where histology images are large in size and visual context is crucial, synthesis of large high-resolution images via generative modeling is an important but challenging task due to memory and computational constraints. To address this challenge, we propose a novel framework called SAFRON (Stitching Across the FROntier Network) to construct realistic, large high-resolution tissue images conditioned on input tissue component masks. The main novelty in the framework is integration of stitching in its loss function which enables generation of images of arbitrarily large sizes after training on relatively small image patches while preserving morphological features with minimal boundary artifacts. We have used the proposed framework for generating, to the best of our knowledge, the largest-sized synthetic histology images to date (up to 11K_8K pixels). Compared to existing approaches, our framework is efficient in terms of the memory required for training and computations needed for synthesizing large high-resolution images. The quality of generated images was assessed quantitatively using Frechet Inception Distance as well as by 7 trained pathologists, who assigned a realism score to a set of images generated by SAFRON. The average realism score across all pathologists for synthetic images was as high as that of real images. We also show that training with additional synthetic data generated by SAFRON can significantly boost prediction performance of gland segmentation and cancer detection algorithms in colorectal cancer histology images. © 2021;Health related;1"Adeboye O.; Dargahi T.; Babaie M.; Saraee M.; Yu C.-M.";DeepClean: A Robust Deep Learning Technique for Autonomous Vehicle Camera Data Privacy;2022;Autonomous Vehicles (AVs) are equipped with several sensors which produce various forms of data, such as geo-location, distance, and camera data. The volume and utility of these data, especially camera data, have contributed to the advancement of high-performance self-driving applications. However, these vehicles and their collected data are prone to security and privacy attacks. One of the main attacks against AV-generated camera data is location inference, in which camera data is used to extract knowledge for tracking the users. A few research studies have proposed privacy-preserving approaches for analysing AV-generated camera data using powerful generative models, such as Variational Auto Encoder (VAE) and Generative Adversarial Network (GAN). However, the related work considers a weak geo-localisation attack model, which leads to weak privacy protection against stronger attack models. This paper proposes DeepClean, a robust deep-learning model that combines VAE and a private clustering technique. DeepClean learns distinct labelled object structures of the image data as clusters and generates a more visual representation of the non-private object clusters, e.g., roads. It then distorts the private object areas using a private Gaussian Mixture Model (GMM) to learn distinct cluster structures of the labelled object areas. The synthetic images generated from our model guarantee privacy and resist a robust location inference attack by less than 4% localisation accuracy. This result implies that using DeepClean for synthetic data generation makes it less likely for a subject to be localised by an attacker, even when using a robust geo-localisation attack. The overall image utility level of the generated synthetic images by DeepClean is comparable to the benchmark studies.  © 2013 IEEE.;Not health related;0"Fan C.; Chen M.; Tang R.; Wang J.";A novel deep generative modeling-based data augmentation strategy for improving short-term building energy predictions;2022;Short-term building energy predictions serve as one of the fundamental tasks in building operation management. While large numbers of studies have explored the value of various supervised machine learning techniques in energy predictions, few studies have addressed the potential data shortage problem in developing data-driven models. One promising solution is data augmentation, which aims to enrich existing building data resources for reliable predictive modeling. This study proposes a deep generative modeling-based data augmentation strategy for improving short-term building energy predictions. Two types of conditional variational autoencoders have been designed for synthetic energy data generation using fully connected and one-dimensional convolutional layers respectively. Data experiments have been designed to evaluate the value of data augmentation using actual measurements from 52 buildings. The results indicate that conditional variational autoencoders are capable of generating high-quality synthetic data samples, which in turns helps to enhance the accuracy in short-term building energy predictions. The average performance enhancement ratios in terms of CV-RMSE range between 12% and 18%. Practical guidelines have been obtained to ensure the validity and quality of synthetic building energy data. The research outcomes are valuable for enhancing the robustness and reliability of data-driven models for smart building operation management. © 2021, Tsinghua University Press and Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Xue Z.; Mao W.; Liu Y.";Image-level dataset synthesis with an end-to-end trainable framework;2022;Dataset synthesis via virtual engines like Unity is attracting much more attention in recent years due to its low cost at obtaining ground-truth labels. For this kind of work, virtual environments are constructed within the engine to mimic the real-world, either with great manual efforts or learning-based methods. The latter shows superiority over the former when the target real-world scenes are changeable, from which the attributes of environments can be automatically adjusted based on the distribution difference between the synthetic and real-world datasets. However, the non-differentiability of whole pipeline hinders the efficiency of attribute optimization. To this end, this paper proposes to simulate synthetic datasets from a fine-grained perspective, such that the system can be trained at an end-to-end manner. Specifically, it is converted into an image-level data synthesis problem, and designs a constraint using the content loss between two images. As the rendering process of virtual engine is mathematically unknown, which blocks the back propagation of the gradients, a generative model is trained to approximate the engine. As a result, the whole framework becomes fully differentiable and the attributes can be optimized efficiently by gradient descent. Experimental result shows the efficiency of our method in obtaining useful synthetic training datasets. Besides, it is found that the image-level method enables to learn the potential distribution of real-world data, which is hard to be achieved by existing methods. As far as we know, it is the first attempt to finish this task with a differentiable process. © 2022 The Authors. IET Image Processing published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.;Not health related;0"Liu C.; Wang D.; Zhang H.; Wu W.; Sun W.; Zhao T.; Zheng N.";Using Simulated Training Data of Voxel-Level Generative Models to Improve 3D Neuron Reconstruction;2022;Reconstructing neuron morphologies from fluorescence microscope images plays a critical role in neuroscience studies. It relies on image segmentation to produce initial masks either for further processing or final results to represent neuronal morphologies. This has been a challenging step due to the variation and complexity of noisy intensity patterns in neuron images acquired from microscopes. Whereas progresses in deep learning have brought the goal of accurate segmentation much closer to reality, creating training data for producing powerful neural networks is often laborious. To overcome the difficulty of obtaining a vast number of annotated data, we propose a novel strategy of using two-stage generative models to simulate training data with voxel-level labels. Trained upon unlabeled data by optimizing a novel objective function of preserving predefined labels, the models are able to synthesize realistic 3D images with underlying voxel labels. We showed that these synthetic images could train segmentation networks to obtain even better performance than manually labeled data. To demonstrate an immediate impact of our work, we further showed that segmentation results produced by networks trained upon synthetic data could be used to improve existing neuron reconstruction methods.  © 1982-2012 IEEE.;Not health related;1"da Rocha M.V.G.; Alves K.S.T.R.; Queiroz E.R.C.; Oliveira F.L.C.; Hell M.B.; de Aguiar E.P.";Power Transformers Thermal Modeling Based on the Modified Set-Membership Evolving Multivariable Gaussian and Variable Step-Size Evolving Multivariable Gaussian;2022;"Knowledge of temperature distribution in power transformers is essential for the management of electrical distribution systems. Monitoring the hot-spot temperature of a power transformer can extend its lifetime. This paper introduces two novel models called Modified Set-Membership evolving multivariable Gaussian (MSM-eMG) and variable step-size evolving multivariable Gaussian (VS-eMG) for time series forecasting. Both approaches are an enhanced version of the evolving multivariable Gaussian model that use adaptive filtering to update the learning rate parameter, which updates the centers of the clusters, aiming to achieve better performance of the models. To evaluate their performance were used two data sets from a real power transformer; the first data set of the transformer has no overload conditions, and the second one has it. A synthetic data set was also used, as a benchmark, in order to show the effectiveness of these models in different scenarios. The obtained results are compared with the performance of the original evolving multivariable Gaussian and with other classical evolving and non-evolving models suggested in the literature. Both proposed models obtained the lowest errors in all simulations and presented a competitive number of rules in the real data, suggesting these models are flexible and efficient approaches to forecast complex data with high accuracy. © 2021, Brazilian Society for Automatics--SBA.";Not health related;0"Pavlou E.; Kourkoumelis N.";Deep adversarial data augmentation for biomedical spectroscopy: Application to modelling Raman spectra of bone;2022;Deep learning algorithms have performed remarkably well to predict state of health. Nevertheless, they typically rely on ample training data to avoid overfitting. In the biomedical sector, sufficient data are not typically available due to low availability or accessibility. Data augmentation of physiological recordings can be achieved using Generative Adversarial Networks (GAN). GAN is a computational framework for approximating generative models within an adversarial process, where two neural networks compete against one other while being trained simultaneously. Despite the widespread use and adoption of deep learning algorithms in life sciences, concerns have been raised about the lack of biological context. Therefore, to assess a data augmentation workflow, both computational and physiological quality metrics must be considered. Raman spectroscopy can be effectively used to study the molecular properties of bone tissue. Both inorganic and organic phases can be analysed simultaneously as probes of bone health status. In this work, we describe an easy-to-follow GAN approach for generating synthetic Raman spectra from a small dataset of ex vivo healthy and osteoporotic bone samples. The model was applied to raw Raman spectra, while it can be modified accordingly to produce any one-dimensional biomedical signal. We also introduced a novel unsupervised methodology to evaluate the variability of the synthetic dataset, based on successive Principal Component Analysis (PCA) modelling. The properties of the synthetic spectra were scrutinized by Fréchet Distance and difference spectroscopy, as well as by bone quality metrics, like mineral-to-matrix ratio and crystallinity. Finally, classification studies demonstrated the increased discrimination accuracy of the augmented dataset. © 2022 Elsevier B.V.;Health related;0"Wang L.; Wu Z.; Zhong Y.; Yuan X.";Snapshot spectral compressive imaging reconstruction using convolution and contextual Transformer;2022;Spectral compressive imaging (SCI) is able to encode a high-dimensional hyperspectral image into a two-dimensional snapshot measurement, and then use algorithms to reconstruct the spatio-spectral data-cube. At present, the main bottleneck of SCI is the reconstruction algorithm, and state-of-the-art (SOTA) reconstruction methods generally face problems of long reconstruction times and/or poor detail recovery. In this paper, we propose a hybrid network module, namely, a convolution and contextual Transformer (CCoT) block, that can simultaneously acquire the inductive bias ability of convolution and the powerful modeling ability of Transformer, which is conducive to improving the quality of reconstruction to restore fine details. We integrate the proposed CCoT block into a physics-driven deep unfolding framework based on the generalized alternating projection (GAP) algorithm, and further propose the GAP-CCoT network. Finally, we apply the GAP-CCoT algorithm to SCI reconstruction. Through experiments on a large amount of synthetic data and real data, our proposed model achieves higher reconstruction quality (>2 dB in peak signal-to-noise ratio on simulated benchmark datasets) and a shorter running time than existing SOTA algorithms by a large margin. The code and models are publicly available at https://github.com/ucaswangls/GAP-CCoT. © 2022 Chinese Laser Press.;Not health related;0"Allen C.; Aryal S.; Do T.; Gautum R.; Hasan M.M.; Jasthi B.K.; Gnimpieba E.; Gadhamshetty V.";Deep learning strategies for addressing issues with small datasets in 2D materials research: Microbial Corrosion;2022;Protective coatings based on two dimensional materials such as graphene have gained traction for diverse applications. Their impermeability, inertness, excellent bonding with metals, and amenability to functionalization renders them as promising coatings for both abiotic and microbiologically influenced corrosion (MIC). Owing to the success of graphene coatings, the whole family of 2D materials, including hexagonal boron nitride and molybdenum disulphide are being screened to obtain other promising coatings. AI-based data-driven models can accelerate virtual screening of 2D coatings with desirable physical and chemical properties. However, lack of large experimental datasets renders training of classifiers difficult and often results in over-fitting. Generate large datasets for MIC resistance of 2D coatings is both complex and laborious. Deep learning data augmentation methods can alleviate this issue by generating synthetic electrochemical data that resembles the training data classes. Here, we investigated two different deep generative models, namely variation autoencoder (VAE) and generative adversarial network (GAN) for generating synthetic data for expanding small experimental datasets. Our model experimental system included few layered graphene over copper surfaces. The synthetic data generated using GAN displayed a greater neural network system performance (83-85% accuracy) than VAE generated synthetic data (78-80% accuracy). However, VAE data performed better (90% accuracy) than GAN data (84%-85% accuracy) when using XGBoost. Finally, we show that synthetic data based on VAE and GAN models can drive machine learning models for developing MIC resistant 2D coatings. Copyright © 2022 Allen, Aryal, Do, Gautum, Hasan, Jasthi, Gnimpieba and Gadhamshetty.;Not health related;0"Zhang Z.; Yan C.; Malin B.A.";Membership inference attacks against synthetic health data;2022;Synthetic data generation has emerged as a promising method to protect patient privacy while sharing individual-level health data. Intuitively, sharing synthetic data should reduce disclosure risks because no explicit linkage is retained between the synthetic records and the real data upon which it is based. However, the risks associated with synthetic data are still evolving, and what seems protected today may not be tomorrow. In this paper, we show that membership inference attacks, whereby an adversary infers if the data from certain target individuals (known to the adversary a priori) were relied upon by the synthetic data generation process, can be substantially enhanced through state-of-the-art machine learning frameworks, which calls into question the protective nature of existing synthetic data generators. Specifically, we formulate the membership inference problem from the perspective of the data holder, who aims to perform a disclosure risk assessment prior to sharing any health data. To support such an assessment, we introduce a framework for effective membership inference against synthetic health data without specific assumptions about the generative model or a well-defined data structure, leveraging the principles of contrastive representation learning. To illustrate the potential for such an attack, we conducted experiments against synthesis approaches using two datasets derived from several health data resources (Vanderbilt University Medical Center, the All of Us Research Program) to determine the upper bound of risk brought by an adversary who invokes an optimal strategy. The results indicate that partially synthetic data are vulnerable to membership inference at a very high rate. By contrast, fully synthetic data are only marginally susceptible and, in most cases, could be deemed sufficiently protected from membership inference. © 2021 Elsevier Inc.;Health related;1"Contisciani M.; Safdari H.; De Bacco C.";Community detection and reciprocity in networks by jointly modelling pairs of edges;2022;To unravel the driving patterns of networks, the most popular models rely on community detection algorithms. However, these approaches are generally unable to reproduce the structural features of the network. Therefore, attempts are always made to develop models that incorporate these network properties beside the community structure. In this article, we present a probabilistic generative model and an efficient algorithm to both perform community detection and capture reciprocity in networks. Our approach jointly models pairs of edges with exact two-edge joint distributions. In addition, it provides closed-form analytical expressions for both marginal and conditional distributions. We validate our model on synthetic data in recovering communities, edge prediction tasks and generating synthetic networks that replicate the reciprocity values observed in real networks. We also highlight these findings on two real datasets that are relevant for social scientists and behavioural ecologists. Our method overcomes the limitations of both standard algorithms and recent models that incorporate reciprocity through a pseudo-likelihood approximation. The inference of the model parameters is implemented by the efficient and scalable expectation-maximization algorithm, as it exploits the sparsity of the dataset. We provide an open-source implementation of the code online.  © 2022 The Author(s). Published by Oxford University Press.;Not health related;0"Tian Y.; Bai K.";End-to-End Multitask Learning With Vision Transformer;2023;Multitask learning (MTL) is a challenging puzzle, particularly in the realm of computer vision (CV). Setting up vanilla deep MTL requires either hard or soft parameter sharing schemes that employ greedy search to find the optimal network designs. Despite its widespread application, the performance of MTL models is vulnerable to under-constrained parameters. In this article, we draw on the recent success of vision transformer (ViT) to propose a multitask representation learning method called multitask ViT (MTViT), which proposes a multiple branch transformer to sequentially process the image patches (i.e., tokens in transformer) that are associated with various tasks. Through the proposed cross-task attention (CA) module, a task token from each task branch is regarded as a query for exchanging information with other task branches. In contrast to prior models, our proposed method extracts intrinsic features using the built-in self-attention mechanism of the ViT and requires just linear time on memory and computation complexity, rather than quadratic time. Comprehensive experiments are carried out on two benchmark datasets, including NYU-Depth V2 (NYUDv2) and CityScapes, after which it is found that our proposed MTViT outperforms or is on par with existing convolutional neural network (CNN)-based MTL methods. In addition, we apply our method to a synthetic dataset in which task relatedness is controlled. Surprisingly, experimental results reveal that the MTViT exhibits excellent performance when tasks are less related. IEEE;Not health related;0"Fu Y.; Wang Z.; Zhang T.; Zhang J.";Low-Light Raw Video Denoising With a High-Quality Realistic Motion Dataset;2023;Recently, supervised deep-learning methods have shown their effectiveness on raw video denoising in low-light. However, existing training datasets have specific drawbacks, e.g., inaccurate noise modeling in synthetic datasets, simple motion created by hand or fixed motion, and limited-quality ground truth caused by the beam splitter in real captured datasets. These defects significantly decline the performance of network when tackling real low-light video sequences, where noise distribution and motion patterns are extremely complex. In this paper, we collect a raw video denoising dataset in low-light with complex motion and high-quality ground truth, overcoming the drawbacks of previous datasets. Specifically, we capture 210 paired videos, each containing short/long exposure pairs of real video frames with dynamic objects and diverse scenes displayed on a high-end monitor. Besides, since spatial self-similarity has been extensively utilized in image tasks, harnessing this property for network design is more crucial for video denoising as temporal redundancy. To effectively exploit the intrinsic temporal-spatial self-similarity of complex motion in real videos, we propose a new Transformer-based network, which can effectively combine the locality of convolution with the long-range modeling ability of 3D temporal-spatial self-attention. Extensive experiments verify the value of our dataset and the effectiveness of our method on various metrics.  © 1999-2012 IEEE.;Not health related;0"Chen Z.; Wang Y.; Guan T.; Xu L.; Liu W.";Transformer-Based 3D Face Reconstruction with End-to-End Shape-Preserved Domain Transfer;2022;Learning-based face reconstruction methods have recently shown promising performance in recovering face geometry from a single image. However, the lack of training data with 3D annotations severely limits the performance. To tackle this problem, we proposed a novel end-to-end 3D face reconstruction network consisting of a conditional GAN (cGAN) for cross-domain face synthesis and a novel mesh transformer for face reconstruction. Our method first uses cGAN to translate the realistic face images to the specific rendered style, with a 2D facial edge consistency loss function. The domain-transferred images are then fed into face reconstruction network which uses a novel mesh transformer to output 3D mesh vertices. To exploit the domain-transferred in-the-wild images, we further propose a reprojection consistency loss to restrict face reconstruction network in a self-supervised way. Our approach can be trained with annotated dataset, synthetic dataset and in-the-wild images to learn a unified face model. Extensive experiments have demonstrated the effectiveness of our method.  © 1991-2012 IEEE.;Not health related;0"Yang Y.; Zhang X.; Guan Q.; Lin Y.";Making Invisible Visible: Data-Driven Seismic Inversion with Spatio-Temporally Constrained Data Augmentation;2022;Deep learning and data-driven approaches have shown great potential in scientific domains. The promise of data-driven techniques relies on the availability of a large volume of high-quality training datasets. Due to the high cost of obtaining data through expensive physical experiments, instruments, and simulations, data augmentation techniques for scientific applications have emerged as a new direction for obtaining scientific data recently. However, existing data augmentation techniques originating from computer vision yield physically unacceptable data samples that are not helpful for the domain problems that we are interested in. In this article, we develop new data augmentation techniques based on convolutional neural networks. Specifically, our generative models leverage different physics knowledge (such as governing equations, observable perception, and physics phenomena) to improve the quality of the synthetic data. To validate the effectiveness of our data augmentation techniques, we apply them to solve a subsurface seismic full-waveform inversion using simulated CO2 leakage data. Our interest is to invert for subsurface velocity models associated with very small CO2 leakage. We validate the performance of our methods using comprehensive numerical tests. Via comparison and analysis, we show that data-driven seismic imaging can be significantly enhanced by using our data augmentation techniques. Particularly, the imaging quality has been improved by 15% in test scenarios of general-sized leakage and 17% in small-sized leakage when using an augmented training set obtained with our techniques. © 1980-2012 IEEE.;Not health related;0"Baptista M.L.; Henriques E.M.P.";1D-DGAN-PHM: A 1-D denoising GAN for Prognostics and Health Management with an application to turbofan;2022;The performance of prognostics is closely related to the quality of condition monitoring signals (e.g., temperature, pressure, or vibration signals), which reveal the degradation of the system of interest. However, typical condition monitoring signals include noise and outliers. Disentangling noise from these signals is essential to obtain the actual degradation trajectories. Different denoising methods have been proposed in prognostics. Conventional denoising methods have low complexity but usually do not preserve edge information and do not involve physical considerations. A promising deep learning approach is denoising generative models. This approach is popular in Computer Vision, which has been shown to outperform other classical techniques but has seldom been used in prognostics on 1-D signals. In this paper, we propose the 1-D Denoising Generative Adversarial Network for Prognostics and Health Management (1D-DGAN-PHM). The 1D-DGAN-PHM is trained on synthetic data generated by a custom data generator that infuses physics-of-failure knowledge in paired samples of noisy and noise-free trajectories. The network consists of two components, a denoising generator and a discriminator. The denoising generator aims to learn to denoise a 1-D input signal. The discriminator guides the learning by comparing noise-free signals with signals from the denoising generator. Advantages of the 1D-DGAN-PHM include the physics-of-failure information in the synthetic data generator and the model sophistication. In this work, we apply the 1D-DGAN-PHM to denoise the raw signals derived from NASA's C-MAPSS simulator of an aircraft turbofan engine. Baseline methods are Moving Average, Median filter, Savitzky–Golay filter, and a denoising autoencoder. The 1D-DGAN-PHM produces smooth trajectories and preserves the initial linear degradation of the signals. The 1D-DGAN-PHM has the most significant improvement in prognosability (on average, 0.73 to 0.81). Data from the 1D-DGAN-PHM resulted in the best MAE (29 to 25 cycles) and RMSE (score of 39 to 36) for a Random Forest. The code is publicly available at 1D-DGAN-PHM. © 2022 The Author(s);Health related;0"Carvajal-Patiño D.; Ramos-Pollán R.";Synthetic data generation with deep generative models to enhance predictive tasks in trading strategies;2022;This work develops machine learning (ML) predictive models on price signals for financial instruments and their integration into trading strategies. In general, ML models have been shown powerful when trained with large amounts of data. In practice, the time-series nature of financial datasets limits the effective amount of data available to train, validate and retrain models since special care must be taken not to include future data in any way. In this setting, we develop deep generative models to produce synthetic time-series data, enhancing the amount of data available for training predictive models. Synthetic data obtained this way replicates the distribution properties of real historical data, leads to better performance, and enables thorough validation of predictive models for price signals. We leverage machine-generated predictive signals on synthetic data to build trading strategies. We show consistent improvement leading up to profits in our simulations for commodities and forex exchange markets. © 2022 Elsevier B.V.;Not health related;0"Abedi M.; Hempel L.; Sadeghi S.; Kirsten T.";GAN-Based Approaches for Generating Structured Data in the Medical Domain;2022;Modern machine and deep learning methods require large datasets to achieve reliable and robust results. This requirement is often difficult to meet in the medical field, due to data sharing limitations imposed by privacy regulations or the presence of a small number of patients (e.g., rare diseases). To address this data scarcity and to improve the situation, novel generative models such as Generative Adversarial Networks (GANs) have been widely used to generate synthetic data that mimic real data by representing features that reflect health-related information without reference to real patients. In this paper, we consider several GAN models to generate synthetic data used for training binary (malignant/benign) classifiers, and compare their performances in terms of classification accuracy with cases where only real data are considered. We aim to investigate how synthetic data can improve classification accuracy, especially when a small amount of data is available. To this end, we have developed and implemented an evaluation framework where binary classifiers are trained on extended datasets containing both real and synthetic data. The results show improved accuracy for classifiers trained with generated data from more advanced GAN models, even when limited amounts of original data are available. © 2022 by the authors.;Health related;1"Harada S.; Kashima H.";InfoCEVAE: treatment effect estimation with hidden confounding variables matching;2022;Treatment effect estimation is a fundamental problem in various domains for effective decision making. While many studies assume that observational data include all the confounding variables, we cannot practically guarantee that observational data include such confounding variables, and there might be confounding variables that are not included in observational data, referred to as hidden confounding variables. Recently, variational autencoder (VAE) based methods have been successfully applied to treatment effect estimation problem. However, although they can recover a large class of latent variable models, they do not give the correct treatment effect, even when they achieve an optimal solution due to the nature of VAE loss function. We propose an efficient VAE-based method that employs information theory to estimate treatment effect and combines it with a matching technique. To the best of our knowledge, this is the first work that gives the correct treatment effect given an optimal solution using VAE-based methods. Experiments on a semi-real dataset and synthetic dataset demonstrate that the proposed method mitigates VAE problems and observational bias effectively, even under hidden confounding variables, and outperforms strong baseline methods. © 2022, The Author(s).;Health related;1"Ding H.; Lu Y.; Sze N.N.; Chen T.; Guo Y.; Lin Q.";A deep generative approach for crash frequency model with heterogeneous imbalanced data;2022;Crash frequency model is often subject to excessive zero observation because of the rare nature of crashes. To address the problem of imbalanced crash data, a deep generative approach – augmented variational autoencoder – was proposed to generate synthetic crash data for the association measure between crash and possible explanatory factors. This approach was characterized by a factorized generative model and refined objective function. For instance, the generative model can handle heterogeneous data including real-valued, nominal and ordinal distributions. On the other hand, the refined objective function can control for the random effect by better recognizing both the zero-crash and non-zero crash cases. In this study, comprehensive traffic and crash data of multiple distribution types in Hong Kong in the period between 2014 and 2016 were used. To assess the data generation performance of the proposed augmented variational autoencoder method, a conventional data synthesis technique (synthetic minority oversampling technique-nominal continuous) was also considered. Performances of crash frequency models of total crashes and fatal and severe injury crashes are assessed. For total crashes, the results of parameter estimation, in terms of statistical fit, prediction accuracy, and explanatory factors identified, of the crash frequency model based on synthetic data using the augmented variational autoencoder method adhered closer to that based on original data, compared to that based on synthetic data using the synthetic minority oversampling technique-nominal continuous method. For fatal and severe injury crashes, zero-crash observations were prevalent, with the ratio of zero-crash to non-zero crash cases of 9 to 1. Crash data was first balanced using the proposed augmented variational autoencoder method. Then, fatal and severe injury crash frequency models using correlated random parameter models based on original data and balanced data were estimated respectively. Results indicate that fatal and severe injury crash frequency model based on balanced data outperforms its counterpart, with the lowest root mean square error, lowest mean absolute error, and highest number of crash explanatory factors identified. More importantly, correlation between the random parameters can be revealed. Findings of this study should shed light to both researchers and practitioners for the development of crash frequency models, with which the problem of excessive zero observations is prevalent when highly disaggregated traffic and crash data by time and space are used. © 2022 Elsevier Ltd;Not health related;0"Kim K.; Chun C.";Synthetic Data Generator for Solving Korean Arithmetic Word Problem;2022;A math word problems (MWPs) comprises mathematical logic, numbers, and natural language. To solve these problems, a solver model requires an understanding of language and the ability to reason. Since the 1960s, research on the design of a model that provides automatic solutions for mathematical problems has been continuously conducted, and numerous methods and datasets have been published. However, the published datasets in Korean are insufficient. In this study, we propose a Korean data generator for the first time to address this issue. The proposed data generator comprised problem types and data variations. Moreover, it has 4 problem types and 42 subtypes. The data variation has four categories, which adds robustness to the model. In total, 210,311 pieces of data were used for the experiment, of which 210,000 data points were generated. The training dataset had 150,000 data points. Each validation and test dataset had 30,000 data points. Furthermore, 311 problems were sourced from commercially available books on mathematical problems. We used these problems to evaluate the validity of our data generator on actual math word problems. The experiments confirm that models developed using the proposed data generator can be applied to real data. The proposed generator can be used to solve Korean MWPs in the field of education and the service industry, as well as serve as a basis for future research in this field. © 2022 by the authors.;Not health related;0Bykov N.Yu.;"RECONSTRUCTING THE THERMAL PROCESS MODEL USING THE TIME-SPACE DISTRIBUTIONS OF TEMPERATURE; [______________ ______ _________ ________ __ _______________-_________ ______________ ___________]";2022;The method of generative model design (GMD) has been applied to reconstruct the structure and coefficients of a partial differential equation describing the target's heating and its evaporation by laser radiation. The initial synthetic data includes heating scenarios corresponding to surface energy absorption or to volume one. It was shown that reconstructing the model correctly required the use of a preprocessing technique providing the exclusion of a part of the initial data if the volume absorption took place. A modification of the method that made it possible to take into account the temperature dependence of the coefficients of the reconstructed equation was put forward. The influence of various statistical criteria used in selecting the optimal subset of elements on the accuracy of reconstructing the equation structure was discussed. The efficiency of the GMD was demonstrated for a wide range of target heating parameters and different options for setting the energy input. The possibility of model generating by noisy data was shown. © Bykov N. Yu., 2022. Published by Peter the Great St. Petersburg Polytechnic University.;Not health related;0"Khalitov R.; Yu T.; Cheng L.; Yang Z.";Sparse factorization of square matrices with application to neural attention modeling;2022;Square matrices appear in many machine learning problems and models. Optimization over a large square matrix is expensive in memory and in time. Therefore an economic approximation is needed. Conventional approximation approaches factorize the square matrix into a number matrices of much lower ranks. However, the low-rank constraint is a performance bottleneck if the approximated matrix is intrinsically high-rank or close to full rank. In this paper, we propose to approximate a large square matrix with a product of sparse full-rank matrices. In the approximation, our method needs only N(logN)2 non-zero numbers for an N_N full matrix. Our new method is especially useful for scalable neural attention modeling. Different from the conventional scaled dot-product attention methods, we train neural networks to map input data to the non-zero entries of the factorizing matrices. The sparse factorization method is tested for various square matrices, and the experimental results demonstrate that our method gives a better approximation when the approximated matrix is sparse and high-rank. As an attention module, our new method defeats Transformer and its several variants for long sequences in synthetic data sets and in the Long Range Arena benchmarks. Our code is publicly available. © 2022 The Author(s);Not health related;0"Wang X.; Lin Y.; Xiong Y.; Zhang S.; He Y.; He Y.; Zhang Z.; Plasek J.M.; Zhou L.; Bates D.W.; Tang C.";Using an optimized generative model to infer the progression of complications in type 2 diabetes patients;2022;Background: People live a long time in pre-diabetes/early diabetes without a formal diagnosis or management. Heterogeneity of progression coupled with deficiencies in electronic health records related to incomplete data, discrete events, and irregular event intervals make identification of pre-diabetes and critical points of diabetes progression challenging. Methods: We utilized longitudinal electronic health records of 9298 patients with type 2 diabetes or prediabetes from 2005 to 2016 from a large regional healthcare delivery network in China. We optimized a generative Markov-Bayesian-based model to generate 5000 synthetic illness trajectories. The synthetic data were manually reviewed by endocrinologists. Results: We build an optimized generative progression model for type 2 diabetes using anchor information to reduce the number of parameters learning in the third layer of the model from O(N_ W) to O((N- C) _ W) , where N is the number of clinical findings, W is the number of complications, C is the number of anchors. Based on this model, we infer the relationships between progression stages, the onset of complication categories, and the associated diagnoses during the whole progression of type 2 diabetes using electronic health records. Discussion: Our findings indicate that 55.3% of single complications and 31.8% of complication patterns could be predicted early and managed appropriately to potentially delay (as it is a progressive disease) or prevented (by lifestyle modifications that keep patient from developing/triggering diabetes in the first place). Conclusions: The full type 2 diabetes patient trajectories generated by the chronic disease progression model can counter a lack of real-world evidence of desired longitudinal timeframe while facilitating population health management. © 2022, The Author(s).;Health related;1"Makrushin A.; Uhl A.; Dittmann J.";A Survey on Synthetic Biometrics: Fingerprint, Face, Iris and Vascular Patterns;2023;Synthetic biometric samples are created with an ultimate goal of getting around privacy concerns, mitigating biases in biometric datasets, and reducing the sample acquisition effort to enable large-scale evaluations. The recent breakthrough in the development of neural generative models shifted the focus from image synthesis by mathematical modeling of biometric modalities to data-driven image generation. This paradigm shift on the one hand greatly improves the realism of synthetic biometric samples and therefore enables new use cases, but on the other hand new challenges and concerns arise. Despite their realism, synthetic samples have to be checked for appropriateness for the tasks they are intended which includes new quality metrics. Focusing on sample images of fingerprint, face, iris and vascular patterns, we highlight the benefits of using synthetic samples, review the use cases, and summarize and categorize the most prominent studies on synthetic biometrics aiming at showing recent progress and the direction of future research.  © 2023 IEEE.;Not health related;0"Harsuko R.; Alkhalifah T.A.";StorSeismic: A New Paradigm in Deep Learning for Seismic Processing;2022;Machine learned tasks on seismic data are often trained sequentially and separately, even though they utilize the same features (i.e., geometrical) of the data. We present StorSeismic as a dataset-centric framework for seismic data processing, which consists of neural network (NN) pretraining and fine-tuning procedures. We, specifically, utilize a NN as a preprocessing tool to extract and store seismic data features of a particular dataset for any downstream tasks. After pretraining, the resulting model can be utilized later, through a fine-tuning procedure, to perform different tasks using limited additional training. Used often in natural language processing (NLP) and lately in vision tasks, bidirectional encoder representations from transformer (BERT), a form of a transformer model, provides an optimal platform for this framework. The attention mechanism of BERT, applied here on a sequence of traces within the shot gather, is able to capture and store key geometrical features of the seismic data. We pretrain StorSeismic on field data, along with synthetically generated ones, in the self-supervised step. Then, we use the labeled synthetic data to fine-tune the pretrained network in a supervised fashion to perform various seismic processing tasks, such as denoising, velocity estimation, first arrival picking, and normal moveout (NMO). Finally, the fine-tuned model is used to obtain satisfactory inference results on the field data.  © 1980-2012 IEEE.;Not health related;0"Cornell S.; Omologo M.; Squartini S.; Vincent E.";Overlapped Speech Detection and speaker counting using distant microphone arrays;2022;We study the problem of detecting and counting simultaneous, overlapping speakers in a multichannel, distant-microphone scenario. Focusing on a supervised learning approach, we treat Voice Activity Detection (VAD), Overlapped Speech Detection (OSD), joint VAD and OSD (VAD+OSD) and speaker counting in a unified way, as instances of a general Overlapped Speech Detection and Counting (OSDC) multi-class supervised learning problem. We consider a Temporal Convolutional Network (TCN) and a Transformer based architecture for this task, and compare them with previously proposed state-of-the art methods based on Recurrent Neural Networks (RNN) or hybrid Convolutional-Recurrent Neural Networks (CRNN). In addition, we propose ways of exploiting multichannel input by means of early or late fusion of single-channel features with spatial features extracted from one or more microphone pairs. We conduct an extensive experimental evaluation on the AMI and CHiME-6 datasets and on a purposely made multichannel synthetic dataset. We show that the Transformer-based architecture performs best among all architectures and that neural network based spatial localization features outperform signal-based spatial features and significantly improve performance compared to single-channel features only. Finally, we find that training with a speaker counting objective improves OSD compared to training with a VAD+OSD objective. © 2021 Elsevier Ltd;Not health related;0"Tiago C.; Snare S.R.; Sprem J.; McLeod K.";A Domain Translation Framework With an Adversarial Denoising Diffusion Model to Generate Synthetic Datasets of Echocardiography Images;2023;Currently, medical image domain translation operations show a high demand from researchers and clinicians. Amongst other capabilities, this task allows the generation of new medical images with sufficiently high image quality, making them clinically relevant. Deep Learning (DL) architectures, most specifically deep generative models, are widely used to generate and translate images from one domain to another. The proposed framework relies on an adversarial Denoising Diffusion Model (DDM) to synthesize echocardiography images and perform domain translation. Contrary to Generative Adversarial Networks (GANs), DDMs are able to generate high quality image samples with a large diversity. If a DDM is combined with a GAN, this ability to generate new data is completed at an even faster sampling time. In this work we trained an adversarial DDM combined with a GAN to learn the reverse denoising process, relying on a guide image, making sure relevant anatomical structures of each echocardiography image were kept and represented on the generated image samples. For several domain translation operations, the results verified that such generative model was able to synthesize high quality image samples: MSE: 11.50 ± 3.69, PSNR (dB): 30.48 ± 0.09, SSIM: 0.47 ± 0.03. The proposed method showed high generalization ability, introducing a framework to create echocardiography images suitable to be used for clinical research purposes. © 2013 IEEE.;Health related;1Steinhoff J.;Toward a political economy of synthetic data: A data-intensive capitalism that is not a surveillance capitalism?;2022;Surveillance of human subjects is how data-intensive companies obtain much of their data, yet surveillance increasingly meets with social and regulatory resistance. Data-intensive companies are thus seeking other ways to meet their data needs. This article explores one of these: the creation of synthetic data, or data produced artificially as an alternative to real-world data. I show that capital is already heavily invested in synthetic data. I argue that its appeal goes beyond circumventing surveillance to accord with a structural tendency within capitalism toward the autonomization of the circuit of capital. By severing data from human subjectivity, synthetic data contributes to the automation of the production of automation technologies like machine learning. A shift from surveillance to synthesis, I argue, has epistemological, ontological, and political economic consequences for a society increasingly structured around data-intensive capital. © The Author(s) 2022.;Not health related;0"Zhang Q.; Rothe S.; Koukourakis N.; Czarske J.";Learning the matrix of few-mode fibers for high-fidelity spatial mode transmission;2022;Few-mode fibers (FMFs) are promising for advancements in transmission capacity in classical and quantum communications. However, the inherent modal crosstalk limits the practical application of FMF. One reliable way to overcome this obstacle is the measurement of the complex transmission matrix (TM), describing the light propagation behavior of fiber. The TM can be obtained by performing mode decomposition (MD) of the spatial modes at the output of the fiber. MD techniques require the retrieval of both the amplitude and phase components of the detected light field, which is commonly done by using holography. However, the provision of a reference wave is highly unfavorable for the implementation of a holography-based MD in communication technology, especially for long fibers. Using deep neural networks to process intensity-only images, this drawback can be overcome. We introduce the mode transformer network, which can perform MD on 23 modes and has been trained offline using synthetic data. Experimentally, we demonstrate, for the first time, not only the measurement of complex TM of an FMF but also the inversion of the TM using a deep learning-based MD method. For mode transmission, we achieve an average fidelity of 97%. The short duration of the determination of TM allows for overcoming time-varying effects due to, e.g., mechanical stress or temperature fluctuations. The proposed reference-less calibration is promising for fiber communication with classical light and single photons, such as at quantum key distribution.  © 2022 Author(s).;Not health related;0"Vu H.; Bui N.D.";On the scalability of data augmentation techniques for low-resource machine translation between Chinese and Vietnamese;2023;Neural Machine Translation (NMT) has constantly been shown to be a standard choice to build a translation system, in both academia and industry. For low-resource language pairs, data augmentation techniques have been widely used to tackle the data shortage problem in NMT. In this paper, we investigate the scaling behaviour of transformer-based NMT model to the increasing amount of synthetic data. Through the experiments, conducted in the Chinese-to-Vietnamese translation task, we aim to provide a guideline to the application of several methods such as back-translation, tagged back-translation, self-training and sentence concatenation in a low-resource, less-related language pair. Our results suggest that choosing the appropriate amount of synthetic data is a crucial task when building NMT systems. In addition, when combining methods, it is recommended to tag the data sources before training. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.;Not health related;0"Wang H.; Li P.; Lang X.; Tao D.; Ma J.; Li X.";FTGAN: A Novel GAN-Based Data Augmentation Method Coupled Time-Frequency Domain for Imbalanced Bearing Fault Diagnosis;2023;For imbalanced bearing fault diagnosis, generative adversarial networks (GANs) are a common data augmentation (DA) approach. Nevertheless, current GAN-based methods cannot update the generator from time-frequency domain simultaneously, downgrading the authenticity of signal time-frequency character. In this article, Fourier-like transform GAN (FTGAN), a novel GAN method, is proposed by introducing a Fourier-like transformer (FLT) based on autoencoder (AE) to improve synthetic data quality. FLT approximates the discrete Fourier transform (DFT) by the neural network, learning a universal map from time to frequency domain during training. FTGAN with FLT can decouple input into a time-frequency domain, fitting the distribution of time and frequency of data simultaneously. Multidomain distribution is manipulated in FTGAN without introducing additional signal transformation means. Furthermore, train on real, test on synthetic (TRTS) and train on synthetic, test on real (TSTR) analyses of 1-D data are introduced to evaluate data quality. Real and synthetic data are applied as training or test sets of diagnostic classifiers by turns so that data quality can be analyzed through diagnosis results. Experiment results show that the proposed method can generate bearing fault signals closer to real data in the time and frequency domains, effectively improving the performance under an imbalanced dataset.  © 1963-2012 IEEE.;Health related;0"Winter B.; Winter C.; Schilling J.; Bardow A.";A smile is all you need: predicting limiting activity coefficients from SMILES with natural language processing;2022;The knowledge of mixtures’ phase equilibria is crucial in nature and technical chemistry. Phase equilibria calculations of mixtures require activity coefficients. However, experimental data on activity coefficients are often limited due to the high cost of experiments. For an accurate and efficient prediction of activity coefficients, machine learning approaches have been recently developed. However, current machine learning approaches still extrapolate poorly for activity coefficients of unknown molecules. In this work, we introduce a SMILES-to-properties-transformer (SPT), a natural language processing network, to predict binary limiting activity coefficients from SMILES codes. To overcome the limitations of available experimental data, we initially train our network on a large dataset of synthetic data sampled from COSMO-RS (10 million data points) and then fine-tune the model on experimental data (20 870 data points). This training strategy enables the SPT to accurately predict limiting activity coefficients even for unknown molecules, cutting the mean prediction error in half compared to state-of-the-art models for activity coefficient predictions such as COSMO-RS and UNIFACDortmund, and improving on recent machine learning approaches. © 2022 The Author(s). Published by the Royal Society of Chemistry.;Not health related;0"García-Jara G.; Protopapas P.; Estévez P.A.";Improving Astronomical Time-series Classification via Data Augmentation with Generative Adversarial Networks;2022;Due to the latest advances in technology, telescopes with significant sky coverage will produce millions of astronomical alerts per night that must be classified both rapidly and automatically. Currently, classification consists of supervised machine-learning algorithms whose performance is limited by the number of existing annotations of astronomical objects and their highly imbalanced class distributions. In this work, we propose a data augmentation methodology based on generative adversarial networks (GANs) to generate a variety of synthetic light curves from variable stars. Our novel contributions, consisting of a resampling technique and an evaluation metric, can assess the quality of generative models in unbalanced data sets and identify GAN-overfitting cases that the Fréchet inception distance does not reveal. We applied our proposed model to two data sets taken from the Catalina and Zwicky Transient Facility surveys. The classification accuracy of variable stars is improved significantly when training with synthetic data and testing with real data with respect to the case of using only real data.  © 2022. The Author(s). Published by the American Astronomical Society.;Not health related;0"Zuo Z.; Zhao L.; Li A.; Wang Z.; Chen H.; Xing W.; Lu D.";Dual distribution matching GAN;2022;Generative Adversarial Network (GAN) has become the dominant generative model in recent years. Although GAN is capable of generating sharp and realistic images, it faces several problems such as training instability and mode collapse. To address these issues, aside from the usual distribution matching via GAN's adversarial training in a high-dimensional data space, we propose to perform distribution matching within a low-dimensional latent representation space as well. Such a low-dimensional latent representation space is obtained through training an Autoencoder (AE), which not only captures salient features and modes of the data distribution but can also be regularized to learn a nice latent manifold structure of the data. Based on that, we develop a novel hybrid generative model that combines AE and GAN, namely Dual Distribution Matching GAN (DM2GAN), that performs distribution matching in both data and latent space simultaneously. We theoretically show that the optimum of the proposed distribution matching constraint in the latent space is attained if and only if the generated and the real data distribution match exactly. The empirical evaluations on the 2D synthetic data, MNIST-1K, and several real-world datasets demonstrate the effectiveness of the proposed method to stabilize the training and increase mode coverage for GAN. © 2021 Elsevier B.V.;Not health related;0"Gu Z.; Zhang G.; Yang C.";Horizontally Partitioned Data Publication with Differential Privacy;2022;"In this paper, we study the privacy-preserving data publishing problem in a distributed environment. The data contain sensitive information; hence, directly pooling and publishing the local data will lead to privacy leaks. To solve this problem, we propose a multiparty horizontally partitioned data publishing method under differential privacy (HPDP-DP). First, in order to make the noise level of the published data in the distributed scenario the same as in the centralized scenario, we use the infinite divisibility of the Laplace distribution to design a distributed noise addition scheme to perturb the locally shared data and use Paillier encryption to transmit the locally shared data to the semitrusted curator. Then, the semitrusted curator obtains the estimator of the covariance matrix of the aggregated data with Laplace noise and then obtains the principal components of the aggregated data and returns them to each data owner. Finally, the data owner utilizes the generative model of probabilistic principal component analysis to generate a synthetic data set for publication. We conducted experiments on different real data sets; the experimental results demonstrate that the synthetic data set released by the HPDP-DP method can maintain high utility. © 2022 Zhen Gu et al.";Not health related;0"Abdelmoumin G.; Whitaker J.; Rawat D.B.; Rahman A.";A Survey on Data-Driven Learning for Intelligent Network Intrusion Detection Systems;2022;"An effective anomaly-based intelligent IDS (AN-Intel-IDS) must detect both known and unknown attacks. Hence, there is a need to train AN-Intel-IDS using dynamically generated, real-time data in an adversarial setting. Unfortunately, the public datasets available to train AN-Intel-IDS are ineluctably static, unrealistic, and prone to obsolescence. Further, the need to protect private data and conceal sensitive data features has limited data sharing, thus encouraging the use of synthetic data for training predictive and intrusion detection models. However, synthetic data can be unrealistic and potentially bias. On the other hand, real-time data are realistic and current; however, it is inherently imbalanced due to the uneven distribution of anomalous and non-anomalous examples. In general, non-anomalous or normal examples are more frequent than anomalous or attack examples, thus leading to skewed distribution. While imbalanced data are commonly predominant in intrusion detection applications, it can lead to inaccurate predictions and degraded performance. Furthermore, the lack of real-time data produces potentially biased models that are less effective in predicting unknown attacks. Therefore, training AN-Intel-IDS using imbalanced and adversarial learning is instrumental to their efficacy and high performance. This paper investigates imbalanced learning and adversarial learning for training AN-Intel-IDS using a qualitative study. It surveys and synthesizes generative-based data augmentation techniques for addressing the uneven data distribution and generative-based adversarial techniques for generating synthetic yet realistic data in an adversarial setting using rapid review, structured reporting, and subgroup analysis. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.";Not health related;0"Lopes S.M.D.A.; Flauzino R.A.; Altafim R.A.C.";Incipient fault diagnosis in power transformers by data-driven models with over-sampled dataset;2021;"Early diagnosis of incipient faults in power transformers enables their predictive maintenance and guarantees their proper operation. Recently, machine learning (ML) techniques have played special role in fault diagnosis in power transformers; however, the application of such data-driven methods has been hampered by the lack of quality data to support their learning process. Since the collection of dissolved gas analysis (DGA) data depends on equipment failures, the obtaining of large labeled datasets that characterize incipient faults is a difficult task. The use of over-sampling techniques can overcome this challenge by providing a synthetic dataset with balanced classes for the ML method's learning process. This paper addresses a novel application of a deep neural network classifier for the diagnosis of a dataset enriched by the Borderline synthetic minority over-sampling method. The performance of the model was compared with those of traditional DGA interpretation methods, traditional multilayer percetron networks (MLP) and a DNN working with the original dataset. The results indicate the superiority of the approach, and a noise-resilience analysis conducted revealed its ability to deal with corrupted data. The methodology is of simple implementation, highly accurate, and capable of correctly classifying over 84% of the test samples. © 2021";Health related;0"Turan M.; Durmus F.";UC-NfNet: Deep learning-enabled assessment of ulcerative colitis from colonoscopy images;2022;Ulcerative colitis (UC) belongs to the inflammatory bowel disease (IBD) family, which is mainly caused by inflammation of the tissue in the colon and rectum. The severity of this infection can radically affect the patient's overall well-being. Although there is no definitive treatment for this disease, diagnosis of the severity of the disease through colonoscopy imaging and the use of personalized treatment can prevent progression to more malignant stages. Inter- and intra-observer variability combined with the complex nature of UC infection makes medical assessment cumbersome. Diagnosis and treatment of UC can be made more accurate and robust if disease severity can be determined in a standardized and automated manner. Therefore, the development of a computerized tool that can be integrated into the clinical decision-making process of UC classification is of great importance. In this work, we present an automated UC classification method, UC-NfNet, complemented by a synthetic data generation pipeline aimed at classifying colonoscopy UC images. We show that our model quantitatively outperforms state-of-the-art classification models such as ConViT, Inception-v4, NFNets, ResNets and Swin Transformer. In an independent reader study of five gastroenterologists, the average agreement between the UC-NfNet and individual gastroenterologists was higher than the agreement between individual gastroenterologists. This robust evaluation of the proposed AI system paves the way for clinical trials of AI-assisted UC classification. The code and dataset are publicly available at https://github.com/DeepMIALab/UC-NfNet. © 2022 Elsevier B.V.;Health related;1"Smith B.; Van Steelandt S.; Khojandi A.";Evaluating the Impact of Health Care Data Completeness for Deep Generative Models;2022;Background Deep generative models (DGMs) present a promising avenue for generating realistic, synthetic data to augment existing health care datasets. However, exactly how the completeness of the original dataset affects the quality of the generated synthetic data is unclear. Objectives In this paper, we investigate the effect of data completeness on samples generated by the most common DGM paradigms. Methods We create both cross-sectional and panel datasets with varying missingness and subset rates and train generative adversarial networks, variational autoencoders, and autoregressive models (Transformers) on these datasets. We then compare the distributions of generated data with original training data to measure similarity. Results We find that increased incompleteness is directly correlated with increased dissimilarity between original and generated samples produced through DGMs. Conclusions Care must be taken when using DGMs to generate synthetic data as data completeness issues can affect the quality of generated data in both panel and cross-sectional datasets. © 2022 Georg Thieme Verlag. All rights reserved.;Health related;1"Zhou Y.; Ji A.; Zhang L.";Sewer defect detection from 3D point clouds using a transformer-based deep learning model;2022;Targeting the defect classification from 3D point clouds, this research develops a deep learning method named the Transformer-based point cloud classification network (TransPCNet) to obtain superior classification results. The developed TransPCNet primarily consists of the feature embedding module, the attention module, and the classification module, where the first two modules are to enhance the feature extraction and learning capability for assisting the classification module to classify the 3D point clouds more accurately. In addition, a novel loss function is proposed to support the TransPCNet by strengthening feature learning and tackling data imbalance. The effectiveness of the developed TransPCNet is demonstrated on a publicly available dataset with both real and synthetic point clouds. In comparison with other state-of-the-art methods, the TransPCNet outperforms others with improvements of over 13.6%, 15.2%, and 13.7% in terms of precision, recall, and F1-score on the overall dataset. Moreover, the TransPCNet is robust and efficient in different scenarios, where the synthetic data is beneficial to enhancing the detection accuracy on real datasets. Overall, this research contributes to developing TransPCNet to conduct 3D point cloud classification, resulting in a more accurate and effective result with great practical potential. © 2022 Elsevier B.V.;Not health related;0"Alves K.S.T.R.; Pestana de Aguiar E.";A novel rule-based evolving Fuzzy System applied to the thermal modeling of power transformers[Formula presented];2021;Big Data advancements motivate researchers to develop and improve intelligent models to deal efficiently and effectively with data. In this scenario, time series forecasting obtains even more attention. The literature demonstrated the better performance of such models in this subject. Forecasting is widely used in strategic planning to support decision-making, providing competitive differential to organizations. In this paper, a novel rule-based evolving Fuzzy System is proposed for time series forecasting. This is a robust model able to develop and update its structure in unknown environments, capture dynamics and changes of streams, and produce accurate results even when dealing with complex data. The introduced model implements the distance correlation to improve the rules’ quality by reducing their standard deviation. The model is evaluated using two synthetic datasets: the Mackey–Glass time-series and the nonlinear dynamic system identification. And finally, the introduced system is implemented to predict the hot spot temperature using three datasets from a real power transformer. Hot spot monitoring is necessary to maximize the load capacity and the lifespan of power transformers. The proposed method is evaluated in terms of root-mean-square error, non-dimensional index error, mean absolute error, runtime, and the number of final rules. The results are compared with traditional forecasting models and with some related state-of-the-art rule-based evolving Fuzzy Systems. The new evolving Fuzzy System outperformed the compared models for the Mackey–Glass time-series and the power transformers datasets concerning the errors. A statistical test comprised the superior performance of the introduced model. The algorithm also obtained a competitive execution time and number of final rules. The results demonstrate the high level of autonomy and adaptation of the model to predict accurately complex and non-stationary data. Seeing the importance of accurate models to deal with data to support decision-making, the results suggest the model's implementation as a forecasting tool in strategic planning. © 2021 Elsevier B.V.;Not health related;0"Chen P.; Liu H.; Xin R.; Carval T.; Zhao J.; Xia Y.; Zhao Z.";Effectively Detecting Operational Anomalies In Large-Scale IoT Data Infrastructures By Using A GAN-Based Predictive Model;2022;Quality of data services is crucial for operational large-scale internet-of-things (IoT) research data infrastructure, in particular when serving large amounts of distributed users. Effectively detecting runtime anomalies and diagnosing their root cause helps to defend against adversarial attacks, thereby essentially boosting system security and robustness of the IoT infrastructure services. However, conventional anomaly detection methods are inadequate when facing the dynamic complexities of these systems. In contrast, supervised machine learning methods are unable to exploit large amounts of data due to the unavailability of labeled data. This paper leverages popular GAN-based generative models and end-to-end one-class classification to improve unsupervised anomaly detection. A novel heterogeneous BiGAN-based anomaly detection model Heterogeneous Temporal Anomaly-reconstruction GAN (HTA-GAN) is proposed to make better use of a one-class classifier and a novel anomaly scoring function. The Generator-Encoder-Discriminator BiGAN structure can lead to practical anomaly score computation and temporal feature capturing. We empirically compare the proposed approach with several state-of-the-art anomaly detection methods on real-world datasets, anomaly benchmarks and synthetic datasets. The results show that HTA-GAN outperforms its competitors and demonstrates better robustness.  © 2022 The British Computer Society.;Not health related;0"Kang L.; Riba P.; Rusinol M.; Fornes A.; Villegas M.";Content and Style Aware Generation of Text-Line Images for Handwriting Recognition;2022;Handwritten Text Recognition has achieved an impressive performance in public benchmarks. However, due to the high inter-and intra-class variability between handwriting styles, such recognizers need to be trained using huge volumes of manually labeled training data. To alleviate this labor-consuming problem, synthetic data produced with TrueType fonts has been often used in the training loop to gain volume and augment the handwriting style variability. However, there is a significant style bias between synthetic and real data which hinders the improvement of recognition performance. To deal with such limitations, we propose a generative method for handwritten text-line images, which is conditioned on both visual appearance and textual content. Our method is able to produce long text-line samples with diverse handwriting styles. Once properly trained, our method can also be adapted to new target data by only accessing unlabeled text-line images to mimic handwritten styles and produce images with any textual content. Extensive experiments have been done on making use of the generated samples to boost Handwritten Text Recognition performance. Both qualitative and quantitative results demonstrate that the proposed approach outperforms the current state of the art.  © 1979-2012 IEEE.;Not health related;0"Momeni S.; Fazlollahi A.; Lebrat L.; Yates P.; Rowe C.; Gao Y.; Liew A.W.-C.; Salvado O.";Generative Model of Brain Microbleeds for MRI Detection of Vascular Marker of Neurodegenerative Diseases;2021;Cerebral microbleeds (CMB) are increasingly present with aging and can reveal vascular pathologies associated with neurodegeneration. Deep learning-based classifiers can detect and quantify CMB from MRI, such as susceptibility imaging, but are challenging to train because of the limited availability of ground truth and many confounding imaging features, such as vessels or infarcts. In this study, we present a novel generative adversarial network (GAN) that has been trained to generate three-dimensional lesions, conditioned by volume and location. This allows one to investigate CMB characteristics and create large training datasets for deep learning-based detectors. We demonstrate the benefit of this approach by achieving state-of-the-art CMB detection of real CMB using a convolutional neural network classifier trained on synthetic CMB. Moreover, we showed that our proposed 3D lesion GAN model can be applied on unseen dataset, with different MRI parameters and diseases, to generate synthetic lesions with high diversity and without needing laboriously marked ground truth. Copyright © 2021 Momeni, Fazlollahi, Lebrat, Yates, Rowe, Gao, Liew and Salvado.;Health related;1"Rizvi S.K.J.; Azad M.A.; Fraz M.M.";Spectrum of Advancements and Developments in Multidisciplinary Domains for Generative Adversarial Networks (GANs);2021;The survey paper summarizes the recent applications and developments in the domain of Generative Adversarial Networks (GANs) i.e. a back propagation based neural network architecture for generative modeling. GANs is one of the most highlighted research avenue due to its synthetic data generation capabilities and benefits of representations comprehended irrespective of the application. While several reviews for GANs in the arena of image processing have been conducted by present but none have given attention on the review of GANs over multi-disciplinary domains. Therefore, in this survey, use of GAN in multidisciplinary applications areas and its implementation challenges have been done by conducting a rigorous search for journal/research article related to GAN and in this regard five renowned journal databases i.e. “ACM Digital Library”,” Elsevier”, “IEEE Explore”, “Science Direct”, “Springer” and proceedings of best domain specific conference are considered. By employing hybrid research methodology and article inclusion and exclusion criteria, 100 research articles are considered encompassing 23 application domains for the survey. In this paper applications of GAN in various practical domain and their implementation challenges its associated advantages and disadvantages have been discussed. For the first time a survey of this type have been done where GAN with wide range of application and its associated advantages and disadvantages issue have been reviewed. Finally, this article presents several diversified prominent developing trends in the respective research domain which will provide a visionary perspective regarding ongoing GANs related research and eventually help to develop an intuition for problem solving using GANs. © 2021, CIMNE, Barcelona, Spain.;Not health related;0"Castelli M.; Manzoni L.; Espindola T.; Popovi_ A.; De Lorenzo A.";Generative adversarial networks for generating synthetic features for Wi-Fi signal quality;2021;Wireless networks are among the fundamental technologies used to connect people. Considering the constant advancements in the field, telecommunication operators must guarantee a high-quality service to keep their customer portfolio. To ensure this high-quality service, it is common to establish partnerships with specialized technology companies that deliver software services in order to monitor the networks and identify faults and respective solutions. A common barrier faced by these specialized companies is the lack of data to develop and test their products. This paper investigates the use of generative adversarial networks (GANs), which are state-of-the-art generative models, for generating synthetic telecommunication data related to Wi-Fi signal quality. We developed, trained, and compared two of the most used GAN architectures: The Vanilla GAN and the Wasserstein GAN (WGAN). Both models presented satisfactory results and were able to generate synthetic data similar to the real ones. In particular, the distribution of the synthetic data overlaps the distribution of the real data for all of the considered features. Moreover, the considered generative models can reproduce the same associations observed for the synthetic features. We chose the WGAN as the final model, but both models are suitable for addressing the problem at hand.  © 2021 Castelli et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.;Not health related;0"Naveed M.H.; Hashmi U.S.; Tajved N.; Sultan N.; Imran A.";Assessing Deep Generative Models on Time Series Network Data;2022;To achieve zero touch automation in next generation wireless networks through artificial intelligence (AI), large amounts of training data is required. This training data is publicly unavailable and is a major hindrance in research on AI applications to wireless communication. One solution is using limited real data to generate synthetic data that can be used in lieu of real data. Generative Adversarial Networks (GAN) have been used successfully for this purpose. In this paper, we choose two publicly available GAN - based models and one deep learning - based auto-regressive model. We then compare their performance at generating synthetic time-series wireless network traffic data. We also assess the impact of data scarcity on the generated data quality by varying the level of data available to the models for training. Moreover, in order to assess the usefulness of this generated data, we compare the performance of a gradient boosting regressor trained solely on generated data, real data, and a mix of both at forecasting network traffic. Our experiments show that the GANs perform better than the auto-regressive approach in each aspect considered in this work and forecasting models trained to predict network load based on data generated by these GANs yield error rates comparable to models trained on real data. Finally, augmenting small amounts of real data with generated data leads to minor performance gains in some cases.  © 2013 IEEE.;Not health related;0"Castillo-Hair S.M.; Seelig G.";Machine Learning for Designing Next-Generation mRNA Therapeutics;2022;Over just the last 2 years, mRNA therapeutics and vaccines have undergone a rapid transition from an intriguing concept to real-world impact. However, whereas some aspects of mRNA therapeutics, such as the use of chemical modifications to increase stability and reduce immunogenicity, have been extensively optimized for over two decades, other aspects, particularly the selection and design of the noncoding leader and trailer sequences which control translation efficiency and stability, have received comparably less attention. In practice, such 5_ and 3_ untranslated regions (UTRs) are often borrowed from highly expressed human genes with few or no modifications, as in the case for the Pfizer/BioNTech Covid vaccine. Focusing on the 5_UTR, we here argue that model-driven design is a promising alternative that provides unprecedented control over 5_UTR function. We review recent work that combines synthetic biology with machine learning to build quantitative models that relate ribosome loading, and thus translation efficiency, to the 5_UTR sequence. We first introduce an experimental approach that uses polysome profiling and high-throughput sequencing to quantify ribosome loading for hundreds of thousands of 5_UTRs in parallel. We apply this approach to measure ribosome loading in synthetic RNA libraries with a random sequence inserted into the 5_UTR. We then review Optimus 5-Prime, a convolutional neural network model trained on the experimental data. We highlight that very accurate models of biological regulation can be learned from synthetic data sets with degenerate 5_UTRs. We validate model predictions not only on held-out data sets from our random library but also on a large library of over 30 000 human 5_UTR fragments and using translation reporter data collected independently by other groups. Both the experiment and model are compatible with commonly used chemically modified nucleosides, in particular, pseudouridine (_) and 1-methyl-pseudouridine (m1_). We find that, in general, 5_UTRs have very similar impacts when combined with different protein-coding sequences and even in the context of different chemical modifications. We demonstrate that Optimus 5-Prime can be combined with design algorithms to generate de novo sequences with precisely defined translation efficiencies. We emphasize recent developments in design algorithms that rely on activation maximization and generative modeling to improve both the fitness and diversity of designed sequences. Compared with prior approaches such as genetic algorithms, we show that these approaches are not only faster but also less likely to get stuck in local sequence optima. Finally, we discuss how the approach reviewed here can be generalized to other gene regions and applications. © 2021 The Authors. Published by American Chemical Society.;Health related;1"Sinclair M.; Schuh A.; Hahn K.; Petersen K.; Bai Y.; Batten J.; Schaap M.; Glocker B.";Atlas-ISTN: Joint segmentation, registration and atlas construction with image-and-spatial transformer networks;2022;Deep learning models for semantic segmentation are able to learn powerful representations for pixel-wise predictions, but are sensitive to noise at test time and may lead to implausible topologies. Image registration models on the other hand are able to warp known topologies to target images as a means of segmentation, but typically require large amounts of training data, and have not widely been benchmarked against pixel-wise segmentation models. We propose the Atlas Image-and-Spatial Transformer Network (Atlas-ISTN), a framework that jointly learns segmentation and registration on 2D and 3D image data, and constructs a population-derived atlas in the process. Atlas-ISTN learns to segment multiple structures of interest and to register the constructed atlas labelmap to an intermediate pixel-wise segmentation. Additionally, Atlas-ISTN allows for test time refinement of the model's parameters to optimize the alignment of the atlas labelmap to an intermediate pixel-wise segmentation. This process both mitigates for noise in the target image that can result in spurious pixel-wise predictions, as well as improves upon the one-pass prediction of the model. Benefits of the Atlas-ISTN framework are demonstrated qualitatively and quantitatively on 2D synthetic data and 3D cardiac computed tomography and brain magnetic resonance image data, out-performing both segmentation and registration baseline models. Atlas-ISTN also provides inter-subject correspondence of the structures of interest. © 2022;Not health related;1"Desai R.; Shah A.; Kothari S.; Surve A.; Shekokar N.";TextBrew: Automated Model Selection and Hyperparameter Optimization for Text Classification;2022;In building a machine learning solution, algorithm selection and hyperparameter tuning is the most time-consuming task. Automated Machine Learning is a solution to fully automate the process of finding the best model for a given task without actually having to try various models. This paper introduces a new AutoML system, TextBrew, explicitly built for the NLP task of text classification. Our system provides an automated method for selecting transformer models, tuning hyperparameters, and combining the best models into one by ensembling. Keeping in mind that new state-of-the-art models are being constantly introduced, TextBrew has been designed to be highly flexible and thus can support additional models easily. In our work, we experiment with multiple transformer models, each with numerous different hyperparameter settings, and select the most robust models. These models are then trained on multiple datasets to obtain accuracy scores, which are then used to build the metadataset to train the meta-model. Since text classification datasets are not as abundant, our system generates synthetic data to augment the meta-dataset using CopulaGAN, a deep generative model. The meta-model is an ensemble of five models, which predicts the best candidate model with an accuracy of 78.75%. The final model returned to the user is an ensemble of all the best models that can be trained under the given time constraint. Experiments on various datasets and comparisons with existing systems demonstrate the effectiveness of our system © 2022, International Journal of Advanced Computer Science and Applications.All Rights Reserved.;Not health related;0"Platscher M.; Zopes J.; Federau C.";Image translation for medical image generation: Ischemic stroke lesion segmentation;2022;Deep learning based disease detection and segmentation algorithms promise to improve many clinical processes. However, such algorithms require vast amounts of annotated training data, which are typically not available in the medical context due to data privacy, legal obstructions, and non-uniform data acquisition protocols. Synthetic databases with annotated pathologies could provide the required amounts of training data. We demonstrate with the example of ischemic stroke that an improvement in lesion segmentation is feasible using deep learning based augmentation. To this end, we train different image-to-image translation models to synthesize magnetic resonance images of brain volumes with and without stroke lesions from semantic segmentation maps. In addition, we train a generative adversarial network to generate synthetic lesion masks. Subsequently, we combine these two components to build a large database of synthetic stroke images. The performance of the various models is evaluated using a U-Net which is trained to segment stroke lesions on a clinical test set. We report a Dice score of 72.8% [70.8±1.0%] for the model with the best performance, which outperforms the model trained on the clinical images alone 67.3% [63.2±1.9%], and is close to the human inter-reader Dice score of 76.9%. Moreover, we show that for a small database of only 10 or 50 clinical cases, synthetic data augmentation yields significant improvement compared to a setting where no synthetic data is used. To the best of our knowledge, this presents the first comparative analysis of synthetic data augmentation based on image-to-image translation, and first application to ischemic stroke. © 2021 The Authors;Health related;1"Heidrich B.; Mannsperger L.; Turowski M.; Phipps K.; Schäfer B.; Mikut R.; Hagenmeyer V.";Boost short-term load forecasts with synthetic data from transferred latent space information;2022;Sustainable energy systems are characterised by an increased integration of renewable energy sources, which magnifies the fluctuations in energy supply. Methods to to cope with these magnified fluctuations, such as load shifting, typically require accurate short-term load forecasts. Although numerous machine learning models have been developed to improve short-term load forecasting (STLF), these models often require large amounts of training data. Unfortunately, such data is usually not available, for example, due to new users or privacy concerns. Therefore, obtaining accurate short-term load forecasts with little data is a major challenge. The present paper thus proposes the latent space-based forecast enhancer (LSFE), a method which combines transfer learning and data augmentation to enhance STLF when training data is limited. The LSFE first trains a generative model on source data similar to the target data before using the latent space data representation of the target data to generate seed noise. Finally, we use this seed noise to generate synthetic data, which we combine with real data to enhance STLF. We evaluate the LSFE on real-world electricity data by examining the influence of its components, analysing its influence on obtained forecasts, and comparing its performance to benchmark models. We show that the Latent Space-based Forecast Enhancer is generally capable of improving the forecast accuracy and thus helps to successfully meet the challenge of limited available training data. © 2022, The Author(s).;Not health related;0"Mohammadjafari S.; Cevik M.; Basar A.";VARGAN: variance enforcing network enhanced GAN;2023;Generative adversarial networks (GANs) are one of the most widely used generative models. GANs can learn complex multi-modal distributions, and generate real-like samples. Despite the major success of GANs in generating synthetic data, they might suffer from unstable training process, and mode collapse. In this paper, we propose a new GAN architecture called variance enforcing GAN (VARGAN), which incorporates a third network to introduce diversity in the generated samples. The third network measures the diversity of the generated samples, which is used to penalize the generator’s loss for low diversity samples. The network is trained on the available training data and undesired distributions with limited modality. On a set of synthetic and real-world image data, VARGAN generates a more diverse set of samples compared to the recent state-of-the-art models. High diversity and low computational complexity, as well as fast convergence, make VARGAN a promising model to alleviate mode collapse. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.;Not health related;0"El Emam K.; Mosquera L.; Fang X.; El-Hussuna A.";Utility Metrics for Evaluating Synthetic Health Data Generation Methods: Validation Study;2022;Background: A regular task by developers and users of synthetic data generation (SDG) methods is to evaluate and compare the utility of these methods. Multiple utility metrics have been proposed and used to evaluate synthetic data. However, they have not been validated in general or for comparing SDG methods. Objective: This study evaluates the ability of common utility metrics to rank SDG methods according to performance on a specific analytic workload. The workload of interest is the use of synthetic data for logistic regression prediction models, which is a very frequent workload in health research. Methods: We evaluated 6 utility metrics on 30 different health data sets and 3 different SDG methods (a Bayesian network, a Generative Adversarial Network, and sequential tree synthesis). These metrics were computed by averaging across 20 synthetic data sets from the same generative model. The metrics were then tested on their ability to rank the SDG methods based on prediction performance. Prediction performance was defined as the difference between each of the area under the receiver operating characteristic curve and area under the precision-recall curve values on synthetic data logistic regression prediction models versus real data models. Results: The utility metric best able to rank SDG methods was the multivariate Hellinger distance based on a Gaussian copula representation of real and synthetic joint distributions. Conclusions: This study has validated a generative model utility metric, the multivariate Hellinger distance, which can be used to reliably rank competing SDG methods on the same data set. The Hellinger distance metric can be used to evaluate and compare alternate SDG methods. © 2022 JMIR Publications Inc.. All right reserved.;Health related;1"dos Santos Ferreira A.; Junior J.M.; Pistori H.; Melgani F.; Gonçalves W.N.";Unsupervised domain adaptation using transformers for sugarcane rows and gaps detection;2022;Deep learning represented an impressive advance in the field of machine learning and is continually breaking records in dozens of areas of artificial intelligence, such as image recognition. Nevertheless, the success of these architectures depends on a large amount of labeled data and the annotation of training data is a costly process that is often performed manually. The cost of labeling and the difficulty of generalizing the model knowledge to unseen data poses an obstacle to the use of these techniques in real-world agricultural challenges. In this work, we propose an approach to deal with this problem when detecting crop rows and gaps and our findings can be extended to other problems related with few modifications. Our approach proposes to generate approximated segmentation maps from annotated one-pixel-wide lines using dilation. This method speeds up the pixel labeling process and reduces the line detection problem to semantic segmentation. We considered the transformer-based method, SegFormer, and compared it with ConvNet segmentation models, PSPNet and DeepLabV3+, on datasets containing aerial images of four different sugarcane farms. To evaluate the ability to transfer the knowledge learned from source datasets to target datasets, we used a very recent and current state-of-the-state unsupervised domain adaptation (UDA) model, DAFormer, which has achieved great results in adapting knowledge from synthetic data to real data. In this work, we were able to evaluate its performance using only real-world images from different but related domains. Even without using domain adaptation, the Transformer-based model, SegFormer, performed significantly better than ConvNets for unseen data, but when applying UDA using DAFormer, the results were even better, reaching from 71.1% to 94.5% relative performance regarding the average F1-score achieved when using supervised training with labeled data. © 2022 Elsevier B.V.;Not health related;0"Sreejith Kumar A.J.; Chong R.S.; Crowston J.G.; Chua J.; Bujor I.; Husain R.; Vithana E.N.; Girard M.J.A.; Ting D.S.W.; Cheng C.-Y.; Aung T.; Popa-Cherecheanu A.; Schmetterer L.; Wong D.";Evaluation of Generative Adversarial Networks for High-Resolution Synthetic Image Generation of Circumpapillary Optical Coherence Tomography Images for Glaucoma;2022;"Importance: Deep learning (DL) networks require large data sets for training, which can be challenging to collect clinically. Generative models could be used to generate large numbers of synthetic optical coherence tomography (OCT) images to train such DL networks for glaucoma detection. Objective: To assess whether generative models can synthesize circumpapillary optic nerve head OCT images of normal and glaucomatous eyes and determine the usability of synthetic images for training DL models for glaucoma detection. Design, Setting, and Participants: Progressively growing generative adversarial network models were trained to generate circumpapillary OCT scans. Image gradeability and authenticity were evaluated on a clinical set of 100 real and 100 synthetic images by 2 clinical experts. DL networks for glaucoma detection were trained with real or synthetic images and evaluated on independent internal and external test data sets of 140 and 300 real images, respectively. Main Outcomes and Measures: Evaluations of the clinical set between the experts were compared. Glaucoma detection performance of the DL networks was assessed using area under the curve (AUC) analysis. Class activation maps provided visualizations of the regions contributing to the respective classifications. Results: A total of 990 normal and 862 glaucomatous eyes were analyzed. Evaluations of the clinical set were similar for gradeability (expert 1: 92.0%; expert 2: 93.0%) and authenticity (expert 1: 51.8%; expert 2: 51.3%). The best-performing DL network trained on synthetic images had AUC scores of 0.97 (95% CI, 0.95-0.99) on the internal test data set and 0.90 (95% CI, 0.87-0.93) on the external test data set, compared with AUCs of 0.96 (95% CI, 0.94-0.99) on the internal test data set and 0.84 (95% CI, 0.80-0.87) on the external test data set for the network trained with real images. An increase in the AUC for the synthetic DL network was observed with the use of larger synthetic data set sizes. Class activation maps showed that the regions of the synthetic images contributing to glaucoma detection were generally similar to that of real images. Conclusions and Relevance: DL networks trained with synthetic OCT images for glaucoma detection were comparable with networks trained with real images. These results suggest potential use of generative models in the training of DL networks and as a means of data sharing across institutions without patient information confidentiality issues. © 2022 American Medical Association. All rights reserved.";Health related;1"Gierjatowicz P.; Sabate-Vidales M.; _i_ka D.; Szpruch _.; _uri_ _.";Robust pricing and hedging via neural stochastic differential equations;2022;Modern data science techniques are opening the door to data-driven model selection mechanisms. However, most machine learning models are “black boxes”, as indi-vidual parameters do not have a meaningful interpretation. In contrast, classical risk models based on stochastic differential equations (SDEs) with fixed parameterization are well understood. Unfortunately, the risk of using an inadequate model is hard to detect and quantify. In this paper, instead of choosing a fixed parameterization for the model SDE, we aim to learn the drift and diffusion from data using overparam-eterized neural networks. The resulting model, called neural SDE, allows consistent calibration under both risk-neutral and real-world measures and is an instantiation of generative models closely linked with the theory of causal optimal transport. We demonstrate how neural SDEs make it possible to find robust bounds for the prices of derivatives and the corresponding hedging strategies. Further, the model can simulate the market scenarios needed for assessing risk profiles and hedging strategies. We develop and analyze novel algorithms for the efficient use of neural SDEs and we validate our approach with numerical experiments using both market and synthetic data. © 2023 Infopro Digital Risk (IP) Limited.;Not health related;0"Najar F.; Bourouis S.; Bouguila N.; Belghith S.";A new hybrid discriminative/generative model using the full-covariance multivariate generalized Gaussian mixture models;2020;Discriminative models have been shown to be more advantageous for pattern recognition problem in machine learning. For this study, the main focus is developing a new hybrid model that combines the advantages of a discriminative technique namely the support vector machines (SVM) with the full efficiency offered through covariance multivariate generalized Gaussian mixture models (MGGMM). This new hybrid MGGMM applies the Fisher and Kullback–Leibler kernels derived from MGGMM to improve the kernel function of SVM. This approach is based on two different learning techniques explicitly: the Fisher scoring algorithm and the Bayes inference technique based on Markov Chain Monte Carlo and Metropolis–Hastings algorithm. These learning methods work with two model selection approaches (minimum message length and marginal likelihood) to determine the number of clusters. The effectiveness of the framework is demonstrated through extensive experiments including synthetic datasets, facial expression recognition and human activity recognition. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Wiles O.; Zisserman A.";Learning to Predict 3D Surfaces of Sculptures from Single and Multiple Views;2019;"The objective of this work is to reconstruct the 3D surfaces of sculptures from one or more images using a view-dependent representation. To this end, we train a network, SiDeNet, to predict the Silhouette and Depth of the surface given a variable number of images; the silhouette is predicted at a different viewpoint from the inputs (e.g. from the side), while the depth is predicted at the viewpoint of the input images. This has three benefits. First, the network learns a representation of shape beyond that of a single viewpoint, as the silhouette forces it to respect the visual hull, and the depth image forces it to predict concavities (which don’t appear on the visual hull). Second, as the network learns about 3D using the proxy tasks of predicting depth and silhouette images, it is not limited by the resolution of the 3D representation. Finally, using a view-dependent representation (e.g. additionally encoding the viewpoint with the input image) improves the network’s generalisability to unseen objects. Additionally, the network is able to handle the input views in a flexible manner. First, it can ingest a different number of views during training and testing, and it is shown that the reconstruction performance improves as additional views are added at test-time. Second, the additional views do not need to be photometrically consistent. The network is trained and evaluated on two synthetic datasets—a realistic sculpture dataset (SketchFab), and ShapeNet. The design of the network is validated by comparing to state of the art methods for a set of tasks. It is shown that (i) passing the input viewpoint (i.e. using a view-dependent representation) improves the network’s generalisability at test time. (ii) Predicting depth/silhouette images allows for higher quality predictions in 2D, as the network is not limited by the chosen latent 3D representation. (iii) On both datasets the method of combining views in a global manner performs better than a local method. Finally, we show that the trained network generalizes to real images, and probe how the network has encoded the latent 3D shape. © 2018, The Author(s).";Not health related;0"Trampert P.; Rubinstein D.; Boughorbel F.; Schlinkmann C.; Luschkova M.; Slusallek P.; Dahmen T.; Sandfeld S.";Deep neural networks for analysis of microscopy images—synthetic data generation and adaptive sampling;2021;The analysis of microscopy images has always been an important yet time consuming process in materials science. Convolutional Neural Networks (CNNs) have been very successfully used for a number of tasks, such as image segmentation. However, training a CNN requires a large amount of hand annotated data, which can be a problem for material science data. We present a procedure to generate synthetic data based on ad hoc parametric data modelling for enhancing generalization of trained neural network models. Especially for situations where it is not possible to gather a lot of data, such an approach is beneficial and may enable to train a neural network reasonably. Furthermore, we show that targeted data generation by adaptively sampling the parameter space of the generative models gives superior results compared to generating random data points. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Not health related;0"Li Y.-H.; Aslam M.S.; Harfiya L.N.; Chang C.-C.";Conditional Wasserstein generative adversarial networks for rebalancing iris image datasets;2021;The recent development of deep learning-based generative models has sharply intensified the interest in data synthesis and its applications. Data synthesis takes on an added importance especially for some pattern recognition tasks in which some classes of data are rare and difficult to collect. In an iris dataset, for instance, the minority class samples include images of eyes with glasses, oversized or undersized pupils, misaligned iris locations, and iris occluded or contaminated by eyelids, eyelashes, or lighting reflections. Such class-imbalanced datasets often result in biased classification performance. Generative adversarial networks (GANs) are one of the most promising frameworks that learn to generate synthetic data through a two-player minimax game between a generator and a discriminator. In this paper, we utilized the state-of-the-art conditional Wasserstein generative adversarial network with gradient penalty (CWGAN-GP) for generating the minority class of iris images which saves huge amount of cost of human labors for rare data collection. With our model, the researcher can generate as many iris images of rare cases as they want and it helps to develop any deep learning algorithm whenever large size of dataset is needed. Copyright © 2021 The Institute of Electronics, Information and Communication Engineers;Not health related;0"Honorio J.; Ortiz L.";Learning the structure and parameters of large-population graphical games from behavioral data;2015;"We consider learning, from strictly behavioral data, the structure and parameters of linear influence games (LIGs), a class of parametric graphical games introduced by Irfan and Ortiz (2014). LIGs facilitate causal strategic inference (CSI): Making inferences from causal interventions on stable behavior in strategic settings. Applications include the identification of the most influential individuals in large (social) networks. Such tasks can also support policy-making analysis. Motivated by the computational work on LIGs, we cast the learning problem as maximum-likelihood estimation (MLE) of a generative model defined by pure-strategy Nash equilibria (PSNE). Our simple formulation uncovers the fundamental interplay between goodness-of-fit and model complexity: good models capture equilibrium behavior within the data while controlling the true number of equilibria, including those unobserved. We provide a generalization bound establishing the sample complexity for MLE in our framework. We propose several algorithms including convex loss minimization (CLM) and sigmoidal approximations. We prove that the number of exact PSNE in LIGs is small, with high probability; thus, CLM is sound. We illustrate our approach on synthetic data and real-world U.S. congressional voting records. We briefly discuss our learning framework's generality and potential applicability to general graphical games. © 2015 Jean Honorio and Luis Ortiz.";Not health related;0"Buffington T.; Cabrera J.-M.; Kurzawski A.; Ezekoye O.A.";Deep-Learning Emulators of Transient Compartment Fire Simulations for Inverse Problems and Room-Scale Calorimetry;2021;"This work describes a deep learning methodology for “emulating” temperature outputs produced by the Fire Dynamics Simulator (FDS), a CFD software. An array of artificial neural networks (ANNs) is trained to predict transient temperatures at specified locations for a transient heat release rate (HRR) input. These locations correspond to the locations of thermocouples used in an experimental burn structure. In order to build the training set, A Gaussian process (GP) framework is used to develop a generative model that produces random viable HRR ramps. Although this procedure may require thousands of FDS runs to build a sufficient training set, the application of transfer learning can reduce the required number of runs by nearly an order of magnitude. This refers to the process of initially training an ANN to predict the output of the Consolidated Model of Fire and Smoke Transport (CFAST) and then transferring its knowledge to an ANN that learns to predict FDS outputs. CFAST is a much faster model than FDS, so a large training set can be generated quickly. The final state of the ANN trained to emulate CFAST is used as the initial state of an ANN that learns to emulate FDS. The result is a model that produces FDS temperature predictions with a mean absolute error (MAE) of less than 2°C and runs over five orders of magnitude faster than FDS. The emulators are also capable of learning inverse mappings; i.e. for a given temperature output, they can predict the HRR ramp that would cause FDS to produce the temperature response. This ability to invert for the HRR profile is exercised on data collected from eight fire experiments with peak HRRs up to 200 kW, including four propane burner fires, two methanol pool fires, and two n-Hexane pool fires. The model inverts for the experimental HRR with a MAE of 5.8 kW-15.4 kW (11.3%–16.7%) for the burner tests and 5.0 kW–25.5 kW (12.1%–28.6%) for the pool fire tests, with a tendency to underestimate the HRR of the pool fires. Finally, the computational speed of the emulators allows for the incorporation of CFD physics in Bayesian parameter inversion. As an example, this is demonstrated to infer the radiative fraction from experimental and synthetic data in conjunction with reported uncertainties from the FDS Validation Guide. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.";Not health related;0"Kurthen M.; Enßlin T.";A bayesian model for bivariate causal inference;2020;We address the problem of two-variable causal inference without intervention. This task is to infer an existing causal relation between two random variables, i.e., X _ Y or Y _ X, from purely observational data. As the option to modify a potential cause is not given in many situations, only structural properties of the data can be used to solve this ill-posed problem. We briefly review a number of state-of-the-art methods for this, including very recent ones. A novel inference method is introduced, Bayesian Causal Inference (BCI) which assumes a generative Bayesian hierarchical model to pursue the strategy of Bayesian model selection. In the adopted model, the distribution of the cause variable is given by a Poisson lognormal distribution, which allows to explicitly regard the discrete nature of datasets, correlations in the parameter spaces, as well as the variance of probability densities on logarithmic scales. We assume Fourier diagonal Field covariance operators. The model itself is restricted to use cases where a direct causal relation X _ Y has to be decided against a relation Y _ X, therefore we compare it other methods for this exact problem setting. The generative model assumed provides synthetic causal data for benchmarking our model in comparison to existing state-of-the-art models, namely LiNGAM, ANM-HSIC, ANM-MML, IGCI, and CGNN. We explore how well the above methods perform in case of high noise settings, strongly discretized data, and very sparse data. BCI performs generally reliably with synthetic data as well as with the real world TCEP benchmark set, with an accuracy comparable to state-of-the-art algorithms. We discuss directions for the future development of BCI. © 2019 by the authors.;Not health related;0"Stallmann D.; Göpfert J.P.; Schmitz J.; Grünberger A.; Hammer B.";Towards an automatic analysis of CHO-K1 suspension growth in microfluidic single-cell cultivation;2021;"Motivation: Innovative microfluidic systems carry the promise to greatly facilitate spatio-temporal analysis of single cells under well-defined environmental conditions, allowing novel insights into population heterogeneity and opening new opportunities for fundamental and applied biotechnology. Microfluidics experiments, however, are accompanied by vast amounts of data, such as time series of microscopic images, for which manual evaluation is infeasible due to the sheer number of samples. While classical image processing technologies do not lead to satisfactory results in this domain, modern deep-learning technologies, such as convolutional networks can be sufficiently versatile for diverse tasks, including automatic cell counting as well as the extraction of critical parameters, such as growth rate. However, for successful training, current supervised deep learning requires label information, such as the number or positions of cells for each image in a series; obtaining these annotations is very costly in this setting. Results: We propose a novel machine-learning architecture together with a specialized training procedure, which allows us to infuse a deep neural network with human-powered abstraction on the level of data, leading to a highperforming regression model that requires only a very small amount of labeled data. Specifically, we train a generative model simultaneously on natural and synthetic data, so that it learns a shared representation, from which a target variable, such as the cell count, can be reliably estimated.  © 2021 The Author(s).";Not health related;0"Siyaev A.; Jo G.-S.";Neuro-Symbolic Speech Understanding in Aircraft Maintenance Metaverse;2021;In the emerging world of metaverses, it is essential for speech communication systems to be aware of context to interact with virtual assets in the 3D world. This paper proposes the metaverse for aircraft maintenance training and education of Boeing-737, supplied with legacy manuals, 3D models, 3D simulators, and aircraft maintenance knowledge. Furthermore, to navigate and control operational flow in the metaverse, which is strictly followed by maintenance manuals, the context-aware speech understanding module Neuro-Symbolic Speech Executor (NSSE) is presented. Unlike conventional speech recognition methods, NSSE applies Neuro-Symbolic AI, which combines neural networks and traditional symbolic reasoning, to understand users' requests and reply based on context and aircraft-specific knowledge. NSSE is developed with an industrially flexible approach by applying only synthetic data for training. Nevertheless, the evaluation process performed with various automatic speech recognition metrics on real users' data showed sustainable results with an average accuracy of 94.7%, Word Error Rate (WER) of 7.5%, and the generalization ability to handle speech requests of users with the non-native pronunciation. The proposed Aircraft Maintenance Metaverse is a cheap and scalable solution for aviation colleges since it replaces expensive physical aircraft with virtual one that can be easily modified and updated. Moreover, the Neuro-Symbolic Speech Executor, playing the role of field expert, provides technical guidance and all the resources to facilitate effective training and education of aircraft maintenance.  © 2013 IEEE.;Not health related;0"Kleinebrahm M.; Torriti J.; McKenna R.; Ardone A.; Fichtner W.";Using neural networks to model long-term dependencies in occupancy behavior;2021;Models simulating household energy demand based on different occupant and household types and their behavioral patterns have received increasing attention over the last years due the need to better understand fundamental characteristics that shape the demand side. Most of the models described in the literature are based on Time Use Survey data and Markov chains. Due to the nature of the underlying data and the Markov property, it is not sufficiently possible to consider long-term dependencies over several days in occupant behavior. An accurate mapping of long-term dependencies in behavior is of increasing importance, e.g. for the determination of flexibility potentials of individual households urgently needed to compensate supply-side fluctuations of renewable based energy systems. The aim of this study is to bridge the gap between social practice theory, energy related activity modelling and novel machine learning approaches. The weaknesses of existing approaches are addressed by combining time use survey data with mobility data, which provide information about individual mobility behavior over periods of one week. In social practice theory, emphasis is placed on the sequencing and repetition of practices over time. This suggests that practices have a memory. Transformer models based on the attention mechanism and Long short-term memory (LSTM) based neural networks define the state of the art in the field of natural language processing (NLP) and are for the first time introduced in this paper for the generation of weekly activity profiles. In a first step an autoregressive model is presented, which generates synthetic weekly mobility schedules of individual occupants and thereby captures long-term dependencies in mobility behavior. In a second step, an imputation model enriches the weekly mobility schedules with detailed information about energy relevant at home activities. The weekly activity profiles build the basis for multiple use cases one of which is modelling consistent electricity, heat and mobility demand profiles of households. The approach developed provides the basis for making high-quality weekly activity data available to the general public without having to carry out complex application procedures. © 2021 Elsevier B.V.;Not health related;0"Gutiérrez-Becker B.; Sarasua I.; Wachinger C.";Discriminative and generative models for anatomical shape analysis on point clouds with deep neural networks;2021;We introduce deep neural networks for the analysis of anatomical shapes that learn a low-dimensional shape representation from the given task, instead of relying on hand-engineered representations. Our framework is modular and consists of several computing blocks that perform fundamental shape processing tasks. The networks operate on unordered point clouds and provide invariance to similarity transformations, avoiding the need to identify point correspondences between shapes. Based on the framework, we assemble a discriminative model for disease classification and age regression, as well as a generative model for the accruate reconstruction of shapes. In particular, we propose a conditional generative model, where the condition vector provides a mechanism to control the generative process. For instance, it enables to assess shape variations specific to a particular diagnosis, when passing it as side information. Next to working on single shapes, we introduce an extension for the joint analysis of multiple anatomical structures, where the simultaneous modeling of multiple structures can lead to a more compact encoding and a better understanding of disorders. We demonstrate the advantages of our framework in comprehensive experiments on real and synthetic data. The key insights are that (i) learning a shape representation specific to the given task yields higher performance than alternative shape descriptors, (ii) multi-structure analysis is both more efficient and more accurate than single-structure analysis, and (iii) point clouds generated by our model capture morphological differences associated to Alzheimer's disease, to the point that they can be used to train a discriminative model for disease classification. Our framework naturally scales to the analysis of large datasets, giving it the potential to learn characteristic variations in large populations. © 2020 Elsevier B.V.;Health related;1"Li B.; Luo S.; Qin X.; Pan L.";Improving GAN with inverse cumulative distribution function for tabular data synthesis;2021;Designing a generative model to synthesize realistic tabular data is of great significance in data science. Existing tabular data generative models have difficulty in handling complicated and diverse marginal distribution types due to the gradient vanishing problem, and these models pay little attention to the correlation between attributes. We propose a method that improves the generative adversarial network (GAN) with inverse cumulative distribution function for tabular data synthesis. This method first transforms continuous columns into uniform distribution data by using the cumulative distribution function, which can alleviate the gradient vanishing problem in model training. Then the method trains GAN with the transformed data, where the discriminator with label reconstruction function is presented to model the correlation among attributes accurately by introducing an auxiliary supervised task to help the correlations extraction. After that, we train a neural network for each continuous column to perform the inverse transformation of generated data into the target distribution, thereby the synthetic data is obtained. Experiments on simulated and real-world datasets show that our method compares favorably against the state-of-the-art methods in modeling tabular data. © 2021 Elsevier B.V.;Not health related;0"Lee M.C.H.; Petersen K.; Pawlowski N.; Glocker B.; Schaap M.";TeTrIS: Template Transformer Networks for Image Segmentation with Shape Priors;2019;In this paper, we introduce and compare different approaches for incorporating shape prior information into neural network-based image segmentation. Specifically, we introduce the concept of template transformer networks, where a shape template is deformed to match the underlying structure of interest through an end-to-end trained spatial transformer network. This has the advantage of explicitly enforcing shape priors, and this is free of discretization artifacts by providing a soft partial volume segmentation. We also introduce a simple yet effective way of incorporating priors in the state-of-the-art pixel-wise binary classification methods such as fully convolutional networks and U-net. Here, the template shape is given as an additional input channel, incorporating this information significantly reduces false positives. We report results on synthetic data and sub-voxel segmentation of coronary lumen structures in cardiac computed tomography showing the benefit of incorporating priors in neural network-based image segmentation. © 2019 IEEE.;Not health related;0"Burt J.B.; Helmer M.; Shinn M.; Anticevic A.; Murray J.D.";Generative modeling of brain maps with spatial autocorrelation;2020;Studies of large-scale brain organization have revealed interesting relationships between spatial gradients in brain maps across multiple modalities. Evaluating the significance of these findings requires establishing statistical expectations under a null hypothesis of interest. Through generative modeling of synthetic data that instantiate a specific null hypothesis, quantitative benchmarks can be derived for arbitrarily complex statistical measures. Here, we present a generative null model, provided as an open-access software platform, that generates surrogate maps with spatial autocorrelation (SA) matched to SA of a target brain map. SA is a prominent and ubiquitous property of brain maps that violates assumptions of independence in conventional statistical tests. Our method can simulate surrogate brain maps, constrained by empirical data, that preserve the SA of cortical, subcortical, parcellated, and dense brain maps. We characterize how SA impacts p-values in pairwise brain map comparisons. Furthermore, we demonstrate how SA-preserving surrogate maps can be used in gene set enrichment analyses to test hypotheses of interest related to brain map topography. Our findings demonstrate the utility of SA-preserving surrogate maps for hypothesis testing in complex statistical analyses, and underscore the need to disambiguate meaningful relationships from chance associations in studies of large-scale brain organization. © 2020;Not health related;1"Karadag O.O.; Cicek O.E.";Empirical evaluation of the effectiveness of variational autoencoders on data augmentation for the image classification problem;2020;"In the last decade, deep learning methods have become the key solution for various machine learning problems. One major drawback of deep learning methods is that they require large datasets to have a good generalization performance. Researchers propose data augmentation techniques for generating synthetic data to overcome this problem. Traditional methods, such as flipping, rotation etc., which are referred as transformation based methods in this study are commonly used for obtaining synthetic data in the literature. These methods take as input an image and process that image to obtain a new one. On the other hand, generative models such as generative adversarial networks, auto-encoders, after trained with a set of image learn to generate synthetic data. Recently generative models are commonly used for data augmentation in various domains. In this study, we evaluate the effectiveness of a generative model, variational autoencoders (VAE), on the image classification problem. For this purpose, we train a VAE using CIFAR-10 dataset and generate synthetic samples with this model. We evaluate the classification performance using various sized datasets and compare the classification performances on four datasets; dataset without augmentation, dataset augmented with VAE and two datasets augmented with transformation based methods. We observe that the contribution of data augmentation is sensitive to the size of the dataset and VAE augmentation is as effective as the transformation based augmentation methods. © 2020, Ismail Saritas. All rights reserved.";Not health related;0"Grande R.C.; Walsh T.J.; Chowdhary G.; Ferguson S.; How J.P.";Online Regression for Data with Changepoints Using Gaussian Processes and Reusable Models;2017;Many prediction, decision-making, and control architectures rely on online learned Gaussian process (GP) models. However, most existing GP regression algorithms assume a single generative model, leading to poor predictive performance when the data are nonstationary, i.e., generated from multiple switching processes. Furthermore, existing methods for GP regression over nonstationary data require significant computation, do not come with provable guarantees on correctness and speed, and many only work in batch settings, making them ill-suited for real-time prediction. We present an efficient online GP framework, GP-non-Bayesian clustering (GP-NBC), which addresses these computational and theoretical issues, allowing for real-time changepoint detection and regression using GPS. Our empirical results on two real-world data sets and two synthetic data set show that GP-NBC outperforms state-of-the-art methods for nonstationary regression in terms of both regression error and computation. For example, it outperforms Dirichlet process GP clustering with Gibbs sampling by 98% in computation time reduction while the mean absolute error is comparable. © 2012 IEEE.;Not health related;0"Fathy Y.; Jaber M.; Brintrup A.";Learning with Imbalanced Data in Smart Manufacturing: A Comparative Analysis;2021;"The Internet of Things (IoT) paradigm is revolutionising the world of manufacturing into what is known as Smart Manufacturing or Industry 4.0. The main pillar in smart manufacturing looks at harnessing IoT data and leveraging machine learning (ML) to automate the prediction of faults, thus cutting maintenance time and cost and improving the product quality. However, faults in real industries are overwhelmingly outweighed by instances of good performance (faultless samples); this bias is reflected in the data captured by IoT devices. Imbalanced data limits the success of ML in predicting faults, thus presents a significant hindrance in the progress of smart manufacturing. Although various techniques have been proposed to tackle this challenge in general, this work is the first to present a framework for evaluating the effectiveness of these remedies in the context of manufacturing. We present a comprehensive comparative analysis in which we apply our proposed framework to benchmark the performance of different combinations of algorithm components using a real-world manufacturing dataset. We draw key insights into the effectiveness of each component and inter-relatedness between the dataset, the application context, and the design of the ML algorithm.  © 2013 IEEE.";Not health related;0"Kahlen J.N.; Andres M.; Moser A.";Improving machine-learning diagnostics with model-based data augmentation showcased for a transformer fault;2021;Machine-learning diagnostic systems are widely used to detect abnormal conditions in electrical equipment. Training robust and accurate diagnostic systems is challenging because only small databases of abnormal-condition data are available. However, the performance of the diagnostic systems depends on the quantity and quality of the data. The training database can be augmented utilizing data augmentation techniques that generate synthetic data to improve diagnostic performance. However, existing data augmentation techniques are generic methods that do not include additional information in the synthetic data. In this paper, we develop a model-based data augmentation technique integrating computer-implementable electromechanical models. Synthetic normal-and abnormal-condition data are generated with an electromechanical model and a stochastic parameter value sampling method. The model-based data augmentation is showcased to detect an abnormal condition of a distribution transformer. First, the synthetic data are compared with the measurements to verify the synthetic data. Then, ML-based diagnostic systems are created using model-based data augmentation and are compared with state-of-the-art diagnostic systems. It is shown that using the model-based data augmentation results in an improved accuracy compared to state-of-the-art diagnostic systems. This holds especially true when only a small abnormal-condition database is available. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Not health related;0"Besedin A.; Blanchart P.; Crucianu M.; Ferecatu M.";Deep online classification using pseudo-generative models;2020;In this work we propose a new deep learning based approach for online classification on streams of high-dimensional data. While requiring very little historical data storage, our approach is able to alleviate catastrophic forgetting in the scenario of continual learning with no assumption on the stationarity of the data in the stream. To make up for the absence of historical data, we propose a new generative autoencoder endowed with an auxiliary loss function that ensures fast task-sensitive convergence. To evaluate our approach we perform experiments on two well-known image datasets, MNIST and LSUN, in a continuous streaming mode. We extend the experiments to a large multi-class synthetic dataset that allows to check the performance of our method in more challenging settings with up to 1000 distinct classes. Our approach is able to perform classification on dynamic data streams with an accuracy close to the results obtained in the offline classification setup where all the data are available for the full duration of training. In addition, we demonstrate the ability of our method to adapt to unseen data classes and new instances of already known data categories, while avoiding catastrophic forgetting of previously acquired knowledge. © 2020 Elsevier Inc.;Not health related;0"Rasheed K.; Qadir J.; O'Brien T.J.; Kuhlmann L.; Razi A.";A Generative Model to Synthesize EEG Data for Epileptic Seizure Prediction;2021;Objective: Scarcity of good quality electroencephalography (EEG) data is one of the roadblocks for accurate seizure prediction. This work proposes a deep convolutional generative adversarial network (DCGAN) to generate synthetic EEG data. Another objective of our study is to use transfer-learning (TL) for evaluating the performance of four well-known deep-learning (DL) models to predict epileptic seizure. Methods: We proposed an algorithm that generate synthetic data using DCGAN trained on real EEG data in a patient-specific manner. We validate quality of generated data using one-class SVM and a new proposal namely convolutional epileptic seizure predictor (CESP). We evaluate performance of VGG16, VGG19, ResNet50, and Inceptionv3 trained on augmented data using TL with average time of 10 min between true prediction and seizure onset samples. Results: The CESP model achieves sensitivity of 78.11% and 88.21%, and false prediction rate of 0.27/h and 0.14/h for training on synthesized and testing on real Epilepsyecosystem and CHB-MIT datasets, respectively. Using TL and augmented data, Inceptionv3 achieved highest accuracy with sensitivity of 90.03% and 0.03 FPR/h. With the proposed data augmentation method prediction results of CESP model and Inceptionv3 increased by 4-5% as compared to state-of-the-art augmentation techniques. Conclusion: The performance of CESP shows that synthetic data acquired association between features and labels very well and by using the augmented data CESP predicted better than chance level for both datasets. Significance: The proposed DCGAN can be used to generate synthetic data to increase the prediction performance and to overcome good quality data scarcity issue.  © 2001-2011 IEEE.;Not health related;1"Krishnamurthy V.; Bhatt S.; Pedersen T.";Tracking Infection Diffusion in Social Networks: Filtering Algorithms and Threshold Bounds;2017;This paper deals with the statistical signal processing over graphs for tracking infection diffusion in social networks. Infection (or Information) diffusion is modeled using the susceptible-infected-susceptible (SIS) model. Mean field approximation is employed to approximate the discrete valued infection dynamics by a deterministic difference equation, thereby yielding a generative model for the infection diffusion. The infection is shown to follow polynomial dynamics and is estimated using an exact nonlinear Bayesian filter. We compute posterior Cramér-Rao bounds to obtain the fundamental limits of the filter that depend on the structure of the network. The SIS model is extended to include homophily, and filtering on these networks is illustrated. Considering the randomly evolving nature of real world networks, a filtering algorithm for estimating the underlying degree distribution is also investigated using generative models for the time evolution of the network. We validate the efficacy of the proposed models and algorithms with synthetic data and Twitter datasets. We find that the SIS model is a satisfactory fit for the information diffusion, and the nonlinear filter effectively tracks the information diffusion. © 2015 IEEE.;Not health related;0"Cheng Z.; Ligouri A.; Fogle R.; Webb T.";Capturing Human Motion in Natural Environments;2015;The problem of capturing human motion in a natural environment is discussed from the perspective of needs, significance, scenarios, and technical challenges. The technologies that can be potentially used to capture human motion and activity in a natural environment are briefly discussed with an emphasis on computer vision-based markerless motion capture technology. Three representative markerless motion capture methods for capturing human motion from video imagery are implemented in this paper. The synthetic data generated by modeling and simulation and the data collected in laboratory environments are used for the training and validation. The initial results of three methods are presented and analyzed, and the advantages and disadvantages of each are discussed and compared. © 2015;Not health related;0"Bernton E.; Jacob P.E.; Gerber M.; Robert C.P.";Approximate Bayesian computation with the Wasserstein distance;2019;A growing number of generative statistical models do not permit the numerical evaluation of their likelihood functions. Approximate Bayesian computation has become a popular approach to overcome this issue, in which one simulates synthetic data sets given parameters and compares summaries of these data sets with the corresponding observed values. We propose to avoid the use of summaries and the ensuing loss of information by instead using the Wasserstein distance between the empirical distributions of the observed and synthetic data. This generalizes the well-known approach of using order statistics within approximate Bayesian computation to arbitrary dimensions. We describe how recently developed approximations of the Wasserstein distance allow the method to scale to realistic data sizes, and we propose a new distance based on the Hilbert space filling curve. We provide a theoretical study of the method proposed, describing consistency as the threshold goes to 0 while the observations are kept fixed, and concentration properties as the number of observations grows. Various extensions to time series data are discussed. The approach is illustrated on various examples, including univariate and multivariate g-and-k distributions, a toggle switch model from systems biology, a queuing model and a Lévy-driven stochastic volatility model. © 2019 Royal Statistical Society;Not health related;0"Benedetti M.; Realpe-Gómez J.; Biswas R.; Perdomo-Ortiz A.";Quantum-assisted learning of hardware-embedded probabilistic graphical models;2017;"Mainstream machine-learning techniques such as deep learning and probabilistic programming rely heavily on sampling from generally intractable probability distributions. There is increasing interest in the potential advantages of using quantum computing technologies as sampling engines to speed up these tasks or to make them more effective. However, some pressing challenges in state-of-the-art quantum annealers have to be overcome before we can assess their actual performance. The sparse connectivity, resulting from the local interaction between quantum bits in physical hardware implementations, is considered the most severe limitation to the quality of constructing powerful generative unsupervised machine-learning models. Here, we use embedding techniques to add redundancy to data sets, allowing us to increase the modeling capacity of quantum annealers. We illustrate our findings by training hardware-embedded graphical models on a binarized data set of handwritten digits and two synthetic data sets in experiments with up to 940 quantum bits. Our model can be trained in quantum hardware without full knowledge of the effective parameters specifying the corresponding quantum Gibbs-like distribution; therefore, this approach avoids the need to infer the effective temperature at each iteration, speeding up learning; it also mitigates the effect of noise in the control parameters, making it robust to deviations from the reference Gibbs distribution. Our approach demonstrates the feasibility of using quantum annealers for implementing generative models, and it provides a suitable framework for benchmarking these quantum technologies on machine-learning-related tasks.";Not health related;0"Protopapas P.; Huijse P.; Estévez P.A.; Zegers P.; Príncipe J.C.; Marquette J.-B.";A novel, fully automated pipeline for period estimation in the eros 2 data set;2015;We present a new method to discriminate periodic from nonperiodic irregularly sampled light curves. We introduce a periodic kernel and maximize a similarity measure derived from information theory to estimate the periods and a discriminator factor. We tested the method on a data set containing 100,000 synthetic periodic and nonperiodic light curves with various periods, amplitudes, and shapes generated using a multivariate generative model. We correctly identified periodic and nonperiodic light curves with a completeness of 90% and a precision of 95%, for light curves with a signal-to-noise ratio (S/N) larger than 0.5. We characterize the efficiency and reliability of the model using these synthetic light curves and apply the method on the EROS-2 data set. A crucial consideration is the speed at which the method can be executed. Using a hierarchical search and some simplification on the parameter search, we were able to analyze 32.8 million light curves in 18 hr on a cluster of GPGPUs. Using the sensitivity analysis on the synthetic data set, we infer that 0.42% of the sources in the LMC and 0.61% of the sources in the SMC show periodic behavior. The training set, catalogs, and source code are all available at http://timemachine.iic.harvard.edu. © 2015. The American Astronomical Society. All rights reserved..;Not health related;0"Rubino R.; Marie B.; Dabre R.; Fujita A.; Utiyama M.; Sumita E.";Extremely low-resource neural machine translation for Asian languages;2020;This paper presents a set of effective approaches to handle extremely low-resource language pairs for self-attention based neural machine translation (NMT) focusing on English and four Asian languages. Starting from an initial set of parallel sentences used to train bilingual baseline models, we introduce additional monolingual corpora and data processing techniques to improve translation quality. We describe a series of best practices and empirically validate the methods through an evaluation conducted on eight translation directions, based on state-of-the-art NMT approaches such as hyper-parameter search, data augmentation with forward and backward translation in combination with tags and noise, as well as joint multilingual training. Experiments show that the commonly used default architecture of self-attention NMT models does not reach the best results, validating previous work on the importance of hyper-parameter tuning. Additionally, empirical results indicate the amount of synthetic data required to efficiently increase the parameters of the models leading to the best translation quality measured by automatic metrics. We show that the best NMT models trained on large amount of tagged back-translations outperform three other synthetic data generation approaches. Finally, comparison with statistical machine translation (SMT) indicates that extremely low-resource NMT requires a large amount of synthetic parallel data obtained with back-translation in order to close the performance gap with the preceding SMT approach. © 2021, The Author(s).;Not health related;0"Song L.; Xu Y.; Zhang L.; Du B.; Zhang Q.; Wang X.";Learning from Synthetic Images via Active Pseudo-Labeling;2020;Synthetic visual data refers to the data automatically rendered by the mature computer graphic algorithms. With the rapid development of these techniques, we can now collect photo-realistic synthetic images with accurate pixel-level annotations without much effort. However, due to the domain gaps between synthetic data and real data, in terms of not only visual appearance but also label distribution, directly applying models trained on synthetic images to real ones can hardly yield satisfactory performance. Since the collection of accurate labels for real images is very laborious and time-consuming, developing algorithms which can learn from synthetic images is of great significance. In this paper, we propose a novel framework, namely Active Pseudo-Labeling (APL), to reduce the domain gaps between synthetic images and real images. In APL framework, we first predict pseudo-labels for the unlabeled real images in the target domain by actively adapting the style of the real images to source domain. Specifically, the style of real images is adjusted via a novel task guided generative model, and then pseudo-labels are predicted for these actively adapted images. Lastly, we fine-tune the source-trained model in the pseudo-labeled target domain, which helps to fit the distribution of the real data. Experiments on both semantic segmentation and object detection tasks with several challenging benchmark data sets demonstrate the priority of our proposed method compared to the existing state-of-the-art approaches.  © 1992-2012 IEEE.;Not health related;0"Li L.; Yan J.; Wang H.; Jin Y.";Anomaly Detection of Time Series with Smoothness-Inducing Sequential Variational Auto-Encoder;2021;Deep generative models have demonstrated their effectiveness in learning latent representation and modeling complex dependencies of time series. In this article, we present a smoothness-inducing sequential variational auto-encoder (VAE) (SISVAE) model for the robust estimation and anomaly detection of multidimensional time series. Our model is based on VAE, and its backbone is fulfilled by a recurrent neural network to capture latent temporal structures of time series for both the generative model and the inference model. Specifically, our model parameterizes mean and variance for each time-stamp with flexible neural networks, resulting in a nonstationary model that can work without the assumption of constant noise as commonly made by existing Markov models. However, such flexibility may cause the model fragile to anomalies. To achieve robust density estimation which can also benefit detection tasks, we propose a smoothness-inducing prior over possible estimations. The proposed prior works as a regularizer that places penalty at nonsmooth reconstructions. Our model is learned efficiently with a novel stochastic gradient variational Bayes estimator. In particular, we study two decision criteria for anomaly detection: reconstruction probability and reconstruction error. We show the effectiveness of our model on both synthetic data sets and public real-world benchmarks.  © 2012 IEEE.;Not health related;0"Hebert L.; Ahamed T.; Costa A.C.; O’Shaughnessy L.; Stephens G.J.";WormPose: Image synthesis and convolutional networks for pose estimation in C. elegans;2021;An important model system for understanding genes, neurons and behavior, the nematode worm C. elegans naturally moves through a variety of complex postures, for which estimation from video data is challenging. We introduce an open-source Python package, WormPose, for 2D pose estimation in C. elegans, including self-occluded, coiled shapes. We leverage advances in machine vision afforded from convolutional neural networks and introduce a synthetic yet realistic generative model for images of worm posture, thus avoiding the need for human-labeled training. WormPose is effective and adaptable for imaging conditions across worm tracking efforts. We quantify pose estimation using synthetic data as well as N2 and mutant worms in on-food conditions. We further demonstrate WormPose by analyzing long (* 8 hour), fast-sampled (* 30 Hz) recordings of on-food N2 worms to provide a posture-scale analysis of roaming/dwelling behaviors. © 2021 Hebert et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.;Not health related;0"Severoglu N.; Salor O.";Statistical Models of EAF Harmonics Developed for Harmonic Estimation Directly from Waveform Samples Using Deep Learning Framework;2021;In this research work, a deep learning (DL)-based method for the fast and accurate analysis of current harmonics of electric arc furnaces (EAF) is proposed. For such a system, a large amount of EAF current data is required for the training phase of the DL-based structure, which is not only a thorny but also an expensive procedure. Hence, the second focus of this research work is to gain the ability to generate EAF currents with realistic harmonic contents based on a much smaller amount of field data of EAF currents. For this purpose, EAF current data, recorded at a transformer substation supplying an EAF plant during a tap-to-tap time of the EAF operation, are examined in terms of harmonic component amplitudes and phases. Then, a significantly larger amount of EAF current data is regenerated based on the statistics of current harmonics mimicking the real EAF behavior and this synthetic data are used to train the DL-based harmonic estimator. This estimator is able to estimate both amplitudes and phases of the harmonics without computing any time- or frequency-domain features during the estimation process. Hence, the outcomes of this research work are twofold: First, detailed analysis of the EAF current harmonic behavior is achieved, which reveals the operation principles of the EAF. Second, a DL-based harmonic estimator is trained, which is able to output the amplitude and phase estimations directly out of waveform samples without any feature extraction. The proposed system aims to serve the needs of active power filters of the EAF installations in the electricity system, since it has been shown that fast and accurate harmonic amplitude and phase estimations are obtained.  © 1972-2012 IEEE.;Not health related;0"Corneli M.; Bouveyron C.; Latouche P.";Co-Clustering of Ordinal Data via Latent Continuous Random Variables and Not Missing at Random Entries;2020;This article is about the co-clustering of ordinal data. Such data are very common on e-commerce platforms where customers rank the products/services they bought. In more detail, we focus on arrays of ordinal (possibly missing) data involving two disjoint sets of individuals/objects corresponding to the rows/columns of the arrays. Typically, an observed entry (i, j) in the array is an ordinal score assigned by the individual/row i to the object/column j. A new generative model for arrays of ordinal data is introduced along with an inference algorithm for parameters estimation. The model accounts for not missing at random data and relies on latent continuous random variables. The fitting allows to simultaneously co-cluster the rows and columns of an array. The estimation of the model parameters is performed via a classification expectation maximization algorithm. A model selection criterion is formally obtained to select the number of row and column clusters. To show that our approach reaches and often outperforms the state of the art, we carry out numerical experiments on synthetic data. Finally, applications on real datasets highlight the model capacity to deal with very sparse arrays. Supplementary materials for this article are available online. © 2020 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.;Not health related;0"Rodrigues J.; Andrade A.";Synthetic neuronal datasets for benchmarking directed functional connectivity metrics;2015;Background. Datasets consisting of synthetic neural data generated with quantifiable and controlled parameters are a valuable asset in the process of testing and validating directed functional connectivity metrics. Considering the recent debate in the neuroimaging community concerning the use of these metrics for fMRI data, synthetic datasets that emulate the BOLD signal dynamics have played a central role by supporting claims that argue in favor or against certain choices. Generative models often used in studies that simulate neuronal activity, with the aim of gaining insight into specific brain regions and functions, have different requirements fromthe generative models for benchmarking datasets. Even though the lattermust be realistic, there is a tradeoff between realism and computational demand that needs to be contemplated and simulations that efficiently mimic the real behavior of single neurons or neuronal populations are preferred, instead of more cumbersome and marginally precise ones. Methods. This work explores how simple generative models are able to produce neuronal datasets, for benchmarking purposes, that reflect the simulated effective connectivity and, how these can be used to obtain synthetic recordings of EEG and fMRI BOLD signals. The generative models covered here are AR processes, neural mass models consisting of linear and nonlinear stochastic differential equations and populations with thousands of spiking units. Forward models for EEG consist in the simple three-shell head model while the fMRI BOLD signal is modeled with the Balloon-Windkessel model or by convolution with a hemodynamic response function. Results. The simulated datasets are tested for causality with the original spectral formulation for Granger causality.Modeled effective connectivity can be detected in the generated data for varying connection strengths and interaction delays. Discussion. All generative models produce synthetic neuronal data with detectable causal effects although the relation between modeled and detected causality varies and less biophysically realistic models offer more control in causal relations such as modeled strength and frequency location. © 2015 Rodrigues and Andrade.;Not health related;1"Nyczka P.; Hütt M.-T.";Generative network model of transcriptome patterns in disease cohorts with tunable signal strength;2020;Algorithmic methods for interpreting the collective transcriptome (gene expression) patterns of disease cohorts in the context of biological networks are a cornerstone of systems medicine. The calibration of these algorithms using synthetic data with predefined statistical properties can be a relevant benchmarking procedure, facilitating the choice of the appropriate algorithm and the detailed mechanistic interpretation of the results. Here we present a generative model producing patterns of significantly up- A nd down-regulated genes for synthetic disease cohorts, in which the statistical agreement between the given biological network and the transcriptome patterns can be tuned. Parameters of this generative model are, among others, the size of the cohort, the number of disease-associated genes, the clustering of differentially expressed genes in the network and the network size. Several properties of the model can be analyzed analytically. In a first application of this generative model to produce test instances, we show that considering the subset of significant expression changes occurring in more than one patient of the cohort as an additional filtering step serves as an efficient noise suppression mechanism to enhance the recall of the signal contained in the data by the network connectivity. © 2020 authors.;Health related;1"Goncalves A.; Ray P.; Soper B.; Stevens J.; Coyle L.; Sales A.P.";Generation and evaluation of synthetic patient data;2020;"Background: Machine learning (ML) has made a significant impact in medicine and cancer research; however, its impact in these areas has been undeniably slower and more limited than in other application domains. A major reason for this has been the lack of availability of patient data to the broader ML research community, in large part due to patient privacy protection concerns. High-quality, realistic, synthetic datasets can be leveraged to accelerate methodological developments in medicine. By and large, medical data is high dimensional and often categorical. These characteristics pose multiple modeling challenges. Methods: In this paper, we evaluate three classes of synthetic data generation approaches; probabilistic models, classification-based imputation models, and generative adversarial neural networks. Metrics for evaluating the quality of the generated synthetic datasets are presented and discussed. Results: While the results and discussions are broadly applicable to medical data, for demonstration purposes we generate synthetic datasets for cancer based on the publicly available cancer registry data from the Surveillance Epidemiology and End Results (SEER) program. Specifically, our cohort consists of breast, respiratory, and non-solid cancer cases diagnosed between 2010 and 2015, which includes over 360,000 individual cases. Conclusions: We discuss the trade-offs of the different methods and metrics, providing guidance on considerations for the generation and usage of medical synthetic data. © 2020 The Author(s).";Health related;1"Xiao Q.; Qin M.; Yin Y.";Skeleton-based Chinese sign language recognition and generation for bidirectional communication between deaf and hearing people;2020;Chinese sign language (CSL) is one of the most widely used sign language systems in the world. As such, the automatic recognition and generation of CSL is a key technology enabling bidirectional communication between deaf and hearing people. Most previous studies have focused solely on sign language recognition (SLR), which only addresses communication in a single direction. As such, there is a need for sign language generation (SLG) to enable communication in the other direction (i.e., from hearing people to deaf people). To achieve a smoother exchange of ideas between these two groups, we propose a skeleton-based CSL recognition and generation framework based on a recurrent neural network (RNN), to support bidirectional CSL communication. This process can also be extended to other sequence-to-sequence information interactions. The core of the proposed framework is a two-level probability generative model. Compared with previous techniques, this approach offers a more flexible approximate posterior distribution, which can produce skeletal sequences of varying styles that are recognizable to humans. In addition, the proposed generation method compensated for a lack of training data. A series of experiments in bidirectional communication were conducted on the large 500 CSL dataset. The proposed algorithm achieved high recognition accuracy for both real and synthetic data, with a reduced runtime. Furthermore, the generated data improved the performance of the discriminator. These results suggest the proposed bidirectional communication framework and generation algorithm to be an effective new approach to CSL recognition. © 2020 Elsevier Ltd;Not health related;0"De Bacco C.; Power E.A.; Larremore D.B.; Moore C.";Community detection, link prediction, and layer interdependence in multilayer networks;2017;Complex systems are often characterized by distinct types of interactions between the same entities. These can be described as a multilayer network where each layer represents one type of interaction. These layers may be interdependent in complicated ways, revealing different kinds of structure in the network. In this work we present a generative model, and an efficient expectation-maximization algorithm, which allows us to perform inference tasks such as community detection and link prediction in this setting. Our model assumes overlapping communities that are common between the layers, while allowing these communities to affect each layer in a different way, including arbitrary mixtures of assortative, disassortative, or directed structure. It also gives us a mathematically principled way to define the interdependence between layers, by measuring how much information about one layer helps us predict links in another layer. In particular, this allows us to bundle layers together to compress redundant information and identify small groups of layers which suffice to predict the remaining layers accurately. We illustrate these findings by analyzing synthetic data and two real multilayer networks, one representing social support relationships among villagers in South India and the other representing shared genetic substring material between genes of the malaria parasite. © 2017 American Physical Society.;Not health related;0"Song W.; Dong W.; Kang L.";Group anomaly detection based on Bayesian framework with genetic algorithm;2020;Anomaly detection is an important application field of evolutionary algorithm. Unlike traditionly anomaly detection, group anomaly detection aims to discover the anomalous aggregate behaviors in data points. Over past decades, a large number of promising methods have been successfully applied for group anomaly detection. However, they inherently neglect the correlations among groups in data points, limiting their abilities. This paper presents a correlated hierarchical generative model, which can model the intricate correlations hidden in groups by introducing a logistic normal distribution to capture the correlations among groups. With the proposed model, we construct a full variational Bayesian framework, which can data-adaptively optimize the model parameters of the proposed model. The model is designed and trained using Genetic Algorithm (GA), which helps automating the use of generative model. Further, a new score function is proposed as an anomaly criterion to estimate final anomaly groups in data points. Several experiments on synthetic data and real astronomical star data from Sloan Digital Sky Survey demonstrate the effectiveness of proposed method compared with the-state-of-art methods, in terms of average accurac (AP) and area under the Receiver Operating Characteristic(ROC) curve(AUC). © 2020;Not health related;0"Alain G.; Bengio Y.; Yao L.; Yosinski J.; Thibodeau-Laufer É.; Zhang S.; Vincent P.";GSNs: Generative stochastic networks;2016;"We introduce a novel training principle for generative probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSNs) framework generalizes Denoising Auto-Encoders (DAEs), and is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution is a conditional distribution that generally involves a small move, so it has fewer dominant modes and is unimodal in the limit of small moves. This simplifies the learning problem, making it less like density estimation and more akin to supervised function approximation, with gradients that can be obtained by backprop. The theorems provided here provide a probabilistic interpretation for DAEs and generalize them; seen in the context of this framework, auto-encoders that learn with injected noise are a special case of GSNs and can be interpreted as generative models. The theorems also provide an interesting justification for dependency networks and generalized pseudolikelihood, and define an appropriate joint distribution and sampling mechanism, even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the others. Experiments validating these theoretical results are conducted on both synthetic datasets and image datasets. The experiments employ a particular architecture that mimics the Deep Boltzmann Machine Gibbs sampler, but that allows training to proceed with backprop through a recurrent neural network with noise injected inside and without the need for layerwise pretraining. © The authors 2016.";Not health related;0"Shaikh S.; Daudpota S.M.; Imran A.S.; Kastrati Z.";Towards improved classification accuracy on highly imbalanced text dataset using deep neural language models;2021;Data imbalance is a frequently occurring problem in classification tasks where the number of samples in one category exceeds the amount in others. Quite often, the minority class data is of great importance representing concepts of interest and is often challenging to obtain in real-life scenarios and applications. Imagine a customers’ dataset for bank loans-majority of the instances belong to non-defaulter class, only a small number of customers would be labeled as defaulters, however, the performance accuracy is more important on defaulters labels than non-defaulter in such highly imbalance datasets. Lack of enough data samples across all the class labels results in data imbalance causing poor classification performance while training the model. Synthetic data generation and oversampling techniques such as SMOTE, AdaSyn can address this issue for statistical data, yet such methods suffer from overfitting and substantial noise. While such techniques have proved useful for synthetic numerical and image data generation using GANs, the effectiveness of approaches proposed for textual data, which can retain grammatical structure, context, and semantic information, has yet to be evaluated. In this paper, we address this issue by assessing text sequence generation algorithms coupled with grammatical validation on domain-specific highly imbalanced datasets for text classification. We exploit recently proposed GPT-2 and LSTM-based text generation models to introduce balance in highly imbalanced text datasets. The experiments presented in this paper on three highly imbalanced datasets from different domains show that the performance of same deep neural network models improve up to 17% when datasets are balanced using generated text. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Not health related;0"Wang Y.; Deng W.";Generative Model with Coordinate Metric Learning for Object Recognition Based on 3D Models;2018;One of the bottlenecks in acquiring a perfect database for deep learning is the tedious process of collecting and labeling data. In this paper, we propose a generative model trained with synthetic images rendered from 3D models which can reduce the burden on collecting real training data and make the background conditions more realistic. Our architecture is composed of two sub-networks: a semantic foreground object reconstruction network based on Bayesian inference and a classification network based on multi-triplet cost training for avoiding overfitting on the monotone synthetic object surface and utilizing accurate information of synthetic images like object poses and lighting conditions which are helpful for recognizing regular photos. First, our generative model with metric learning utilizes additional foreground object channels generated from semantic foreground object reconstruction sub-network for recognizing the original input images. Multi-triplet cost function based on poses is used for metric learning which makes it possible to train an effective categorical classifier purely based on synthetic data. Second, we design a coordinate training strategy with the help of adaptive noise applied on the inputs of both of the concatenated sub-networks to make them benefit from each other and avoid inharmonious parameter tuning due to different convergence speeds of two sub-networks. Our architecture achieves the state-of-the-art accuracy of 50.5% on the ShapeNet database with data migration obstacle from synthetic images to real images. This pipeline makes it applicable to do recognition on real images only based on 3D models. Our codes are available at https://github.com/wangyida/gm-cml. © 1992-2012 IEEE.;Not health related;0"Vaz De Melo P.O.S.; Faloutsos C.; Assunçaõ R.; Alves R.; Loureiro A.A.F.";Universal and distinct properties of communication dynamics: How to generate realistic inter-event times;2015;With the advancement of information systems, means of communications are becoming cheaper, faster, and more available. Today, millions of people carrying smartphones or tablets are able to communicate practically any time and anywhere they want. They can access their e-mails, comment on weblogs, watch and post videos and photos (as well as comment on them), and make phone calls or text messages almost ubiquitously. Given this scenario, in this article, we tackle a fundamental aspect of this new era of communication: How the time intervals between communication events behave for different technologies and means of communications. Are there universal patterns for the Inter-Event Time Distribution (IED)? How do inter-event times behave differently among particular technologies? To answer these questions, we analyzed eight different datasets from real andmodern communication data and found four well-defined patterns seen in all the eight datasets. Moreover, we propose the use of the Self-Feeding Process (SFP) to generate inter-event times between communications. The SFP is an extremely parsimonious point process that requires at most two parameters and is able to generate inter-event times with all the universal properties we observed in the data. We also show three potential applications of the SFP: as a framework to generate a synthetic dataset containing realistic communication events of any one of the analyzed means of communications, as a technique to detect anomalies, and as a building block for more specific models that aim to encompass the particularities seen in each of the analyzed systems.;Not health related;0"Ding G.; Zhang S.; Khan S.; Tang Z.; Zhang J.; Porikli F.";Feature Affinity-Based Pseudo Labeling for Semi-Supervised Person Re-Identification;2019;Vision-based person re-identification aims to match a person's identity across multiple images, which is a fundamental task in multimedia content analysis and retrieval. Deep neural networks have recently manifested great potential in this task. However, a major bottleneck of existing supervised deep networks is their reliance on a large amount of annotated training data. Manual labeling for person identities in large-scale surveillance camera systems is quite challenging and incurs significant costs. Some recent studies adopt generative model outputs as training data augmentation. To more effectively use these synthetic data for an improved feature learning and re-identification performance, this paper proposes a novel feature affinity-based pseudo labeling method with two possible label encodings. To the best of our knowledge, this is the first study that employs pseudo-labeling by measuring the affinity of unlabeled samples with the underlying clusters of labeled data samples using the intermediate feature representations from deep networks. We propose training the network with the joint supervision of cross-entropy loss together with a center regularization term, which not only ensures discriminative feature representation learning but also simultaneously predicts pseudo-labels for unlabeled data. We show that both label encodings can be learned in a unified manner and help improve the overall performance. Our extensive experiments on three person re-identification datasets: Market-1501, DukeMTMC-reID, and CUHK03, demonstrate significant performance boost over the state-of-the-art person re-identification approaches. © 1999-2012 IEEE.;Not health related;0"Li C.; Cheung W.K.; Ye Y.; Zhang X.; Chu D.; Li X.";The Author-Topic-Community model for author interest profiling and community discovery;2015;In this paper, we propose a generative model named the author-topic-community (ATC) model for representing a corpus of linked documents. The ATC model allows each author to be associated with a topic distribution and a community distribution as its model parameters. A learning algorithm based on variational inference is derived for the model parameter estimation where the two distributions are essentially reinforcing each other during the estimation. We compare the performance of the ATC model with two related generative models using first synthetic data sets and then real data sets, which include a research community data set, a blog data set, a news-sharing data set, and a microblogging data set. The empirical results obtained confirm that the proposed ATC model outperforms the existing models for tasks such as author interest profiling and author community discovery. We also demonstrate how the inferred ATC model can be used to characterize the roles of users/authors in online communities. © 2014, Springer-Verlag London.;Not health related;0"Hernandez-Matamoros A.; Fujita H.; Perez-Meana H.";A novel approach to create synthetic biomedical signals using BiRNN;2020;"Human health is threatened by several diseases for this reason automated medical diagnosis systems has been developed several years ago. These systems need databases, the creation of these databases is tedious, arduous and stops being done so the created database is incomplete or unbalanced. Sometimes the databases are private to protect the private information of the patients, among other problems. For this reason, the researchers have started to use synthetic data. The synthetic data have been applied by different hospitals in the USA. The creation of synthetic data has different problems like the synthetic data are generated using rules defined by the user, the proposed approaches only can create one kind of data, the proposals require input from domain experts, among others. To address these kinds of problems, we propose a novel approach, which consists of the Bidirectional Recurrent Neural Network and the statistical stage to generate synthetic biomedical signals. The approach is able to create 5 kinds of biomedical signals (ECG, EEG, BCG, PPG, and Respiratory Impedance). Our approach is able to create synthetic data for patients or for specific events. The performance of our approach is compared with other generative models (GAN's) through evaluation metrics. The created synthetic data are used to construct models; these models are able to successfully differentiate between different signals with high accuracies. © 2020 Elsevier Inc.";Health related;1"Catrambone V.; Greco A.; Vanello N.; Scilingo E.P.; Valenza G.";Time-Resolved Directional Brain–Heart Interplay Measurement Through Synthetic Data Generation Models;2019;Although a plethora of synthetic data generation models have been proposed to validate biomarkers of brain and cardiovascular dynamics separately, a limited number of computational methods estimating directed brain–heart information flow are currently available in the scientific literature. This study introduces a computational framework exploiting existing generative models for a novel time-resolved quantification of causal brain–heart interplay. Exemplarily, having electroencephalographic signals and heart rate variability series as inputs, respective synthetic data models are coupled through parametrised functions defined in accordance with current central autonomic network (CAN) knowledge. We validate this concept using data from 30 healthy volunteers undergoing notable sympathetic elicitation through a cold-pressor test, and further compare the obtained results with a state-of-the-art method as maximal information coefficient. Although our findings are in agreement with previous CAN findings, we report new insights into the role of fronto-parietal region activity and lateralisation mechanisms over the temporal cortices during prolonged peripheral elicitation, which occur with specific time delays. Additionally, the afferent autonomic outflow maps to brain oscillations in the _ and _ bands, whereas complementary cortical dynamics in the _, _, and _ bands act on efferent autonomic control. The proposed framework paves the way towards novel biomarker definitions for the assessment of complex physiological networks using existing data generation models for brain and peripheral dynamics. © 2019, Biomedical Engineering Society.;Health related;1"Svensson C.-M.; Bondoc K.G.; Pohnert G.; Figge M.T.";Segmentation of clusters by template rotation expectation maximization;2017;To solve the task of segmenting clusters of nearly identical objects we here present the template rotation expectation maximization (TREM) approach which is based on a generative model. We explore both a general purpose optimization approach for maximizing the log-likelihood and a modification of the standard expectation maximization (EM) algorithm. The general purpose approach is strict template matching, while TREM allows for a more deformable model. As benchmarking we compare TREM with standard EM for a two dimensional Gaussian mixture model (GMM) as well as direct maximization of the log-likelihood using general purpose optimization. We find that the EM based algorithms, TREM and standard GMM, are faster than the general purpose optimizer algorithms without any loss of segmentation accuracy. When applying TREM and GMM to a synthetic data set consisting of pairs of almost parallel objects we find that the TREM is better at segmenting those than an unconstrained GMM. Finally we demonstrate that this advantage for TREM over GMM gives significant improvement in segmentation of microscopy images of the motile unicellular alga Seminavis robusta. © 2016 Elsevier Inc.;Not health related;0"Tan Z.; Song Y.; Ou Z.";Calibrated adversarial algorithms for generative modelling;2019;Generative adversarial networks are useful for unsupervised learning but may be difficult to train. We study a class of adversarial algorithms based on f-divergence minimization and provide an extension by allowing two objective functions instead of one to be chosen (hence calibrated) for updating the discriminator and the generator, respectively. The extension is derived and justified from theoretical analysis, which identifies specific objective functions for achieving stable gradients in the corresponding updates. Our experiments on synthetic data and MNIST and CIFAR-10 datasets demonstrate that the proposed method consistently achieves competitive or superior results when compared with various existing methods. © 2019 John Wiley & Sons, Ltd.;Not health related;0"Zhang L.; Zhao J.; Ye X.; Chen Y.";Cooperation: A new force for boosting generative adversarial nets with dual-network structure;2020;The principle of generative adversarial net is to fit the given data distribution by combining a generative model and discriminative model. There are two major challenges to conventional systems - they are difficult to train and they easily fall into 'mode collapse'. To improve it, this study describes a novel network structure with dual generators. A 'cooperation' mechanism is introduced to help the generators work together. During training, generators not only learn from discriminative feedback but also from each other (like a study group). Compared with a single-generator network, a dual-generator network could capture many more 'modes' and eventually reduce the impact of 'mode collapse.' Dual networks also require extra computational resources. However, our experiment shows that even with network parameters of similar size, dual networks still achieved better results. Additionally, a dual-generator structure could be extended to multiple generators. The proposed network structure is also very robust and flexible. It can be adapted to various application scenarios, such as high-resolution image generation, domain adaptation and 3D model generation. The experimental results showed that with the same computing resources, multiple generators can generate better quality synthetic data, including 2D images, 3D objects, style transferring etc. © The Institution of Engineering and Technology 2019;Not health related;0"Wingate D.; Kane J.; Wolinsky M.; Sylvester Z.";A New Approach for Conditioning Process-Based Geologic Models to Well Data;2016;Generating a realistic earth model that simultaneously fits data observed at multiple well locations has been a long-standing problem in petroleum geology. Two insights are offered for solving this problem in a Bayesian framework. The first is conceptual—it connects geologic inversion to the new field of probabilistic programming and shows that the usual description of a Bayesian problem in terms of a graphical model is inadequate for describing a process-based geologic model due to the dynamics of the generative algorithm. This is a paradigm shift in probabilistic modeling where stochastic generative models are represented using a syntax resembling modern programming languages. Probabilistic programming allows one to generalize this structure to include complex programming concepts, while also simplifying the process of developing new inference algorithms. The second insight is algorithmic and involves using variational inference to derive a simpler, more computationally tractable approximation to the posterior probability density function. If this surrogate distribution is close to the true posterior, it allows for very fast simulation of an arbitrary number of models that all fit the data equally well. This study focuses on the particular geologic formation known as submarine lobes: elongated pancake-like formations which are sequentially laid down, one on top of the other over geologic time, forming potential petroleum reservoirs. The location and orientation of the lobes at each time step are the variables that are optimized so that, at the final time step, all available well data are approximately fit. The methodology is illustrated on synthetic data as a proof-of-concept, and compared to several alternatives. An important conclusion is that, even though the variational approximation is crude, it produces better predictions than any point-based method, including maximum likelihood. The fact that probabilistic programming outperforms conventional Bayesian approaches in the case of lobe models offers the potential for attacking more complicated forward models where multiple geologic processes are simultaneously active. © 2015, International Association for Mathematical Geosciences.;Not health related;0"Livezey J.A.; Bujan A.F.; Sommer F.T.";Learning overcomplete, low coherence dictionaries with linear inference;2019;Finding overcomplete latent representations of data has applications in data analysis, signal processing, machine learning, theoretical neuroscience and many other fields. In an overcomplete representation, the number of latent features exceeds the data dimensionality, which is useful when the data is undersampled by the measurements (compressed sensing or information bottlenecks in neural systems) or composed from multiple complete sets of linear features, each spanning the data space. Independent Components Analysis (ICA) is a linear technique for learning sparse latent representations, which typically has a lower computational cost than sparse coding, a linear generative model which requires an iterative, nonlinear inference step. While well suited for finding complete representations, we show that overcompleteness poses a challenge to existing ICA algorithms. Specifically, the coherence control used in existing ICA and other dictionary learning algorithms, necessary to prevent the formation of duplicate dictionary features, is ill-suited in the overcomplete case. We show that in the overcomplete case, several existing ICA algorithms have undesirable global minima that maximize coherence. We provide a theoretical explanation of these failures and, based on the theory, propose improved coherence control costs for overcomplete ICA algorithms. Further, by comparing ICA algorithms to the computationally more expensive sparse coding on synthetic data, we show that the limited applicability of overcomplete, linear inference can be extended with the proposed cost functions. Finally, when trained on natural images, we show that the coherence control biases the exploration of the data manifold, sometimes yielding suboptimal, coherent solutions. All told, this study contributes new insights into and methods for coherence control for linear ICA, some of which are applicable to many other nonlinear models. ©c 2019 Jesse A. Livezey, Alejandro F. Bujan, Friedrich T. Sommer.;Not health related;0"Simões L.D.; Costa H.J.D.; Aires M.N.O.; Medeiros R.P.; Costa F.B.; Bretas A.S.";A power transformer differential protection based onsupport vector machine and wavelet transform;2021;This paper presents a power transformer differential protection scheme based on support vector machines (SVM) combined with high-frequency features extracted with the real-time boundary stationary wavelet transform (RT-BSWT). SVM models are derived with synthetic data, considering a wide variety of events, such as inter-turn faults, external faults during CT saturation, and evolving external-to-internal faults. A comparative performance assessment is carried out considering accuracy and other reliability indices, as well as operating time, and good results were achieved. The simplicity of the presented SVM-based relay, without hard-to-derive parameters, built on the classical differential protection framework, highlights potential aspects towards real-life implementation. © 2021;Not health related;0"Maya P.; Dhivya N.; Kartikga C.; Soman K.P.";Discrimination between inrush and internal fault currents in a power transformer using Variational Mode Decomposition Method;2015;Transformers, which are critical and expensive components of a power system, require suitable measures for their protection to ensure reliable operation. Identification between in rush current and internal fault current is important in the design of transformer protection relay. Often nuisance tripping of protection relay occurs when inrush current flows in the system. Identification methods based on higher second harmonic content present in inrush current has limitations in its application. This work investigates the scope of classification method based on Variation Mode Decomposition (VMD) and Support Vector Machine (SVM) in distinguishing internal fault current and inrush current in a power transformer. Validation of this method is done using synthetic data from MATLAB/SIMULINK. Choice of various kernel functions for SVM for better accuracy is also investigated. © Research India Publications.;Not health related;0"Lavda F.; Gregorová M.; Kalousis A.";Data-Dependent conditional priors for unsupervised learning of multimodal data;2020;One of the major shortcomings of variational autoencoders is the inability to produce generations from the individual modalities of data originating from mixture distributions. This is primarily due to the use of a simple isotropic Gaussian as the prior for the latent code in the ancestral sampling procedure for data generations. In this paper, we propose a novel formulation of variational autoencoders, conditional prior VAE (CP-VAE), with a two-level generative process for the observed data where continuous z and a discrete c variables are introduced in addition to the observed variables x. By learning data-dependent conditional priors, the new variational objective naturally encourages a better match between the posterior and prior conditionals, and the learning of the latent categories encoding the major source of variation of the original data in an unsupervised manner. Through sampling continuous latent code from the data-dependent conditional priors, we are able to generate new samples from the individual mixture components corresponding, to the multimodal structure over the original data. Moreover, we unify and analyse our objective under different independence assumptions for the joint distribution of the continuous and discrete latent variables. We provide an empirical evaluation on one synthetic dataset and three image datasets, FashionMNIST, MNIST, and Omniglot, illustrating the generative performance of our new model comparing to multiple baselines. © 2020 by the authors.;Not health related;0"de Souza C.R.; Gaidon A.; Cabon Y.; Murray N.; López A.M.";Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models;2020;Deep video action recognition models have been highly successful in recent years but require large quantities of manually-annotated data, which are expensive and laborious to obtain. In this work, we investigate the generation of synthetic training data for video action recognition, as synthetic data have been successfully used to supervise models for a variety of other computer vision tasks. We propose an interpretable parametric generative model of human action videos that relies on procedural generation, physics models and other components of modern game engines. With this model we generate a diverse, realistic, and physically plausible dataset of human action videos, called PHAV for “Procedural Human Action Videos”. PHAV contains a total of 39,982 videos, with more than 1000 examples for each of 35 action categories. Our video generation approach is not limited to existing motion capture sequences: 14 of these 35 categories are procedurally-defined synthetic actions. In addition, each video is represented with 6 different data modalities, including RGB, optical flow and pixel-level semantic labels. These modalities are generated almost simultaneously using the Multiple Render Targets feature of modern GPUs. In order to leverage PHAV, we introduce a deep multi-task (i.e. that considers action classes from multiple datasets) representation learning architecture that is able to simultaneously learn from synthetic and real video datasets, even when their action categories differ. Our experiments on the UCF-101 and HMDB-51 benchmarks suggest that combining our large set of synthetic videos with small real-world datasets can boost recognition performance. Our approach also significantly outperforms video representations produced by fine-tuning state-of-the-art unsupervised generative models of videos. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.;Not health related;0"Taniguchi T.; Nagasaka S.; Nakashima R.";Nonparametric Bayesian double articulation analyzer for direct language acquisition from continuous speech signals;2016;"Human infants can discover words directly from unsegmented speech signals without any explicitly labeled data. Current machine learning methods cannot efficiently estimate language model (LM) and acoustic model (AM) and discover words directly from continuous human speech signals in an unsupervised manner. To solve this problem, we propose an integrative generative model that combines an LM and an AM into a single generative model called the hierarchical Dirichlet process hidden LM (HDP-HLM). The HDP-HLM is obtained by extending the hierarchical Dirichlet process hidden semi-Markov model (HDP-HSMM) proposed by Johnson et al. An inference procedure for the HDP-HLM is derived using the blocked Gibbs sampler originally proposed for the HDP-HSMM. This procedure enables the simultaneous and direct inference of LM and AM from continuous speech signals. Based on the HDP-HLM and its inference procedure, we develop a novel machine learning method called nonparametric Bayesian double articulation analyzer (NPB-DAA) that can directly acquire LM and AM from observed continuous speech signals. By assuming HDP-HLM as a generative model of observed time series data, and by inferring latent variables of the model, the method can analyze latent double articulation structure, i.e., hierarchically organized latent words and phonemes, of the data in an unsupervised manner. We also carried out two evaluation experiments using synthetic data and actual human continuous speech signals representing Japanese vowel sequences. In the word acquisition and phoneme categorization tasks, the NPB-DAA outperformed a conventional double articulation analyzer and baseline automatic speech recognition system whose AM was trained in a supervised manner. The main contributions of this paper are as follows: 1) we develop a probabilistic generative model that integrates LM and AM, i.e., HDP-HLM; 2) we derive an inference method for this, and propose the NPB-DAA; and 3) we show that the NPB-DAA can discover words directly from continuous human speech signals in an unsupervised manner. ©2016 IEEE.";Not health related;0"Yu X.; Creamer M.S.; Randi F.; Sharma A.K.; Linderman S.W.; Leifer A.M.";Wfast deep neural correspondence for tracking and identifying neurons in c. Elegans using semi-synthetic training;2021;We present an automated method to track and identify neurons in C. elegans, called “fast Deep Neural Correspondence” or fDNC, based on the transformer network architecture. The model is trained once on empirically derived semi-synthetic data and then predicts neural correspondence across held-out real animals. The same pre-trained model both tracks neurons across time and identifies corresponding neurons across individuals. Performance is evaluated against hand-annotated datasets, including NeuroPAL [1]. Using only position information, the method achieves 79.1% accuracy at tracking neurons within an individual and 64.1% accuracy at identifying neurons across individuals. Accuracy at identifying neurons across individuals is even higher (78.2%) when the model is applied to a dataset published by another group [2]. Accuracy reaches 74.7% on our dataset when using color information from NeuroPAL. Unlike previous methods, fDNC does not require straightening or transforming the animal into a canonical coordinate system. The method is fast and predicts correspondence in 10 ms making it suitable for future real-time applications. © 2021, eLife Sciences Publications Ltd. All rights reserved.;Not health related;0"Sanchez G.; Lecaignard F.; Otman A.; Maby E.; Mattout J.";Active sampling protocol (ASAP) to optimize individual neurocognitive hypothesis testing: A BCI-inspired dynamic experimental design;2016;The relatively young field of Brain-Computer Interfaces has promoted the use of electrophysiology and neuroimaging in real-time. In the meantime, cognitive neuroscience studies, which make extensive use of functional exploration techniques, have evolved toward model-based experiments and fine hypothesis testing protocols. Although these two developments are mostly unrelated, we argue that, brought together, they may trigger an important shift in the way experimental paradigms are being designed, which should prove fruitful to both endeavors. This change simply consists in using real-time neuroimaging in order to optimize advanced neurocognitive hypothesis testing.We refer to this new approach as the instantiation of an Active SAmpling Protocol (ASAP). As opposed to classical (static) experimental protocols, ASAP implements online model comparison, enabling the optimization of design parameters (e.g., stimuli) during the course of data acquisition. This follows the well-known principle of sequential hypothesis testing. What is radically new, however, is our ability to perform online processing of the huge amount of complex data that brain imaging techniques provide. This is all the more relevant at a time when physiological and psychological processes are beginning to be approached using more realistic, generative models which may be difficult to tease apart empirically. Based upon Bayesian inference, ASAP proposes a generic and principled way to optimize experimental design adaptively. In this perspective paper, we summarize the main steps in ASAP. Using synthetic data we illustrate its superiority in selecting the right perceptual model compared to a classical design. Finally, we briefly discuss its future potential for basic and clinical neuroscience as well as some remaining challenges. © 2016 Sanchez, Lecaignard, Otman, Maby and Mattout.;Health related;0"Dankar F.K.; Ibrahim M.";Fake it till you make it: Guidelines for effective synthetic data generation;2021;Synthetic data provides a privacy protecting mechanism for the broad usage and sharing of healthcare data for secondary purposes. It is considered a safe approach for the sharing of sensitive data as it generates an artificial dataset that contains no identifiable information. Synthetic data is increasing in popularity with multiple synthetic data generators developed in the past decade, yet its utility is still a subject of research. This paper is concerned with evaluating the effect of various synthetic data generation and usage settings on the utility of the generated synthetic data and its derived models. Specifically, we investigate (i) the effect of data pre-processing on the utility of the synthetic data generated, (ii) whether tuning should be applied to the synthetic datasets when generating supervised machine learning models, and (iii) whether sharing preliminary machine learning results can improve the synthetic data models. Lastly, (iv) we investigate whether one utility measure (Propensity score) can predict the accuracy of the machine learning models generated from the synthetic data when employed in real life. We use two popular measures of synthetic data utility, propensity score and classification accuracy, to compare the different settings. We adopt a recent mechanism for the calculation of propensity, which looks carefully into the choice of model for the propensity score calculation. Accordingly, this paper takes a new direction with investigat-ing the effect of various data generation and usage settings on the quality of the generated data and its ensuing models. The goal is to inform on the best strategies to follow when generating and using synthetic data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.;Health related;1"Lopez-Martin M.; Carro B.; Sanchez-Esguevillas A.";Variational data generative model for intrusion detection;2019;A Network Intrusion Detection System is a system which detects intrusive, malicious activities or policy violations in a host or hosts network. The ability to access balanced and diversified data to train the system is very important for any detection system. Intrusion data rarely have these characteristics, since samples of network traffic are strongly biased to normal traffic, being difficult to access traffic associated with intrusion events. Therefore, it is important to have a method to synthesize intrusion data with a probabilistic and behavioral structure similar to the original one. In this work, we provide such a method. Intrusion data have continuous and categorical features, with a strongly unbalanced distribution of intrusion labels. That is the reason why we generate synthetic samples conditioned to the distribution of labels. That is, from a particular set of labels, we generate training samples associated with that set of labels, replicating the probabilistic structure of the original data that comes from those labels. We use a generative model based on a customized variational autoencoder, using the labels of the intrusion class as an additional input to the network. This modification provides an advantage, as we can readily generate new data using only the labels, without having to rely on training samples as canonical representatives for each label, which makes the generation process more reliable, less complex and faster. We show that the synthetic data are similar to the real data, and that the new synthesized data can be used to improve the performance scores of common machine learning classifiers. © 2018, Springer-Verlag London Ltd., part of Springer Nature.;Not health related;0"Chan M.H.; Noor M.H.M.";A unified generative model using generative adversarial network for activity recognition;2021;The recent advancement of deep learning methods has seen a significant increase in recognition accuracy in many important applications such as human activity recognition. However, deep learning methods require a vast amount of sensor data to automatically extract the most salient features for activity classification. Therefore, in this paper, a unified generative model is proposed to generate verisimilar data of different activities for activity recognition. The proposed generative model not only able to generate data that have a similar pattern, but also data with diverse characteristics. This allows for data augmentation in activity classification to improve the overall recognition accuracy. Three similarity measures are proposed to assess the quality of the synthetic data in addition to two visual evaluation methods. The proposed generative model was evaluated on a public dataset. The training data was prepared by systematically varying the combination of original and synthetic data. Results have shown that classification using the hybrid training data achieved a comparable recognition accuracy with the classification using the original training data. The performance of the classifiers maintained at the recognition accuracy of 85%. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Emam K.E.; Mosquera L.; Bass J.";Evaluating identity disclosure risk in fully synthetic health data: model development and validation;2020;"Background: There has been growing interest in data synthesis for enabling the sharing of data for secondary analysis; however, there is a need for a comprehensive privacy risk model for fully synthetic data: If the generative models have been overfit, then it is possible to identify individuals from synthetic data and learn something new about them. Objective: The purpose of this study is to develop and apply a methodology for evaluating the identity disclosure risks of fully synthetic data. Methods: A full risk model is presented, which evaluates both identity disclosure and the ability of an adversary to learn something new if there is a match between a synthetic record and a real person. We term this “meaningful identity disclosure risk.” The model is applied on samples from the Washington State Hospital discharge database (2007) and the Canadian COVID-19 cases database. Both of these datasets were synthesized using a sequential decision tree process commonly used to synthesize health and social science data. Results: The meaningful identity disclosure risk for both of these synthesized samples was below the commonly used 0.09 risk threshold (0.0198 and 0.0086, respectively), and 4 times and 5 times lower than the risk values for the original datasets, respectively. Conclusions: We have presented a comprehensive identity disclosure risk model for fully synthetic data. The results for this synthesis method on 2 datasets demonstrate that synthesis can reduce meaningful identity disclosure risks considerably. The risk model can be applied in the future to evaluate the privacy of fully synthetic data. ©Khaled El Emam, Lucy Mosquera, Jason Bass.";Health related;1"Hess M.; Hackenberg M.; Binder H.";Exploring generative deep learning for omics data using log-linear models;2020;Motivation: Following many successful applications to image data, deep learning is now also increasingly considered for omics data. In particular, generative deep learning not only provides competitive prediction performance, but also allows for uncovering structure by generating synthetic samples. However, exploration and visualization is not as straightforward as with image applications. Results: We demonstrate how log-linear models, fitted to the generated, synthetic data can be used to extract patterns from omics data, learned by deep generative techniques. Specifically, interactions between latent representations learned by the approaches and generated synthetic data are used to determine sets of joint patterns. Distances of patterns with respect to the distribution of latent representations are then visualized in low-dimensional coordinate systems, e.g. for monitoring training progress. This is illustrated with simulated data and subsequently with cortical single-cell gene expression data. Using different kinds of deep generative techniques, specifically variational autoencoders and deep Boltzmann machines, the proposed approach highlights how the techniques uncover underlying structure. It facilitates the real-world use of such generative deep learning techniques to gain biological insights from omics data. © 2020 The Author(s).;Not health related;0"Navidan H.; Moshiri P.F.; Nabati M.; Shahbazian R.; Ghorashi S.A.; Shah-Mansouri V.; Windridge D.";Generative Adversarial Networks (GANs) in networking: A comprehensive survey & evaluation;2021;Despite the recency of their conception, Generative Adversarial Networks (GANs) constitute an extensively-researched machine learning sub-field for the creation of synthetic data through deep generative modeling. GANs have consequently been applied in a number of domains, most notably computer vision, in which they are typically used to generate or transform synthetic images. Given their relative ease of use, it is therefore natural that researchers in the field of networking (which has seen extensive application of deep learning methods) should take an interest in GAN-based approaches. The need for a comprehensive survey of such activity is therefore urgent. In this paper, we demonstrate how this branch of machine learning can benefit multiple aspects of computer and communication networks, including mobile networks, network analysis, internet of things, physical layer, and cybersecurity. In doing so, we shall provide a novel evaluation framework for comparing the performance of different models in non-image applications, applying this to a number of reference network datasets. © 2021 Elsevier B.V.;Not health related;0"Xu C.; Ren J.; Zhang D.; Zhang Y.; Qin Z.; Ren K.";GANobfuscator: Mitigating information leakage under GAN via differential privacy;2019;By learning generative models of semantic-rich data distributions from samples, generative adversarial network (GAN) has recently attracted intensive research interests due to its excellent empirical performance as a generative model. The model is used to estimate the underlying distribution of a dataset and randomly generate realistic samples according to their estimated distribution. However, GANs can easily remember training samples due to the high model complexity of deep networks. When GANs are applied to private or sensitive data, the concentration of distribution may divulge some critical information. It consequently requires new technological advances to mitigate the information leakage under GANs. To address this issue, we propose GANobfuscator, a differentially private GAN, which can achieve differential privacy under GANs by adding carefully designed noise to gradients during the learning procedure. With GANobfuscator, analysts are able to generate an unlimited amount of synthetic data for arbitrary analysis tasks without disclosing the privacy of training data. Moreover, we theoretically prove that GANobfuscator can provide strict privacy guarantee with differential privacy. In addition, we develop a gradient-pruning strategy for GANobfuscator to improve the scalability and stability of data training. Through extensive experimental evaluation on benchmark datasets, we demonstrate that GANobfuscator can produce high-quality generated data and retain desirable utility under practical privacy budgets. © 2019 IEEE.;Not health related;0"Manukian H.; Pei Y.R.; Bearden S.R.B.; Di Ventra M.";Mode-assisted unsupervised learning of restricted Boltzmann machines;2020;Restricted Boltzmann machines (RBMs) are a powerful class of generative models, but their training requires computing a gradient that, unlike supervised backpropagation on typical loss functions, is notoriously difficult even to approximate. Here, we show that properly combining standard gradient updates with an off-gradient direction, constructed from samples of the RBM ground state (mode), improves training dramatically over traditional gradient methods. This approach, which we call ‘mode-assisted training’, promotes faster training and stability, in addition to lower converged relative entropy (KL divergence). We demonstrate its efficacy on synthetic datasets where we can compute KL divergences exactly, as well as on a larger machine learning standard (MNIST). The proposed mode-assisted training can be applied in conjunction with any given gradient method, and is easily extended to more general energy-based neural network structures such as deep, convolutional and unrestricted Boltzmann machines. © 2020, The Author(s).;Not health related;0"Yu Q.; Yu Z.; Wang Z.; Wang X.; Wang Y.";Estimating posterior inference quality of the relational infinite latent feature model for overlapping community detection;2020;Overlapping community detection has become a very hot research topic in recent decades, and a plethora of methods have been proposed. But, a common challenge in many existing overlapping community detection approaches is that the number of communities K must be predefined manually. We propose a flexible nonparametric Bayesian generative model for count-value networks, which can allow K to increase as more and more data are encountered instead of to be fixed in advance. The Indian buffet process was used to model the community assignment matrix Z, and an uncollapsed Gibbs sampler has been derived. However, as the community assignment matrix Z is a structured multi-variable parameter, how to summarize the posterior inference results and estimate the inference quality about Z, is still a considerable challenge in the literature. In this paper, a graph convolutional neural network based graph classifier was utilized to help to summarize the results and to estimate the inference quality about Z. We conduct extensive experiments on synthetic data and real data, and find that empirically, the traditional posterior summarization strategy is reliable. © 2020, Higher Education Press and Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Gabrié M.; Manoel A.; Luneau C.; Barbier J.; Macris N.; Krzakala F.; Zdeborová L.";Entropy and mutual information in models of deep neural networks;2019;We examine a class of stochastic deep learning models with a tractable method to compute information-theoretic quantities. Our contributions are three-fold: (i) we show how entropies and mutual informations can be derived from heuristic statistical physics methods, under the assumption that weight matrices are independent and orthogonally-invariant. (ii) We extend particular cases in which this result is known to be rigorously exact by providing a proof for two-layers networks with Gaussian random weights, using the recently introduced adaptive interpolation method. (iii) We propose an experiment framework with generative models of synthetic datasets, on which we train deep neural networks with a weight constraint designed so that the assumption in (i) is verified during learning. We study the behavior of entropies and mutual informations throughout learning and conclude that, in the proposed setting, the relationship between compression and generalization remains elusive. © 2019 The Author(s). Published by IOP Publishing Ltd on behalf of SISSA Medialab srl.;Not health related;0"Szlobodnyik G.; Farkas L.";Data Augmentation by Guided Deep Interpolation;2021;State-of-the-art machine learning algorithms require large amount of high quality data. In practice, however, the sample size is commonly low and data is imbalanced along different class labels. Low sample size and imbalanced class distribution can significantly deteriorate the predictive performance of machine learning models. In order to overcome data quality issues, we propose a novel data augmentation method, Guided Deep Interpolation (GDI). It is based on a convolutional auto-encoder network, which is equipped with an auxiliary linear self-expressive layer. The network is trained by minimizing a composite objective function so that to extract the underlying clustered structure of semantic similarities of data points while high reconstruction quality is also preserved. The trained network is used to define a sampling strategy and a synthetic data generation procedure. Making use of the weights of the self-expressive layer, we introduce a measure of semantic variability to quantify how similar a data point to other data points on average. Based on the proposed measure of semantic variability, a joint distribution is defined. Using the distribution we can draw pairs of similar data points so that one point is semantically underrepresented (isolated) while its pair possesses relatively high semantic variability. A sampled pair is interpolated in the deep feature space of the network so that to increase semantic variability while preserve class label of the semantically underrepresented data point. The trained decoder is used to determine pixel space representations of latent space interpolations. The resulting data augmentation procedure generates synthetic samples by increasing the semantic variability of semantically underrepresented instances in a class label preserving way. Our experimental results show that the proposed method outperforms traditional and generative model-based data augmentation methods on low sample size and imbalanced data sets. © 2021 Elsevier B.V.;Not health related;0"Azzam M.; Wu W.; Cao W.; Wu S.; Wong H.-S.";KTransGAN: Variational Inference-Based Knowledge Transfer for Unsupervised Conditional Generative Learning;2021;Class-conditional generative models have gained popularity due to their characteristics of learning disentangled representations. However, these models typically require labeled examples in training. In this paper, we explore the feasibility of training these models on completely unlabeled data, under the assumption that we have access to other labeled data. The labeled data share the same label space, while their domain is shifted. Our model, which we refer to as KTransGAN, incorporates a classifier to transfer knowledge from the labeled data and performs collaborative learning with the conditional generator. By adopting these measures, KTransGAN is able to approximate the conditional distribution of the unlabeled data and simultaneously introduces a new solution to the unsupervised domain adaptation problem. To mitigate the training difficulty of our generative adversarial networks-based model, variational encoding and feature matching are also considered. From the empirical results, KTransGAN exhibits outstanding performance on a number of synthetic datasets and multiple real-world benchmarks. The quality of the synthesized instances is far superior to the pure variational autoencoding model. For example, on the CIFAR-10 dataset, our model scores 35.3 in FID, while the other model scores 128.45. In addition, the synthesis quality is close to the case when the model is trained in a fully supervised setting over the same number of training iterations. Regarding the classification performance, for instance, our model surpasses the highest state-of-the-art results (89.19%) by a large margin and achieves a test accuracy of 95.31% on the unlabeled data SVHN, while MNIST represents the labeled data. These results highlight the effectiveness of our proposed framework.  © 1999-2012 IEEE.;Not health related;0"Tra V.; Duong B.-P.; Kim J.-M.";Improving diagnostic performance of a power transformer using an adaptive over-sampling method for imbalanced data;2019;Dissolved gas analysis (DGA) of insulating oil in power transformers can offer valuable information related to faults. Due to the poor and unbalanced characteristics of typical DGA datasets, which threaten the generalization capability of artificial intelligent (AI)-based models, we propose the use of a new over-sampling technique called ASMOTE (adaptive synthetic minority over-sampling TEchnique) in the pre-processing step to enrich the dataset. ASMOTE can significantly improve the generalization performance of AI-based models by providing a sufficient synthetic dataset to train an AI classifier. To authenticate the effectiveness of the ASMOTE algorithm, we validate the transformer diagnostic accuracy of some typical classification algorithms such as multilayer perceptron (MLP), support vector machine (SVM), and k-nearest neighbor (k-NN) using synthetic datasets created by the SMOTE technique. In addition, the use of DGA ratios is also considered. By investigating the interactions between byproduct gases in insulating oil and transformer faults, the non-code ratios of the dissolved emissions are chosen as the characterizing input to the AI-based models. Moreover, with the ability to extract discriminate faulty information of a transformer from DGA data, MLP is used as a preferable classifier for diagnosing symptoms present in transformers. The empirical results of this study demonstrate that the proposed technique remarkably increases the diagnostic performance of power transformer faults. © 1994-2012 IEEE.;Not health related;0"Fernandes T.T.; Direito B.; Sayal A.; Pereira J.; Andrade A.; Castelo-Branco M.";The boundaries of state-space Granger causality analysis applied to BOLD simulated data: A comparative modelling and simulation approach;2020;Background: The analysis of connectivity has become a fundamental tool in human neuroscience. Granger Causality Mapping is a data-driven method that uses Granger Causality (GC) to assess the existence and direction of influence between signals, based on temporal precedence of information. More recently, a theory of Granger causality has been developed for state-space (SS-GC) processes, but little is known about its statistical validation and application on functional magnetic resonance imaging (fMRI) data. New method: We explored different multivariate computational frameworks to define the optimal combination for GC estimation. We hypothesized a new heuristic, combining SS-GC with a distinct statistical validation technique, Time Reversed Testing, validating it on synthetic data. We test its performance with a number of experimental parameters, including block structure, sampling frequency, noise and system mean pairwise correlation, using a statistical framework of binary classification. Results: We found that SS-GC with time reversed testing outperforms other frameworks. The results validate the application of SS-GC to generative models. When estimating reliable causal relations, SS-GC returns promising results, especially when considering synthetic data with a high impact of noise and sampling rate. Conclusions: In this study, we empirically explored the boundaries of SS-GC with time reversed testing, a data-driven causality analysis framework with potential applicability to fMRI data. © 2020;Not health related;0"Garrido S.; Borysov S.; Rich J.; Pereira F.";Estimating causal effects with the neural autoregressive density estimator;2021;The estimation of causal effects is fundamental in situations where the underlying system will be subject to active interventions. Part of building a causal inference engine is defining how variables relate to each other, that is, defining the functional relationship between variables entailed by the graph conditional dependencies. In this article, we deviate from the common assumption of linear relationships in causal models by making use of neural autoregressive density estimators and use them to estimate causal effects within Pearl's do-calculus framework. Using synthetic data, we show that the approach can retrieve causal effects from non-linear systems without explicitly modeling the interactions between the variables and include confidence bands using the non-parametric bootstrap. We also explore scenarios that deviate from the ideal causal effect estimation setting such as poor data support or unobserved confounders.  © 2021 Sergio Garrido et al., published by De Gruyter.;Not health related;0"Pozi M.S.M.; Omar M.H.";A kernel density estimation method to generate synthetic shifted datasets in privacy-preserving task;2020;In order to perform comprehensive analytic task, it requires the availability of any particular complete dataset in the first place. However, due to privacy concern, the specific demand on sharing full dataset to third parties is hardly to be fulfilled. New methods using systematically synthetic data generation in order to preserve the data privacy have recently been explored and identified as a suitable ap-proach to address the privacy concern. Throughout this work, a privacy-preserving probability based synthetic data generation framework for supervised based data analytic is proposed. Using a generative model that captures and represents the probability density function of dataset features, a new privacy-preserving synthetic dataset is synthesized, such that, the new dataset is statistically different from the original dataset. Then, we simulate a supervised learning task using two different machine learning classifiers, as a method to compare the utility of original and the new privacy-preserving synthesized dataset. From the experimental results, we found that the proposed synthetic generation model can produces a new privacy-preserving synthesized dataset, that has similar data utility as to the original dataset. © 2020, Innovative Information Science and Technology Research Group. All rights reserved.;Not health related;0"Hosseini R.; Hassanpour N.; Liu L.-P.; Hassoun S.";Pathway-activity likelihood analysis and metabolite annotation for untargeted metabolomics using probabilistic modeling;2020;Motivation: Untargeted metabolomics comprehensively characterizes small molecules and elucidates activities of biochemical pathways within a biological sample. Despite computational advances, interpreting collected measurements and determining their biological role remains a challenge. Results: To interpret measurements, we present an inference-based approach, termed Probabilistic modeling for Untargeted Metabolomics Analysis (PUMA). Our approach captures metabolomics measurements and the biological network for the biological sample under study in a generative model and uses stochastic sampling to compute posterior probability distributions. PUMA predicts the likelihood of pathways being active, and then derives probabilistic annotations, which assign chemical identities to measurements. Unlike prior pathway analysis tools that analyze differentially active pathways, PUMA defines a pathway as active if the likelihood that the path generated the observed measurements is above a particular (user-defined) threshold. Due to the lack of “ground truth” metabolomics datasets, where all measurements are annotated and pathway activities are known, PUMA is validated on synthetic datasets that are designed to mimic cellular processes. PUMA, on average, outperforms pathway enrichment analysis by 8%. PUMA is applied to two case studies. PUMA suggests many biological meaningful pathways as active. Annotation results were in agreement to those obtained using other tools that utilize additional information in the form of spectral signatures. Importantly, PUMA annotates many measurements, suggesting 23 chemical identities for metabolites that were previously only identified as isomers, and a significant number of additional putative annotations over spectral database lookups. For an experimentally validated 50-compound dataset, annotations using PUMA yielded 0.833 precision and 0.676 recall. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.;Not health related;0"Piatkowski N.; Lee S.; Morik K.";Integer undirected graphical models for resource-constrained systems;2016;Machine learning on resource-constrained ubiquitous devices suffers from high energy consumption and slow execution. The number of clock cycles that is consumed by arithmetic instructions has an immediate impact on both. In computer systems, the number of consumed cycles depends on particular operations and the types of their operands. We propose a new class of probabilistic graphical models that approximates the full joint probability distribution of discrete multivariate random variables by relying only on integer addition/multiplication and binary bit shift operations. This allows us to sample from high-dimensional generative models and to use structured discriminative classifiers even on computational devices with slow floating point units or in situations where energy has to be saved. While theory and experiments on random synthetic data suggest that hard instances (leading to a large approximation error) exist, experiments on benchmark and real-world data show that the integer models achieve qualitatively the same results as their double-precision counterparts. Moreover, clock cycle consumption on two hardware platforms is regarded, where our results show that resource savings due to integer approximation is even larger on low-end hardware. The integer models consume half of the clock cycles and a small fraction of memory compared to ordinary undirected graphical models. © 2015 Elsevier B.V.;Not health related;0"Tao J.; Michailidis G.";A statistical framework for detecting electricity theft activities in smart grid distribution networks;2020;Electricity distribution networks have undergone rapid change with the introduction of smart meter technology, that have advanced sensing and communications capabilities, resulting in improved measurement and control functions. However, the same capabilities have enabled various cyber-attacks. A particular attack focuses on electricity theft, where the attacker alters (increases) the electricity consumption measurements recorded by the smart meter of other users, while reducing her own measurement. Thus, such attacks, since they maintain the total amount of power consumed at the distribution transformer are hard to detect by techniques that monitor mean levels of consumption patterns. To address this data integrity problem, we develop statistical techniques that utilize information on higher order statistics of electricity consumption and thus are capable of detecting such attacks and also identify the users (attacker and victims) involved. The models work both for independent and correlated electricity consumption streams. The results are illustrated on synthetic data, as well as emulated attacks leveraging real consumption data. © 1983-2012 IEEE.;Not health related;0"Ho S.; Qu Y.; Gu B.; Gao L.; Li J.; Xiang Y.";DP-GAN: Differentially private consecutive data publishing using generative adversarial nets;2021;In the era of big data, increasingly massive volumes of data is generated and published consecutively for both research and commercial purposes. The potential value of sensitive information also attracts interest from adversaries and thereby arises public concern. Current research mostly focuses on privacy-preserving data publishing in a statistic manner rather than taking the dynamics and correlation of context into consideration. Motivated by this, we propose a novel idea that combining differential privacy and generative adversarial nets. Generative adversarial nets and its extensions are used to generate a synthetic dataset with indistinguishable statistic features while differential privacy guarantees a trade-off between privacy protection and data utility. By employing a min-max game with three players, we devise a deep generative model, namely DP-GAN model, for synthetic data generation while fulfilling the privacy constraints in a differentially private manner. Extensive simulation results on a real-world dataset testify the superiority of the proposed model in terms of privacy protection, data utility, and efficiency. © 2021;Not health related;0"Alletto S.; Abati D.; Calderara S.; Cucchiara R.; Rigazio L.";Self-Supervised Optical Flow Estimation by Projective Bootstrap;2019;Dense optical flow estimation is complex and time consuming, with state-of-the-art methods relying either on large synthetic data sets or on pipelines requiring up to a few minutes per frame pair. In this paper, we address the problem of optical flow estimation in the automotive scenario in a self-supervised manner. We argue that optical flow can be cast as a geometrical warping between two successive video frames and devise a deep architecture to estimate such transformation in two stages. First, a dense pixel-level flow is computed with a projective bootstrap on rigid surfaces. We show how such global transformation can be approximated with a homography and extend spatial transformer layers so that they can be employed to compute the flow field implied by such transformation. Subsequently, we refine the prediction by feeding a second, deeper network that accounts for moving objects. A final reconstruction loss compares the warping of frame Xt with the subsequent frame Xt+1 and guides both estimates. The model has the speed advantages of end-to-end deep architectures while achieving competitive performances, both outperforming recent unsupervised methods and showing good generalization capabilities on new automotive data sets. © 2000-2011 IEEE.;Not health related;0"Yelmen B.; Decelle A.; Ongaro L.; Marnetto D.; Tallec C.; Montinaro F.; Furtlehner C.; Pagani L.; Jay F.";Creating artificial human genomes using generative neural networks;2021;Generative models have shown breakthroughs in a wide spectrum of domains due to recent advancements in machine learning algorithms and increased computational power. Despite these impressive achievements, the ability of generative models to create realistic synthetic data is still under-exploited in genetics and absent from population genetics. Yet a known limitation in the field is the reduced access to many genetic databases due to concerns about violations of individual privacy, although they would provide a rich resource for data mining and integration towards advancing genetic studies. In this study, we demonstrated that deep generative adversarial networks (GANs) and restricted Boltzmann machines (RBMs) can be trained to learn the complex distributions of real genomic datasets and generate novel high-quality artificial genomes (AGs) with none to little privacy loss. We show that our generated AGs replicate characteristics of the source dataset such as allele frequencies, linkage disequilibrium, pairwise haplotype distances and population structure. Moreover, they can also inherit complex features such as signals of selection. To illustrate the promising outcomes of our method, we showed that imputation quality for low frequency alleles can be improved by data augmentation to reference panels with AGs and that the RBM latent space provides a relevant encoding of the data, hence allowing further exploration of the reference dataset and features for solving supervised tasks. Generative models and AGs have the potential to become valuable assets in genetic studies by providing a rich yet compact representation of existing genomes and high-quality, easy-access and anonymous alternatives for private databases.  © 2021 Yelmen et al.;Not health related;0"Ovalle-Magallanes E.; Avina-Cervantes J.G.; Cruz-Aceves I.; Ruiz-Pinales J.";Transfer learning for stenosis detection in X-ray Coronary Angiography;2020;Coronary artery disease is the most frequent type of heart disease caused by an abnormal narrowing of coronary arteries, also called stenosis or atherosclerosis. It is also the leading cause of death globally. Currently, X-ray Coronary Angiography (XCA) remains the gold-standard imaging technique for medical diagnosis of stenosis and other related conditions. This paper presents a new method for the automatic detection of coronary artery stenosis in XCA images, employing a pre-trained (VGG16, ResNet50, and Inception-v3) Convolutional Neural Network (CNN) via Transfer Learning. The method is based on a network-cut and fine-tuning approach. The optimal cut and fine-tuned layers were selected following 20 different configurations for each network. The three networks were fine-tuned using three strategies: only real data, only artificial data, and artificial with real data. The synthetic dataset consists of 10,000 images (80% for training, 20% for validation) produced by a generative model. These different configurations were analyzed and compared using a real dataset of 250 real XCA images (125 for testing and 125 for fine-tuning), regarding their randomly initiated CNNs and a fourth custom CNN, trained as well with artificial and real data. The results showed that pre-trained VGG16, ResNet50, and Inception-v3 cut on an early layer and fine-tuned, overcame the referencing CNNs performance. Specifically, Inception-v3 provided the best stenosis detection with an accuracy of 0.95, a precision of 0.93, sensitivity, specificity, and F1 score of 0.98, 0.92, and 0.95, respectively. Moreover, a class activation map is applied to identify the high attention regions for stenosis detection. © 2020 by the authors.;Health related;1"Sterling A.; Rewkowski N.; Klatzky R.L.; Lin M.C.";Audio-Material Reconstruction for Virtualized Reality Using a Probabilistic Damping Model;2019;Modal sound synthesis has been used to create realistic sounds from rigid-body objects, but requires accurate real-world material parameters. These material parameters can be estimated from recorded sounds of an impacted object, but external factors can interfere with accurate parameter estimation. We present a novel technique for estimating the damping parameters of materials from recorded impact sounds that probabilistically models these external factors. We represent the combined effects of material damping, support damping, and sampling inaccuracies with a probabilistic generative model, then use maximum likelihood estimation to fit a damping model to recorded data. This technique greatly reduces the human effort needed and does not require the precise object geometry or the exact hit location. We validate the effectiveness of this technique with a comprehensive analysis of a synthetic dataset and a perceptual study on object identification. We also present a study establishing human performance on the same parameter estimation task for comparison. © 2019 IEEE.;Not health related;0"Wang M.; Tsai T.-H.; Di Poto C.; Ferrarini A.; Yu G.; Ressom H.W.";Topic model-based mass spectrometric data analysis in cancer biomarker discovery studies;2016;Background: A fundamental challenge in quantitation of biomolecules for cancer biomarker discovery is owing to the heterogeneous nature of human biospecimens. Although this issue has been a subject of discussion in cancer genomic studies, it has not yet been rigorously investigated in mass spectrometry based proteomic and metabolomic studies. Purification of mass spectometric data is highly desired prior to subsequent analysis, e.g., quantitative comparison of the abundance of biomolecules in biological samples. Methods: We investigated topic models to computationally analyze mass spectrometric data considering both integrated peak intensities and scan-level features, i.e., extracted ion chromatograms (EICs). Probabilistic generative models enable flexible representation in data structure and infer sample-specific pure resources. Scan-level modeling helps alleviate information loss during data preprocessing. We evaluated the capability of the proposed models in capturing mixture proportions of contaminants and cancer profiles on LC-MS based serum proteomic and GC-MS based tissue metabolomic datasets acquired from patients with hepatocellular carcinoma (HCC) and liver cirrhosis as well as synthetic data we generated based on the serum proteomic data. Results: The results we obtained by analysis of the synthetic data demonstrated that both intensity-level and scan-level purification models can accurately infer the mixture proportions and the underlying true cancerous sources with small average error ratios (<7 %) between estimation and ground truth. By applying the topic model-based purification to mass spectrometric data, we found more proteins and metabolites with significant changes between HCC cases and cirrhotic controls. Candidate biomarkers selected after purification yielded biologically meaningful pathway analysis results and improved disease discrimination power in terms of the area under ROC curve compared to the results found prior to purification. Conclusions: We investigated topic model-based inference methods to computationally address the heterogeneity issue in samples analyzed by LC/GC-MS. We observed that incorporation of scan-level features have the potential to lead to more accurate purification results by alleviating the loss in information as a result of integrating peaks. We believe cancer biomarker discovery studies that use mass spectrometric analysis of human biospecimens can greatly benefit from topic model-based purification of the data prior to statistical and pathway analyses. © 2016 The Author(s).;Health related;1"Gao Y.; Kong B.; Mosalam K.M.";Deep leaf-bootstrapping generative adversarial network for structural image data augmentation;2019;Employing Deep Learning (DL) technologies to solve Civil Engineering problems is an emerging topic in recent years. However, due to the lack of labeled data, it is difficult to obtain accurate results with DL. One commonly used method to tackle this issue is to use affine transformation to augment the data set, but it can only generate new images that are highly correlated with the original ones. Moreover, unlike normal natural objects, distribution of structural images is much more complex and mixed. To address these challenges, Generative Adversarial Network (GAN) can be one feasible choice. We introduce one specific generative model, namely, Deep Convolutional Generative Adversarial Network (DCGAN) and propose a Leaf-Bootstrapping (LB) method to improve the performance of this DCGAN. To effectively and quantitatively evaluate the quality of the synthetic images generated by DCGAN to complement human evaluation, Self-Inception Score (SIS) and Generalization Ability (GA) are proposed. We also propose a pipeline based on Transfer Learning (TL) using synthetic images to help enhance a weak classifier performance under the condition of low-data regime and limited computational resources. Finally, we conduct computer experiments with the proposed methods for two scenarios (scene level identification and damage state check) and one special synthetic data aggregation case. The results demonstrate the effectiveness and robustness of the proposed methods. © 2019_Computer-Aided Civil and Infrastructure Engineering;Not health related;0"Gooya A.; Lekadir K.; Castro-Mateos I.; Pozo J.M.; Frangi A.F.";Mixture of Probabilistic Principal Component Analyzers for Shapes from Point Sets;2018;Inferring a probability density function (pdf) for shape from a population of point sets is a challenging problem. The lack of point-to-point correspondences and the non-linearity of the shape spaces undermine the linear models. Methods based on manifolds model the shape variations naturally, however, statistics are often limited to a single geodesic mean and an arbitrary number of variation modes. We relax the manifold assumption and consider a piece-wise linear form, implementing a mixture of distinctive shape classes. The pdf for point sets is defined hierarchically, modeling a mixture of Probabilistic Principal Component Analyzers (PPCA) in higher dimension. A Variational Bayesian approach is designed for unsupervised learning of the posteriors of point set labels, local variation modes, and point correspondences. By maximizing the model evidence, the numbers of clusters, modes of variations, and points on the mean models are automatically selected. Using the predictive distribution, we project a test shape to the spaces spanned by the local PPCA's. The method is applied to point sets from: i) synthetic data, ii) healthy versus pathological heart morphologies, and iii) lumbar vertebrae. The proposed method selects models with expected numbers of clusters and variation modes, achieving lower generalization-specificity errors compared to state-of-the-art. © 1979-2012 IEEE.;Health related;0"Park S.; Elhilali M.; Han D.K.; Ko H.";Amphibian Sounds Generating Network Based on Adversarial Learning;2020;This letter proposes a generative network based on adversarial learning for synthesizing short-time audio streams and investigates the effectiveness of data augmentation for amphibian call sounds classification. Based on Fourier analysis, the generator is designed by a multi-layer perceptron composed of frequency basis learning layers and an output layer, and a discriminator is constructed by a convolutional neural network. Additionally, regularization on weights is introduced to train the networks with practical data that includes some disturbances. Synthetic audio streams are evaluated by quantitative comparison using inception score, and classification results are compared for real versus synthetic data. In conclusion, the proposed generative network is shown to produce realistic sounds and therefore useful for data augmentation.  © 1994-2012 IEEE.;Not health related;0"Carden S.W.; Livsey J.";Small-sample reinforcement learning: Improving policies using synthetic data;2017;Reinforcement learning (RL) concerns algorithms tasked with learning optimal control policies by interacting with or observing a system. In computer science and other fields in which RL originated, large sample sizes are the norm, because data can be generated at will from a generative model. Recently, RL methods have been adapted for use in clinical trials, resulting in much smaller sample sizes. Nonparametric methods are common in RL, but are likely to over-generalize when limited data is available. This paper proposes a novel methodology for learning optimal policies by leveraging the researcher's partial knowledge about the probability transition structure into an approximate generative model from which synthetic data can be produced. Our method is applied to a scenario where the researcher must create a medical prescription policy for managing a disease with sporadically appearing symptoms. © 2017 IOS Press and the authors. All rights reserved.;Health related;1"Abi Nader C.; Ayache N.; Robert P.; Lorenzi M.";Monotonic Gaussian Process for spatio-temporal disease progression modeling in brain imaging data;2020;We introduce a probabilistic generative model for disentangling spatio-temporal disease trajectories from collections of high-dimensional brain images. The model is based on spatio-temporal matrix factorization, where inference on the sources is constrained by anatomically plausible statistical priors. To model realistic trajectories, the temporal sources are defined as monotonic and time-reparameterized Gaussian Processes. To account for the non-stationarity of brain images, we model the spatial sources as sparse codes convolved at multiple scales. The method was tested on synthetic data favourably comparing with standard blind source separation approaches. The application on large-scale imaging data from a clinical study allows to disentangle differential temporal progression patterns mapping brain regions key to neurodegeneration, while revealing a disease-specific time scale associated to the clinical diagnosis. © 2019 Elsevier Inc.;Health related;1"Ghorban F.; Milani N.; Schugk D.; Roese-Koerner L.; Su Y.; Müller D.; Kummert A.";Conditional multichannel generative adversarial networks with an application to traffic signs representation learning;2019;Generative adversarial networks (GANs) are known to produce photorealistic representations. However, we show in this study that this is only valid when the input channels come from a regular RGB camera sensor. In order to alleviate this shortcoming, we propose a general solution to which we refer to as multichannel GANs (MCGANs). In contrast to the existing approaches, MCGANs can process multiple channels with different textures and resolutions. This is achieved by using known concepts in deep learning such as weight sharing and specially separated convolutions. The proposed pipeline enables particular kernels to learn low-level characteristics from the different channels without the need for exhaustive hyper-parameter tuning. We demonstrate the improved representational ability of the framework on traffic sign samples that are captured by a camera with a so-called red-clear-clear-clear pixel topology. Furthermore, we extend our solution by applying the concept of conditions, that offers a whole spectrum of new features, especially for the generation of traffic signs. Throughout this paper, we further discuss relevant applications for the generated synthetic data. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.;Not health related;0"Chen S.; Wang W.; Xia B.; You X.; Peng Q.; Cao Z.; Ding W.";CDE-GAN: Cooperative Dual Evolution-Based Generative Adversarial Network;2021;Generative adversarial networks (GANs) have been a popular deep generative model for real-world applications. Despite many recent efforts on GANs that have been contributed, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this article, motivated by the cooperative co-evolutionary algorithm, we propose a cooperative dual evolution-based GAN (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to the generator(s) and discriminators into a unified evolutionary adversarial framework to conduct effective adversarial multiobjective optimization. Thus, it exploits the complementary properties and injects dual mutation diversity into the training, to steadily diversify the estimated density in capturing multimodes and improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation (E-Generators and E-Discriminators), evolved by its own evolutionary algorithm. Additionally, we further propose a Soft Mechanism to balance the tradeoff between E-Generators and E-Discriminators to conduct steady training for CDE-GAN. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets demonstrate that the proposed CDE-GAN achieves a competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html.  © 1997-2012 IEEE.;Not health related;0"Atapour-Abarghouei A.; Akcay S.; Payen de La Garanderie G.; Breckon T.P.";Generative adversarial framework for depth filling via Wasserstein metric, cosine transform and domain transfer;2019;In this work, the issue of depth filling is addressed using a self-supervised feature learning model that predicts missing depth pixel values based on the context and structure of the scene. A fully-convolutional generative model is conditioned on the available depth information and full RGB colour information from the scene and trained in an adversarial fashion to complete scene depth. Since ground truth depth is not readily available, synthetic data is instead used with a separate model developed to predict where holes would appear in a sensed (non-synthetic) depth image based on the contents of the RGB image. The resulting synthetic data with realistic holes is utilized in training the depth filling model which makes joint use of a reconstruction loss which employs the Discrete Cosine Transform for more realistic outputs, an adversarial loss which measures the distribution distances via the Wasserstein metric and a bottleneck feature loss that aids in better contextual feature execration. Additionally, the model is adversarially adapted to perform well on naturally-obtained data with no available ground truth. Qualitative and quantitative evaluations demonstrate the efficacy of the approach compared to contemporary depth filling techniques. The strength of the feature learning capabilities of the resulting deep network model is also demonstrated by performing the task of monocular depth estimation using our pre-trained depth hole filling model as the initialization for subsequent transfer learning. © 2019 Elsevier Ltd;Not health related;0"Taghia J.; Ryali S.; Chen T.; Supekar K.; Cai W.; Menon V.";Bayesian switching factor analysis for estimating time-varying functional connectivity in fMRI;2017;There is growing interest in understanding the dynamical properties of functional interactions between distributed brain regions. However, robust estimation of temporal dynamics from functional magnetic resonance imaging (fMRI) data remains challenging due to limitations in extant multivariate methods for modeling time-varying functional interactions between multiple brain areas. Here, we develop a Bayesian generative model for fMRI time-series within the framework of hidden Markov models (HMMs). The model is a dynamic variant of the static factor analysis model (Ghahramani and Beal, 2000). We refer to this model as Bayesian switching factor analysis (BSFA) as it integrates factor analysis into a generative HMM in a unified Bayesian framework. In BSFA, brain dynamic functional networks are represented by latent states which are learnt from the data. Crucially, BSFA is a generative model which estimates the temporal evolution of brain states and transition probabilities between states as a function of time. An attractive feature of BSFA is the automatic determination of the number of latent states via Bayesian model selection arising from penalization of excessively complex models. Key features of BSFA are validated using extensive simulations on carefully designed synthetic data. We further validate BSFA using fingerprint analysis of multisession resting-state fMRI data from the Human Connectome Project (HCP). Our results show that modeling temporal dependencies in the generative model of BSFA results in improved fingerprinting of individual participants. Finally, we apply BSFA to elucidate the dynamic functional organization of the salience, central-executive, and default mode networks—three core neurocognitive systems with central role in cognitive and affective information processing (Menon, 2011). Across two HCP sessions, we demonstrate a high level of dynamic interactions between these networks and determine that the salience network has the highest temporal flexibility among the three networks. Our proposed methods provide a novel and powerful generative model for investigating dynamic brain connectivity. © 2017 Elsevier Inc.;Not health related;1"Lin W.; Gao J.; Wang Q.; Li X.";Learning to detect anomaly events in crowd scenes from synthetic data;2021;Recently, due to its widespread applications in public safety, anomaly detection in crowd scenes has become a hot topic. Some deep-learning-based methods attain significant achievements in this field. Nevertheless, most of them suffer from over-fitting to some extent because of scarce data, which are usually abrupt and low-frequency in the real world. To remedy the above problem, this paper firstly develops a synthetic anomaly event generating system, which could simulate typical specific abnormal events. By utilizing this system, a large synthetic, diverse anomaly event dataset is built, which contains 2,149 video sequences. After getting the dataset, a 3D CNN is designed to detect the abnormal types at the video level. However, we find that there are obvious domain differences (also named as “domain gap/shifts”) between synthetic videos and real-world data, which results in performance degradation when applying the model to the real world. Thus, this paper further proposes a cyclic 3D GAN for domain adaption to reduce the domain gap, which translates the synthetic data to the photorealistic video sequences. Then the detection model is trained on the translated data and it can perform well in the real data. Experimental results illustrate that the proposed method outperforms these baselines for the domain adaptation anomaly detection. © 2021 Elsevier B.V.;Not health related;0"Meng N.; Ge Z.; Zeng T.; Lam E.Y.";LightGAN: A Deep Generative Model for Light Field Reconstruction;2020;A light field image captured by a plenoptic camera can be considered a sampling of light distribution within a given space. However, with the limited pixel count of the sensor, the acquisition of a high-resolution sample often comes at the expense of losing parallax information. In this work, we present a learning-based generative framework to overcome such tradeoff by directly simulating the light field distribution. An important module of our model is the high-dimensional residual block, which fully exploits the spatio-angular information. By directly learning the distribution, our approach can generate both high-quality sub-aperture images and densely-sampled light fields. Experimental results on both real-world and synthetic datasets demonstrate that the proposed method outperforms other state-of-the-art approaches and achieves visually more realistic results. © 2013 IEEE.;Not health related;0Van Laarhoven T.;Generative models for local network community detection;2018;Local network community detection aims to find a single community in a large network, while inspecting only a small part of that network around a given seed node. This is much cheaper than finding all communities in a network. Most methods for local community detection are formulated as ad hoc optimization problems. In this paper, we instead start from a generative model for networks with a community structure. By assuming that the network is uniform, we can approximate the structure of the unobserved parts of the network to obtain a method for local community detection. We apply this local approximation technique to two variants of the stochastic block model. This results in local community detection methods based on probabilistic models. Interestingly, in the limit, one of the proposed approximations corresponds to conductance, a popular metric in this field. Experiments on real and synthetic data sets show comparable or improved results compared to state-of-the-art local community detection algorithms. © 2018 American Physical Society.;Not health related;0"Quinn C.J.; Kiyavash N.; Coleman T.P.";Directed Information Graphs;2015;We propose a graphical model for representing networks of stochastic processes, the minimal generative model graph. It is based on reduced factorizations of the joint distribution over time. We show that under appropriate conditions, it is unique and consistent with another type of graphical model, the directed information graph, which is based on a generalization of Granger causality. We demonstrate how directed information quantifies Granger causality in a particular sequential prediction setting. We also develop efficient methods to estimate the topological structure from data that obviate estimating the joint statistics. One algorithm assumes upper bounds on the degrees and uses the minimal dimension statistics necessary. In the event that the upper bounds are not valid, the resulting graph is nonetheless an optimal approximation in terms of Kullback-Leibler (KL) divergence. Another algorithm uses near-minimal dimension statistics when no bounds are known, but the distribution satisfies a certain criterion. Analogous to how structure learning algorithms for undirected graphical models use mutual information estimates, these algorithms use directed information estimates. We characterize the sample-complexity of two plug-in directed information estimators and obtain confidence intervals. For the setting when point estimates are unreliable, we propose an algorithm that uses confidence intervals to identify the best approximation that is robust to estimation error. Last, we demonstrate the effectiveness of the proposed algorithms through the analysis of both synthetic data and real data from the Twitter network. In the latter case, we identify which news sources influence users in the network by merely analyzing tweet times. © 1963-2012 IEEE.;Not health related;0"Burlina P.M.; Joshi N.; Pacheco K.D.; Liu T.Y.A.; Bressler N.M.";Assessment of Deep Generative Models for High-Resolution Synthetic Retinal Image Generation of Age-Related Macular Degeneration;2019;Importance: Deep learning (DL) used for discriminative tasks in ophthalmology, such as diagnosing diabetic retinopathy or age-related macular degeneration (AMD), requires large image data sets graded by human experts to train deep convolutional neural networks (DCNNs). In contrast, generative DL techniques could synthesize large new data sets of artificial retina images with different stages of AMD. Such images could enhance existing data sets of common and rare ophthalmic diseases without concern for personally identifying information to assist medical education of students, residents, and retinal specialists, as well as for training new DL diagnostic models for which extensive data sets from large clinical trials of expertly graded images may not exist. Objective: To develop DL techniques for synthesizing high-resolution realistic fundus images serving as proxy data sets for use by retinal specialists and DL machines. Design, Setting, and Participants: Generative adversarial networks were trained on 133 821 color fundus images from 4613 study participants from the Age-Related Eye Disease Study (AREDS), generating synthetic fundus images with and without AMD. We compared retinal specialists' ability to diagnose AMD on both real and synthetic images, asking them to assess image gradability and testing their ability to discern real from synthetic images. The performance of AMD diagnostic DCNNs (referable vs not referable AMD) trained on either all-real vs all-synthetic data sets was compared. Main Outcomes and Measures: Accuracy of 2 retinal specialists (T.Y.A.L. and K.D.P.) for diagnosing and distinguishing AMD on real vs synthetic images and diagnostic performance (area under the curve) of DL algorithms trained on synthetic vs real images. Results: The diagnostic accuracy of 2 retinal specialists on real vs synthetic images was similar. The accuracy of diagnosis as referable vs nonreferable AMD compared with certified human graders for retinal specialist 1 was 84.54% (error margin, 4.06%) on real images vs 84.12% (error margin, 4.16%) on synthetic images and for retinal specialist 2 was 89.47% (error margin, 3.45%) on real images vs 89.19% (error margin, 3.54%) on synthetic images. Retinal specialists could not distinguish real from synthetic images, with an accuracy of 59.50% (error margin, 3.93%) for retinal specialist 1 and 53.67% (error margin, 3.99%) for retinal specialist 2. The DCNNs trained on real data showed an area under the curve of 0.9706 (error margin, 0.0029), and those trained on synthetic data showed an area under the curve of 0.9235 (error margin, 0.0045). Conclusions and Relevance: Deep learning-synthesized images appeared to be realistic to retinal specialists, and DCNNs achieved diagnostic performance on synthetic data close to that for real images, suggesting that DL generative techniques hold promise for training humans and machines. © 2018 American Medical Association. All rights reserved.;Health related;1"Henriet S.; _im_ekli U.; Fuentes B.; Richard G.";A generative model for non-Intrusive load monitoring in commercial buildings;2018;In the recent years, there has been an increasing academic and industrial interest for analyzing the electrical consumption of commercial buildings. Whilst having similarities with the Non Intrusive Load Monitoring (NILM) tasks for residential buildings, the nature of the signals that are collected from large commercial buildings introduces additional difficulties to the NILM research causing existing NILM approaches to fail. On the other hand, the amount of publicly available datasets collected from commercial buildings is very limited, which makes the NILM research even more challenging for this type of large buildings. In this study, we aim at addressing these issues. We first present an extensive statistical analysis of both commercial and residential measurements from public and private datasets and show important differences. Secondly, we develop an algorithm for generating synthetic current data based on a modelization of the current flowing through an electrical device. We then demonstrate that our electrical device model fits well real measurements and that our simulations are realistic by using the quantitative metrics described in the previous section. Finally, to encourage research on commercial buildings we release a synthesized dataset called SHED that can be used to evaluate NILM algorithms. © 2018 Elsevier B.V.;Not health related;0"Krause J.; Grabsch H.I.; Kloor M.; Jendrusch M.; Echle A.; Buelow R.D.; Boor P.; Luedde T.; Brinker T.J.; Trautwein C.; Pearson A.T.; Quirke P.; Jenniskens J.; Offermans K.; van den Brandt P.A.; Kather J.N.";Deep learning detects genetic alterations in cancer histology generated by adversarial networks;2021;Deep learning can detect microsatellite instability (MSI) from routine histology images in colorectal cancer (CRC). However, ethical and legal barriers impede sharing of images and genetic data, hampering development of new algorithms for detection of MSI and other biomarkers. We hypothesized that histology images synthesized by conditional generative adversarial networks (CGANs) retain information about genetic alterations. To test this, we developed a ‘histology CGAN’ which was trained on 256 patients (training cohort 1) and 1457 patients (training cohort 2). The CGAN synthesized 10 000 synthetic MSI and non-MSI images which contained a range of tissue types and were deemed realistic by trained observers in a blinded study. Subsequently, we trained a deep learning detector of MSI on real or synthetic images and evaluated the performance of MSI detection in a held-out set of 142 patients. When trained on real images from training cohort 1, this system achieved an area under the receiver operating curve (AUROC) of 0.742 [0.681, 0.854]. Training on the larger cohort 2 only marginally improved the AUROC to 0.757 [0.707, 0.869]. Training on purely synthetic data resulted in an AUROC of 0.743 [0.658, 0.801]. Training on both real and synthetic data further increased AUROC to 0.777 [0.715, 0.821]. We conclude that synthetic histology images retain information reflecting underlying genetic alterations in colorectal cancer. Using synthetic instead of real images to train deep learning systems yields non-inferior classifiers. This approach can be used to create large shareable data sets or to augment small data sets with rare molecular features. © 2021 The Authors. The Journal of Pathology published by John Wiley & Sons, Ltd. on behalf of The Pathological Society of Great Britain and Ireland. © 2021 The Authors. The Journal of Pathology published by John Wiley & Sons, Ltd. on behalf of The Pathological Society of Great Britain and Ireland.;Health related;1"Cai Q.; Abdel-Aty M.; Yuan J.; Lee J.; Wu Y.";Real-time crash prediction on expressways using deep generative models;2020;"Real-time crash prediction is essential for proactive traffic safety management. However, developing an accurate prediction model is challenging as the traffic data of crash and non-crash cases are extremely imbalanced. Most of the previous studies undersampled non-crash cases to balance the data, which may not capture the heterogeneity of the full non-crash data. This study aims to use the emerging deep learning method called deep convolutional generative adversarial network (DCGAN) model to fully understand the traffic data leading to crashes. With the full understanding of the traffic data of crashes, the DCGAN model could generate more synthetic data related to crashes to balance the dataset. All non-crash data could be used for developing the prediction models. To capture the correlations between different variables, the data are augmented to 2-D matrix as the input for the DCGAN model. The suggested model is evaluated based on data from expressways and compared to two counterparts: (1) synthetic minority over-sampling technique (SMOTE); (2) random undersampling technique. The results suggest that the DCGAN could better understand the crash data characteristics by generating data with better fit of the real data distribution. Four different crash prediction algorithms (i.e., logistic regression model, support vector machine, artificial neural network, and convolutional neural network) are developed based on each balanced data and totally twelve models were estimated. The results indicate that the convolutional neural network model based on the DCGAN balanced data could provide the best prediction accuracy, validating that the proposed oversampling method could be used for the data balance. Besides, compared to other two models, only the DCGAN-based model could identify the significant effects of speed difference between the upstream and downstream locations which could help guide traffic management strategies. With the prediction model developed based on the balanced data by DCGAN, it is expected that more crashes could be predicted and prevented with more appropriate proactive traffic safety management strategies such as Variable Speed Limits (VSL) and Dynamic Message Signs (DMS). © 2020";Not health related;0"Santos T.; Schrunner S.; Geiger B.C.; Pfeiler O.; Zernig A.; Kaestner A.; Kern R.";Feature Extraction from Analog Wafermaps: A Comparison of Classical Image Processing and a Deep Generative Model;2019;Semiconductor manufacturing is a highly innovative branch of industry, where a high degree of automation has already been achieved. For example, devices tested to be outside of their specifications in electrical wafer test are automatically scrapped. In this paper, we go one step further and analyze test data of devices still within the limits of the specification, by exploiting the information contained in the analog wafermaps. To that end, we propose two feature extraction approaches with the aim to detect patterns in the wafer test dataset. Such patterns might indicate the onset of critical deviations in the production process. The studied approaches are: 1) classical image processing and restoration techniques in combination with sophisticated feature engineering and 2) a data-driven deep generative model. The two approaches are evaluated on both a synthetic and a real-world dataset. The synthetic dataset has been modeled based on real-world patterns and characteristics. We found both approaches to provide similar overall evaluation metrics. Our in-depth analysis helps to choose one approach over the other depending on data availability as a major aspect, as well as on available computing power and required interpretability of the results. © 1988-2012 IEEE.;Not health related;0"Salazar A.; Vergara L.; Serrano A.; Igual J.";A general procedure for learning mixtures of independent component analyzers;2010;This paper presents a new procedure for learning mixtures of independent component analyzers. The procedure includes non-parametric estimation of the source densities, supervised-unsupervised learning of the model parameters, incorporation of any independent component analysis (ICA) algorithm into the learning of the ICA mixtures, and estimation of residual dependencies after training for correction of the posterior probability of every class to the testing observation vector. We demonstrate the performance of the procedure in the classification of ICA mixtures of two, three, and four classes of synthetic data, and in the classification of defective materials, consisting of 3D finite element models and lab specimens, in non-destructive testing using the impact-echo technique. The application of the proposed posterior probability correction demonstrates an improvement in the classification accuracy. Semi-supervised learning shows that unlabeled data can degrade the performance of the classifier when they do not fit the generative model. Comparative results of the proposed method and standard ICA algorithms for blind source separation in one and multiple ICA data mixtures show the suitability of the non-parametric ICA mixture-based method for data modeling. © 2009 Elsevier Ltd. All rights reserved.;Not health related;0"Hufnagel H.; Pennec X.; Ehrhardt J.; Ayache N.; Handels H.";Computation of a probabilistic statistical shape model in maximum-a-posteriori framework;2009;Objectives: When analyzing shapes and shape variabilities, the first step is bringing those shapes into correspondence. This is a fundamental problem even when solved by manually determining exact correspondences such as landmarks. We developed a method to represent a mean shape and a variability model for a training data set based on probabilistic correspondence computed between the observations. Methods: First the observations are matched on each other with an affine transformation found by the Expectation-Maximization Iterative- Closest-Points (EM-ICP) registration. We then propose a maximum-a-posteriori (MAP) framework in order to compute the statistical shape model (SSM) parameters which result in an optimal adaptation of the model to the observations. The optimization of the MAP explanation is realized with respect to the observation parameters and the generative model parameters in a global criterion and leads to very efficient and closed-form solutions for (almost) all parameters. Results: We compared our probabilistic SSM to a SSM based on one-to-one correspondences and the PCA (classical SSM). Experiments on synthetic data served to test the performances on non-convex shapes (15 training shapes) which have proved difficult in terms of proper correspondence determination. We then computed the SSMs for real putamen data (21 training shapes). The evaluation was done by measuring the generalization ability as well as the specificity of both SSMs and showed that especially shape detail differences are better modeled by the probabilistic SSM (Hausdorff distance in generalization ability≈ 25% smaller). Conclusions: The experimental outcome shows the efficiency and advantages of the new approach as the probabilistic SSM performs better in modeling shape details and differences. © 2009 Schattauer.;Not health related;0Bouguila N.;Bayesian hybrid generative discriminative learning based on finite Liouville mixture models;2011;Recently hybrid generative discriminative approaches have emerged as an efficient knowledge representation and data classification engine. However, little attention has been devoted to the modeling and classification of non-Gaussian and especially proportional vectors. Our main goal, in this paper, is to discover the true structure of this kind of data by building probabilistic kernels from generative mixture models based on Liouville family, from which we develop the Beta-Liouville distribution, and which includes the well-known Dirichlet as a special case. The Beta-Liouville has a more general covariance structure than the Dirichlet which makes it more practical and useful. Our learning technique is based on a principled purely Bayesian approach which resulted models are used to generate support vector machine (SVM) probabilistic kernels based on information divergence. In particular, we show the existence of closed-form expressions of the KullbackLeibler and Rnyi divergences between two Beta-Liouville distributions and then between two Dirichlet distributions as a special case. Through extensive simulations and a number of experiments involving synthetic data, visual scenes and texture images classification, we demonstrate the effectiveness of the proposed approaches. © 2010 Elsevier Ltd. All rights reserved.;Not health related;0"Yin H.; Cui B.; Sun Y.; Hu Z.; Chen L.";LCARS: A spatial item recommender system;2014;Newly emerging location-based and event-based social network services provide us with a new platform to understand users' preferences based on their activity history. A user can only visit a limited number of venues/events and most of them are within a limited distance range, so the user-item matrix is very sparse, which creates a big challenge to the traditional collaborative filtering-based recommender systems. The problem becomes even more challenging when people travel to a new city where they have no activity information. In this article, we propose LCARS, a location-content-Aware recommender system that offers a particular user a set of venues (e.g., restaurants and shopping malls) or events (e.g., concerts and exhibitions) by giving consideration to both personal interest and local preference. This recommender system can facilitate people's travel not only near the area in which they live, but also in a city that is new to them. Specifically, LCARS consists of two components: offline modeling and online recommendation. The offline modeling part, called LCA-LDA, is designed to learn the interest of each individual user and the local preference of each individual city by capturing item cooccurrence patterns and exploiting item contents. The online recommendation part takes a querying user along with a querying city as input, and automatically combines the learned interest of the querying user and the local preference of the querying city to produce the topk recommendations. To speed up the online process, a scalable query processing technique is developed by extending both the Threshold Algorithm (TA) and TA-Approximation algorithm.We evaluate the performance of our recommender system on two real datasets, that is, DoubanEvent and Foursquare, and one large-scale synthetic dataset. The results show the superiority of LCARS in recommending spatial items for users, especially when traveling to new cities, in terms of both effectiveness and efficiency. Besides, the experimental analysis results also demonstrate the excellent interpretability of LCARS.;Not health related;0"Gauvin L.; Panisson A.; Cattuto C.; Barrat A.";Activity clocks: Spreading dynamics on temporal networks of human contact;2013;Dynamical processes on time-varying complex networks are key to understanding and modeling a broad variety of processes in socio-technical systems. Here we focus on empirical temporal networks of human proximity and we aim at understanding the factors that, in simulation, shape the arrival time distribution of simple spreading processes. Abandoning the notion of wall-clock time in favour of node-specific clocks based on activity exposes robust statistical patterns in the arrival times across different social contexts. Using randomization strategies and generative models constrained by data, we show that these patterns can be understood in terms of heterogeneous inter-event time distributions coupled with heterogeneous numbers of events per edge. We also show, both empirically and by using a synthetic dataset, that significant deviations from the above behavior can be caused by the presence of edge classes with strong activity correlations.;Not health related;0"El-Attar A.; Pigeau A.; Gelgon M.";Robust estimation of a global Gaussian mixture by decentralized aggregations of local models;2013;Distributed data collections are now more and more common due to the emergence of cloud computing, to spatially decentralized businesses, or to the availability of various data sharing web services. Obtain knowledge in such a collection raises then the need of new data mining methods to apply in a decentralized architecture. In this paper, we explore a machine learning side of this work direction. We propose a novel technique for decentralized estimation of probabilistic mixture models, which are among the most versatile generative models for understanding data sets. More precisely, we demonstrate how to estimate a global mixture model from a set of local models. Our approach accommodates dynamic topology and data sources and is statistically robust, i.e. resilient to the presence of unreliable local models. Such outlier models may arise from local data which are outliers, compared to the global trend, or poor mixture estimation. We report experiments on synthetic data and real geo-location data from Flickr. © 2013 - IOS Press and the authors. All rights reserved.;Not health related;0Pulkkinen S.;Ridge-based method for finding curvilinear structures from noisy data;2015;Extraction of curvilinear structures from noisy data is an essential task in many application fields such as data analysis, pattern recognition and machine vision. The proposed approach assumes a random process in which the samples are obtained from a generative model. The model specifies a set of generating functions describing curvilinear structures as well as sampling noise and background clutter. It is shown that ridge curves of the marginal density induced by the model can be used to estimate the generating functions. Given a Gaussian kernel density estimate for the marginal density, ridge curves of the density estimate are parametrized as the solution to a differential equation. Finally, a predictor-corrector algorithm for tracing the ridge curve set of such a density estimate is developed. Efficiency and robustness of the algorithm are demonstrated by numerical experiments on synthetic datasets as well as observational datasets from seismology and cosmology. © 2014 Elsevier B.V. All rights reserved.;Not health related;0"Barbosa D.; Mendelzon A.O.";Declarative generation of synthetic XML data;2006;Synthetic data can be extremely useful in testing and evaluating algorithms, tools and systems. Most synthetic data generators available today are the result of individual benchmarking efforts. Typically, these are complex programs in which the specifications of both the structure and the contents of the data are hard-coded. As a result, it is often difficult to customize these tools for producing synthetic data tailored for specific needs. In this article, we describe the ToXgene synthetic data generator, which is a declarative tool for generating realistic XML data for benchmarking as well as testing purposes. We present our template specification language, which consists of augmenting XML Schema with probabilistic models that guide the data-generation process. We discuss the architecture of our current implementation and we argue about ToXgene's usefulness by discussing experimental results as well as describing two projects that use our tool. Copyright © 2006 John Wiley & Sons, Ltd.;Not health related;0"Islam F.; Nath B.; Kamruzzaman J.";Reactive load control of parallel transformer operations using neural networks;2002;Artificial Neural Network (ANN) is used in various fields including control and analysis of power systems. ANN in its learning process establishes the relationship between input variables by means of its weights updating, and provides a good response to another nonidentical but similar input. This paper proposes the use of neural network to control the on-load tap changer of parallel operation of two transformers supplying power to a local area. For simplicity, only two transformers are considered although operation of multiple transformers can be dealt with in a similar manner. A synthetic data set relating to tap changer operation sequence was used for training a backpropagation network to decide automatically on transformer.s on-load tap changer whether to raise, lower or hold the same desired position. Preliminary results show that a trained neural network can be successfully used for on load tap changing operation of transformers. © Springer-Verlag Berlin Heidelberg 2002.;Not health related;0"Gong J.; Fan G.; Yu L.; Havlicek J.P.; Chen D.; Fan N.";Joint view-identity manifold for infrared target tracking and recognition;2014;We propose a new joint view-identity manifold (JVIM) for multi-view and multi-target shape modeling that is well-suited for automated target tracking and recognition (ATR) in infrared imagery. As a shape generative model, JVIM features a novel manifold structure that imposes a conditional dependency between the two shape-related factors, view and identity, in a unified latent space, which is embedded with one view-independent identity manifold and infinite identity-dependent view manifolds. A modified local linear Gaussian process latent variable model (LL-GPLVM) is proposed for JVIM learning where a stochastic gradient descent method is used to improve the learning efficiency. We also develop a local inference technique to speed up JVIM-based shape interpolation. Due to its probabilistic and continuous nature, JVIM provides effective shape synthesis and supports robust ATR inference for both known and unknown target types under arbitrary views. Experiments on both synthetic data and the SENSIAC infrared ATR database demonstrate the advantages of the proposed method over several existing techniques both qualitatively and quantitatively. © 2013 Elsevier Inc. All rights reserved.;Not health related;0"Liang T.; Fan X.; Li Q.; Li S.-Y.R.";Detection of dispersed short tandem repeats using reversible jump Markov chain Monte Carlo;2012;Tandem repeats occur frequently in biological sequences. They are important for studying genome evolution and human disease. A number of methods have been designed to detect a single tandem repeat in a sliding window. In this article, we focus on the case that an unknown number of tandem repeat segments of the same pattern are dispersively distributed in a sequence. We construct a probabilistic generative model for the tandem repeats, where the sequence pattern is represented by a motif matrix. A Bayesian approach is adopted to compute this model. Markov chain Monte Carlo (MCMC) algorithms are used to explore the posterior distribution as an effort to infer both the motif matrix of tandem repeats and the location of repeat segments. Reversible jump Markov chain Monte Carlo (RJMCMC) algorithms are used to address the transdimensional model selection problem raised by the variable number of repeat segments. Experiments on both synthetic data and real data show that this new approach is powerful in detecting dispersed short tandem repeats. As far as we know, it is the first work to adopt RJMCMC algorithms in the detection of tandem repeats. © 2012 The Author(s).;Health related;0"Daunizeau J.; Grova C.; Marrelec G.; Mattout J.; Jbabdi S.; Pélégrini-Issac M.; Lina J.-M.; Benali H.";Symmetrical event-related EEG/fMRI information fusion in a variational Bayesian framework;2007;In this work, we propose a symmetrical multimodal EEG/fMRI information fusion approach dedicated to the identification of event-related bioelectric and hemodynamic responses. Unlike existing, asymmetrical EEG/fMRI data fusion algorithms, we build a joint EEG/fMRI generative model that explicitly accounts for local coupling/uncoupling of bioelectric and hemodynamic activities, which are supposed to share a common substrate. Under a dedicated assumption of spatio-temporal separability, the spatial profile of the common EEG/fMRI sources is introduced as an unknown hierarchical prior on both markers of cerebral activity. Thereby, a devoted Variational Bayesian (VB) learning scheme is derived to infer common EEG/fMRI sources from a joint EEG/fMRI dataset. This yields an estimate of the common spatial profile, which is built as a trade-off between information extracted from EEG and fMRI datasets. Furthermore, the spatial structure of the EEG/fMRI coupling/uncoupling is learned exclusively from the data. The proposed data generative model and devoted VBEM learning scheme thus provide an un-supervised well-balanced approach for the fusion of EEG/fMRI information. We first demonstrate our approach on synthetic data. Results show that, in contrast to classical EEG/fMRI fusion approach, the method proved efficient and robust regardless of the EEG/fMRI discordance level. We apply the method on EEG/fMRI recordings from a patient with epilepsy, in order to identify brain areas involved during the generation of epileptic spikes. The results are validated using intracranial EEG measurements. © 2007 Elsevier Inc. All rights reserved.;Not health related;1"Messe A.; Benali H.; Marrelec G.";Relating structural and functional connectivity in MRI: A simple model for a complex brain;2015;Advances in magnetic resonance imaging (MRI) allow to gain critical insight into the structure of neural networks and their functional dynamics. To relate structural connectivity [as quantified by diffusion-weighted imaging (DWI) tractography] and functional connectivity [as obtained from functional MRI (fMRI)], increasing emphasis has been put on computational models of brain activity. In the present study, we use structural equation modeling (SEM) with structural connectivity to predict functional connectivity. The resulting model takes the simple form of a spatial simultaneous autoregressive model (sSAR), whose parameters can be estimated in a Bayesian framework. On synthetic data, results showed very good accuracy and reliability of the inference process. On real data, we found that the sSAR performed significantly better than two other reference models as well as than structural connectivity alone, but that the Bayesian procedure did not bring significant improvement in fit compared to two simpler approaches. Nonetheless, we also found that the values of the region-specific parameters inferred using Bayesian inference differed significantly across resting-state networks. These results demonstrate 1) that a simple abstract model is able to perform better that more complex models based on more realistic assumptions, 2) that the parameters of the sSAR can be estimated and can potentially be used as biomarkers, but also 3) that the sSAR, while being the best-performing model, is at best still a very crude model of the relationship between structure and function in MRI. © 1982-2012 IEEE.;Not health related;1"Daunizeau J.; Friston K.J.";A mesostate-space model for EEG and MEG;2007;We present a multi-scale generative model for EEG, that entails a minimum number of assumptions about evoked brain responses, namely: (1) bioelectric activity is generated by a set of distributed sources, (2) the dynamics of these sources can be modelled as random fluctuations about a small number of mesostates, (3) mesostates evolve in a temporal structured way and are functionally connected (i.e. influence each other), and (4) the number of mesostates engaged by a cognitive task is small (e.g. between one and a few). A Variational Bayesian learning scheme is described that furnishes the posterior density on the models parameters and its evidence. Since the number of meso-sources specifies the model, the model evidence can be used to compare models and find the optimum number of meso-sources. In addition to estimating the dynamics at each cortical dipole, the mesostate-space model and its inversion provide a description of brain activity at the level of the mesostates (i.e. in terms of the dynamics of meso-sources that are distributed over dipoles). The inclusion of a mesostate level allows one to compute posterior probability maps of each dipole being active (i.e. belonging to an active mesostate). Critically, this model accommodates constraints on the number of meso-sources, while retaining the flexibility of distributed source models in explaining data. In short, it bridges the gap between standard distributed and equivalent current dipole models. Furthermore, because it is explicitly spatiotemporal, the model can embed any stochastic dynamical causal model (e.g. a neural mass model) as a Markov process prior on the mesostate dynamics. The approach is evaluated and compared to standard inverse EEG techniques, using synthetic data and real data. The results demonstrate the added-value of the mesostate-space model and its variational inversion. © 2007 Elsevier Inc. All rights reserved.;Not health related;1"Kiebel S.J.; Klöppel S.; Weiskopf N.; Friston K.J.";Dynamic causal modeling: A generative model of slice timing in fMRI;2007;Dynamic causal modeling (DCM) of functional magnetic resonance imaging (fMRI) data allows one to make inferences about the architecture of distributed networks in the brain, in terms of effective connectivity. fMRI data are usually acquired using echo planar imaging (EPI). EPI sequences typically acquire slices at different times over a few seconds. DCM, in its original inception, was not informed about these slice timings and assumed that all slices were acquired simultaneously. It has been shown that DCM can cope with slice timing differences of up to 1 s. However, many fMRI studies employ a repetition time (TR) of 3 to 5 s, which precludes a straightforward DCM of these data. We show that this limitation can be overcome easily by including slice timing in the DCM. Using synthetic data we show that the extended DCM furnishes veridical posterior means, even if there are large slice-timing differences. Model comparisons show that, in general, the extended DCM out-performs the original model. We contrast the modeling of slice timing, in the context of DCM, with the less effective approach of 'slice-timing correction', prior to modeling. We apply our procedure to real data and show that slice timings are important parameters. We conclude that, generally, one should use DCM with slice timing. © 2006 Elsevier Inc. All rights reserved.;Not health related;1"Dabrowski J.J.; De Villiers J.P.";Maritime piracy situation modelling with dynamic Bayesian networks;2015;A generative model for modelling maritime vessel behaviour is proposed. The model is a novel variant of the dynamic Bayesian network (DBN). The proposed DBN is in the form of a switching linear dynamic system (SLDS) that has been extended into a larger DBN. The application of synthetic data fabrication of maritime vessel behaviour is considered. Behaviour of various vessels in a maritime piracy situation is simulated. A means to integrate information from context based external factors that influence behaviour is provided. Simulated observations of the vessels kinematic states are generated. The generated data may be used for the purpose of developing and evaluating counter-piracy methods and algorithms. A novel methodology for evaluating and optimising behavioural models such as the proposed model is presented. The log-likelihood, cross entropy, Bayes factor and the Bhattacharyya distance measures are applied for evaluation. The results demonstrate that the generative model is able to model both spatial and temporal datasets. © 2014 Elsevier B.V. All rights reserved.;Not health related;0"Sabuncu M.R.; Balci S.K.; Golland P.; Shenton M.E.";Image-Driven Population Analysis Through Mixture Modeling;2009;We present iCluster, a fast and efficient algorithm that clusters a set of images while co-registering them using a parameterized, nonlinear transformation model. The output of the algorithm is a small number of template images that represent different modes in a population. This is in contrast with traditional, hypothesis-driven computational anatomy approaches that assume a single template to construct an atlas. We derive the algorithm based on a generative model of an image population as a mixture of deformable template images. We validate and explore our method in four experiments. In the first experiment, we use synthetic data to explore the behavior of the algorithm and inform a design choice on parameter settings. In the second experiment, we demonstrate the utility of having multiple atlases for the application of localizing temporal lobe brain structures in a pool of subjects that contains healthy controls and schizophrenia patients. Next, we employ iCluster to partition a data set of 415 whole brain MR volumes of subjects aged 18 through 96 years into three anatomical subgroups. Our analysis suggests that these subgroups mainly correspond to age groups. The templates reveal significant structural differences across these age groups that confirm previous findings in aging research. In the final experiment, we run iCluster on a group of 15 patients with dementia and 15 age-matched healthy controls. The algorithm produces two modes, one of which contains dementia patients only. These results suggest that the algorithm can be used to discover subpopulations that correspond to interesting structural or functional “modes”. © 2009, IEEE. All rights reserved.;Health related;1"Harrison L.M.; David O.; Friston K.J.";Stochastic models of neuronal dynamics;2005;Cortical activity is the product of interactions among neuronal populations. Macroscopic electrophysiological phenomena are generated by these interactions. In principle, the mechanisms of these interactions afford constraints on biologically plausible models of electrophysiological responses. In other words, the macroscopic features of cortical activity can be modelled in terms of the microscopic behaviour of neurons. An evoked response potential (ERP) is the mean electrical potential measured from an electrode on the scalp, in response to some event. The purpose of this paper is to outline a population density approach to modelling ERPs. We propose a biologically plausible model of neuronal activity that enables the estimation of physiologically meaningful parameters from electrophysiological data. The model encompasses four basic characteristics of neuronal activity and organization: (i) neurons are dynamic units, (ii) driven by stochastic forces, (iii) organized into populations with similar biophysical properties and response characteristics and (iv) multiple populations interact to form functional networks. This leads to a formulation of population dynamics in terms of the Fokker-Planck equation. The solution of this equation is the temporal evolution of a probability density over state-space, representing the distribution of an ensemble of trajectories. Each trajectory corresponds to the changing state of a neuron. Measurements can be modelled by taking expectations over this density, e.g. mean membrane potential, firing rate or energy consumption per neuron. The key motivation behind our approach is that ERPs represent an average response over many neurons. This means it is sufficient to model the probability density over neurons, because this implicitly models their average state. Although the dynamics of each neuron can be highly stochastic, the dynamics of the density is not. This means we can use Bayesian inference and estimation tools that have already been established for deterministic systems. The potential importance of modelling density dynamics (as opposed to more conventional neural mass models) is that they include interactions among the moments of neuronal states (e.g. the mean depolarization may depend on the variance of synaptic currents through nonlinear mechanisms). Here, we formulate a population model, based on biologically informed model-neurons with spike-rate adaptation and synaptic dynamics. Neuronal sub-populations are coupled to form an observation model, with the aim of estimating and making inferences about coupling among sub-populations using real data. We approximate the time-dependent solution of the system using a bi-orthogonal set and first-order perturbation expansion. For didactic purposes, the model is developed first in the context of deterministic input, and then extended to include stochastic effects. The approach is demonstrated using synthetic data, where model parameters are identified using a Bayesian estimation scheme we have described previously. © 2005 The Royal Society.;Not health related;1"Luessi M.; Babacan S.D.; Molina R.; Booth J.R.; Katsaggelos A.K.";Bayesian symmetrical EEG/fMRI fusion with spatially adaptive priors;2011;In this paper, we propose a novel symmetrical EEG/fMRI fusion method which combines EEG and fMRI by means of a common generative model. We use a total variation (TV) prior to model the spatial distribution of the cortical current responses and hemodynamic response functions, and utilize spatially adaptive temporal priors to model their temporal shapes. The spatial adaptivity of the prior model allows for adaptation to the local characteristics of the estimated responses and leads to high estimation performance for the cortical current distribution and the hemodynamic response functions. We utilize a Bayesian formulation with a variational Bayesian framework and obtain a fully automatic fusion algorithm. Simulations with synthetic data and experiments with real data from a multimodal study on face perception demonstrate the performance of the proposed method. © 2010 Elsevier Inc.;Not health related;1"Iwata T.; Yamada T.; Ueda N.";Modeling noisy annotated data with application to social annotation;2013;We propose a probabilistic topic model for analyzing and extracting content-related annotations from noisy annotated discrete data such as webpages stored using social bookmarking services. With these services, because users can attach annotations freely, some annotations do not describe the semantics of the content, thus they are noisy, i.e., not content related. The extraction of content-related annotations can be used as a prepossessing step in machine learning tasks such as text classification and image recognition, or can improve information retrieval performance. The proposed model is a generative model for content and annotations, in which the annotations are assumed to originate either from topics that generated the content or from a general distribution unrelated to the content. We demonstrate the effectiveness of the proposed method by using synthetic data and real social annotation data for text and images. © 1989-2012 IEEE.;Not health related;0"Huang A.; Liu H.-M.; Lee C.-W.; Yang C.-Y.; Tsang Y.-M.";On concise 3-D simple point characterizations: A marching cubes paradigm;2009;"The centerlines of tubular structures are useful for medical image visualization and computer-aided diagnosis applications. They can be effectively extracted by using a thinning algorithm that erodes an object layer by layer until only a skeleton is left. An object point is ""simple"" and can be safely deleted only if the resultant image is topologically equivalent to the original. Numerous characterizations of 3-D simple points based on digital topology already exist. However, little work has been done in the context of marching cubes (MC). This paper reviews several concise 3-D simple point characterizations in a MC paradigm. By using the Euler characteristic and a few newly observed properties in the context of connectivity-consistent MC, we present concise and more self-explanatory proofs. We also present an efficient method for computing the Euler characteristic locally for MC surfaces. Performance evaluations on different implementations are conducted on synthetic data and multidetector computed tomography examination of virtual colonoscopy and angiography. © 2006 IEEE.";Health related;0"Üstünda_ A.; Zahn M.";Finite element based Kerr electro-optic reconstruction of space charge;2001;Recently we used the onion peeling method to reconstruct the axisymmetric electric field distribution of point/plane electrodes from Kerr electro-optic measurements. The method accurately reconstructed the electric field from numerically generated data. However in the presence of experimental noise the performance was less satisfactory. The measurements were especially noisy and unstable near the needle tip which is also the interesting region since most charge injection initiates here. We develop a new algorithm for Kerr electro-optic reconstruction of space charge in axisymmetric point/plane electrode geometries. The algorithm is built on the finite element method (FEM) for Poisson's equation and will be called finite element based Kerr electro-optic reconstruction (FEBKER) hereafter. FEBKER calculates the space charge density directly to avoid the numerical problems associated with taking the divergence of the electric field, uses single parameter light intensity measurements to enable transient analysis, which otherwise is difficult since multiple parameter intensity measurements are slow due to the rotation of polarizers, and is capable of reconstruction even when the number and/or position of measurements are limited by the electrodes and/or the experimental setup. The performance of the algorithm is tested on synthetic Kerr electro-optic data obtained for an axisymmetric point/plane electrode geometry in transformer oil with specified space charge density distributions. The impact of experimental error is analyzed by incorporating random error to the synthetic data. Regularization techniques that decrease the impact of experimental error are applied. In principle FEBKER is applicable to arbitrary three-dimensional geometries as well.;Not health related;0