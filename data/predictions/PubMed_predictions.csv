Authors;Title;Abstract; Year;Mig Review;GPT4 Review;Predicted Label
Castillo-Hair SM, Seelig G.;Machine Learning for Designing Next-Generation mRNA Therapeutics;"Over just the last 2 years, mRNA therapeutics and vaccines have undergone a 
rapid transition from an intriguing concept to real-world impact. However, 
whereas some aspects of mRNA therapeutics, such as the use of chemical 
modifications to increase stability and reduce immunogenicity, have been 
extensively optimized for over two decades, other aspects, particularly the 
selection and design of the noncoding leader and trailer sequences which control 
translation efficiency and stability, have received comparably less attention. 
In practice, such 5' and 3' untranslated regions (UTRs) are often borrowed from 
highly expressed human genes with few or no modifications, as in the case for 
the Pfizer/BioNTech Covid vaccine. Focusing on the 5'UTR, we here argue that 
model-driven design is a promising alternative that provides unprecedented 
control over 5'UTR function. We review recent work that combines synthetic 
biology with machine learning to build quantitative models that relate ribosome 
loading, and thus translation efficiency, to the 5'UTR sequence. We first 
introduce an experimental approach that uses polysome profiling and 
high-throughput sequencing to quantify ribosome loading for hundreds of 
thousands of 5'UTRs in parallel. We apply this approach to measure ribosome 
loading in synthetic RNA libraries with a random sequence inserted into the 
5'UTR. We then review Optimus 5-Prime, a convolutional neural network model 
trained on the experimental data. We highlight that very accurate models of 
biological regulation can be learned from synthetic data sets with degenerate 
5'UTRs. We validate model predictions not only on held-out data sets from our 
random library but also on a large library of over 30_000 human 5'UTR fragments 
and using translation reporter data collected independently by other groups. 
Both the experiment and model are compatible with commonly used chemically 
modified nucleosides, in particular, pseudouridine (_) and 
1-methyl-pseudouridine (m1_). We find that, in general, 5'UTRs have very similar 
impacts when combined with different protein-coding sequences and even in the 
context of different chemical modifications. We demonstrate that Optimus 5-Prime 
can be combined with design algorithms to generate de novo sequences with 
precisely defined translation efficiencies. We emphasize recent developments in 
design algorithms that rely on activation maximization and generative modeling 
to improve both the fitness and diversity of designed sequences. Compared with 
prior approaches such as genetic algorithms, we show that these approaches are 
not only faster but also less likely to get stuck in local sequence optima. 
Finally, we discuss how the approach reviewed here can be generalized to other 
gene regions and applications.";2022;Not health related;Health related;1
Nußberger J, Boesel F, Lenz S, Binder H, Hess M.;Synthetic observations from deep generative models and binary omics data with limited sample size;"Deep generative models can be trained to represent the joint distribution of 
data, such as measurements of single nucleotide polymorphisms (SNPs) from 
several individuals. Subsequently, synthetic observations are obtained by 
drawing from this distribution. This has been shown to be useful for several 
tasks, such as removal of noise, imputation, for better understanding underlying 
patterns, or even exchanging data under privacy constraints. Yet, it is still 
unclear how well these approaches work with limited sample size. We investigate 
such settings specifically for binary data, e.g. as relevant when considering 
SNP measurements, and evaluate three frequently employed generative modeling 
approaches, variational autoencoders (VAEs), deep Boltzmann machines (DBMs) and 
generative adversarial networks (GANs). This includes conditional approaches, 
such as when considering gene expression conditional on SNPs. Recovery of 
pair-wise odds ratios (ORs) is considered as a primary performance criterion. 
For simulated as well as real SNP data, we observe that DBMs generally can 
recover structure for up to 300 variables, with a tendency of over-estimating 
ORs when not carefully tuned. VAEs generally get the direction and relative 
strength of pairwise relations right, yet with considerable under-estimation of 
ORs. GANs provide stable results only with larger sample sizes and strong 
pair-wise relations in the data. Taken together, DBMs and VAEs (in contrast to 
GANs) appear to be well suited for binary omics data, even at rather small 
sample sizes. This opens the way for many potential applications where synthetic 
observations from omics data might be useful.";2021;Not health related;Not Health related;0
Treppner M, Salas-Bastos A, Hess M, Lenz S, Vogel T, Binder H.;Synthetic single cell RNA sequencing data from small pilot studies using deep generative models;"Deep generative models, such as variational autoencoders (VAEs) or deep 
Boltzmann machines (DBMs), can generate an arbitrary number of synthetic 
observations after being trained on an initial set of samples. This has mainly 
been investigated for imaging data but could also be useful for single-cell 
transcriptomics (scRNA-seq). A small pilot study could be used for planning a 
full-scale experiment by investigating planned analysis strategies on synthetic 
data with different sample sizes. It is unclear whether synthetic observations 
generated based on a small scRNA-seq dataset reflect the properties relevant for 
subsequent data analysis steps. We specifically investigated two deep generative 
modeling approaches, VAEs and DBMs. First, we considered single-cell variational 
inference (scVI) in two variants, generating samples from the posterior 
distribution, the standard approach, or the prior distribution. Second, we 
propose single-cell deep Boltzmann machines (scDBMs). When considering the 
similarity of clustering results on synthetic data to ground-truth clustering, 
we find that the [Formula: see text] variant resulted in high variability, most 
likely due to amplifying artifacts of small datasets. All approaches showed 
mixed results for cell types with different abundance by overrepresenting highly 
abundant cell types and missing less abundant cell types. With increasing pilot 
dataset sizes, the proportions of the cells in each cluster became more similar 
to that of ground-truth data. We also showed that all approaches learn the 
univariate distribution of most genes, but problems occurred with bimodality. 
Across all analyses, in comparing 10[Formula: see text] Genomics and Smart-seq2 
technologies, we could show that for 10[Formula: see text] datasets, which have 
higher sparsity, it is more challenging to make inference from small to larger 
datasets. Overall, the results show that generative deep learning approaches 
might be valuable for supporting the design of scRNA-seq experiments.";2021;Not health related;Not Health related;0
Schaudt D, Späte C, von Schwerin R, Reichert M, von Schwerin M, Beer M, Kloth C.;A Critical Assessment of Generative Models for Synthetic Data Augmentation on Limited Pneumonia X-ray Data;"In medical imaging, deep learning models serve as invaluable tools for 
expediting diagnoses and aiding specialized medical professionals in making 
clinical decisions. However, effectively training deep learning models typically 
necessitates substantial quantities of high-quality data, a resource often 
lacking in numerous medical imaging scenarios. One way to overcome this 
deficiency is to artificially generate such images. Therefore, in this 
comparative study we train five generative models to artificially increase the 
amount of available data in such a scenario. This synthetic data approach is 
evaluated on a a downstream classification task, predicting four causes for 
pneumonia as well as healthy cases on 1082 chest X-ray images. Quantitative and 
medical assessments show that a Generative Adversarial Network (GAN)-based 
approach significantly outperforms more recent diffusion-based approaches on 
this limited dataset with better image quality and pathological plausibility. We 
show that better image quality surprisingly does not translate to improved 
classification performance by evaluating five different classification models 
and varying the amount of additional training data. Class-specific metrics like 
precision, recall, and F1-score show a substantial improvement by using 
synthetic images, emphasizing the data rebalancing effect of less frequent 
classes. However, overall performance does not improve for most models and 
configurations, except for a DreamBooth approach which shows a +0.52 improvement 
in overall accuracy. The large variance of performance impact in this study 
suggests a careful consideration of utilizing generative models for limited data 
scenarios, especially with an unexpected negative correlation between image 
quality and downstream classification improvement.";2023;Health related;Health related;1
Goncalves A, Ray P, Soper B, Stevens J, Coyle L, Sales AP.;Generation and evaluation of synthetic patient data;"Machine learning (ML) has made a significant impact in medicine and 
cancer research; however, its impact in these areas has been undeniably slower 
and more limited than in other application domains. A major reason for this has 
been the lack of availability of patient data to the broader ML research 
community, in large part due to patient privacy protection concerns. 
High-quality, realistic, synthetic datasets can be leveraged to accelerate 
methodological developments in medicine. By and large, medical data is high 
dimensional and often categorical. These characteristics pose multiple modeling 
challenges.
METHODS: In this paper, we evaluate three classes of synthetic data generation 
approaches; probabilistic models, classification-based imputation models, and 
generative adversarial neural networks. Metrics for evaluating the quality of 
the generated synthetic datasets are presented and discussed.
RESULTS: While the results and discussions are broadly applicable to medical 
data, for demonstration purposes we generate synthetic datasets for cancer based 
on the publicly available cancer registry data from the Surveillance 
Epidemiology and End Results (SEER) program. Specifically, our cohort consists 
of breast, respiratory, and non-solid cancer cases diagnosed between 2010 and 
2015, which includes over 360,000 individual cases.
CONCLUSIONS: We discuss the trade-offs of the different methods and metrics, 
providing guidance on considerations for the generation and usage of medical 
synthetic data.";2020;Health related;Health related;1
El Emam K, Mosquera L, Bass J.;Evaluating Identity Disclosure Risk in Fully Synthetic Health Data: Model Development and Validation;"There has been growing interest in data synthesis for enabling the 
sharing of data for secondary analysis; however, there is a need for a 
comprehensive privacy risk model for fully synthetic data: If the generative 
models have been overfit, then it is possible to identify individuals from 
synthetic data and learn something new about them.
OBJECTIVE: The purpose of this study is to develop and apply a methodology for 
evaluating the identity disclosure risks of fully synthetic data.
METHODS: A full risk model is presented, which evaluates both identity 
disclosure and the ability of an adversary to learn something new if there is a 
match between a synthetic record and a real person. We term this ""meaningful 
identity disclosure risk."" The model is applied on samples from the Washington 
State Hospital discharge database (2007) and the Canadian COVID-19 cases 
database. Both of these datasets were synthesized using a sequential decision 
tree process commonly used to synthesize health and social science data.
RESULTS: The meaningful identity disclosure risk for both of these synthesized 
samples was below the commonly used 0.09 risk threshold (0.0198 and 0.0086, 
respectively), and 4 times and 5 times lower than the risk values for the 
original datasets, respectively.
CONCLUSIONS: We have presented a comprehensive identity disclosure risk model 
for fully synthetic data. The results for this synthesis method on 2 datasets 
demonstrate that synthesis can reduce meaningful identity disclosure risks 
considerably. The risk model can be applied in the future to evaluate the 
privacy of fully synthetic data.";2020;Health related;Health related;1
Lenz S, Hess M, Binder H.;Deep generative models in DataSHIELD;"The best way to calculate statistics from medical data is to use the 
data of individual patients. In some settings, this data is difficult to obtain 
due to privacy restrictions. In Germany, for example, it is not possible to pool 
routine data from different hospitals for research purposes without the consent 
of the patients.
METHODS: The DataSHIELD software provides an infrastructure and a set of 
statistical methods for joint, privacy-preserving analyses of distributed data. 
The contained algorithms are reformulated to work with aggregated data from the 
participating sites instead of the individual data. If a desired algorithm is 
not implemented in DataSHIELD or cannot be reformulated in such a way, using 
artificial data is an alternative. Generating artificial data is possible using 
so-called generative models, which are able to capture the distribution of given 
data. Here, we employ deep Boltzmann machines (DBMs) as generative models. For 
the implementation, we use the package ""BoltzmannMachines"" from the Julia 
programming language and wrap it for use with DataSHIELD, which is based on R.
RESULTS: We present a methodology together with a software implementation that 
builds on DataSHIELD to create artificial data that preserve complex patterns 
from distributed individual patient data. Such data sets of artificial patients, 
which are not linked to real patients, can then be used for joint analyses. As 
an exemplary application, we conduct a distributed analysis with DBMs on a 
synthetic data set, which simulates genetic variant data. Patterns from the 
original data can be recovered in the artificial data using hierarchical 
clustering of the virtual patients, demonstrating the feasibility of the 
approach. Additionally, we compare DBMs, variational autoencoders, generative 
adversarial networks, and multivariate imputation as generative approaches by 
assessing the utility and disclosure of synthetic data generated from real 
genetic variant data in a distributed setting with data of a small sample size.
CONCLUSIONS: Our implementation adds to DataSHIELD the ability to generate 
artificial data that can be used for various analyses, e.g., for pattern 
recognition with deep learning. This also demonstrates more generally how 
DataSHIELD can be flexibly extended with advanced algorithms from languages 
other than R.";2021;Health related;Health related;1
Rasheed K, Qadir J, O'Brien TJ, Kuhlmann L, Razi A.;A Generative Model to Synthesize EEG Data for Epileptic Seizure Prediction;"Scarcity of good quality electroencephalography (EEG) data is one of 
the roadblocks for accurate seizure prediction. This work proposes a deep 
convolutional generative adversarial network (DCGAN) to generate synthetic EEG 
data. Another objective of our study is to use transfer-learning (TL) for 
evaluating the performance of four well-known deep-learning (DL) models to 
predict epileptic seizure.
METHODS: We proposed an algorithm that generate synthetic data using DCGAN 
trained on real EEG data in a patient-specific manner. We validate quality of 
generated data using one-class SVM and a new proposal namely convolutional 
epileptic seizure predictor (CESP). We evaluate performance of VGG16, VGG19, 
ResNet50, and Inceptionv3 trained on augmented data using TL with average time 
of 10 min between true prediction and seizure onset samples.
RESULTS: The CESP model achieves sensitivity of 78.11% and 88.21%, and false 
prediction rate of 0.27/h and 0.14/h for training on synthesized and testing on 
real Epilepsyecosystem and CHB-MIT datasets, respectively. Using TL and 
augmented data, Inceptionv3 achieved highest accuracy with sensitivity of 90.03% 
and 0.03 FPR/h. With the proposed data augmentation method prediction results of 
CESP model and Inceptionv3 increased by 4-5% as compared to state-of-the-art 
augmentation techniques.
CONCLUSION: The performance of CESP shows that synthetic data acquired 
association between features and labels very well and by using the augmented 
data CESP predicted better than chance level for both datasets.
SIGNIFICANCE: The proposed DCGAN can be used to generate synthetic data to 
increase the prediction performance and to overcome good quality data scarcity 
issue.";2021;Health related;Health related;1
Kawashima T, Hino H.;Gaussian Process Koopman Mode Decomposition;"We propose a nonlinear probabilistic generative model of Koopman mode 
decomposition based on an unsupervised gaussian process. Existing data-driven 
methods for Koopman mode decomposition have focused on estimating the quantities 
specified by Koopman mode decomposition: eigenvalues, eigenfunctions, and modes. 
Our model enables the simultaneous estimation of these quantities and latent 
variables governed by an unknown dynamical system. Furthermore, we introduce an 
efficient strategy to estimate the parameters of our model by low-rank 
approximations of covariance matrices. Applying the proposed model to both 
synthetic data and a real-world epidemiological data set, we show that various 
analyses are available using the estimated parameters.";2022;Not health related;Not Health related;0
Monachino G, Zanchi B, Fiorillo L, Conte G, Auricchio A, Tzovara A, Faraci FD.;Deep Generative Models: The winning key for large and easily accessible ECG datasets?;"Large high-quality datasets are essential for building powerful artificial 
intelligence (AI) algorithms capable of supporting advancement in cardiac 
clinical research. However, researchers working with electrocardiogram (ECG) 
signals struggle to get access and/or to build one. The aim of the present work 
is to shed light on a potential solution to address the lack of large and easily 
accessible ECG datasets. Firstly, the main causes of such a lack are identified 
and examined. Afterward, the potentials and limitations of cardiac data 
generation via deep generative models (DGMs) are deeply analyzed. These very 
promising algorithms have been found capable not only of generating large 
quantities of ECG signals but also of supporting data anonymization processes, 
to simplify data sharing while respecting patients' privacy. Their application 
could help research progress and cooperation in the name of open science. 
However several aspects, such as a standardized synthetic data quality 
evaluation and algorithm stability, need to be further explored.";2023;Health related;Health related;1
Hess M, Hackenberg M, Binder H.;Exploring generative deep learning for omics data using log-linear models;"MOTIVATION: Following many successful applications to image data, deep learning 
is now also increasingly considered for omics data. In particular, generative 
deep learning not only provides competitive prediction performance, but also 
allows for uncovering structure by generating synthetic samples. However, 
exploration and visualization is not as straightforward as with image 
applications.
RESULTS: We demonstrate how log-linear models, fitted to the generated, 
synthetic data can be used to extract patterns from omics data, learned by deep 
generative techniques. Specifically, interactions between latent representations 
learned by the approaches and generated synthetic data are used to determine 
sets of joint patterns. Distances of patterns with respect to the distribution 
of latent representations are then visualized in low-dimensional coordinate 
systems, e.g. for monitoring training progress. This is illustrated with 
simulated data and subsequently with cortical single-cell gene expression data. 
Using different kinds of deep generative techniques, specifically variational 
autoencoders and deep Boltzmann machines, the proposed approach highlights how 
the techniques uncover underlying structure. It facilitates the real-world use 
of such generative deep learning techniques to gain biological insights from 
omics data.";2020;Not health related;Not Health related;0
Gutiérrez-Becker B, Sarasua I, Wachinger C.;Discriminative and generative models for anatomical shape analysis on point clouds with deep neural networks;"We introduce deep neural networks for the analysis of anatomical shapes that 
learn a low-dimensional shape representation from the given task, instead of 
relying on hand-engineered representations. Our framework is modular and 
consists of several computing blocks that perform fundamental shape processing 
tasks. The networks operate on unordered point clouds and provide invariance to 
similarity transformations, avoiding the need to identify point correspondences 
between shapes. Based on the framework, we assemble a discriminative model for 
disease classification and age regression, as well as a generative model for the 
accruate reconstruction of shapes. In particular, we propose a conditional 
generative model, where the condition vector provides a mechanism to control the 
generative process. For instance, it enables to assess shape variations specific 
to a particular diagnosis, when passing it as side information. Next to working 
on single shapes, we introduce an extension for the joint analysis of multiple 
anatomical structures, where the simultaneous modeling of multiple structures 
can lead to a more compact encoding and a better understanding of disorders. We 
demonstrate the advantages of our framework in comprehensive experiments on real 
and synthetic data. The key insights are that (i) learning a shape 
representation specific to the given task yields higher performance than 
alternative shape descriptors, (ii) multi-structure analysis is both more 
efficient and more accurate than single-structure analysis, and (iii) point 
clouds generated by our model capture morphological differences associated to 
Alzheimer's disease, to the point that they can be used to train a 
discriminative model for disease classification. Our framework naturally scales 
to the analysis of large datasets, giving it the potential to learn 
characteristic variations in large populations.";2021;Not health related;Health related;1
Zhang Z, Yan C, Malin BA.;Membership inference attacks against synthetic health data;"Synthetic data generation has emerged as a promising method to protect patient 
privacy while sharing individual-level health data. Intuitively, sharing 
synthetic data should reduce disclosure risks because no explicit linkage is 
retained between the synthetic records and the real data upon which it is based. 
However, the risks associated with synthetic data are still evolving, and what 
seems protected today may not be tomorrow. In this paper, we show that 
membership inference attacks, whereby an adversary infers if the data from 
certain target individuals (known to the adversary a priori) were relied upon by 
the synthetic data generation process, can be substantially enhanced through 
state-of-the-art machine learning frameworks, which calls into question the 
protective nature of existing synthetic data generators. Specifically, we 
formulate the membership inference problem from the perspective of the data 
holder, who aims to perform a disclosure risk assessment prior to sharing any 
health data. To support such an assessment, we introduce a framework for 
effective membership inference against synthetic health data without specific 
assumptions about the generative model or a well-defined data structure, 
leveraging the principles of contrastive representation learning. To illustrate 
the potential for such an attack, we conducted experiments against synthesis 
approaches using two datasets derived from several health data resources 
(Vanderbilt University Medical Center, the All of Us Research Program) to 
determine the upper bound of risk brought by an adversary who invokes an optimal 
strategy. The results indicate that partially synthetic data are vulnerable to 
membership inference at a very high rate. By contrast, fully synthetic data are 
only marginally susceptible and, in most cases, could be deemed sufficiently 
protected from membership inference.";2022;Health related;Health related;1
Achuthan S, Chatterjee R, Kotnala S, Mohanty A, Bhattacharya S, Salgia R, Kulkarni P.;Leveraging deep learning algorithms for synthetic data generation to design and analyze biological networks;"The use of synthetic data is gaining an increasingly prominent role in data and 
machine learning workflows to build better models and conduct analyses with 
greater statistical inference. In the domains of healthcare and biomedical 
research, synthetic data may be seen in structured and unstructured formats. 
Concomitant with the adoption of synthetic data, a sub-discipline of machine 
learning known as deep learning has taken the world by storm. At a larger scale, 
deep learning methods tend to outperform traditional methods in regression and 
classification tasks. These techniques are also used in generative modeling and 
are thus prime candidates for generating synthetic data in both structured and 
unstructured formats. Here, we emphasize the generation of synthetic data in 
healthcare and biomedical research using deep learning methods for unstructured 
data formats such as text and images. Deep learning methods leverage the neural 
network algorithm, and in the context of generative modeling, several neural 
network architectures can create new synthetic data for a problem at hand 
including, but not limited to, recurrent neural networks (RNNs), variational 
autoencoders (VAEs), and generative adversarial networks (GANs). To better 
understand these methods, we will look at specific case studies such as 
generating realistic clinical notes of a patient, the generation of synthetic 
DNA sequences, as well as to enrich experimental data collected during the study 
of heterotypic cultures of cancer cells.";2022;Health related;Health related;1
Shin Y, Chun C.;Sound Event Localization and Detection Using Imbalanced Real and Synthetic Data via Multi-Generator;"This study proposes a sound event localization and detection (SELD) method using 
imbalanced real and synthetic data via a multi-generator. The proposed method is 
based on a residual convolutional neural network (RCNN) and a transformer 
encoder for real spatial sound scenes. SELD aims to classify the sound event, 
detect the onset and offset of the classified event, and estimate the direction 
of the sound event. In Detection and Classification of Acoustic Scenes and 
Events (DCASE) 2022 Task 3, SELD is performed with a few real spatial sound 
scene data and a relatively large number of synthetic data. When a model is 
trained using imbalanced data, it can proceed by focusing only on a larger 
number of data. Thus, a multi-generator that samples real and synthetic data at 
a specific rate in one batch is proposed to prevent this problem. We applied the 
data augmentation technique SpecAugment and used time-frequency masking to the 
dataset. Furthermore, we propose a neural network architecture to apply the RCNN 
and transformer encoder. Several models were trained with various structures and 
hyperparameters, and several ensemble models were obtained by ""cherry-picking"" 
specific models. Based on the experiment, the single model of the proposed 
method and the model applied with the ensemble exhibited improved performance 
compared with the baseline model.";2023;Not health related;Not Health related;0
Yang M, Svirsky Y, Cheng Z, Sharf A.;Self-Supervised Fragment Alignment With Gaps;"Image alignment and registration methods typically rely on visual 
correspondences across common regions and boundaries to guide the alignment 
process. Without them, the problem becomes significantly more challenging. 
Nevertheless, in real world, image fragments may be corrupted with no common 
boundaries and little or no overlap. In this work, we address the problem of 
learning the alignment of image fragments with gaps (i.e., without common 
boundaries or overlapping regions). Our setting is unsupervised, having only the 
fragments at hand with no ground truth to guide the alignment process. This is 
usually the situation in the restoration of unique archaeological artifacts such 
as frescoes and mosaics. Hence, we suggest a self-supervised approach utilizing 
self-examples which we generate from the existing data and then feed into an 
adversarial neural network. Our idea is that available information inside 
fragments is often sufficiently rich to guide their alignment with good 
accuracy. Following this observation, our method splits the initial fragments 
into sub-fragments yielding a set of aligned pieces. Thus, sub-fragmentation 
allows exposing new alignment relations and revealing inner structures and 
feature statistics. In fact, the new sub-fragments construct true and false 
alignment relations between fragments. We feed this data to a spatial 
transformer GAN which learns to predict the alignment between fragments gaps. We 
test our technique on various synthetic datasets as well as large scale frescoes 
and mosaics. Results demonstrate our method's capability to learn the alignment 
of deteriorated image fragments in a self-supervised manner, by examining inner 
image statistics for both synthetic and real data.";2023;Not health related;Not Health related;0
Sinclair M, Schuh A, Hahn K, Petersen K, Bai Y, Batten J, Schaap M, Glocker B.;Atlas-ISTN: Joint segmentation, registration and atlas construction with image-and-spatial transformer networks;"Deep learning models for semantic segmentation are able to learn powerful 
representations for pixel-wise predictions, but are sensitive to noise at test 
time and may lead to implausible topologies. Image registration models on the 
other hand are able to warp known topologies to target images as a means of 
segmentation, but typically require large amounts of training data, and have not 
widely been benchmarked against pixel-wise segmentation models. We propose the 
Atlas Image-and-Spatial Transformer Network (Atlas-ISTN), a framework that 
jointly learns segmentation and registration on 2D and 3D image data, and 
constructs a population-derived atlas in the process. Atlas-ISTN learns to 
segment multiple structures of interest and to register the constructed atlas 
labelmap to an intermediate pixel-wise segmentation. Additionally, Atlas-ISTN 
allows for test time refinement of the model's parameters to optimize the 
alignment of the atlas labelmap to an intermediate pixel-wise segmentation. This 
process both mitigates for noise in the target image that can result in spurious 
pixel-wise predictions, as well as improves upon the one-pass prediction of the 
model. Benefits of the Atlas-ISTN framework are demonstrated qualitatively and 
quantitatively on 2D synthetic data and 3D cardiac computed tomography and brain 
magnetic resonance image data, out-performing both segmentation and registration 
baseline models. Atlas-ISTN also provides inter-subject correspondence of the 
structures of interest.";2022;Not health related;Not Health related;1
Campbell E, Cameron JAD, Scheme E.;Feasibility of Data-driven EMG Signal Generation using a Deep Generative Model;"Despite recent advancements in the field of pattern recognition-based 
myoelectric control, the collection of a high quality training set remains a 
challenge limiting its adoption. This paper proposes a framework for a possible 
solution by augmenting short training protocols with subject-specific synthetic 
electromyography (EMG) data generated using a deep generative network, known as 
SinGAN. The aim of this work is to produce high quality synthetic data that 
could improve classification accuracy when combined with a limited training 
protocol. SinGAN was used to generate 1000 synthetic windows of EMG data from a 
single window of six different motions, and results were evaluated 
qualitatively, quantitatively, and in a classification task. Qualitative 
assessment of synthetic data was conducted via visual inspection of principal 
component analysis projections of real and synthetic feature space. Quantitative 
assessment of synthetic data revealed 11 of 32 synthetic features had similar 
location and scale to real features (using univariate two-sample Lepage tests); 
whereas multivariate distributions were found to be statistically different (p 
<0.05). Finally, the addition of these synthetic data to a brief training set of 
real data significantly improved classification accuracy in a cross-validation 
testing scheme by 5.4% (p <0.001).";2020;Not health related;Not Health related;0
Sun C, van Soest J, Dumontier M.;Generating synthetic personal health data using conditional generative adversarial networks combining with differential privacy;"A large amount of personal health data that is highly valuable to the scientific 
community is still not accessible or requires a lengthy request process due to 
privacy concerns and legal restrictions. As a solution, synthetic data has been 
studied and proposed to be a promising alternative to this issue. However, 
generating realistic and privacy-preserving synthetic personal health data 
retains challenges such as simulating the characteristics of the patients' data 
that are in the minority classes, capturing the relations among variables in 
imbalanced data and transferring them to the synthetic data, and preserving 
individual patients' privacy. In this paper, we propose a differentially private 
conditional Generative Adversarial Network model (DP-CGANS) consisting of data 
transformation, sampling, conditioning, and network training to generate 
realistic and privacy-preserving personal data. Our model distinguishes 
categorical and continuous variables and transforms them into latent space 
separately for better training performance. We tackle the unique challenges of 
generating synthetic patient data due to the special data characteristics of 
personal health data. For example, patients with a certain disease are typically 
the minority in the dataset and the relations among variables are crucial to be 
observed. Our model is structured with a conditional vector as an additional 
input to present the minority class in the imbalanced data and maximally capture 
the dependency between variables. Moreover, we inject statistical noise into the 
gradients in the networking training process of DP-CGANS to provide a 
differential privacy guarantee. We extensively evaluate our model with 
state-of-the-art generative models on personal socio-economic datasets and 
real-world personal health datasets in terms of statistical similarity, machine 
learning performance, and privacy measurement. We demonstrate that our model 
outperforms other comparable models, especially in capturing the dependence 
between variables. Finally, we present the balance between data utility and 
privacy in synthetic data generation considering the different data structures 
and characteristics of real-world personal health data such as imbalanced 
classes, abnormal distributions, and data sparsity.";2023;Health related;Health related;1
Liu C, Wang D, Zhang H, Wu W, Sun W, Zhao T, Zheng N.;Using Simulated Training Data of Voxel-Level Generative Models to Improve 3D Neuron Reconstruction;"Reconstructing neuron morphologies from fluorescence microscope images plays a 
critical role in neuroscience studies. It relies on image segmentation to 
produce initial masks either for further processing or final results to 
represent neuronal morphologies. This has been a challenging step due to the 
variation and complexity of noisy intensity patterns in neuron images acquired 
from microscopes. Whereas progresses in deep learning have brought the goal of 
accurate segmentation much closer to reality, creating training data for 
producing powerful neural networks is often laborious. To overcome the 
difficulty of obtaining a vast number of annotated data, we propose a novel 
strategy of using two-stage generative models to simulate training data with 
voxel-level labels. Trained upon unlabeled data by optimizing a novel objective 
function of preserving predefined labels, the models are able to synthesize 
realistic 3D images with underlying voxel labels. We showed that these synthetic 
images could train segmentation networks to obtain even better performance than 
manually labeled data. To demonstrate an immediate impact of our work, we 
further showed that segmentation results produced by networks trained upon 
synthetic data could be used to improve existing neuron reconstruction methods.";2022;Health related;Not Health related;1
Buoy R, Iwamura M, Srun S, Kise K.;Explainable Connectionist-Temporal-Classification-Based Scene Text Recognition;"Connectionist temporal classification (CTC) is a favored decoder in scene text 
recognition (STR) for its simplicity and efficiency. However, most CTC-based 
methods utilize one-dimensional (1D) vector sequences, usually derived from a 
recurrent neural network (RNN) encoder. This results in the absence of 
explainable 2D spatial relationship between the predicted characters and 
corresponding image regions, essential for model explainability. On the other 
hand, 2D attention-based methods enhance recognition accuracy and offer 
character location information via cross-attention mechanisms, linking 
predictions to image regions. However, these methods are more computationally 
intensive, compared with the 1D CTC-based methods. To achieve both low latency 
and model explainability via character localization using a 1D CTC decoder, we 
propose a marginalization-based method that processes 2D feature maps and 
predicts a sequence of 2D joint probability distributions over the height and 
class dimensions. Based on the proposed method, we newly introduce an 
association map that aids in character localization and model prediction 
explanation. This map parallels the role of a cross-attention map, as seen in 
computationally-intensive attention-based architectures. With the proposed 
method, we consider a ViT-CTC STR architecture that uses a 1D CTC decoder and a 
pretrained vision Transformer (ViT) as a 2D feature extractor. Our ViT-CTC 
models were trained on synthetic data and fine-tuned on real labeled sets. These 
models outperform the recent state-of-the-art (SOTA) CTC-based methods on 
benchmarks in terms of recognition accuracy. Compared with the baseline 
Transformer-decoder-based models, our ViT-CTC models offer a speed boost up to 
12 times regardless of the backbone, with a maximum 3.1% reduction in total word 
recognition accuracy. In addition, both qualitative and quantitative assessments 
of character locations estimated from the association map align closely with 
those from the cross-attention map and ground-truth character-level bounding 
boxes.";2023;Not health related;Not Health related;0
Yelmen B, Decelle A, Ongaro L, Marnetto D, Tallec C, Montinaro F, Furtlehner C, Pagani L, Jay F.;Creating artificial human genomes using generative neural networks;"Generative models have shown breakthroughs in a wide spectrum of domains due to 
recent advancements in machine learning algorithms and increased computational 
power. Despite these impressive achievements, the ability of generative models 
to create realistic synthetic data is still under-exploited in genetics and 
absent from population genetics. Yet a known limitation in the field is the 
reduced access to many genetic databases due to concerns about violations of 
individual privacy, although they would provide a rich resource for data mining 
and integration towards advancing genetic studies. In this study, we 
demonstrated that deep generative adversarial networks (GANs) and restricted 
Boltzmann machines (RBMs) can be trained to learn the complex distributions of 
real genomic datasets and generate novel high-quality artificial genomes (AGs) 
with none to little privacy loss. We show that our generated AGs replicate 
characteristics of the source dataset such as allele frequencies, linkage 
disequilibrium, pairwise haplotype distances and population structure. Moreover, 
they can also inherit complex features such as signals of selection. To 
illustrate the promising outcomes of our method, we showed that imputation 
quality for low frequency alleles can be improved by data augmentation to 
reference panels with AGs and that the RBM latent space provides a relevant 
encoding of the data, hence allowing further exploration of the reference 
dataset and features for solving supervised tasks. Generative models and AGs 
have the potential to become valuable assets in genetic studies by providing a 
rich yet compact representation of existing genomes and high-quality, 
easy-access and anonymous alternatives for private databases.";2021;Not health related;Not Health related;0
Castelli M, Manzoni L, Espindola T, Popovi_ A, De Lorenzo A.;Generative adversarial networks for generating synthetic features for Wi-Fi signal quality;"Wireless networks are among the fundamental technologies used to connect people. 
Considering the constant advancements in the field, telecommunication operators 
must guarantee a high-quality service to keep their customer portfolio. To 
ensure this high-quality service, it is common to establish partnerships with 
specialized technology companies that deliver software services in order to 
monitor the networks and identify faults and respective solutions. A common 
barrier faced by these specialized companies is the lack of data to develop and 
test their products. This paper investigates the use of generative adversarial 
networks (GANs), which are state-of-the-art generative models, for generating 
synthetic telecommunication data related to Wi-Fi signal quality. We developed, 
trained, and compared two of the most used GAN architectures: the Vanilla GAN 
and the Wasserstein GAN (WGAN). Both models presented satisfactory results and 
were able to generate synthetic data similar to the real ones. In particular, 
the distribution of the synthetic data overlaps the distribution of the real 
data for all of the considered features. Moreover, the considered generative 
models can reproduce the same associations observed for the synthetic features. 
We chose the WGAN as the final model, but both models are suitable for 
addressing the problem at hand.";2021;Not health related;Not Health related;0
Wang Y, Deng W.;Generative Model With Coordinate Metric Learning for Object Recognition Based on 3D Models;"One of the bottlenecks in acquiring a perfect database for deep learning is the 
tedious process of collecting and labeling data. In this paper, we propose a 
generative model trained with synthetic images rendered from 3D models which can 
reduce the burden on collecting real training data and make the background 
conditions more realistic. Our architecture is composed of two sub-networks: a 
semantic foreground object reconstruction network based on Bayesian inference 
and a classification network based on multi-triplet cost training for avoiding 
overfitting on the monotone synthetic object surface and utilizing accurate 
information of synthetic images like object poses and lighting conditions which 
are helpful for recognizing regular photos. First, our generative model with 
metric learning utilizes additional foreground object channels generated from 
semantic foreground object reconstruction sub-network for recognizing the 
original input images. Multi-triplet cost function based on poses is used for 
metric learning which makes it possible to train an effective categorical 
classifier purely based on synthetic data. Second, we design a coordinate 
training strategy with the help of adaptive noise applied on the inputs of both 
of the concatenated sub-networks to make them benefit from each other and avoid 
inharmonious parameter tuning due to different convergence speeds of two 
sub-networks. Our architecture achieves the state-of-the-art accuracy of 50.5% 
on the ShapeNet database with data migration obstacle from synthetic images to 
real images. This pipeline makes it applicable to do recognition on real images 
only based on 3D models. Our codes are available at 
https://github.com/wangyida/gm-cml.";2018;Not health related;Not Health related;0
El Kababji S, Mitsakakis N, Fang X, Beltran-Bless AA, Pond G, Vandermeer L, Radhakrishnan D, Mosquera L, Paterson A, Shepherd L, Chen B, Barlow WE, Gralow J, Savard MF, Clemons M, El Emam K.;Evaluating the Utility and Privacy of Synthetic Breast Cancer Clinical Trial Data Sets;"PURPOSE: There is strong interest from patients, researchers, the pharmaceutical 
industry, medical journal editors, funders of research, and regulators in 
sharing clinical trial data for secondary analysis. However, data access remains 
a challenge because of concerns about patient privacy. It has been argued that 
synthetic data generation (SDG) is an effective way to address these privacy 
concerns. There is a dearth of evidence supporting this on oncology clinical 
trial data sets, and on the utility of privacy-preserving synthetic data. The 
objective of the proposed study is to validate the utility and privacy risks of 
synthetic clinical trial data sets across multiple SDG techniques.
METHODS: We synthesized data sets from eight breast cancer clinical trial data 
sets using three types of generative models: sequential synthesis, conditional 
generative adversarial network, and variational autoencoder. Synthetic data 
utility was evaluated by replicating the published analyses on the synthetic 
data and assessing concordance of effect estimates and CIs between real and 
synthetic data. Privacy was evaluated by measuring attribution disclosure risk 
and membership disclosure risk.
RESULTS: Utility was highest using the sequential synthesis method where all 
results were replicable and the CI overlap most similar or higher for seven of 
eight data sets. Both types of privacy risks were low across all three types of 
generative models.
DISCUSSION: Synthetic data using sequential synthesis methods can act as a proxy 
for real clinical trial data sets, and simultaneously have low privacy risks. 
This type of generative model can be one way to enable broader sharing of 
clinical trial data.";2023;Health related;Health related;1
Burlina PM, Joshi N, Pacheco KD, Liu TYA, Bressler NM.;Assessment of Deep Generative Models for High-Resolution Synthetic Retinal Image Generation of Age-Related Macular Degeneration;"IMPORTANCE: Deep learning (DL) used for discriminative tasks in ophthalmology, 
such as diagnosing diabetic retinopathy or age-related macular degeneration 
(AMD), requires large image data sets graded by human experts to train deep 
convolutional neural networks (DCNNs). In contrast, generative DL techniques 
could synthesize large new data sets of artificial retina images with different 
stages of AMD. Such images could enhance existing data sets of common and rare 
ophthalmic diseases without concern for personally identifying information to 
assist medical education of students, residents, and retinal specialists, as 
well as for training new DL diagnostic models for which extensive data sets from 
large clinical trials of expertly graded images may not exist.
OBJECTIVE: To develop DL techniques for synthesizing high-resolution realistic 
fundus images serving as proxy data sets for use by retinal specialists and DL 
machines.
DESIGN, SETTING, AND PARTICIPANTS: Generative adversarial networks were trained 
on 133 821 color fundus images from 4613 study participants from the Age-Related 
Eye Disease Study (AREDS), generating synthetic fundus images with and without 
AMD. We compared retinal specialists' ability to diagnose AMD on both real and 
synthetic images, asking them to assess image gradability and testing their 
ability to discern real from synthetic images. The performance of AMD diagnostic 
DCNNs (referable vs not referable AMD) trained on either all-real vs 
all-synthetic data sets was compared.
MAIN OUTCOMES AND MEASURES: Accuracy of 2 retinal specialists (T.Y.A.L. and 
K.D.P.) for diagnosing and distinguishing AMD on real vs synthetic images and 
diagnostic performance (area under the curve) of DL algorithms trained on 
synthetic vs real images.
RESULTS: The diagnostic accuracy of 2 retinal specialists on real vs synthetic 
images was similar. The accuracy of diagnosis as referable vs nonreferable AMD 
compared with certified human graders for retinal specialist 1 was 84.54% (error 
margin, 4.06%) on real images vs 84.12% (error margin, 4.16%) on synthetic 
images and for retinal specialist 2 was 89.47% (error margin, 3.45%) on real 
images vs 89.19% (error margin, 3.54%) on synthetic images. Retinal specialists 
could not distinguish real from synthetic images, with an accuracy of 59.50% 
(error margin, 3.93%) for retinal specialist 1 and 53.67% (error margin, 3.99%) 
for retinal specialist 2. The DCNNs trained on real data showed an area under 
the curve of 0.9706 (error margin, 0.0029), and those trained on synthetic data 
showed an area under the curve of 0.9235 (error margin, 0.0045).
CONCLUSIONS AND RELEVANCE: Deep learning-synthesized images appeared to be 
realistic to retinal specialists, and DCNNs achieved diagnostic performance on 
synthetic data close to that for real images, suggesting that DL generative 
techniques hold promise for training humans and machines.";2019;Health related;Health related;1
El Emam K, Mosquera L, Fang X, El-Hussuna A.;Utility Metrics for Evaluating Synthetic Health Data Generation Methods: Validation Study;"BACKGROUND: A regular task by developers and users of synthetic data generation 
(SDG) methods is to evaluate and compare the utility of these methods. Multiple 
utility metrics have been proposed and used to evaluate synthetic data. However, 
they have not been validated in general or for comparing SDG methods.
OBJECTIVE: This study evaluates the ability of common utility metrics to rank 
SDG methods according to performance on a specific analytic workload. The 
workload of interest is the use of synthetic data for logistic regression 
prediction models, which is a very frequent workload in health research.
METHODS: We evaluated 6 utility metrics on 30 different health data sets and 3 
different SDG methods (a Bayesian network, a Generative Adversarial Network, and 
sequential tree synthesis). These metrics were computed by averaging across 20 
synthetic data sets from the same generative model. The metrics were then tested 
on their ability to rank the SDG methods based on prediction performance. 
Prediction performance was defined as the difference between each of the area 
under the receiver operating characteristic curve and area under the 
precision-recall curve values on synthetic data logistic regression prediction 
models versus real data models.
RESULTS: The utility metric best able to rank SDG methods was the multivariate 
Hellinger distance based on a Gaussian copula representation of real and 
synthetic joint distributions.
CONCLUSIONS: This study has validated a generative model utility metric, the 
multivariate Hellinger distance, which can be used to reliably rank competing 
SDG methods on the same data set. The Hellinger distance metric can be used to 
evaluate and compare alternate SDG methods.";2022;Health related;Health related;1
Noguer J, Contreras I, Mujahid O, Beneyto A, Vehi J.;Generation of Individualized Synthetic Data for Augmentation of the Type 1 Diabetes Data Sets Using Deep Learning Models;"In this paper, we present a methodology based on generative adversarial network 
architecture to generate synthetic data sets with the intention of augmenting 
continuous glucose monitor data from individual patients. We use these synthetic 
data with the aim of improving the overall performance of prediction models 
based on machine learning techniques. Experiments were performed on two cohorts 
of patients suffering from type 1 diabetes mellitus with significant differences 
in their clinical outcomes. In the first contribution, we have demonstrated that 
the chosen methodology is able to replicate the intrinsic characteristics of 
individual patients following the statistical distributions of the original 
data. Next, a second contribution demonstrates the potential of synthetic data 
to improve the performance of machine learning approaches by testing and 
comparing different prediction models for the problem of predicting nocturnal 
hypoglycemic events in type 1 diabetic patients. The results obtained for both 
generative and predictive models are quite encouraging and set a precedent in 
the use of generative techniques to train new machine learning models.";2022;Health related;Health related;1
Orlichenko A, Qu G, Zhou Z, Ding Z, Wang YP.;Angle Basis: a Generative Model and Decomposition for Functional Connectivity;"Functional connectivity (FC) is one of the most common inputs to fMRI-based 
predictive models, due to a combination of its simplicity and robustness. 
However, there may be a lack of theoretical models for the generation of FC. In 
this work, we present a straightforward decomposition of FC into a set of basis 
states of sine waves with an additional jitter component. We show that the 
decomposition matches the predictive ability of FC after including 5-10 bases. 
We also find that both the decomposition and its residual have approximately 
equal predictive value, and when combined into an ensemble, exceed the AUC of 
FC-based prediction by up to 5%. Additionally, we find the residual can be used 
for subject fingerprinting, with 97.3% same-subject, different-scan 
identifiability, compared to 62.5% for FC. Unlike PCA or Factor Analysis 
methods, our method does not require knowledge of a population to perform its 
decomposition; a single subject is enough. Our decomposition of FC into two 
equally-predictive components may lead to a novel appreciation of group 
differences in patient populations. Additionally, we generate synthetic patient 
FC based on user-specified characteristics such as age, sex, and disease 
diagnosis. By creating synthetic datasets or augmentations we may reduce the 
high financial burden associated with fMRI data acquisition.";2023;Health related;Health related;0
Smith B, Van Steelandt S, Khojandi A.;Evaluating the Impact of Health Care Data Completeness for Deep Generative Models;"BACKGROUND: Deep generative models (DGMs) present a promising avenue for 
generating realistic, synthetic data to augment existing health care datasets. 
However, exactly how the completeness of the original dataset affects the 
quality of the generated synthetic data is unclear.
OBJECTIVES: In this paper, we investigate the effect of data completeness on 
samples generated by the most common DGM paradigms.
METHODS: We create both cross-sectional and panel datasets with varying 
missingness and subset rates and train generative adversarial networks, 
variational autoencoders, and autoregressive models (Transformers) on these 
datasets. We then compare the distributions of generated data with original 
training data to measure similarity.
RESULTS: We find that increased incompleteness is directly correlated with 
increased dissimilarity between original and generated samples produced through 
DGMs.
CONCLUSIONS: Care must be taken when using DGMs to generate synthetic data as 
data completeness issues can affect the quality of generated data in both panel 
and cross-sectional datasets.";2023;Health related;Health related;1
Song L, Xu Y, Zhang L, Du B, Zhang Q, Wang X.;Learning from Synthetic Images via Active Pseudo-Labeling;"Synthetic visual data refers to the data automatically rendered by the mature 
computer graphic algorithms. With the rapid development of these techniques, we 
can now collect photo-realistic synthetic images with accurate pixel-level 
annotations without much effort. However, due to the domain gaps between 
synthetic data and real data, in terms of not only visual appearance but also 
label distribution, directly applying models trained on synthetic images to real 
ones can hardly yield satisfactory performance. Since the collection of accurate 
labels for real images is very laborious and time-consuming, developing 
algorithms which can learn from synthetic images is of great significance. In 
this paper, we propose a novel framework, namely Active Pseudo-Labeling (APL), 
to reduce the domain gaps between synthetic images and real images. In APL 
framework, we first predict pseudo-labels for the unlabeled real images in the 
target domain by actively adapting the style of the real images to source 
domain. Specifically, the style of real images is adjusted via a novel task 
guided generative model, and then pseudo-labels are predicted for these actively 
adapted images. Lastly, we fine-tune the source-trained model in the 
pseudo-labeled target domain, which helps to fit the distribution of the real 
data. Experiments on both semantic segmentation and object detection tasks with 
several challenging benchmark data sets demonstrate the priority of our proposed 
method compared to the existing state-of-the-art approaches.";2020;Not health related;Not Health related;0
El Emam K, Mosquera L, Fang X.;Validating a membership disclosure metric for synthetic health data;"BACKGROUND: One of the increasingly accepted methods to evaluate the privacy of 
synthetic data is by measuring the risk of membership disclosure. This is a 
measure of the F1 accuracy that an adversary would correctly ascertain that a 
target individual from the same population as the real data is in the dataset 
used to train the generative model, and is commonly estimated using a data 
partitioning methodology with a 0.5 partitioning parameter.
OBJECTIVE: Validate the membership disclosure F1 score, evaluate and improve the 
parametrization of the partitioning method, and provide a benchmark for its 
interpretation.
MATERIALS AND METHODS: We performed a simulated membership disclosure attack on 
4 population datasets: an Ontario COVID-19 dataset, a state hospital discharge 
dataset, a national health survey, and an international COVID-19 behavioral 
survey. Two generative methods were evaluated: sequential synthesis and a 
generative adversarial network. A theoretical analysis and a simulation were 
used to determine the correct partitioning parameter that would give the same F1 
score as a ground truth simulated membership disclosure attack.
RESULTS: The default 0.5 parameter can give quite inaccurate membership 
disclosure values. The proportion of records from the training dataset in the 
attack dataset must be equal to the sampling fraction of the real dataset from 
the population. The approach is demonstrated on 7 clinical trial datasets.
CONCLUSIONS: Our proposed parameterization, as well as interpretation and 
generative model training guidance provide a theoretically and empirically 
grounded basis for evaluating and managing membership disclosure risk for 
synthetic data.";2022;Health related;Health related;1
Tu L, Talbot A, Gallagher NM, Carlson DE.;Supervising the Decoder of Variational Autoencoders to Improve Scientific Utility;"Probabilistic generative models are attractive for scientific modeling because 
their inferred parameters can be used to generate hypotheses and design 
experiments. This requires that the learned model provides an accurate 
representation of the input data and yields a latent space that effectively 
predicts outcomes relevant to the scientific question. Supervised Variational 
Autoencoders (SVAEs) have previously been used for this purpose, as a carefully 
designed decoder can be used as an interpretable generative model of the data, 
while the supervised objective ensures a predictive latent representation. 
Unfortunately, the supervised objective forces the encoder to learn a biased 
approximation to the generative posterior distribution, which renders the 
generative parameters unreliable when used in scientific models. This issue has 
remained undetected as reconstruction losses commonly used to evaluate model 
performance do not detect bias in the encoder. We address this 
previously-unreported issue by developing a second-order supervision framework 
(SOS-VAE) that updates the decoder parameters, rather than the encoder, to 
induce a predictive latent representation. This ensures that the encoder 
maintains a reliable posterior approximation and the decoder parameters can be 
effectively interpreted. We extend this technique to allow the user to trade-off 
the bias in the generative parameters for improved predictive performance, 
acting as an intermediate option between SVAEs and our new SOS-VAE. We also use 
this methodology to address missing data issues that often arise when combining 
recordings from multiple scientific experiments. We demonstrate the 
effectiveness of these developments using synthetic data and 
electrophysiological recordings with an emphasis on how our learned 
representations can be used to design scientific experiments.";2022;Not health related;Not Health related;0
Haradal S, Hayashi H, Uchida S.;Biosignal Data Augmentation Based on Generative Adversarial Networks;"In this paper, we propose a synthetic generationmethod for time-series data 
based on generative adversarial networks (GANs) and apply it to data 
augmentation for biosinal classification. GANs are a recently proposed framework 
for learning a generative model, where two neural networks, one generating 
synthetic data and the other discriminating synthetic and real data, are trained 
while competing with each other. In the proposed method, each neural network in 
GANs is developed based on a recurrent neural network using long short-term 
memories, thereby allowing the adaptation of the GANs framework to time-series 
data generation. In the experiments, we confirmed the capability of the proposed 
method for generating synthetic biosignals using the electrocardiogram and 
electroencephalogram datasets. We also showed the effectiveness of the proposed 
method for data augmentation in the biosignal classification problem.";2018;Not health related;Not Health related;0
Catrambone V, Greco A, Vanello N, Scilingo EP, Valenza G.;Time-Resolved Directional Brain-Heart Interplay Measurement Through Synthetic Data Generation Models;"Although a plethora of synthetic data generation models have been proposed to 
validate biomarkers of brain and cardiovascular dynamics separately, a limited 
number of computational methods estimating directed brain-heart information flow 
are currently available in the scientific literature. This study introduces a 
computational framework exploiting existing generative models for a novel 
time-resolved quantification of causal brain-heart interplay. Exemplarily, 
having electroencephalographic signals and heart rate variability series as 
inputs, respective synthetic data models are coupled through parametrised 
functions defined in accordance with current central autonomic network (CAN) 
knowledge. We validate this concept using data from 30 healthy volunteers 
undergoing notable sympathetic elicitation through a cold-pressor test, and 
further compare the obtained results with a state-of-the-art method as maximal 
information coefficient. Although our findings are in agreement with previous 
CAN findings, we report new insights into the role of fronto-parietal region 
activity and lateralisation mechanisms over the temporal cortices during 
prolonged peripheral elicitation, which occur with specific time delays. 
Additionally, the afferent autonomic outflow maps to brain oscillations in the _ 
and _ bands, whereas complementary cortical dynamics in the _, _, and _ bands 
act on efferent autonomic control. The proposed framework paves the way towards 
novel biomarker definitions for the assessment of complex physiological networks 
using existing data generation models for brain and peripheral dynamics.";2019;Health related;Health related;1
Krause J, Grabsch HI, Kloor M, Jendrusch M, Echle A, Buelow RD, Boor P, Luedde T, Brinker TJ, Trautwein C, Pearson AT, Quirke P, Jenniskens J, Offermans K, van den Brandt PA, Kather JN.;Deep learning detects genetic alterations in cancer histology generated by adversarial networks;"Deep learning can detect microsatellite instability (MSI) from routine histology 
images in colorectal cancer (CRC). However, ethical and legal barriers impede 
sharing of images and genetic data, hampering development of new algorithms for 
detection of MSI and other biomarkers. We hypothesized that histology images 
synthesized by conditional generative adversarial networks (CGANs) retain 
information about genetic alterations. To test this, we developed a 'histology 
CGAN' which was trained on 256 patients (training cohort 1) and 1457 patients 
(training cohort 2). The CGAN synthesized 10_000 synthetic MSI and non-MSI 
images which contained a range of tissue types and were deemed realistic by 
trained observers in a blinded study. Subsequently, we trained a deep learning 
detector of MSI on real or synthetic images and evaluated the performance of MSI 
detection in a held-out set of 142 patients. When trained on real images from 
training cohort 1, this system achieved an area under the receiver operating 
curve (AUROC) of 0.742 [0.681, 0.854]. Training on the larger cohort 2 only 
marginally improved the AUROC to 0.757 [0.707, 0.869]. Training on purely 
synthetic data resulted in an AUROC of 0.743 [0.658, 0.801]. Training on both 
real and synthetic data further increased AUROC to 0.777 [0.715, 0.821]. We 
conclude that synthetic histology images retain information reflecting 
underlying genetic alterations in colorectal cancer. Using synthetic instead of 
real images to train deep learning systems yields non-inferior classifiers. This 
approach can be used to create large shareable data sets or to augment small 
data sets with rare molecular features. © 2021 The Authors. The Journal of 
Pathology published by John Wiley & Sons, Ltd. on behalf of The Pathological 
Society of Great Britain and Ireland.";2021;Health related;Health related;1
Nikbakht M, Gazi AH, Zia J, An S, Lin DJ, Inan OT, Kamaleswaran R.;Synthetic seismocardiogram generation using a transformer-based neural network;"OBJECTIVE: To design and validate a novel deep generative model for 
seismocardiogram (SCG) dataset augmentation. SCG is a noninvasively acquired 
cardiomechanical signal used in a wide range of cardivascular monitoring tasks; 
however, these approaches are limited due to the scarcity of SCG data.
METHODS: A deep generative model based on transformer neural networks is 
proposed to enable SCG dataset augmentation with control over features such as 
aortic opening (AO), aortic closing (AC), and participant-specific morphology. 
We compared the generated SCG beats to real human beats using various 
distribution distance metrics, notably Sliced-Wasserstein Distance (SWD). The 
benefits of dataset augmentation using the proposed model for other machine 
learning tasks were also explored.
RESULTS: Experimental results showed smaller distribution distances for all 
metrics between the synthetically generated set of SCG and a test set of human 
SCG, compared to distances from an animal dataset (1.14_ SWD), Gaussian noise 
(2.5_ SWD), or other comparison sets of data. The input and output features also 
showed minimal error (95% limits of agreement for pre-ejection period [PEP] and 
left ventricular ejection time [LVET] timings are 0.03_±_3.81 ms and 
-0.28_±_6.08 ms, respectively). Experimental results for data augmentation for a 
PEP estimation task showed 3.3% accuracy improvement on an average for every 10% 
augmentation (ratio of synthetic data to real data).
CONCLUSION: The model is thus able to generate physiologically diverse, 
realistic SCG signals with precise control over AO and AC features. This will 
uniquely enable dataset augmentation for SCG processing and machine learning to 
overcome data scarcity.";2023;Health related;Not Health related;1
Li L, Yan J, Wang H, Jin Y.;Anomaly Detection of Time Series With Smoothness-Inducing Sequential Variational Auto-Encoder;"Deep generative models have demonstrated their effectiveness in learning latent 
representation and modeling complex dependencies of time series. In this 
article, we present a smoothness-inducing sequential variational auto-encoder 
(VAE) (SISVAE) model for the robust estimation and anomaly detection of 
multidimensional time series. Our model is based on VAE, and its backbone is 
fulfilled by a recurrent neural network to capture latent temporal structures of 
time series for both the generative model and the inference model. Specifically, 
our model parameterizes mean and variance for each time-stamp with flexible 
neural networks, resulting in a nonstationary model that can work without the 
assumption of constant noise as commonly made by existing Markov models. 
However, such flexibility may cause the model fragile to anomalies. To achieve 
robust density estimation which can also benefit detection tasks, we propose a 
smoothness-inducing prior over possible estimations. The proposed prior works as 
a regularizer that places penalty at nonsmooth reconstructions. Our model is 
learned efficiently with a novel stochastic gradient variational Bayes 
estimator. In particular, we study two decision criteria for anomaly detection: 
reconstruction probability and reconstruction error. We show the effectiveness 
of our model on both synthetic data sets and public real-world benchmarks.";2021;Not health related;Not Health related;0
Turan M, Durmus F.;UC-NfNet: Deep learning-enabled assessment of ulcerative colitis from colonoscopy images;"Ulcerative colitis (UC) belongs to the inflammatory bowel disease (IBD) family, 
which is mainly caused by inflammation of the tissue in the colon and rectum. 
The severity of this infection can radically affect the patient's overall 
well-being. Although there is no definitive treatment for this disease, 
diagnosis of the severity of the disease through colonoscopy imaging and the use 
of personalized treatment can prevent progression to more malignant stages. 
Inter- and intra-observer variability combined with the complex nature of UC 
infection makes medical assessment cumbersome. Diagnosis and treatment of UC can 
be made more accurate and robust if disease severity can be determined in a 
standardized and automated manner. Therefore, the development of a computerized 
tool that can be integrated into the clinical decision-making process of UC 
classification is of great importance. In this work, we present an automated UC 
classification method, UC-NfNet, complemented by a synthetic data generation 
pipeline aimed at classifying colonoscopy UC images. We show that our model 
quantitatively outperforms state-of-the-art classification models such as 
ConViT, Inception-v4, NFNets, ResNets and Swin Transformer. In an independent 
reader study of five gastroenterologists, the average agreement between the 
UC-NfNet and individual gastroenterologists was higher than the agreement 
between individual gastroenterologists. This robust evaluation of the proposed 
AI system paves the way for clinical trials of AI-assisted UC classification. 
The code and dataset are publicly available at 
https://github.com/DeepMIALab/UC-NfNet.";2022;Health related;Health related;1
Wang X, Lin Y, Xiong Y, Zhang S, He Y, He Y, Zhang Z, Plasek JM, Zhou L, Bates DW, Tang C.;Using an optimized generative model to infer the progression of complications in type 2 diabetes patients;"BACKGROUND: People live a long time in pre-diabetes/early diabetes without a 
formal diagnosis or management. Heterogeneity of progression coupled with 
deficiencies in electronic health records related to incomplete data, discrete 
events, and irregular event intervals make identification of pre-diabetes and 
critical points of diabetes progression challenging.
METHODS: We utilized longitudinal electronic health records of 9298 patients 
with type 2 diabetes or prediabetes from 2005 to 2016 from a large regional 
healthcare delivery network in China. We optimized a generative 
Markov-Bayesian-based model to generate 5000 synthetic illness trajectories. The 
synthetic data were manually reviewed by endocrinologists.
RESULTS: We build an optimized generative progression model for type 2 diabetes 
using anchor information to reduce the number of parameters learning in the 
third layer of the model from [Formula: see text] to [Formula: see text], where 
[Formula: see text] is the number of clinical findings, [Formula: see text] is 
the number of complications, [Formula: see text] is the number of anchors. Based 
on this model, we infer the relationships between progression stages, the onset 
of complication categories, and the associated diagnoses during the whole 
progression of type 2 diabetes using electronic health records.
DISCUSSION: Our findings indicate that 55.3% of single complications and 31.8% 
of complication patterns could be predicted early and managed appropriately to 
potentially delay (as it is a progressive disease) or prevented (by lifestyle 
modifications that keep patient from developing/triggering diabetes in the first 
place).
CONCLUSIONS: The full type 2 diabetes patient trajectories generated by the 
chronic disease progression model can counter a lack of real-world evidence of 
desired longitudinal timeframe while facilitating population health management.";2022;Health related;Health related;1
Marinescu RV, Lorenzi M, Blumberg SB, Young AL, Planell-Morell P, Oxtoby NP, Eshaghi A, Yong KX, Crutch SJ, Golland P, Alexander DC.;Disease Knowledge Transfer across Neurodegenerative Diseases;"We introduce Disease Knowledge Transfer (DKT), a novel technique for 
transferring biomarker information between related neurodegenerative diseases. 
DKT infers robust multimodal biomarker trajectories in rare neurodegenerative 
diseases even when only limited, unimodal data is available, by transferring 
information from larger multimodal datasets from common neurodegenerative 
diseases. DKT is a joint-disease generative model of biomarker progressions, 
which exploits biomarker relationships that are shared across diseases. Our 
proposed method allows, for the first time, the estimation of plausible 
multimodal biomarker trajectories in Posterior Cortical Atrophy (PCA), a rare 
neurodegenerative disease where only unimodal MRI data is available. For this we 
train DKT on a combined dataset containing subjects with two distinct diseases 
and sizes of data available: 1) a larger, multimodal typical AD (tAD) dataset 
from the TADPOLE Challenge, and 2) a smaller unimodal Posterior Cortical Atrophy 
(PCA) dataset from the Dementia Research Centre (DRC), for which only a limited 
number of Magnetic Resonance Imaging (MRI) scans are available. Although 
validation is challenging due to lack of data in PCA, we validate DKT on 
synthetic data and two patient datasets (TADPOLE and PCA cohorts), showing it 
can estimate the ground truth parameters in the simulation and predict unseen 
biomarkers on the two patient datasets. While we demonstrated DKT on Alzheimer's 
variants, we note DKT is generalisable to other forms of related 
neurodegenerative diseases. Source code for DKT is available online: 
https://github.com/mrazvan22/dkt.";2019;Health related;Health related;1
Grande RC, Walsh TJ, Chowdhary G, Ferguson S, How JP.;Online Regression for Data With Changepoints Using Gaussian Processes and Reusable Models;"Many prediction, decision-making, and control architectures rely on online 
learned Gaussian process (GP) models. However, most existing GP regression 
algorithms assume a single generative model, leading to poor predictive 
performance when the data are nonstationary, i.e., generated from multiple 
switching processes. Furthermore, existing methods for GP regression over 
nonstationary data require significant computation, do not come with provable 
guarantees on correctness and speed, and many only work in batch settings, 
making them ill-suited for real-time prediction. We present an efficient online 
GP framework, GP-non-Bayesian clustering (GP-NBC), which addresses these 
computational and theoretical issues, allowing for real-time changepoint 
detection and regression using GPs. Our empirical results on two real-world data 
sets and two synthetic data set show that GP-NBC outperforms state-of-the-art 
methods for nonstationary regression in terms of both regression error and 
computation. For example, it outperforms Dirichlet process GP clustering with 
Gibbs sampling by 98% in computation time reduction while the mean absolute 
error is comparable.";2017;Not health related;Not Health related;0
Hasegawa K, Moriwaki Y, Terada T, Wei C, Shimizu K.;Feedback-AVPGAN: Feedback-guided generative adversarial network for generating antiviral peptides;"In this study, we propose Feedback-AVPGAN, a system that aims to computationally 
generate novel antiviral peptides (AVPs). This system relies on the key premise 
of the Generative Adversarial Network (GAN) model and the Feedback method. GAN, 
a generative modeling approach that uses deep learning methods, comprises a 
generator and a discriminator. The generator is used to generate peptides; the 
generated proteins are fed to the discriminator to distinguish between the AVPs 
and non-AVPs. The original GAN design uses actual data to train the 
discriminator. However, not many AVPs have been experimentally obtained. To 
solve this problem, we used the Feedback method to allow the discriminator to 
learn from the existing as well as generated synthetic data. We implemented this 
method using a classifier module that classifies each peptide sequence generated 
by the GAN generator as AVP or non-AVP. The classifier uses the transformer 
network and achieves high classification accuracy. This mechanism enables the 
efficient generation of peptides with a high probability of exhibiting antiviral 
activity. Using the Feedback method, we evaluated various algorithms and their 
performance. Moreover, we modeled the structure of the generated peptides using 
AlphaFold2 and determined the peptides having similar physicochemical properties 
and structures to those of known AVPs, although with different sequences.";2022;Not health related;Not Health related;0
Cheng Y, Gong Y, Liu Y, Song B, Zou Q.;Molecular design in drug discovery: a comprehensive review of deep generative models;"Deep generative models have been an upsurge in the deep learning community since 
they were proposed. These models are designed for generating new synthetic data 
including images, videos and texts by fitting the data approximate 
distributions. In the last few years, deep generative models have shown superior 
performance in drug discovery especially de novo molecular design. In this 
study, deep generative models are reviewed to witness the recent advances of de 
novo molecular design for drug discovery. In addition, we divide those models 
into two categories based on molecular representations in silico. Then these two 
classical types of models are reported in detail and discussed about both pros 
and cons. We also indicate the current challenges in deep generative models for 
de novo molecular design. De novo molecular design automatically is promising 
but a long road to be explored.";2021;Not health related;Health related;0
Wickramaratne SD, Parekh A.;SleepSIM: Conditional GAN-based non-REM sleep EEG Signal Generator;"Synthetic data generation has become increasingly popular with the increasing 
use of generative networks. Recently, Generative Adversarial Network (GAN) 
architectures have produced exceptional results in synthetic image generation. 
However, time series generation still needs to be studied. This paper proposes a 
Conditional GAN-based system to generate unique samples of non-REM sleep 
electroencephalographic (EEG) signals. The CGAN model had a 1-D Convolution 
Neural Network based architecture. The model was trained using real EEG from 
healthy controls. The trained model can generate an artificial 30-second epoch 
of non-REM sleep whose power spectrum is identical to that of a real sleep 
EEG.Clinical relevance- Sleep EEG simulation can be used to train and enhance 
the skillset of fellows and technicians in the sleep medicine field. Variations 
in EEG signals can be highly complex to model mathematically; however, here, we 
harness the power of deep learning, using generative models such as CGANs to 
train, model complex data distributions, and generate diverse and artificial but 
realistic EEG signals during non-REM sleep.";2023;Health related;Health related;1
Xu X, Geng G, Cao X, Li K, Zhou M.;TDNet: transformer-based network for point cloud denoising;"This study proposes a novel, to the best of our knowledge, transformer-based 
end-to-end network (TDNet) for point cloud denoising based on encoder-decoder 
architecture. The encoder is based on the structure of a transformer in natural 
language processing (NLP). Even though points and sentences are different types 
of data, the NLP transformer can be improved to be suitable for a point cloud 
because the point can be regarded as a word. The improved model facilitates 
point cloud feature extraction and transformation of the input point cloud into 
the underlying high-dimensional space, which can characterize the semantic 
relevance between points. Subsequently, the decoder learns the latent manifold 
of each sampled point from the high-dimensional features obtained by the 
encoder, finally achieving a clean point cloud. An adaptive sampling approach is 
introduced during denoising to select points closer to the clean point cloud to 
reconstruct the surface. This is based on the view that a 3D object is 
essentially a 2D manifold. Extensive experiments demonstrate that the proposed 
network is superior in terms of quantitative and qualitative results for 
synthetic data sets and real-world terracotta warrior fragments.";2022;Not health related;Not Health related;0
Kurthen M, Enßlin T.;A Bayesian Model for Bivariate Causal Inference;"We address the problem of two-variable causal inference without intervention. 
This task is to infer an existing causal relation between two random variables, 
i.e., X _ Y or Y _ X , from purely observational data. As the option to modify a 
potential cause is not given in many situations, only structural properties of 
the data can be used to solve this ill-posed problem. We briefly review a number 
of state-of-the-art methods for this, including very recent ones. A novel 
inference method is introduced, Bayesian Causal Inference (BCI) which assumes a 
generative Bayesian hierarchical model to pursue the strategy of Bayesian model 
selection. In the adopted model, the distribution of the cause variable is given 
by a Poisson lognormal distribution, which allows to explicitly regard the 
discrete nature of datasets, correlations in the parameter spaces, as well as 
the variance of probability densities on logarithmic scales. We assume Fourier 
diagonal Field covariance operators. The model itself is restricted to use cases 
where a direct causal relation X _ Y has to be decided against a relation Y _ X 
, therefore we compare it other methods for this exact problem setting. The 
generative model assumed provides synthetic causal data for benchmarking our 
model in comparison to existing state-of-the-art models, namely LiNGAM, 
ANM-HSIC, ANM-MML, IGCI, and CGNN. We explore how well the above methods perform 
in case of high noise settings, strongly discretized data, and very sparse data. 
BCI performs generally reliably with synthetic data as well as with the real 
world TCEP benchmark set, with an accuracy comparable to state-of-the-art 
algorithms. We discuss directions for the future development of BCI.";2019;Not health related;Not Health related;0
Lavda F, Gregorová M, Kalousis A.;Data-Dependent Conditional Priors for Unsupervised Learning of Multimodal Data;"One of the major shortcomings of variational autoencoders is the inability to 
produce generations from the individual modalities of data originating from 
mixture distributions. This is primarily due to the use of a simple isotropic 
Gaussian as the prior for the latent code in the ancestral sampling procedure 
for data generations. In this paper, we propose a novel formulation of 
variational autoencoders, conditional prior VAE (CP-VAE), with a two-level 
generative process for the observed data where continuous z and a discrete c 
variables are introduced in addition to the observed variables x. By learning 
data-dependent conditional priors, the new variational objective naturally 
encourages a better match between the posterior and prior conditionals, and the 
learning of the latent categories encoding the major source of variation of the 
original data in an unsupervised manner. Through sampling continuous latent code 
from the data-dependent conditional priors, we are able to generate new samples 
from the individual mixture components corresponding, to the multimodal 
structure over the original data. Moreover, we unify and analyse our objective 
under different independence assumptions for the joint distribution of the 
continuous and discrete latent variables. We provide an empirical evaluation on 
one synthetic dataset and three image datasets, FashionMNIST, MNIST, and 
Omniglot, illustrating the generative performance of our new model comparing to 
multiple baselines.";2020;Not health related;Not Health related;0
Momeni S, Fazlollahi A, Lebrat L, Yates P, Rowe C, Gao Y, Liew AW, Salvado O.;Generative Model of Brain Microbleeds for MRI Detection of Vascular Marker of Neurodegenerative Diseases;"Cerebral microbleeds (CMB) are increasingly present with aging and can reveal 
vascular pathologies associated with neurodegeneration. Deep learning-based 
classifiers can detect and quantify CMB from MRI, such as susceptibility 
imaging, but are challenging to train because of the limited availability of 
ground truth and many confounding imaging features, such as vessels or infarcts. 
In this study, we present a novel generative adversarial network (GAN) that has 
been trained to generate three-dimensional lesions, conditioned by volume and 
location. This allows one to investigate CMB characteristics and create large 
training datasets for deep learning-based detectors. We demonstrate the benefit 
of this approach by achieving state-of-the-art CMB detection of real CMB using a 
convolutional neural network classifier trained on synthetic CMB. Moreover, we 
showed that our proposed 3D lesion GAN model can be applied on unseen dataset, 
with different MRI parameters and diseases, to generate synthetic lesions with 
high diversity and without needing laboriously marked ground truth.";2021;Health related;Health related;1
Zhao Z, Kunar A, Birke R, Van der Scheer H, Chen LY.;CTAB-GAN+: enhancing tabular data synthesis;"The usage of synthetic data is gaining momentum in part due to the 
unavailability of original data due to privacy and legal considerations and in 
part due to its utility as an augmentation to the authentic data. Generative 
adversarial networks (GANs), a paragon of generative models, initially for 
images and subsequently for tabular data, has contributed many of the 
state-of-the-art synthesizers. As GANs improve, the synthesized data 
increasingly resemble the real data risking to leak privacy. Differential 
privacy (DP) provides theoretical guarantees on privacy loss but degrades data 
utility. Striking the best trade-off remains yet a challenging research 
question. In this study, we propose CTAB-GAN+ a novel conditional tabular GAN. 
CTAB-GAN+ improves upon state-of-the-art by (i) adding downstream losses to 
conditional GAN for higher utility synthetic data in both classification and 
regression domains; (ii) using Wasserstein loss with gradient penalty for better 
training convergence; (iii) introducing novel encoders targeting mixed 
continuous-categorical variables and variables with unbalanced or skewed data; 
and (iv) training with DP stochastic gradient descent to impose strict privacy 
guarantees. We extensively evaluate CTAB-GAN+ on statistical similarity and 
machine learning utility against state-of-the-art tabular GANs. The results show 
that CTAB-GAN+ synthesizes privacy-preserving data with at least 21.9% higher 
machine learning utility (i.e., F1-Score) across multiple datasets and learning 
tasks under given privacy budget.";2024;Not health related;Not Health related;0
Burt JB, Helmer M, Shinn M, Anticevic A, Murray JD.;Generative modeling of brain maps with spatial autocorrelation;"Studies of large-scale brain organization have revealed interesting 
relationships between spatial gradients in brain maps across multiple 
modalities. Evaluating the significance of these findings requires establishing 
statistical expectations under a null hypothesis of interest. Through generative 
modeling of synthetic data that instantiate a specific null hypothesis, 
quantitative benchmarks can be derived for arbitrarily complex statistical 
measures. Here, we present a generative null model, provided as an open-access 
software platform, that generates surrogate maps with spatial autocorrelation 
(SA) matched to SA of a target brain map. SA is a prominent and ubiquitous 
property of brain maps that violates assumptions of independence in conventional 
statistical tests. Our method can simulate surrogate brain maps, constrained by 
empirical data, that preserve the SA of cortical, subcortical, parcellated, and 
dense brain maps. We characterize how SA impacts p-values in pairwise brain map 
comparisons. Furthermore, we demonstrate how SA-preserving surrogate maps can be 
used in gene set enrichment analyses to test hypotheses of interest related to 
brain map topography. Our findings demonstrate the utility of SA-preserving 
surrogate maps for hypothesis testing in complex statistical analyses, and 
underscore the need to disambiguate meaningful relationships from chance 
associations in studies of large-scale brain organization.";2020;Health related;Not Health related;1
Paepae T, Bokoro PN, Kyamakya K.;Data Augmentation for a Virtual-Sensor-Based Nitrogen and Phosphorus Monitoring;"To better control eutrophication, reliable and accurate information on 
phosphorus and nitrogen loading is desired. However, the high-frequency 
monitoring of these variables is economically impractical. This necessitates 
using virtual sensing to predict them by utilizing easily measurable variables 
as inputs. While the predictive performance of these data-driven, virtual-sensor 
models depends on the use of adequate training samples (in quality and 
quantity), the procurement and operational cost of nitrogen and phosphorus 
sensors make it impractical to acquire sufficient samples. For this reason, the 
variational autoencoder, which is one of the most prominent methods in 
generative models, was utilized in the present work for generating synthetic 
data. The generation capacity of the model was verified using water-quality data 
from two tributaries of the River Thames in the United Kingdom. Compared to the 
current state of the art, our novel data augmentation-including proper 
experimental settings or hyperparameter optimization-improved the root mean 
squared errors by 23-63%, with the most significant improvements observed when 
up to three predictors were used. In comparing the predictive algorithms' 
performances (in terms of the predictive accuracy and computational cost), 
k-nearest neighbors and extremely randomized trees were the best-performing 
algorithms on average.";2023;Not health related;Not Health related;0
O'Reilly JA, Asadi F.;Identifying Obviously Artificial Medical Images Produced by a Generative Adversarial Network;"Synthetic medical images have an important role to play in developing 
data-driven medical image processing systems. Using a relatively small amount of 
patient data to train generative models that can produce an abundance of 
additional samples could bridge the gap towards big-data in niche medical 
domains. These generative models are evaluated in terms of the synthetic data 
they generate using the Visual Turing Test (VTT), Fréchet Inception Distance 
(FID), and other metrics. However, these are generally interpreted at the group 
level, and do not measure the artificiality of individual synthetic images. The 
present study attempts to address the challenge of automatically identifying 
artificial images that are obviously-artificial-looking, which may be necessary 
for filtering out poorly constructed synthetic images that might otherwise 
deteriorate the performance of assimilating systems. Synthetic computed 
tomography (CT) images from a progressively-grown generative adversarial network 
(PGGAN) were evaluated with a VTT and their image embeddings were analyzed for 
correlation with artificiality. Images categorized as obviously-artificial (≥0. 
7 probability of being rated as fake) were classified using a battery of 
algorithms. The top-performing classifier, a support vector machine, exhibited 
accuracy of 75.5%, sensitivity of 0.743, and specificity of 0.769. This is an 
encouraging result that suggests a potential approach for validating synthetic 
medical image datasets. Clinical Relevance - Next-generation medical AI systems 
for image processing will utilize synthetic images produced by generative 
models. This paper presents an approach towards verifying artificial image 
legibility for quality-control before being deployed for these purposes.";2022;Health related;Health related;1
Zaballa O, Pérez A, Gómez-Inhiesto E, Acaiturri-Ayesta T, Lozano JA.;A probabilistic generative model to discover the treatments of coexisting diseases with missing data;"BACKGROUND AND OBJECTIVE: Comorbidities, defined as the presence of co-existing 
diseases, progress through complex temporal patterns among patients. Learning 
such dynamics from electronic health records is crucial for understanding the 
coevolution of diseases. In general, medical records are represented through 
temporal sequences of clinical variables together with their diagnosis. However, 
we consider the specific problem where most of the diagnoses are missing. We 
present a novel probabilistic generative model with a three-fold objective: (i) 
identify and segment the medical history of patients into treatments associated 
with comorbidities; (ii) learn the model associated with each identified disease 
treatment; and (iii) discover subtypes of patients with similar coevolution of 
comorbidities.
METHODS: To this end, the model considers a latent structure for the sequences, 
where patients are modeled by a latent class defined by the evolution of their 
comorbidities, and each observed medical event of their clinical history is 
associated with a latent disease. The learning process is performed using an 
Expectation-Maximization algorithm that considers the exponential number of 
configurations of the latent variables and is efficiently solved with dynamic 
programming.
RESULTS: The evaluation of the method is carried out both on synthetic and real 
world data: the experiments on synthetic data show that the learning procedure 
allows the generative model underlying the data to be recovered; the experiments 
on real medical data show accurate results in the segmentation of sequences into 
different treatments, subtyping of patients and diagnosis imputation.
CONCLUSION: We present an interpretable generative model that handles the 
incompleteness of EHRs and describes the different joint evolution of coexisting 
diseases depending on the active comorbidities of the patient at each moment.";2024;Health related;Health related;1
Zeraati R, Engel TA, Levina A.;A flexible Bayesian framework for unbiased estimation of timescales;"Timescales characterize the pace of change for many dynamic processes in nature. 
Timescales are usually estimated by fitting the exponential decay of data 
autocorrelation in the time or frequency domain. Here we show that this standard 
procedure often fails to recover the correct timescales due to a statistical 
bias arising from the finite sample size. We develop an alternative approach 
which estimates timescales by fitting the sample autocorrelation or power 
spectrum with a generative model based on a mixture of Ornstein-Uhlenbeck (OU) 
processes using adaptive approximate Bayesian computations (aABC). Our method 
accounts for finite sample size and noise in data and returns a posterior 
distribution of timescales that quantifies the estimation uncertainty and can be 
used for model selection. We demonstrate the accuracy of our method on synthetic 
data and illustrate its application to recordings from primate cortex. We 
provide a customizable Python package implementing our framework with different 
generative models suitable for diverse applications.";2022;Not health related;Not Health related;0
Kar P, Tiruvadi-Krishnan S, Männik J, Männik J, Amir A.;Distinguishing different modes of growth using single-cell data;"Collection of high-throughput data has become prevalent in biology. Large 
datasets allow the use of statistical constructs such as binning and linear 
regression to quantify relationships between variables and hypothesize 
underlying biological mechanisms based on it. We discuss several such examples 
in relation to single-cell data and cellular growth. In particular, we show 
instances where what appears to be ordinary use of these statistical methods 
leads to incorrect conclusions such as growth being non-exponential as opposed 
to exponential and vice versa. We propose that the data analysis and its 
interpretation should be done in the context of a generative model, if possible. 
In this way, the statistical methods can be validated either analytically or 
against synthetic data generated via the use of the model, leading to a 
consistent method for inferring biological mechanisms from data. On applying the 
validated methods of data analysis to infer cellular growth on our experimental 
data, we find the growth of length in E. coli to be non-exponential. Our 
analysis shows that in the later stages of the cell cycle the growth rate is 
faster than exponential.";2021;Not health related;Not Health related;0
Tubiana J, Wolf S, Panier T, Debregeas G.;Blind deconvolution for spike inference from fluorescence recordings;"The parallel developments of genetically-encoded calcium indicators and fast 
fluorescence imaging techniques allows one to simultaneously record neural 
activity of extended neuronal populations in vivo. To fully harness the 
potential of functional imaging, one needs to infer the sequence of action 
potentials from fluorescence traces. Here we build on recently proposed 
computational approaches to develop a blind sparse deconvolution (BSD) algorithm 
based on a generative model for inferring spike trains from fluorescence traces. 
BSD features, (1) automatic (fully unsupervised) estimation of the 
hyperparameters, such as spike amplitude, noise level and rise and decay time 
constants, (2) a novel analytical estimate of the sparsity prior, which yields 
enhanced robustness and computational speed with respect to existing methods, 
(3) automatic thresholding for binarizing spikes that maximizes the 
precision-recall performance, (4) super-resolution capabilities increasing the 
temporal resolution beyond the fluorescence signal acquisition rate. BSD also 
uniquely provides theoretically-grounded estimates of the expected performance 
of the spike reconstruction in terms of precision-recall and temporal accuracy 
for each recording. The performance of the algorithm is established using 
synthetic data and through the SpikeFinder challenge, a community-based 
initiative for spike-rate inference benchmarking based on a collection of joint 
electrophysiological and fluorescence recordings. Our method outperforms 
classical sparse deconvolution algorithms in terms of robustness, speed and/or 
accuracy and performs competitively in the SpikeFinder challenge. This algorithm 
is modular, easy-to-use and made freely available. Its novel features can thus 
be incorporated in a straightforward way into existing calcium imaging packages.";2020;Not health related;Not Health related;0
Xu J, Moyer D, Grant PE, Golland P, Iglesias JE, Adalsteinsson E.;SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI;"Volumetric reconstruction of fetal brains from multiple stacks of MR slices, 
acquired in the presence of almost unpredictable and often severe subject 
motion, is a challenging task that is highly sensitive to the initialization of 
slice-to-volume transformations. We propose a novel slice-to-volume registration 
method using Transformers trained on synthetically transformed data, which model 
multiple stacks of MR slices as a sequence. With the attention mechanism, our 
model automatically detects the relevance between slices and predicts the 
transformation of one slice using information from other slices. We also 
estimate the underlying 3D volume to assist slice-to-volume registration and 
update the volume and transformations alternately to improve accuracy. Results 
on synthetic data show that our method achieves lower registration error and 
better reconstruction quality compared with existing state-of-the-art methods. 
Experiments with real-world MRI data are also performed to demonstrate the 
ability of the proposed model to improve the quality of 3D reconstruction under 
severe fetal motion.";2022;Health related;Not Health related;1
Deveshwar N, Rajagopal A, Sahin S, Shimron E, Larson PEZ.;Synthesizing Complex-Valued Multicoil MRI Data from Magnitude-Only Images;"Despite the proliferation of deep learning techniques for accelerated MRI 
acquisition and enhanced image reconstruction, the construction of large and 
diverse MRI datasets continues to pose a barrier to effective clinical 
translation of these technologies. One major challenge is in collecting the MRI 
raw data (required for image reconstruction) from clinical scanning, as only 
magnitude images are typically saved and used for clinical assessment and 
diagnosis. The image phase and multi-channel RF coil information are not 
retained when magnitude-only images are saved in clinical imaging archives. 
Additionally, preprocessing used for data in clinical imaging can lead to biased 
results. While several groups have begun concerted efforts to collect large 
amounts of MRI raw data, current databases are limited in the diversity of 
anatomy, pathology, annotations, and acquisition types they contain. To address 
this, we present a method for synthesizing realistic MR data from magnitude-only 
data, allowing for the use of diverse data from clinical imaging archives in 
advanced MRI reconstruction development. Our method uses a conditional GAN-based 
framework to generate synthetic phase images from input magnitude images. We 
then applied ESPIRiT to derive RF coil sensitivity maps from fully sampled real 
data to generate multi-coil data. The synthetic data generation method was 
evaluated by comparing image reconstruction results from training Variational 
Networks either with real data or synthetic data. We demonstrate that the 
Variational Network trained on synthetic MRI data from our method, consisting of 
GAN-derived synthetic phase and multi-coil information, outperformed Variational 
Networks trained on data with synthetic phase generated using current 
state-of-the-art methods. Additionally, we demonstrate that the Variational 
Networks trained with synthetic k-space data from our method perform comparably 
to image reconstruction networks trained on undersampled real k-space data.";2023;Health related;Health related;1
Yoon J, Mizrahi M, Ghalaty NF, Jarvinen T, Ravi AS, Brune P, Kong F, Anderson D, Lee G, Meir A, Bandukwala F, Kanal E, Arık SÖ, Pfister T.;EHR-Safe: generating high-fidelity and privacy-preserving synthetic electronic health records;"Privacy concerns often arise as the key bottleneck for the sharing of data 
between consumers and data holders, particularly for sensitive data such as 
Electronic Health Records (EHR). This impedes the application of data analytics 
and ML-based innovations with tremendous potential. One promising approach for 
such privacy concerns is to instead use synthetic data. We propose a generative 
modeling framework, EHR-Safe, for generating highly realistic and 
privacy-preserving synthetic EHR data. EHR-Safe is based on a two-stage model 
that consists of sequential encoder-decoder networks and generative adversarial 
networks. Our innovations focus on the key challenging aspects of real-world EHR 
data: heterogeneity, sparsity, coexistence of numerical and categorical features 
with distinct characteristics, and time-varying features with highly-varying 
sequence lengths. Under numerous evaluations, we demonstrate that the fidelity 
of EHR-Safe is almost-identical with real data (<3% accuracy difference for the 
models trained on them) while yielding almost-ideal performance in practical 
privacy metrics.";2023;Health related;Health related;1
Sreejith Kumar AJ, Chong RS, Crowston JG, Chua J, Bujor I, Husain R, Vithana EN, Girard MJA, Ting DSW, Cheng CY, Aung T, Popa-Cherecheanu A, Schmetterer L, Wong D.;Evaluation of Generative Adversarial Networks for High-Resolution Synthetic Image Generation of Circumpapillary Optical Coherence Tomography Images for Glaucoma;"IMPORTANCE: Deep learning (DL) networks require large data sets for training, 
which can be challenging to collect clinically. Generative models could be used 
to generate large numbers of synthetic optical coherence tomography (OCT) images 
to train such DL networks for glaucoma detection.
OBJECTIVE: To assess whether generative models can synthesize circumpapillary 
optic nerve head OCT images of normal and glaucomatous eyes and determine the 
usability of synthetic images for training DL models for glaucoma detection.
DESIGN, SETTING, AND PARTICIPANTS: Progressively growing generative adversarial 
network models were trained to generate circumpapillary OCT scans. Image 
gradeability and authenticity were evaluated on a clinical set of 100 real and 
100 synthetic images by 2 clinical experts. DL networks for glaucoma detection 
were trained with real or synthetic images and evaluated on independent internal 
and external test data sets of 140 and 300 real images, respectively.
MAIN OUTCOMES AND MEASURES: Evaluations of the clinical set between the experts 
were compared. Glaucoma detection performance of the DL networks was assessed 
using area under the curve (AUC) analysis. Class activation maps provided 
visualizations of the regions contributing to the respective classifications.
RESULTS: A total of 990 normal and 862 glaucomatous eyes were analyzed. 
Evaluations of the clinical set were similar for gradeability (expert 1: 92.0%; 
expert 2: 93.0%) and authenticity (expert 1: 51.8%; expert 2: 51.3%). The 
best-performing DL network trained on synthetic images had AUC scores of 0.97 
(95% CI, 0.95-0.99) on the internal test data set and 0.90 (95% CI, 0.87-0.93) 
on the external test data set, compared with AUCs of 0.96 (95% CI, 0.94-0.99) on 
the internal test data set and 0.84 (95% CI, 0.80-0.87) on the external test 
data set for the network trained with real images. An increase in the AUC for 
the synthetic DL network was observed with the use of larger synthetic data set 
sizes. Class activation maps showed that the regions of the synthetic images 
contributing to glaucoma detection were generally similar to that of real 
images.
CONCLUSIONS AND RELEVANCE: DL networks trained with synthetic OCT images for 
glaucoma detection were comparable with networks trained with real images. These 
results suggest potential use of generative models in the training of DL 
networks and as a means of data sharing across institutions without patient 
information confidentiality issues.";2022;Health related;Health related;1
Li Y, Guo J, Qiu H, Chen F, Zhang J.;Denoising Diffusion Probabilistic Models and Transfer Learning for citrus disease diagnosis;"PROBLEMS: Plant Disease diagnosis based on deep learning mechanisms has been 
extensively studied and applied. However, the complex and dynamic agricultural 
growth environment results in significant variations in the distribution of 
state samples, and the lack of sufficient real disease databases weakens the 
information carried by the samples, posing challenges for accurately training 
models.
AIM: This paper aims to test the feasibility and effectiveness of Denoising 
Diffusion Probabilistic Models (DDPM), Swin Transformer model, and Transfer 
Learning in diagnosing citrus diseases with a small sample.
METHODS: Two training methods are proposed: The Method 1 employs the DDPM to 
generate synthetic images for data augmentation. The Swin Transformer model is 
then used for pre-training on the synthetic dataset produced by DDPM, followed 
by fine-tuning on the original citrus leaf images for disease classification 
through transfer learning. The Method 2 utilizes the pre-trained Swin 
Transformer model on the ImageNet dataset and fine-tunes it on the augmented 
dataset composed of the original and DDPM synthetic images.
RESULTS AND CONCLUSION: The test results indicate that Method 1 achieved a 
validation accuracy of 96.3%, while Method 2 achieved a validation accuracy of 
99.8%. Both methods effectively addressed the issue of model overfitting when 
dealing with a small dataset. Additionally, when compared with VGG16, 
EfficientNet, ShuffleNet, MobileNetV2, and DenseNet121 in citrus disease 
classification, the experimental results demonstrate the superiority of the 
proposed methods over existing approaches to a certain extent.";2023;Not health related;Health related;0
Zhu D, Fu L, Kazei V, Li W.;Diffusion Model for DAS-VSP Data Denoising;"Distributed acoustic sensing (DAS) has emerged as a transformational technology 
for seismic data acquisition. However, noise remains a major impediment, 
necessitating advanced denoising techniques. This study pioneers the application 
of diffusion models, a type of generative model, for DAS vertical seismic 
profile (VSP) data denoising. The diffusion network is trained on a new 
generated synthetic dataset that accommodates variations in the acquisition 
parameters. The trained model is applied to suppress noise in synthetic and 
field DAS-VSP data. The results demonstrate the model's effectiveness in 
removing various noise types with minimal signal leakage, outperforming 
conventional methods. This research signifies diffusion models' potential for 
DAS processing.";2023;Not health related;Not Health related;0
Allen C, Aryal S, Do T, Gautum R, Hasan MM, Jasthi BK, Gnimpieba E, Gadhamshetty V.;Deep learning strategies for addressing issues with small datasets in 2D materials research: Microbial Corrosion;"Protective coatings based on two dimensional materials such as graphene have 
gained traction for diverse applications. Their impermeability, inertness, 
excellent bonding with metals, and amenability to functionalization renders them 
as promising coatings for both abiotic and microbiologically influenced 
corrosion (MIC). Owing to the success of graphene coatings, the whole family of 
2D materials, including hexagonal boron nitride and molybdenum disulphide are 
being screened to obtain other promising coatings. AI-based data-driven models 
can accelerate virtual screening of 2D coatings with desirable physical and 
chemical properties. However, lack of large experimental datasets renders 
training of classifiers difficult and often results in over-fitting. Generate 
large datasets for MIC resistance of 2D coatings is both complex and laborious. 
Deep learning data augmentation methods can alleviate this issue by generating 
synthetic electrochemical data that resembles the training data classes. Here, 
we investigated two different deep generative models, namely variation 
autoencoder (VAE) and generative adversarial network (GAN) for generating 
synthetic data for expanding small experimental datasets. Our model experimental 
system included few layered graphene over copper surfaces. The synthetic data 
generated using GAN displayed a greater neural network system performance 
(83-85% accuracy) than VAE generated synthetic data (78-80% accuracy). However, 
VAE data performed better (90% accuracy) than GAN data (84%-85% accuracy) when 
using XGBoost. Finally, we show that synthetic data based on VAE and GAN models 
can drive machine learning models for developing MIC resistant 2D coatings.";2022;Not health related;Not Health related;0
Pan S, Wang T, Qiu RLJ, Axente M, Chang CW, Peng J, Patel AB, Shelton J, Patel SA, Roper J, Yang X.;2D medical image synthesis using transformer-based denoising diffusion probabilistic model;"Objective. Artificial intelligence (AI) methods have gained popularity in 
medical imaging research. The size and scope of the training image datasets 
needed for successful AI model deployment does not always have the desired 
scale. In this paper, we introduce a medical image synthesis framework aimed at 
addressing the challenge of limited training datasets for AI models.Approach. 
The proposed 2D image synthesis framework is based on a diffusion model using a 
Swin-transformer-based network. This model consists of a forward Gaussian noise 
process and a reverse process using the transformer-based diffusion model for 
denoising. Training data includes four image datasets: chest x-rays, heart MRI, 
pelvic CT, and abdomen CT. We evaluated the authenticity, quality, and diversity 
of the synthetic images using visual Turing assessments conducted by three 
medical physicists, and four quantitative evaluations: the Inception score (IS), 
Fréchet Inception Distance score (FID), feature similarity and diversity score 
(DS, indicating diversity similarity) between the synthetic and true images. To 
leverage the framework value for training AI models, we conducted COVID-19 
classification tasks using real images, synthetic images, and mixtures of both 
images.Main results. Visual Turing assessments showed an average accuracy of 
0.64 (accuracy converging to50%indicates a better realistic visual appearance of 
the synthetic images), sensitivity of 0.79, and specificity of 0.50. Average 
quantitative accuracy obtained from all datasets were IS = 2.28, FID = 37.27, 
FDS = 0.20, and DS = 0.86. For the COVID-19 classification task, the baseline 
network obtained an accuracy of 0.88 using a pure real dataset, 0.89 using a 
pure synthetic dataset, and 0.93 using a dataset mixed of real and synthetic 
data.Significance. A image synthesis framework was demonstrated for medical 
image synthesis, which can generate high-quality medical images of different 
imaging modalities with the purpose of supplementing existing training sets for 
AI model deployment. This method has potential applications in many data-driven 
medical imaging research.";2023;Health related;Health related;1
Boelts J, Harth P, Gao R, Udvary D, Yáñez F, Baum D, Hege HC, Oberlaender M, Macke JH.;Simulation-based inference for efficient identification of generative models in computational connectomics;"Recent advances in connectomics research enable the acquisition of increasing 
amounts of data about the connectivity patterns of neurons. How can we use this 
wealth of data to efficiently derive and test hypotheses about the principles 
underlying these patterns? A common approach is to simulate neuronal networks 
using a hypothesized wiring rule in a generative model and to compare the 
resulting synthetic data with empirical data. However, most wiring rules have at 
least some free parameters, and identifying parameters that reproduce empirical 
data can be challenging as it often requires manual parameter tuning. Here, we 
propose to use simulation-based Bayesian inference (SBI) to address this 
challenge. Rather than optimizing a fixed wiring rule to fit the empirical data, 
SBI considers many parametrizations of a rule and performs Bayesian inference to 
identify the parameters that are compatible with the data. It uses simulated 
data from multiple candidate wiring rule parameters and relies on machine 
learning methods to estimate a probability distribution (the 'posterior 
distribution over parameters conditioned on the data') that characterizes all 
data-compatible parameters. We demonstrate how to apply SBI in computational 
connectomics by inferring the parameters of wiring rules in an in silico model 
of the rat barrel cortex, given in vivo connectivity measurements. SBI 
identifies a wide range of wiring rule parameters that reproduce the 
measurements. We show how access to the posterior distribution over all 
data-compatible parameters allows us to analyze their relationship, revealing 
biologically plausible parameter interactions and enabling experimentally 
testable predictions. We further show how SBI can be applied to wiring rules at 
different spatial scales to quantitatively rule out invalid wiring hypotheses. 
Our approach is applicable to a wide range of generative models used in 
connectomics, providing a quantitative and efficient way to constrain model 
parameters with empirical connectivity data.";2023;Not health related;Not Health related;0
Aetesam H, Maji SK.;Perceptually Motivated Generative Model for Magnetic Resonance Image Denoising;"Image denoising is an important preprocessing step in low-level vision problems 
involving biomedical images. Noise removal techniques can greatly benefit raw 
corrupted magnetic resonance images (MRI). It has been discovered that the MR 
data is corrupted by a mixture of Gaussian-impulse noise caused by detector 
flaws and transmission errors. This paper proposes a deep generative model 
(GenMRIDenoiser) for dealing with this mixed noise scenario. This work makes 
four contributions. To begin, Wasserstein generative adversarial network (WGAN) 
is used in model training to mitigate the problem of vanishing gradient, mode 
collapse, and convergence issues encountered while training a vanilla GAN. 
Second, a perceptually motivated loss function is used to guide the training 
process in order to preserve the low-level details in the form of high-frequency 
components in the image. Third, batch renormalization is used between the 
convolutional and activation layers to prevent performance degradation under the 
assumption of non-independent and identically distributed (non-iid) data. 
Fourth, global feature attention module (GFAM) is appended at the beginning and 
end of the parallel ensemble blocks to capture the long-range dependencies that 
are often lost due to the small receptive field of convolutional filters. The 
experimental results over synthetic data and MRI stack obtained from real MR 
scanners indicate the potential utility of the proposed technique across a wide 
range of degradation scenarios.";2023;Health related;Health related;1
Taghia J, Ryali S, Chen T, Supekar K, Cai W, Menon V.;Bayesian switching factor analysis for estimating time-varying functional connectivity in fMRI;"There is growing interest in understanding the dynamical properties of 
functional interactions between distributed brain regions. However, robust 
estimation of temporal dynamics from functional magnetic resonance imaging 
(fMRI) data remains challenging due to limitations in extant multivariate 
methods for modeling time-varying functional interactions between multiple brain 
areas. Here, we develop a Bayesian generative model for fMRI time-series within 
the framework of hidden Markov models (HMMs). The model is a dynamic variant of 
the static factor analysis model (Ghahramani and Beal, 2000). We refer to this 
model as Bayesian switching factor analysis (BSFA) as it integrates factor 
analysis into a generative HMM in a unified Bayesian framework. In BSFA, brain 
dynamic functional networks are represented by latent states which are learnt 
from the data. Crucially, BSFA is a generative model which estimates the 
temporal evolution of brain states and transition probabilities between states 
as a function of time. An attractive feature of BSFA is the automatic 
determination of the number of latent states via Bayesian model selection 
arising from penalization of excessively complex models. Key features of BSFA 
are validated using extensive simulations on carefully designed synthetic data. 
We further validate BSFA using fingerprint analysis of multisession 
resting-state fMRI data from the Human Connectome Project (HCP). Our results 
show that modeling temporal dependencies in the generative model of BSFA results 
in improved fingerprinting of individual participants. Finally, we apply BSFA to 
elucidate the dynamic functional organization of the salience, 
central-executive, and default mode networks-three core neurocognitive systems 
with central role in cognitive and affective information processing (Menon, 
2011). Across two HCP sessions, we demonstrate a high level of dynamic 
interactions between these networks and determine that the salience network has 
the highest temporal flexibility among the three networks. Our proposed methods 
provide a novel and powerful generative model for investigating dynamic brain 
connectivity.";2017;Health related;Not Health related;1
Hebert L, Ahamed T, Costa AC, O'Shaughnessy L, Stephens GJ.;WormPose: Image synthesis and convolutional networks for pose estimation in C. elegans;"An important model system for understanding genes, neurons and behavior, the 
nematode worm C. elegans naturally moves through a variety of complex postures, 
for which estimation from video data is challenging. We introduce an open-source 
Python package, WormPose, for 2D pose estimation in C. elegans, including 
self-occluded, coiled shapes. We leverage advances in machine vision afforded 
from convolutional neural networks and introduce a synthetic yet realistic 
generative model for images of worm posture, thus avoiding the need for 
human-labeled training. WormPose is effective and adaptable for imaging 
conditions across worm tracking efforts. We quantify pose estimation using 
synthetic data as well as N2 and mutant worms in on-food conditions. We further 
demonstrate WormPose by analyzing long (_ 8 hour), fast-sampled (_ 30 Hz) 
recordings of on-food N2 worms to provide a posture-scale analysis of 
roaming/dwelling behaviors.";2021;Not health related;Not Health related;0
Li J, Cairns BJ, Li J, Zhu T.;Generating synthetic mixed-type longitudinal electronic health records for artificial intelligent applications;"The recent availability of electronic health records (EHRs) have provided 
enormous opportunities to develop artificial intelligence (AI) algorithms. 
However, patient privacy has become a major concern that limits data sharing 
across hospital settings and subsequently hinders the advances in AI. Synthetic 
data, which benefits from the development and proliferation of generative 
models, has served as a promising substitute for real patient EHR data. However, 
the current generative models are limited as they only generate single type of 
clinical data for a synthetic patient, i.e., either continuous-valued or 
discrete-valued. To mimic the nature of clinical decision-making which 
encompasses various data types/sources, in this study, we propose a generative 
adversarial network (GAN) entitled EHR-M-GAN that simultaneously synthesizes 
mixed-type timeseries EHR data. EHR-M-GAN is capable of capturing the 
multidimensional, heterogeneous, and correlated temporal dynamics in patient 
trajectories. We have validated EHR-M-GAN on three publicly-available intensive 
care unit databases with records from a total of 141,488 unique patients, and 
performed privacy risk evaluation of the proposed model. EHR-M-GAN has 
demonstrated its superiority over state-of-the-art benchmarks for synthesizing 
clinical timeseries with high fidelity, while addressing the limitations 
regarding data types and dimensionality in the current generative models. 
Notably, prediction models for outcomes of intensive care performed 
significantly better when training data was augmented with the addition of 
EHR-M-GAN-generated timeseries. EHR-M-GAN may have use in developing AI 
algorithms in resource-limited settings, lowering the barrier for data 
acquisition while preserving patient privacy.";2023;Health related;Health related;1
Kuo NI, Perez-Concha O, Hanly M, Mnatzaganian E, Hao B, Di Sipio M, Yu G, Vanjara J, Valerie IC, de Oliveira Costa J, Churches T, Lujic S, Hegarty J, Jorm L, Barbieri S.;Enriching Data Science and Health Care Education: Application and Impact of Synthetic Data Sets Through the Health Gym Project;"Large-scale medical data sets are vital for hands-on education in health data 
science but are often inaccessible due to privacy concerns. Addressing this gap, 
we developed the Health Gym project, a free and open-source platform designed to 
generate synthetic health data sets applicable to various areas of data science 
education, including machine learning, data visualization, and traditional 
statistical models. Initially, we generated 3 synthetic data sets for sepsis, 
acute hypotension, and antiretroviral therapy for HIV infection. This paper 
discusses the educational applications of Health Gym's synthetic data sets. We 
illustrate this through their use in postgraduate health data science courses 
delivered by the University of New South Wales, Australia, and a Datathon event, 
involving academics, students, clinicians, and local health district 
professionals. We also include adaptable worked examples using our synthetic 
data sets, designed to enrich hands-on tutorial and workshop experiences. 
Although we highlight the potential of these data sets in advancing data science 
education and health care artificial intelligence, we also emphasize the need 
for continued research into the inherent limitations of synthetic data.";2024;Health related;Health related;1
Polykovskiy D, Zhebrak A, Sanchez-Lengeling B, Golovanov S, Tatanov O, Belyaev S, Kurbanov R, Artamonov A, Aladinskiy V, Veselov M, Kadurin A, Johansson S, Chen H, Nikolenko S, Aspuru-Guzik A, Zhavoronkov A.;Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models;"Generative models are becoming a tool of choice for exploring the molecular 
space. These models learn on a large training dataset and produce novel 
molecular structures with similar properties. Generated structures can be 
utilized for virtual screening or training semi-supervized predictive models in 
the downstream tasks. While there are plenty of generative models, it is unclear 
how to compare and rank them. In this work, we introduce a benchmarking platform 
called Molecular Sets (MOSES) to standardize training and comparison of 
molecular generative models. MOSES provides training and testing datasets, and a 
set of metrics to evaluate the quality and diversity of generated structures. We 
have implemented and compared several molecular generation models and suggest to 
use our results as reference points for further advancements in generative 
chemistry research. The platform and source code are available at 
https://github.com/molecularsets/moses.";2020;Not health related;Not Health related;0
Ghosheh GO, Thwaites CL, Zhu T.;Synthesizing Electronic Health Records for Predictive Models in Low-Middle-Income Countries (LMICs);"The spread of machine learning models, coupled with by the growing adoption of 
electronic health records (EHRs), has opened the door for developing clinical 
decision support systems. However, despite the great promise of machine learning 
for healthcare in low-middle-income countries (LMICs), many data-specific 
limitations, such as the small size and irregular sampling, hinder the progress 
in such applications. Recently, deep generative models have been proposed to 
generate realistic-looking synthetic data, including EHRs, by learning the 
underlying data distribution without compromising patient privacy. In this 
study, we first use a deep generative model to generate synthetic data based on 
a small dataset (364 patients) from a LMIC setting. Next, we use synthetic data 
to build models that predict the onset of hospital-acquired infections based on 
minimal information collected at patient ICU admission. The performance of the 
diagnostic model trained on the synthetic data outperformed models trained on 
the original and oversampled data using techniques such as SMOTE. We also 
experiment with varying the size of the synthetic data and observe the impact on 
the performance and interpretability of the models. Our results show the promise 
of using deep generative models in enabling healthcare data owners to develop 
and validate models that serve their needs and applications, despite limitations 
in dataset size.";2023;Health related;Health related;1
Zou Q, Priya S, Nagpal P, Jacob M.;Joint Cardiac T(1) Mapping and Cardiac Cine Using Manifold Modeling;"The main focus of this work is to introduce a single free-breathing and ungated 
imaging protocol to jointly estimate cardiac function and myocardial T1 maps. We 
reconstruct a time series of images corresponding to k-space data from a 
free-breathing and ungated inversion recovery gradient echo sequence using a 
manifold algorithm. We model each image in the time series as a non-linear 
function of three variables: cardiac and respiratory phases and inversion time. 
The non-linear function is realized using a convolutional neural networks (CNN) 
generator, while the CNN parameters, as well as the phase information, are 
estimated from the measured k-t space data. We use a dense conditional 
auto-encoder to estimate the cardiac and respiratory phases from the central 
multi-channel k-space samples acquired at each frame. The latent vectors of the 
auto-encoder are constrained to be bandlimited functions with appropriate 
frequency bands, which enables the disentanglement of the latent vectors into 
cardiac and respiratory phases, even when the data are acquired with 
intermittent inversion pulses. Once the phases are estimated, we pose the image 
recovery as the learning of the parameters of the CNN generator from the 
measured k-t space data. The learned CNN generator is used to generate synthetic 
data on demand by feeding it with appropriate latent vectors. The proposed 
approach capitalizes on the synergies between cine MRI and T1 mapping to reduce 
the scan time and improve patient comfort. The framework also enables the 
generation of synthetic breath-held cine movies with different inversion 
contrasts, which improves the visualization of the myocardium. In addition, the 
approach also enables the estimation of the T1 maps with specific phases, which 
is challenging with breath-held approaches.";2023;Health related;Health related;1
Zaballa O, Pérez A, Gómez Inhiesto E, Acaiturri Ayesta T, Lozano JA.;Learning the progression patterns of treatments using a probabilistic generative model;"Modeling a disease or the treatment of a patient has drawn much attention in 
recent years due to the vast amount of information that Electronic Health 
Records contain. This paper presents a probabilistic generative model of 
treatments that are described in terms of sequences of medical activities of 
variable length. The main objective is to identify distinct subtypes of 
treatments for a given disease, and discover their development and progression. 
To this end, the model considers that a sequence of actions has an associated 
hierarchical structure of latent variables that both classifies the sequences 
based on their evolution over time, and segments the sequences into different 
progression stages. The learning procedure of the model is performed with the 
Expectation-Maximization algorithm which considers the exponential number of 
configurations of the latent variables and is efficiently solved with a method 
based on dynamic programming. The evaluation of the model is twofold: first, we 
use synthetic data to demonstrate that the learning procedure allows the 
generative model underlying the data to be recovered; we then further assess the 
potential of our model to provide treatment classification and staging 
information in real-world data. Our model can be seen as a tool for 
classification, simulation, data augmentation and missing data imputation.";2023;Health related;Health related;1
Osuala R, Skorupko G, Lazrak N, Garrucho L, García E, Joshi S, Jouide S, Rutherford M, Prior F, Kushibar K, Díaz O, Lekadir K.;medigan: a Python library of pretrained generative models for medical image synthesis;"PURPOSE: Deep learning has shown great promise as the backbone of clinical 
decision support systems. Synthetic data generated by generative models can 
enhance the performance and capabilities of data-hungry deep learning models. 
However, there is (1) limited availability of (synthetic) datasets and 
(2) generative models are complex to train, which hinders their adoption in 
research and clinical applications. To reduce this entry barrier, we explore 
generative model sharing to allow more researchers to access, generate, and 
benefit from synthetic data.
APPROACH: We propose medigan, a one-stop shop for pretrained generative models 
implemented as an open-source framework-agnostic Python library. After gathering 
end-user requirements, design decisions based on usability, technical 
feasibility, and scalability are formulated. Subsequently, we implement medigan 
based on modular components for generative model (i) execution, 
(ii) visualization, (iii) search & ranking, and (iv) contribution. We integrate 
pretrained models with applications across modalities such as mammography, 
endoscopy, x-ray, and MRI.
RESULTS: The scalability and design of the library are demonstrated by its 
growing number of integrated and readily-usable pretrained generative models, 
which include 21 models utilizing nine different generative adversarial network 
architectures trained on 11 different datasets. We further analyze three medigan 
applications, which include (a) enabling community-wide sharing of restricted 
data, (b) investigating generative model evaluation metrics, and (c) improving 
clinical downstream tasks. In (b), we extract Fréchet inception distances (FID) 
demonstrating FID variability based on image normalization and 
radiology-specific feature extractors.
CONCLUSION: medigan allows researchers and developers to create, increase, and 
domain-adapt their training data in just a few lines of code. Capable of 
enriching and accelerating the development of clinical machine learning models, 
we show medigan's viability as platform for generative model sharing. Our 
multimodel synthetic data experiments uncover standards for assessing and 
reporting metrics, such as FID, in image synthesis studies.";2023;Health related;Health related;1
Khalitov R, Yu T, Cheng L, Yang Z.;Sparse factorization of square matrices with application to neural attention modeling;"Square matrices appear in many machine learning problems and models. 
Optimization over a large square matrix is expensive in memory and in time. 
Therefore an economic approximation is needed. Conventional approximation 
approaches factorize the square matrix into a number matrices of much lower 
ranks. However, the low-rank constraint is a performance bottleneck if the 
approximated matrix is intrinsically high-rank or close to full rank. In this 
paper, we propose to approximate a large square matrix with a product of sparse 
full-rank matrices. In the approximation, our method needs only N(logN)2 
non-zero numbers for an N_N full matrix. Our new method is especially useful for 
scalable neural attention modeling. Different from the conventional scaled 
dot-product attention methods, we train neural networks to map input data to the 
non-zero entries of the factorizing matrices. The sparse factorization method is 
tested for various square matrices, and the experimental results demonstrate 
that our method gives a better approximation when the approximated matrix is 
sparse and high-rank. As an attention module, our new method defeats Transformer 
and its several variants for long sequences in synthetic data sets and in the 
Long Range Arena benchmarks. Our code is publicly available2.";2022;Not health related;Not Health related;0
van Laarhoven T.;Generative models for local network community detection;"Local network community detection aims to find a single community in a large 
network, while inspecting only a small part of that network around a given seed 
node. This is much cheaper than finding all communities in a network. Most 
methods for local community detection are formulated as ad hoc optimization 
problems. In this paper, we instead start from a generative model for networks 
with a community structure. By assuming that the network is uniform, we can 
approximate the structure of the unobserved parts of the network to obtain a 
method for local community detection. We apply this local approximation 
technique to two variants of the stochastic block model. This results in local 
community detection methods based on probabilistic models. Interestingly, in the 
limit, one of the proposed approximations corresponds to conductance, a popular 
metric in this field. Experiments on real and synthetic data sets show 
comparable or improved results compared to state-of-the-art local community 
detection algorithms.";2018;Not health related;Not Health related;0
Vafaii H, Yates JL, Butts DA.;Hierarchical VAEs provide a normative account of motion processing in the primate brain;"The relationship between perception and inference, as postulated by Helmholtz in 
the 19th century, is paralleled in modern machine learning by generative models 
like Variational Autoencoders (VAEs) and their hierarchical variants. Here, we 
evaluate the role of hierarchical inference and its alignment with brain 
function in the domain of motion perception. We first introduce a novel 
synthetic data framework, Retinal Optic Flow Learning (ROFL), which enables 
control over motion statistics and their causes. We then present a new 
hierarchical VAE and test it against alternative models on two downstream tasks: 
(i) predicting ground truth causes of retinal optic flow (e.g., self-motion); 
and (ii) predicting the responses of neurons in the motion processing pathway of 
primates. We manipulate the model architectures (hierarchical versus 
non-hierarchical), loss functions, and the causal structure of the motion 
stimuli. We find that hierarchical latent structure in the model leads to 
several improvements. First, it improves the linear decodability of ground truth 
factors and does so in a sparse and disentangled manner. Second, our 
hierarchical VAE outperforms previous state-of-the-art models in predicting 
neuronal responses and exhibits sparse latent-to-neuron relationships. These 
results depend on the causal structure of the world, indicating that alignment 
between brains and artificial neural networks depends not only on architecture 
but also on matching ecologically relevant stimulus statistics. Taken together, 
our results suggest that hierarchical Bayesian inference underlines the brain's 
understanding of the world, and hierarchical VAEs can effectively model this 
understanding.";2023;Not health related;Not Health related;0
Saitta S, Maga L, Armour C, Votta E, O'Regan DP, Salmasi MY, Athanasiou T, Weinsaft JW, Xu XY, Pirola S, Redaelli A.;Data-driven generation of 4D velocity profiles in the aneurysmal ascending aorta;"BACKGROUND AND OBJECTIVE: Numerical simulations of blood flow are a valuable 
tool to investigate the pathophysiology of ascending thoratic aortic aneurysms 
(ATAA). To accurately reproduce in vivo hemodynamics, computational fluid 
dynamics (CFD) models must employ realistic inflow boundary conditions (BCs). 
However, the limited availability of in vivo velocity measurements, still makes 
researchers resort to idealized BCs. The aim of this study was to generate and 
thoroughly characterize a large dataset of synthetic 4D aortic velocity profiles 
sampled on a 2D cross-section along the ascending aorta with features similar to 
clinical cohorts of patients with ATAA.
METHODS: Time-resolved 3D phase contrast magnetic resonance (4D flow MRI) scans 
of 30 subjects with ATAA were processed through in-house code to extract 
anatomically consistent cross-sectional planes along the ascending aorta, 
ensuring spatial alignment among all planes and interpolating all velocity 
fields to a reference configuration. Velocity profiles of the clinical cohort 
were extensively characterized by computing flow morphology descriptors of both 
spatial and temporal features. By exploiting principal component analysis (PCA), 
a statistical shape model (SSM) of 4D aortic velocity profiles was built and a 
dataset of 437 synthetic cases with realistic properties was generated.
RESULTS: Comparison between clinical and synthetic datasets showed that the 
synthetic data presented similar characteristics as the clinical population in 
terms of key morphological parameters. The average velocity profile 
qualitatively resembled a parabolic-shaped profile, but was quantitatively 
characterized by more complex flow patterns which an idealized profile would not 
replicate. Statistically significant correlations were found between PCA 
principal modes of variation and flow descriptors.
CONCLUSIONS: We built a data-driven generative model of 4D aortic inlet velocity 
profiles, suitable to be used in computational studies of blood flow. The 
proposed software system also allows to map any of the generated velocity 
profiles to the inlet plane of any virtual subject given its coordinate set.";2023;Health related;Health related;0
Liu R, Azabou M, Dabagia M, Lin CH, Azar MG, Hengen KB, Valko M, Dyer EL.;Drop, Swap, and Generate: A Self-Supervised Approach for Generating Neural Activity;"Meaningful and simplified representations of neural activity can yield insights 
into how and what information is being processed within a neural circuit. 
However, without labels, finding representations that reveal the link between 
the brain and behavior can be challenging. Here, we introduce a novel 
unsupervised approach for learning disentangled representations of neural 
activity called Swap-VAE. Our approach combines a generative modeling framework 
with an instance-specific alignment loss that tries to maximize the 
representational similarity between transformed views of the input (brain 
state). These transformed (or augmented) views are created by dropping out 
neurons and jittering samples in time, which intuitively should lead the network 
to a representation that maintains both temporal consistency and invariance to 
the specific neurons used to represent the neural state. Through evaluations on 
both synthetic data and neural recordings from hundreds of neurons in different 
primate brains, we show that it is possible to build representations that 
disentangle neural datasets along relevant latent dimensions linked to behavior.";2021;Not health related;Not Health related;1
Sapai S, Loo JY, Ding ZY, Tan CP, Baskaran VM, Nurzaman SG.;A Deep Learning Framework for Soft Robots with Synthetic Data;"Data-driven methods with deep neural networks demonstrate promising results for 
accurate modeling in soft robots. However, deep neural network models rely on 
voluminous data in discovering the complex and nonlinear representations 
inherent in soft robots. Consequently, while it is not always possible, a 
substantial amount of effort is required for data acquisition, labeling, and 
annotation. This article introduces a data-driven learning framework based on 
synthetic data to circumvent the exhaustive data collection process. More 
specifically, we propose a novel time series generative adversarial network with 
a self-attention mechanism, Transformer TimeGAN (TTGAN) to precisely learn the 
complex dynamics of a soft robot. On top of that, the TTGAN is incorporated with 
a conditioning network that enables it to produce synthetic data for specific 
soft robot behaviors. The proposed framework is verified on a widely used 
pneumatic-based soft gripper as an exemplary experimental setup. Experimental 
results demonstrate that the TTGAN generates synthetic time series data with 
realistic soft robot dynamics. Critically, a combination of the synthetic and 
only partially available original data produces a data-driven model with 
estimation accuracy comparable to models obtained from using complete original 
data.";2023;Not health related;Not Health related;0
Winter B, Winter C, Schilling J, Bardow A.;A smile is all you need: predicting limiting activity coefficients from SMILES with natural language processing;"The knowledge of mixtures' phase equilibria is crucial in nature and technical 
chemistry. Phase equilibria calculations of mixtures require activity 
coefficients. However, experimental data on activity coefficients are often 
limited due to the high cost of experiments. For an accurate and efficient 
prediction of activity coefficients, machine learning approaches have been 
recently developed. However, current machine learning approaches still 
extrapolate poorly for activity coefficients of unknown molecules. In this work, 
we introduce a SMILES-to-properties-transformer (SPT), a natural language 
processing network, to predict binary limiting activity coefficients from SMILES 
codes. To overcome the limitations of available experimental data, we initially 
train our network on a large dataset of synthetic data sampled from COSMO-RS (10 
million data points) and then fine-tune the model on experimental data (20_870 
data points). This training strategy enables the SPT to accurately predict 
limiting activity coefficients even for unknown molecules, cutting the mean 
prediction error in half compared to state-of-the-art models for activity 
coefficient predictions such as COSMO-RS and UNIFACDortmund, and improving on 
recent machine learning approaches.";2022;Not health related;Not Health related;0
Tian Y, Bai K.;End-to-End Multitask Learning With Vision Transformer;"Multitask learning (MTL) is a challenging puzzle, particularly in the realm of 
computer vision (CV). Setting up vanilla deep MTL requires either hard or soft 
parameter sharing schemes that employ greedy search to find the optimal network 
designs. Despite its widespread application, the performance of MTL models is 
vulnerable to under-constrained parameters. In this article, we draw on the 
recent success of vision transformer (ViT) to propose a multitask representation 
learning method called multitask ViT (MTViT), which proposes a multiple branch 
transformer to sequentially process the image patches (i.e., tokens in 
transformer) that are associated with various tasks. Through the proposed 
cross-task attention (CA) module, a task token from each task branch is regarded 
as a query for exchanging information with other task branches. In contrast to 
prior models, our proposed method extracts intrinsic features using the built-in 
self-attention mechanism of the ViT and requires just linear time on memory and 
computation complexity, rather than quadratic time. Comprehensive experiments 
are carried out on two benchmark datasets, including NYU-Depth V2 (NYUDv2) and 
CityScapes, after which it is found that our proposed MTViT outperforms or is on 
par with existing convolutional neural network (CNN)-based MTL methods. In 
addition, we apply our method to a synthetic dataset in which task relatedness 
is controlled. Surprisingly, experimental results reveal that the MTViT exhibits 
excellent performance when tasks are less related.";2023;Not health related;Not Health related;0
Rizvi SKJ, Azad MA, Fraz MM.;Spectrum of Advancements and Developments in Multidisciplinary Domains for Generative Adversarial Networks (GANs);"The survey paper summarizes the recent applications and developments in the 
domain of Generative Adversarial Networks (GANs) i.e. a back propagation based 
neural network architecture for generative modeling. GANs is one of the most 
highlighted research avenue due to its synthetic data generation capabilities 
and benefits of representations comprehended irrespective of the application. 
While several reviews for GANs in the arena of image processing have been 
conducted by present but none have given attention on the review of GANs over 
multi-disciplinary domains. Therefore, in this survey, use of GAN in 
multidisciplinary applications areas and its implementation challenges have been 
done by conducting a rigorous search for journal/research article related to GAN 
and in this regard five renowned journal databases i.e. ""ACM Digital Library"","" 
Elsevier"", ""IEEE Explore"", ""Science Direct"", ""Springer"" and proceedings of best 
domain specific conference are considered. By employing hybrid research 
methodology and article inclusion and exclusion criteria, 100 research articles 
are considered encompassing 23 application domains for the survey. In this paper 
applications of GAN in various practical domain and their implementation 
challenges its associated advantages and disadvantages have been discussed. For 
the first time a survey of this type have been done where GAN with wide range of 
application and its associated advantages and disadvantages issue have been 
reviewed. Finally, this article presents several diversified prominent 
developing trends in the respective research domain which will provide a 
visionary perspective regarding ongoing GANs related research and eventually 
help to develop an intuition for problem solving using GANs.";2021;Not health related;Not Health related;0
Zhou T, Huang J, Yu T, Shao R, Li K.;HDhuman: High-quality Human Novel-view Rendering from Sparse Views;"In this paper, we aim to address the challenge of novel view rendering of human 
performers that wear clothes with complex texture patterns using a sparse set of 
camera views. Although some recent works have achieved remarkable rendering 
quality on humans with relatively uniform textures using sparse views, the 
rendering quality remains limited when dealing with complex texture patterns as 
they are unable to recover the high-frequency geometry details that are observed 
in the input views. To this end, we propose HDhuman, which uses a human 
reconstruction network with a pixel-aligned spatial transformer and a rendering 
network with geometry-guided pixel-wise feature integration to achieve 
high-quality human reconstruction and rendering. The designed pixel-aligned 
spatial transformer calculates the correlations between the input views and 
generates human reconstruction results with high-frequency details. Based on the 
surface reconstruction results, the geometry-guided pixel-wise visibility 
reasoning provides guidance for multi-view feature integration, enabling the 
rendering network to render high-quality images at 2k resolution on novel views. 
Unlike previous neural rendering works that always need to train or fine-tune an 
independent network for a different scene, our method is a general framework 
that is able to generalize to novel subjects. Experiments show that our approach 
outperforms all the prior generic or specific methods on both synthetic data and 
real-world data. Source code and test data will be made publicly available for 
research purposes.";2023;Not health related;Not Health related;0
Mahmoud Z, Li C, Zappatore M, Solyman A, Alfatemi A, Ibrahim AO, Abdelmaboud A.;Semi-supervised learning and bidirectional decoding for effective grammar correction in low-resource scenarios;"The correction of grammatical errors in natural language processing is a crucial 
task as it aims to enhance the accuracy and intelligibility of written language. 
However, developing a grammatical error correction (GEC) framework for 
low-resource languages presents significant challenges due to the lack of 
available training data. This article proposes a novel GEC framework for 
low-resource languages, using Arabic as a case study. To generate more training 
data, we propose a semi-supervised confusion method called the equal 
distribution of synthetic errors (EDSE), which generates a wide range of 
parallel training data. Additionally, this article addresses two limitations of 
the classical seq2seq GEC model, which are unbalanced outputs due to the 
unidirectional decoder and exposure bias during inference. To overcome these 
limitations, we apply a knowledge distillation technique from neural machine 
translation. This method utilizes two decoders, a forward decoder right-to-left 
and a backward decoder left-to-right, and measures their agreement using 
Kullback-Leibler divergence as a regularization term. The experimental results 
on two benchmarks demonstrate that our proposed framework outperforms the 
Transformer baseline and two widely used bidirectional decoding techniques, 
namely asynchronous and synchronous bidirectional decoding. Furthermore, the 
proposed framework reported the highest F1 score, and generating synthetic data 
using the equal distribution technique for syntactic errors resulted in a 
significant improvement in performance. These findings demonstrate the 
effectiveness of the proposed framework for improving grammatical error 
correction for low-resource languages, particularly for the Arabic language.";2023;Not health related;Not Health related;0
Wang M, Tsai TH, Di Poto C, Ferrarini A, Yu G, Ressom HW.;Topic model-based mass spectrometric data analysis in cancer biomarker discovery studies;"BACKGROUND: A fundamental challenge in quantitation of biomolecules for cancer 
biomarker discovery is owing to the heterogeneous nature of human biospecimens. 
Although this issue has been a subject of discussion in cancer genomic studies, 
it has not yet been rigorously investigated in mass spectrometry based proteomic 
and metabolomic studies. Purification of mass spectometric data is highly 
desired prior to subsequent analysis, e.g., quantitative comparison of the 
abundance of biomolecules in biological samples.
METHODS: We investigated topic models to computationally analyze mass 
spectrometric data considering both integrated peak intensities and scan-level 
features, i.e., extracted ion chromatograms (EICs). Probabilistic generative 
models enable flexible representation in data structure and infer 
sample-specific pure resources. Scan-level modeling helps alleviate information 
loss during data preprocessing. We evaluated the capability of the proposed 
models in capturing mixture proportions of contaminants and cancer profiles on 
LC-MS based serum proteomic and GC-MS based tissue metabolomic datasets acquired 
from patients with hepatocellular carcinoma (HCC) and liver cirrhosis as well as 
synthetic data we generated based on the serum proteomic data.
RESULTS: The results we obtained by analysis of the synthetic data demonstrated 
that both intensity-level and scan-level purification models can accurately 
infer the mixture proportions and the underlying true cancerous sources with 
small average error ratios (<7 %) between estimation and ground truth. By 
applying the topic model-based purification to mass spectrometric data, we found 
more proteins and metabolites with significant changes between HCC cases and 
cirrhotic controls. Candidate biomarkers selected after purification yielded 
biologically meaningful pathway analysis results and improved disease 
discrimination power in terms of the area under ROC curve compared to the 
results found prior to purification.
CONCLUSIONS: We investigated topic model-based inference methods to 
computationally address the heterogeneity issue in samples analyzed by LC/GC-MS. 
We observed that incorporation of scan-level features have the potential to lead 
to more accurate purification results by alleviating the loss in information as 
a result of integrating peaks. We believe cancer biomarker discovery studies 
that use mass spectrometric analysis of human biospecimens can greatly benefit 
from topic model-based purification of the data prior to statistical and pathway 
analyses.";2016;Health related;Health related;1
Alcaraz JML, Strodthoff N.;Diffusion-based conditional ECG generation with structured state space models;"Generating synthetic data is a promising solution for addressing privacy 
concerns that arise when distributing sensitive health data. In recent years, 
diffusion models have become the new standard for generating various types of 
data, while structured state space models have emerged as a powerful approach 
for capturing long-term dependencies in time series. Our proposed solution, 
SSSD-ECG, combines these two technologies to generate synthetic 12-lead 
electrocardiograms (ECGs) based on over 70 ECG statements. As reliable baselines 
are lacking, we also propose conditional variants of two state-of-the-art 
unconditional generative models. We conducted a thorough evaluation of the 
quality of the generated samples by assessing pre-trained classifiers on the 
generated data and by measuring the performance of a classifier trained only on 
synthetic data. SSSD-ECG outperformed its GAN-based competitors. Our approach 
was further validated through experiments that included conditional class 
interpolation and a clinical Turing test, which demonstrated the high quality of 
SSSD-ECG samples across a wide range of conditions.";2023;Health related;Health related;1
Khosravi B, Rouzrokh P, Mickley JP, Faghani S, Mulford K, Yang L, Larson AN, Howe BM, Erickson BJ, Taunton MJ, Wyles CC.;Few-shot biomedical image segmentation using diffusion models: Beyond image generation;"BACKGROUND: Medical image analysis pipelines often involve segmentation, which 
requires a large amount of annotated training data, which is time-consuming and 
costly. To address this issue, we proposed leveraging generative models to 
achieve few-shot image segmentation.
METHODS: We trained a denoising diffusion probabilistic model (DDPM) on 480,407 
pelvis radiographs to generate 256 _ 256 px synthetic images. The DDPM was 
conditioned on demographic and radiologic characteristics and was rigorously 
validated by domain experts and objective image quality metrics (Frechet 
inception distance [FID] and inception score [IS]). For the next step, three 
landmarks (greater trochanter [GT], lesser trochanter [LT], and obturator 
foramen [OF]) were annotated on 45 real-patient radiographs; 25 for training and 
20 for testing. To extract features, each image was passed through the 
pre-trained DDPM at three timesteps and for each pass, features from specific 
blocks were extracted. The features were concatenated with the real image to 
form an image with 4225 channels. The feature-set was broken into random 
patches, which were fed to a U-Net. Dice Similarity Coefficient (DSC) was used 
to compare the performance with a vanilla U-Net trained on radiographs.
RESULTS: Expert accuracy was 57.5 % in determining real versus generated images, 
while the model reached an FID = 7.2 and IS = 210. The segmentation UNet trained 
on the 20 feature-sets achieved a DSC of 0.90, 0.84, and 0.61 for OF, GT, and LT 
segmentation, respectively, which was at least 0.30 points higher than the 
naively trained model.
CONCLUSION: We demonstrated the applicability of DDPMs as feature extractors, 
facilitating medical image segmentation with few annotated samples.";2023;Health related;Health related;1
Deshpande S, Minhas F, Graham S, Rajpoot N.;SAFRON: Stitching Across the Frontier Network for Generating Colorectal Cancer Histology Images;"Automated synthesis of histology images has several potential applications 
including the development of data-efficient deep learning algorithms. In the 
field of computational pathology, where histology images are large in size and 
visual context is crucial, synthesis of large high-resolution images via 
generative modeling is an important but challenging task due to memory and 
computational constraints. To address this challenge, we propose a novel 
framework called SAFRON (Stitching Across the FROntier Network) to construct 
realistic, large high-resolution tissue images conditioned on input tissue 
component masks. The main novelty in the framework is integration of stitching 
in its loss function which enables generation of images of arbitrarily large 
sizes after training on relatively small image patches while preserving 
morphological features with minimal boundary artifacts. We have used the 
proposed framework for generating, to the best of our knowledge, the 
largest-sized synthetic histology images to date (up to 11K_8K pixels). Compared 
to existing approaches, our framework is efficient in terms of the memory 
required for training and computations needed for synthesizing large 
high-resolution images. The quality of generated images was assessed 
quantitatively using Frechet Inception Distance as well as by 7 trained 
pathologists, who assigned a realism score to a set of images generated by 
SAFRON. The average realism score across all pathologists for synthetic images 
was as high as that of real images. We also show that training with additional 
synthetic data generated by SAFRON can significantly boost prediction 
performance of gland segmentation and cancer detection algorithms in colorectal 
cancer histology images.";2022;Health related;Health related;1
Carrle FP, Hollenbenders Y, Reichenbach A.;Generation of synthetic EEG data for training algorithms supporting the diagnosis of major depressive disorder;"INTRODUCTION: Major depressive disorder (MDD) is the most common mental disorder 
worldwide, leading to impairment in quality and independence of life. 
Electroencephalography (EEG) biomarkers processed with machine learning (ML) 
algorithms have been explored for objective diagnoses with promising results. 
However, the generalizability of those models, a prerequisite for clinical 
application, is restricted by small datasets. One approach to train ML models 
with good generalizability is complementing the original with synthetic data 
produced by generative algorithms. Another advantage of synthetic data is the 
possibility of publishing the data for other researchers without risking patient 
data privacy. Synthetic EEG time-series have not yet been generated for two 
clinical populations like MDD patients and healthy controls.
METHODS: We first reviewed 27 studies presenting EEG data augmentation with 
generative algorithms for classification tasks, like diagnosis, for the 
possibilities and shortcomings of recent methods. The subsequent empirical study 
generated EEG time-series based on two public datasets with 30/28 and 24/29 
subjects (MDD/controls). To obtain baseline diagnostic accuracies, convolutional 
neural networks (CNN) were trained with time-series from each dataset. The data 
were synthesized with generative adversarial networks (GAN) consisting of CNNs. 
We evaluated the synthetic data qualitatively and quantitatively and finally 
used it for re-training the diagnostic model.
RESULTS: The reviewed studies improved their classification accuracies by 
between 1 and 40% with the synthetic data. Our own diagnostic accuracy improved 
up to 10% for one dataset but not significantly for the other. We found a rich 
repertoire of generative models in the reviewed literature, solving various 
technical issues. A major shortcoming in the field is the lack of meaningful 
evaluation metrics for synthetic data. The few studies analyzing the data in the 
frequency domain, including our own, show that only some features can be 
produced truthfully.
DISCUSSION: The systematic review combined with our own investigation provides 
an overview of the available methods for generating EEG data for a 
classification task, their possibilities, and shortcomings. The approach is 
promising and the technical basis is set. For a broad application of these 
techniques in neuroscience research or clinical application, the methods need 
fine-tuning facilitated by domain expertise in (clinical) EEG research.";2023;Health related;Health related;1
Xu IRL, Van Booven DJ, Goberdhan S, Breto A, Porto J, Alhusseini M, Algohary A, Stoyanova R, Punnen S, Mahne A, Arora H.;Generative Adversarial Networks Can Create High Quality Artificial Prostate Cancer Magnetic Resonance Images;"The recent integration of open-source data with machine learning models, 
especially in the medical field, has opened new doors to studying disease 
progression and/or regression. However, the ability to use medical data for 
machine learning approaches is limited by the specificity of data for a 
particular medical condition. In this context, the most recent technologies, 
like generative adversarial networks (GANs), are being looked upon as a 
potential way to generate high-quality synthetic data that preserve the clinical 
variability of a condition. However, despite some success, GAN model usage 
remains largely minimal when depicting the heterogeneity of a disease such as 
prostate cancer. Previous studies from our group members have focused on 
automating the quantitative multi-parametric magnetic resonance imaging (mpMRI) 
using habitat risk scoring (HRS) maps on the prostate cancer patients in the 
BLaStM trial. In the current study, we aimed to use the images from the BLaStM 
trial and other sources to train the GAN models, generate synthetic images, and 
validate their quality. In this context, we used T2-weighted prostate MRI images 
as training data for Single Natural Image GANs (SinGANs) to make a generative 
model. A deep learning semantic segmentation pipeline trained the model to 
segment the prostate boundary on 2D MRI slices. Synthetic images with a 
high-level segmentation boundary of the prostate were filtered and used in the 
quality control assessment by participating scientists with varying degrees of 
experience (more than ten years, one year, or no experience) to work with MRI 
images. Results showed that the most experienced participating group correctly 
identified conventional vs. synthetic images with 67% accuracy, the group with 
one year of experience correctly identified the images with 58% accuracy, and 
the group with no prior experience reached 50% accuracy. Nearly half (47%) of 
the synthetic images were mistakenly evaluated as conventional. Interestingly, 
in a blinded quality assessment, a board-certified radiologist did not 
significantly differentiate between conventional and synthetic images in the 
context of the mean quality of synthetic and conventional images. Furthermore, 
to validate the usability of the generated synthetic images from prostate cancer 
MRIs, we subjected these to anomaly detection along with the original images. 
Importantly, the success rate of anomaly detection for quality control-approved 
synthetic data in phase one corresponded to that of the conventional images. In 
sum, this study shows promise that high-quality synthetic images from MRIs can 
be generated using GANs. Such an AI model may contribute significantly to 
various clinical applications which involve supervised machine-learning 
approaches.";2023;Health related;Health related;1
Mennella C, Maniscalco U, De Pietro G, Esposito M.;Generating a novel synthetic dataset for rehabilitation exercises using pose-guided conditioned diffusion models: A quantitative and qualitative evaluation;"Machine learning has emerged as a promising approach to enhance rehabilitation 
therapy monitoring and evaluation, providing personalized insights. However, the 
scarcity of data remains a significant challenge in developing robust machine 
learning models for rehabilitation. This paper introduces a novel synthetic 
dataset for rehabilitation exercises, leveraging pose-guided person image 
generation using conditioned diffusion models. By processing a pre-labeled 
dataset of class movements for 6 rehabilitation exercises, the described method 
generates realistic human movement images of elderly subjects engaging in 
home-based exercises. A total of 22,352 images were generated to accurately 
capture the spatial consistency of human joint relationships for predefined 
exercise movements. This novel dataset significantly amplified variability in 
the physical and demographic attributes of the main subject and the background 
environment. Quantitative metrics used for image assessment revealed highly 
favorable results. The generated images successfully maintained intra-class and 
inter-class consistency in motion data, producing outstanding outcomes with 
distance correlation values exceeding the 0.90. This innovative approach 
empowers researchers to enhance the value of existing limited datasets by 
generating high-fidelity synthetic images that precisely augment the 
anthropometric and biomechanical attributes of individuals engaged in 
rehabilitation exercises.";2023;Health related;Health related;1
Yu X, Creamer MS, Randi F, Sharma AK, Linderman SW, Leifer AM.;Fast deep neural correspondence for tracking and identifying neurons in C. elegans using semi-synthetic training;"We present an automated method to track and identify neurons in C. elegans, 
called 'fast Deep Neural Correspondence' or fDNC, based on the transformer 
network architecture. The model is trained once on empirically derived 
semi-synthetic data and then predicts neural correspondence across held-out real 
animals. The same pre-trained model both tracks neurons across time and 
identifies corresponding neurons across individuals. Performance is evaluated 
against hand-annotated datasets, including NeuroPAL (Yemini et al., 2021). Using 
only position information, the method achieves 79.1% accuracy at tracking 
neurons within an individual and 64.1% accuracy at identifying neurons across 
individuals. Accuracy at identifying neurons across individuals is even higher 
(78.2%) when the model is applied to a dataset published by another group 
(Chaudhary et al., 2021). Accuracy reaches 74.7% on our dataset when using color 
information from NeuroPAL. Unlike previous methods, fDNC does not require 
straightening or transforming the animal into a canonical coordinate system. The 
method is fast and predicts correspondence in 10 ms making it suitable for 
future real-time applications.";2021;Not health related;Not Health related;0
Yu S, Zhai DH, Guan Y, Xia Y.;Category-Level 6-D Object Pose Estimation With Shape Deformation for Robotic Grasp Detection;"Category-level 6-D object pose estimation plays a crucial role in achieving 
reliable robotic grasp detection. However, the disparity between synthetic and 
real datasets hinders the direct transfer of models trained on synthetic data to 
real-world scenarios, leading to ineffective results. Additionally, creating 
large-scale real datasets is a time-consuming and labor-intensive task. To 
overcome these challenges, we propose CatDeform, a novel category-level object 
pose estimation network trained on synthetic data but capable of delivering good 
performance on real datasets. In our approach, we introduce a transformer-based 
fusion module that enables the network to leverage multiple sources of 
information and enhance prediction accuracy through feature fusion. To ensure 
proper deformation of the prior point cloud to align with scene objects, we 
propose a transformer-based attention module that deforms the prior point cloud 
from both geometric and feature perspectives. Building upon CatDeform, we design 
a two-branch network for supervised learning, bridging the gap between synthetic 
and real datasets and achieving high-precision pose estimation in real-world 
scenes using predominantly synthetic data supplemented with a small amount of 
real data. To minimize reliance on large-scale real datasets, we train the 
network in a self-supervised manner by estimating object poses in real scenes 
based on the synthetic dataset without manual annotation. We conduct training 
and testing on CAMERA25 and REAL275 datasets, and our experimental results 
demonstrate that the proposed method outperforms state-of-the-art (SOTA) 
techniques in both self-supervised and supervised training paradigms. Finally, 
we apply CatDeform to object pose estimation and robotic grasp experiments in 
real-world scenarios, showcasing a higher grasp success rate.";2023;Not health related;Not Health related;0
Wang W, Feng H, Zhou W, Liao Z, Li H.;Model-Aware Pre-Training for Radial Distortion Rectification;"Camera lenses often suffer from optical aberrations, causing radial distortion 
in the captured images. In those images, there exists a clear and general 
physical distortion model. However, in existing solutions, such rich geometric 
prior is under-utilized, and the formulation of an effective prediction target 
is under-explored. To this end, we introduce Radial Distortion TRansformer 
(RDTR), a new framework for radial distortion rectification. Our RDTR includes a 
model-aware pre-training stage for distortion feature extraction and a 
deformation estimation stage for distortion rectification. Technically, on the 
one hand, we formulate the general radial distortion (i.e., barrel distortion 
and pincushion distortion) in camera-captured images with a shared geometric 
distortion model and perform a unified model-aware pre-training for its 
learning. With the pre-training, the network is capable of encoding the specific 
distortion pattern of a radially distorted image. After that, we transfer the 
learned representations to the learning of distortion rectification. On the 
other hand, we introduce a new prediction target called backward warping flow 
for rectifying images with any resolution while avoiding image defects. 
Extensive experiments are conducted on our synthetic dataset, and the results 
demonstrate that our method achieves state-of-the-art performance while 
operating in real-time. Besides, we also validate the generalization of RDTR on 
real-world images. Our source code and the proposed dataset are publicly 
available at https://github.com/wwd-ustc/RDTR.";2023;Not health related;Not Health related;0
Gelencsér-Horváth A, Kopácsi L, Varga V, Keller D, Dobolyi Á, Karacs K, L_rincz A.;Tracking Highly Similar Rat Instances under Heavy Occlusions: An Unsupervised Deep Generative Pipeline;"Identity tracking and instance segmentation are crucial in several areas of 
biological research. Behavior analysis of individuals in groups of similar 
animals is a task that emerges frequently in agriculture or pharmaceutical 
studies, among others. Automated annotation of many hours of surveillance videos 
can facilitate a large number of biological studies/experiments, which otherwise 
would not be feasible. Solutions based on machine learning generally perform 
well in tracking and instance segmentation; however, in the case of identical, 
unmarked instances (e.g., white rats or mice), even state-of-the-art approaches 
can frequently fail. We propose a pipeline of deep generative models for 
identity tracking and instance segmentation of highly similar instances, which, 
in contrast to most region-based approaches, exploits edge information and 
consequently helps to resolve ambiguity in heavily occluded cases. Our method is 
trained by synthetic data generation techniques, not requiring prior human 
annotation. We show that our approach greatly outperforms other state-of-the-art 
unsupervised methods in identity tracking and instance segmentation of unmarked 
rats in real-world laboratory video recordings.";2022;Not health related;Not Health related;0
Kang P, Jiang S, Shull PB.;Synthetic EMG Based on Adversarial Style Transfer Can Effectively Attack Biometric-Based Personal Identification Models;"Biometric-based personal identification models are generally considered to be 
accurate and secure because biological signals are too complex and 
person-specific to be fabricated, and EMG signals, in particular, have been used 
as biological identification tokens due to their high dimension and 
non-linearity. We investigate the possibility of effectively attacking EMG-based 
identification models with adversarial biological input via a novel EMG signal 
individual-style transformer based on a generative adversarial network and tiny 
leaked data segments. Since two same EMG segments do not exist in nature; the 
leaked data can't be used to attack the model directly or it will be easily 
detected. Therefore, it is necessary to extract the style with the leaked 
personal signals and generate the attack signals with different contents. With 
our proposed method and tiny leaked personal EMG fragments, numerous EMG signals 
with different content can be generated in that person's style. EMG hand gesture 
data from eighteen subjects and three well-recognized deep EMG classifiers were 
used to demonstrate the effectiveness of the proposed attack methods. The 
proposed methods achieved an average of 99.41% success rate on confusing 
identification models and an average of 91.51% success rate on manipulating 
identification models. These results demonstrate that EMG classifiers based on 
deep neural networks can be vulnerable to synthetic data attacks. The 
proof-of-concept results reveal that synthetic EMG biological signals must be 
considered in biological identification system design across a vast array of 
relevant biometric systems to ensure personal identification security for 
individuals and institutions.";2023;Not health related;Not Health related;0
Stallmann D, Göpfert JP, Schmitz J, Grünberger A, Hammer B.;Towards an automatic analysis of CHO-K1 suspension growth in microfluidic single-cell cultivation;"MOTIVATION: Innovative microfluidic systems carry the promise to greatly 
facilitate spatio-temporal analysis of single cells under well-defined 
environmental conditions, allowing novel insights into population heterogeneity 
and opening new opportunities for fundamental and applied biotechnology. 
Microfluidics experiments, however, are accompanied by vast amounts of data, 
such as time series of microscopic images, for which manual evaluation is 
infeasible due to the sheer number of samples. While classical image processing 
technologies do not lead to satisfactory results in this domain, modern 
deep-learning technologies, such as convolutional networks can be sufficiently 
versatile for diverse tasks, including automatic cell counting as well as the 
extraction of critical parameters, such as growth rate. However, for successful 
training, current supervised deep learning requires label information, such as 
the number or positions of cells for each image in a series; obtaining these 
annotations is very costly in this setting.
RESULTS: We propose a novel machine-learning architecture together with a 
specialized training procedure, which allows us to infuse a deep neural network 
with human-powered abstraction on the level of data, leading to a 
high-performing regression model that requires only a very small amount of 
labeled data. Specifically, we train a generative model simultaneously on 
natural and synthetic data, so that it learns a shared representation, from 
which a target variable, such as the cell count, can be reliably estimated.
AVAILABILITY AND IMPLEMENTATION: The project is cross-platform, open-source and 
free (MIT licensed) software. We make the source code available at 
https://github.com/dstallmann/cell_cultivation_analysis; the dataset is 
available at https://pub.uni-bielefeld.de/record/2945513.";2021;Not health related;Not Health related;0
"Billot B, Greve DN, Puonti O, Thielscher A, Van Leemput K, Fischl B, Dalca AV, Iglesias JE; ADNI.";SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining;"Despite advances in data augmentation and transfer learning, convolutional 
neural networks (CNNs) difficultly generalise to unseen domains. When segmenting 
brain scans, CNNs are highly sensitive to changes in resolution and contrast: 
even within the same MRI modality, performance can decrease across datasets. 
Here we introduce SynthSeg, the first segmentation CNN robust against changes in 
contrast and resolution. SynthSeg is trained with synthetic data sampled from a 
generative model conditioned on segmentations. Crucially, we adopt a domain 
randomisation strategy where we fully randomise the contrast and resolution of 
the synthetic training data. Consequently, SynthSeg can segment real scans from 
a wide range of target domains without retraining or fine-tuning, which enables 
straightforward analysis of huge amounts of heterogeneous clinical data. Because 
SynthSeg only requires segmentations to be trained (no images), it can learn 
from labels obtained by automated methods on diverse populations (e.g., ageing 
and diseased), thus achieving robustness to a wide range of morphological 
variability. We demonstrate SynthSeg on 5,000 scans of six modalities (including 
CT) and ten resolutions, where it exhibits unparallelled generalisation compared 
with supervised CNNs, state-of-the-art domain adaptation, and Bayesian 
segmentation. Finally, we demonstrate the generalisability of SynthSeg by 
applying it to cardiac MRI and CT scans.";2023;Health related;Health related;1
Lee MCH, Petersen K, Pawlowski N, Glocker B, Schaap M.;TeTrIS: Template Transformer Networks for Image Segmentation With Shape Priors;"In this paper, we introduce and compare different approaches for incorporating 
shape prior information into neural network-based image segmentation. 
Specifically, we introduce the concept of template transformer networks, where a 
shape template is deformed to match the underlying structure of interest through 
an end-to-end trained spatial transformer network. This has the advantage of 
explicitly enforcing shape priors, and this is free of discretization artifacts 
by providing a soft partial volume segmentation. We also introduce a simple yet 
effective way of incorporating priors in the state-of-the-art pixel-wise binary 
classification methods such as fully convolutional networks and U-net. Here, the 
template shape is given as an additional input channel, incorporating this 
information significantly reduces false positives. We report results on 
synthetic data and sub-voxel segmentation of coronary lumen structures in 
cardiac computed tomography showing the benefit of incorporating priors in 
neural network-based image segmentation.";2019;Not health related;Not Health related;0
Sadad T, Aurangzeb RA, Safran M, Imran, Alfarhood S, Kim J.;Classification of Highly Divergent Viruses from DNA/RNA Sequence Using Transformer-Based Models;"Viruses infect millions of people worldwide each year, and some can lead to 
cancer or increase the risk of cancer. As viruses have highly mutable genomes, 
new viruses may emerge in the future, such as COVID-19 and influenza. 
Traditional virology relies on predefined rules to identify viruses, but new 
viruses may be completely or partially divergent from the reference genome, 
rendering statistical methods and similarity calculations insufficient for all 
genome sequences. Identifying DNA/RNA-based viral sequences is a crucial step in 
differentiating different types of lethal pathogens, including their variants 
and strains. While various tools in bioinformatics can align them, expert 
biologists are required to interpret the results. Computational virology is a 
scientific field that studies viruses, their origins, and drug discovery, where 
machine learning plays a crucial role in extracting domain- and task-specific 
features to tackle this challenge. This paper proposes a genome analysis system 
that uses advanced deep learning to identify dozens of viruses. The system uses 
nucleotide sequences from the NCBI GenBank database and a BERT tokenizer to 
extract features from the sequences by breaking them down into tokens. We also 
generated synthetic data for viruses with small sample sizes. The proposed 
system has two components: a scratch BERT architecture specifically designed for 
DNA analysis, which is used to learn the next codons unsupervised, and a 
classifier that identifies important features and understands the relationship 
between genotype and phenotype. Our system achieved an accuracy of 97.69% in 
identifying viral sequences.";2023;Health related;Health related;1
Bai N, Wang X, Han R, Wang Q, Liu Z.;PAFormer: Anomaly Detection of Time Series With Parallel-Attention Transformer;"Time-series anomaly detection is a critical task with significant impact as it 
serves a pivotal role in the field of data mining and quality management. 
Current anomaly detection methods are typically based on reconstruction or 
forecasting algorithms, as these methods have the capability to learn compressed 
data representations and model time dependencies. However, most methods rely on 
learning normal distribution patterns, which can be difficult to achieve in 
real-world engineering applications. Furthermore, real-world time-series data is 
highly imbalanced, with a severe lack of representative samples for anomalous 
data, which can lead to model learning failure. In this article, we propose a 
novel end-to-end unsupervised framework called the parallel-attention 
transformer (PAFormer), which discriminates anomalies by modeling both the 
global characteristics and local patterns of time series. Specifically, we 
construct parallel-attention (PA), which includes two core modules: the global 
enhanced representation module (GERM) and the local perception module (LPM). 
GERM consists of two pattern units and a normalization module, with attention 
weights that indicate the relationship of each data point to the whole series 
(global). Due to the rarity of anomalous points, they have strong associations 
with adjacent data points. LPM is composed of a learnable Laplace kernel 
function that learns the neighborhood relevancies through the distributional 
properties of the kernel function (local). We employ the PA to learn the 
global-local distributional differences for each data point, which enables us to 
discriminate anomalies. Finally, we propose a two-stage adversarial loss to 
optimize the model. We conduct experiments on five public benchmark datasets 
(real-world datasets) and one synthetic dataset. The results show that PAFormer 
outperforms state-of-the-art baselines.";2023;Not health related;Not Health related;0
Misra R, Mishra SS, Gandhi TK.;Assistive Completion of Agrammatic Aphasic Sentences: Amalgamation of NLP and Neurolinguistics-based Synthetic Dataset;"Damage to the inferior frontal gyrus (Broca's area) can cause agrammatic aphasia 
wherein patients, although able to comprehend, lack the ability to form complete 
sentences. This inability leads to communication gaps which cause difficulties 
in their daily lives. The usage of assistive devices can help in mitigating 
these issues and enable the patients to communicate effectively. However, due to 
lack of large scale studies of linguistic deficits in aphasia, research on such 
assistive technology is relatively limited. In this work, we present two 
contributions that aim to re-initiate research and development in this field. 
Firstly, we propose a model that uses linguistic features from small scale 
studies on aphasia patients and generates large scale datasets of synthetic 
aphasic utterances from grammatically correct datasets. We show that the mean 
length of utterance, the noun/verb ratio, and the simple/complex sentence ratio 
of our synthetic datasets correspond to the reported features of aphasic speech. 
Further, we demonstrate how the synthetic datasets may be utilized to develop 
assistive devices for aphasia patients. The pre-trained T5 transformer is 
fine-tuned using the generated dataset to suggest 5 corrected sentences given an 
aphasic utterance as input. We evaluate the efficacy of the T5 model using the 
BLEU and cosine semantic similarity scores. Affirming results with BLEU score of 
0.827/1.00 and semantic similarity of 0.904/1.00 were obtained. These results 
provide a strong foundation for the concept that a synthetic dataset based on 
small scale studies on aphasia can be used to develop effective assistive 
technology.Clinical relevance- We demonstrate the utilization of Natural 
Language Processing (NLP) for developing assistive technology for Aphasia 
patients. While disorders like Broca's aphasia offer a small sample size of 
patients and data, synthetic linguistic models like ours offer extensive scope 
for developing assistive technology and rehabilitation monitoring.";2023;Health related;Health related;1
Fernandes TT, Direito B, Sayal A, Pereira J, Andrade A, Castelo-Branco M.;The boundaries of state-space Granger causality analysis applied to BOLD simulated data: A comparative modelling and simulation approach;"BACKGROUND: The analysis of connectivity has become a fundamental tool in human 
neuroscience. Granger Causality Mapping is a data-driven method that uses 
Granger Causality (GC) to assess the existence and direction of influence 
between signals, based on temporal precedence of information. More recently, a 
theory of Granger causality has been developed for state-space (SS-GC) 
processes, but little is known about its statistical validation and application 
on functional magnetic resonance imaging (fMRI) data.
NEW METHOD: We explored different multivariate computational frameworks to 
define the optimal combination for GC estimation. We hypothesized a new 
heuristic, combining SS-GC with a distinct statistical validation technique, 
Time Reversed Testing, validating it on synthetic data. We test its performance 
with a number of experimental parameters, including block structure, sampling 
frequency, noise and system mean pairwise correlation, using a statistical 
framework of binary classification.
RESULTS: We found that SS-GC with time reversed testing outperforms other 
frameworks. The results validate the application of SS-GC to generative models. 
When estimating reliable causal relations, SS-GC returns promising results, 
especially when considering synthetic data with a high impact of noise and 
sampling rate.
CONCLUSIONS: In this study, we empirically explored the boundaries of SS-GC with 
time reversed testing, a data-driven causality analysis framework with potential 
applicability to fMRI data.";2020;Not health related;Not Health related;0
Rodrigues J, Andrade A.;Synthetic neuronal datasets for benchmarking directed functional connectivity metrics;"Background. Datasets consisting of synthetic neural data generated with 
quantifiable and controlled parameters are a valuable asset in the process of 
testing and validating directed functional connectivity metrics. Considering the 
recent debate in the neuroimaging community concerning the use of these metrics 
for fMRI data, synthetic datasets that emulate the BOLD signal dynamics have 
played a central role by supporting claims that argue in favor or against 
certain choices. Generative models often used in studies that simulate neuronal 
activity, with the aim of gaining insight into specific brain regions and 
functions, have different requirements from the generative models for 
benchmarking datasets. Even though the latter must be realistic, there is a 
tradeoff between realism and computational demand that needs to be contemplated 
and simulations that efficiently mimic the real behavior of single neurons or 
neuronal populations are preferred, instead of more cumbersome and marginally 
precise ones. Methods. This work explores how simple generative models are able 
to produce neuronal datasets, for benchmarking purposes, that reflect the 
simulated effective connectivity and, how these can be used to obtain synthetic 
recordings of EEG and fMRI BOLD signals. The generative models covered here are 
AR processes, neural mass models consisting of linear and nonlinear stochastic 
differential equations and populations with thousands of spiking units. Forward 
models for EEG consist in the simple three-shell head model while the fMRI BOLD 
signal is modeled with the Balloon-Windkessel model or by convolution with a 
hemodynamic response function. Results. The simulated datasets are tested for 
causality with the original spectral formulation for Granger causality. Modeled 
effective connectivity can be detected in the generated data for varying 
connection strengths and interaction delays. Discussion. All generative models 
produce synthetic neuronal data with detectable causal effects although the 
relation between modeled and detected causality varies and less biophysically 
realistic models offer more control in causal relations such as modeled strength 
and frequency location.";2015;Not health related;Not Health related;1
Yuan Y, Wu Y, Fan X, Gong M, Ma W, Miao Q.;EGST: Enhanced Geometric Structure Transformer for Point Cloud Registration;"We explore the effect of geometric structure descriptors on extracting reliable 
correspondences and obtaining accurate registration for point cloud 
registration. The point cloud registration task involves the estimation of rigid 
transformation motion in unorganized point cloud, hence it is crucial to capture 
the contextual features of the geometric structure in point cloud. Recent 
coordinates-only methods ignore numerous geometric information in the point 
cloud which weaken ability to express the global context. We propose Enhanced 
Geometric Structure Transformer to learn enhanced contextual features of the 
geometric structure in point cloud and model the structure consistency between 
point clouds for extracting reliable correspondences, which encodes three 
explicit enhanced geometric structures and provides significant cues for point 
cloud registration. More importantly, we report empirical results that Enhanced 
Geometric Structure Transformer can learn meaningful geometric structure 
features using none of the following: (i) explicit positional embeddings, (ii) 
additional feature exchange module such as cross-attention, which can simplify 
network structure compared with plain Transformer. Extensive experiments on the 
synthetic dataset and real-world datasets illustrate that our method can achieve 
competitive results.";2023;Not health related;Not Health related;0
Flanagan AR, Glavin FG.;A Comparative Analysis of Data Synthesis Techniques to Improve Classification Accuracy of Raman Spectroscopy Data;"Raman spectra are examples of high dimensional data that can often be limited in 
the number of samples. This is a primary concern when Deep Learning frameworks 
are developed for tasks such as chemical species identification, quantification, 
and diagnostics. Open-source data are difficult to obtain and often sparse; 
furthermore, the collecting and curating of new spectra require expertise and 
resources. Deep generative modeling utilizes Deep Learning architectures to 
approximate high dimensional distributions and aims to generate realistic 
synthetic data. The evaluation of the data and the performance of the deep 
models is usually conducted on a per-task basis and provides no indication of an 
increase to robustness, or generalization, on a wider scale. In this study, we 
compare the benefits and limitations of a standard statistical approach to data 
synthesis (weighted blending) with a popular deep generative model, the 
Variational Autoencoder. Two binary data sets are divided into 3-fold to 
simulate small, limited samples. Synthetic data distributions are created per 
fold using the two methods and then augmented into the training of two Deep 
Learning algorithms, a Convolutional Neural Network and a Fully-Connected Neural 
Network. The goal of this study is to observe the trends in learning as 
synthetic data are continually augmented to the training data in increasing 
batches. To determine the impact of each synthetic method, Principal Component 
Analysis and the discrete Fréchet distance are implemented to visualize and 
measure the distance between the source and synthetic distributions along with 
the Machine Learning metric balanced accuracy for evaluating performance on 
imbalanced data.";2023;Not health related;Not Health related;0
"Abi Nader C, Ayache N, Robert P, Lorenzi M; Alzheimer’s Disease Neuroimaging Initiative.";Monotonic Gaussian Process for spatio-temporal disease progression modeling in brain imaging data;"We introduce a probabilistic generative model for disentangling spatio-temporal 
disease trajectories from collections of high-dimensional brain images. The 
model is based on spatio-temporal matrix factorization, where inference on the 
sources is constrained by anatomically plausible statistical priors. To model 
realistic trajectories, the temporal sources are defined as monotonic and 
time-reparameterized Gaussian Processes. To account for the non-stationarity of 
brain images, we model the spatial sources as sparse codes convolved at multiple 
scales. The method was tested on synthetic data favourably comparing with 
standard blind source separation approaches. The application on large-scale 
imaging data from a clinical study allows to disentangle differential temporal 
progression patterns mapping brain regions key to neurodegeneration, while 
revealing a disease-specific time scale associated to the clinical diagnosis.";2020;Health related;Health related;1
Cai H, Song Y, Ji Y, Li Z, He A.;Displacement extraction of background-oriented schlieren images using Swin Transformer;"Displacement extraction of background-oriented schlieren (BOS) is an essential 
step in BOS reconstruction, which directly determines the accuracy of the 
results. Typically, the displacement is calculated from the background images 
with and without inhomogeneous flow using the cross-correlation (CC) or optical 
flow (OF) method. This paper discusses the disadvantages of the CC and OF 
methods, and an end-to-end deep neural network was designed to estimate the BOS 
displacement. The proposed network is based on a Swin Transformer, which can 
build long-range correlations. A synthetic dataset used for training was 
generated using the simulated flow field by computational fluid dynamics. After 
training, the displacement can be obtained using the BOS image pair without 
additional parameters. Finally, the effectiveness of the proposed network was 
verified through experiments. The experiments illustrate that the proposed 
method performs stably on synthetic and real experimental images and outperforms 
conventional CC or OF methods and classic convolutional neural networks for OF 
tasks.";2023;Not health related;Not Health related;0
Lv J, Zhang L, Xu J, Li W, Li G, Zhou H.;Automatic segmentation of mandibular canal using transformer based neural networks;"Accurate 3D localization of the mandibular canal is crucial for the success of 
digitally-assisted dental surgeries. Damage to the mandibular canal may result 
in severe consequences for the patient, including acute pain, numbness, or even 
facial paralysis. As such, the development of a fast, stable, and highly precise 
method for mandibular canal segmentation is paramount for enhancing the success 
rate of dental surgical procedures. Nonetheless, the task of mandibular canal 
segmentation is fraught with challenges, including a severe imbalance between 
positive and negative samples and indistinct boundaries, which often compromise 
the completeness of existing segmentation methods. To surmount these challenges, 
we propose an innovative, fully automated segmentation approach for the 
mandibular canal. Our methodology employs a Transformer architecture in 
conjunction with cl-Dice loss to ensure that the model concentrates on the 
connectivity of the mandibular canal. Additionally, we introduce a pixel-level 
feature fusion technique to bolster the model's sensitivity to fine-grained 
details of the canal structure. To tackle the issue of sample imbalance and 
vague boundaries, we implement a strategy founded on mandibular foramen 
localization to isolate the maximally connected domain of the mandibular canal. 
Furthermore, a contrast enhancement technique is employed for pre-processing the 
raw data. We also adopt a Deep Label Fusion strategy for pre-training on 
synthetic datasets, which substantially elevates the model's performance. 
Empirical evaluations on a publicly accessible mandibular canal dataset reveal 
superior performance metrics: a Dice score of 0.844, click score of 0.961, IoU 
of 0.731, and HD95 of 2.947 mm. These results not only validate the efficacy of 
our approach but also establish its state-of-the-art performance on the public 
mandibular canal dataset.";2023;Health related;Health related;1
Zhu K, Cheng S, Kovalchuk N, Simmons M, Guo YK, Matar OK, Arcucci R.;Analyzing drop coalescence in microfluidic devices with a deep learning generative model;"
Predicting drop coalescence based on process parameters is crucial for 
experimental design in chemical engineering. However, predictive models can 
suffer from the lack of training data and more importantly, the label imbalance 
problem. In this study, we propose the use of deep learning generative models to 
tackle this bottleneck by training the predictive models using generated 
synthetic data. A novel generative model, named double space conditional 
variational autoencoder (DSCVAE) is developed for labelled tabular data. By 
introducing label constraints in both the latent and the original space, DSCVAE 
is capable of generating consistent and realistic samples compared to the 
standard conditional variational autoencoder (CVAE). Two predictive models, 
namely random forest and gradient boosting classifiers, are enhanced on 
synthetic data and their performances are evaluated based on real experimental 
data. Numerical results show that a considerable improvement in prediction 
accuracy can be achieved by using synthetic data and the proposed DSCVAE clearly 
outperforms the standard CVAE. This research clearly provides more insights into 
handling imbalanced data for classification problems, especially in chemical 
engineering.";2023;Not health related;Not Health related;0
De Bacco C, Power EA, Larremore DB, Moore C.;Community detection, link prediction, and layer interdependence in multilayer networks;"Complex systems are often characterized by distinct types of interactions 
between the same entities. These can be described as a multilayer network where 
each layer represents one type of interaction. These layers may be 
interdependent in complicated ways, revealing different kinds of structure in 
the network. In this work we present a generative model, and an efficient 
expectation-maximization algorithm, which allows us to perform inference tasks 
such as community detection and link prediction in this setting. Our model 
assumes overlapping communities that are common between the layers, while 
allowing these communities to affect each layer in a different way, including 
arbitrary mixtures of assortative, disassortative, or directed structure. It 
also gives us a mathematically principled way to define the interdependence 
between layers, by measuring how much information about one layer helps us 
predict links in another layer. In particular, this allows us to bundle layers 
together to compress redundant information and identify small groups of layers 
which suffice to predict the remaining layers accurately. We illustrate these 
findings by analyzing synthetic data and two real multilayer networks, one 
representing social support relationships among villagers in South India and the 
other representing shared genetic substring material between genes of the 
malaria parasite.";2017;Not health related;Not Health related;0
Gwon H, Ahn I, Kim Y, Kang HJ, Seo H, Choi H, Cho HN, Kim M, Han J, Kee G, Park S, Lee KH, Jun TJ, Kim YH.;LDP-GAN : Generative adversarial networks with local differential privacy for patient medical records synthesis;"Electronic medical records(EMR) have considerable potential to advance 
healthcare technologies, including medical AI. Nevertheless, due to the privacy 
issues associated with the sharing of patient's personal information, it is 
difficult to sufficiently utilize them. Generative models based on deep learning 
can solve this problem by creating synthetic data similar to real patient data. 
However, the data used for training these deep learning models run into the risk 
of getting leaked because of malicious attacks. This means that traditional deep 
learning-based generative models cannot completely solve the privacy issues. 
Therefore, we suggested a method to prevent the leakage of training data by 
protecting the model from malicious attacks using local differential 
privacy(LDP). Our method was evaluated in terms of utility and privacy. 
Experimental results demonstrated that the proposed method can generate medical 
data with reasonable performance while protecting training data from malicious 
attacks.";2024;Health related;Health related;1
Kim K, Chun C, Moon SY.;Conformer-Based Dental AI Patient Clinical Diagnosis Simulation Using Korean Synthetic Data Generator for Multiple Standardized Patient Scenarios;"The goal of clinical practice education is to develop the ability to apply 
theoretical knowledge in a clinical setting and to foster growth as a 
professional healthcare provider. One effective method of achieving this is 
through the utilization of Standardized Patients (SP) in education, which 
familiarizes students with real patient interviews and allows educators to 
assess their clinical performance skills. However, SP education faces challenges 
such as the cost of hiring actors and the shortage of professional educators to 
train them. In this paper, we aim to alleviate these issues by utilizing deep 
learning models to replace the actors. We employ the Conformer model for the 
implementation of the AI patient, and we develop a Korean SP scenario data 
generator to collect data for training responses to diagnostic questions. Our 
Korean SP scenario data generator is devised to generate SP scenarios based on 
the provided patient information, using pre-prepared questions and answers. In 
the AI patient training process, two types of data are employed: common data and 
personalized data. The common data are employed to develop natural general 
conversation skills, while personalized data, from the SP scenario, are utilized 
to learn specific clinical information relevant to a patient's role. Based on 
these data, to evaluate the learning efficiency of the Conformer structure, a 
comparison was conducted with the Transformer using the BLEU score and WER as 
evaluation metrics. Experimental results showed that the Conformer-based model 
demonstrated a 3.92% and 6.74% improvement in BLEU and WER performance compared 
to the Transformer-based model, respectively. The dental AI patient for SP 
simulation presented in this paper has the potential to be applied to other 
medical and nursing fields, provided that additional data collection processes 
are conducted.";2023;Health related;Health related;1
Annys A, Jannis D, Verbeeck J.;Deep learning for automated materials characterisation in core-loss electron energy loss spectroscopy;"Electron energy loss spectroscopy (EELS) is a well established technique in 
electron microscopy that yields information on the elemental content of a sample 
in a very direct manner. One of the persisting limitations of EELS is the 
requirement for manual identification of core-loss edges and their corresponding 
elements. This can be especially bothersome in spectrum imaging, where a large 
amount of spectra are recorded when spatially scanning over a sample area. This 
paper introduces a synthetic dataset with 736,000 labeled EELS spectra, computed 
from available generalized oscillator strength tables, that represents 107 K, L, 
M or N core-loss edges and 80 chemical elements. Generic lifetime broadened 
peaks are used to mimic the fine structure due to band structure effects present 
in experimental core-loss edges. The proposed dataset is used to train and 
evaluate a series of neural network architectures, being a multilayer 
perceptron, a convolutional neural network, a U-Net, a residual neural network, 
a vision transformer and a compact convolutional transformer. An ensemble of 
neural networks is used to further increase performance. The ensemble network is 
used to demonstrate fully automated elemental mapping in a spectrum image, both 
by directly mapping the predicted elemental content and by using the predicted 
content as input for a physical model-based mapping.";2023;Not health related;Not Health related;0
Daunizeau J, Friston KJ.;A mesostate-space model for EEG and MEG;"We present a multi-scale generative model for EEG, that entails a minimum number 
of assumptions about evoked brain responses, namely: (1) bioelectric activity is 
generated by a set of distributed sources, (2) the dynamics of these sources can 
be modelled as random fluctuations about a small number of mesostates, (3) 
mesostates evolve in a temporal structured way and are functionally connected 
(i.e. influence each other), and (4) the number of mesostates engaged by a 
cognitive task is small (e.g. between one and a few). A Variational Bayesian 
learning scheme is described that furnishes the posterior density on the models 
parameters and its evidence. Since the number of meso-sources specifies the 
model, the model evidence can be used to compare models and find the optimum 
number of meso-sources. In addition to estimating the dynamics at each cortical 
dipole, the mesostate-space model and its inversion provide a description of 
brain activity at the level of the mesostates (i.e. in terms of the dynamics of 
meso-sources that are distributed over dipoles). The inclusion of a mesostate 
level allows one to compute posterior probability maps of each dipole being 
active (i.e. belonging to an active mesostate). Critically, this model 
accommodates constraints on the number of meso-sources, while retaining the 
flexibility of distributed source models in explaining data. In short, it 
bridges the gap between standard distributed and equivalent current dipole 
models. Furthermore, because it is explicitly spatiotemporal, the model can 
embed any stochastic dynamical causal model (e.g. a neural mass model) as a 
Markov process prior on the mesostate dynamics. The approach is evaluated and 
compared to standard inverse EEG techniques, using synthetic data and real data. 
The results demonstrate the added-value of the mesostate-space model and its 
variational inversion.";2007;Health related;Not Health related;1
Park H, Li B, Liu Y, Nelson MS, Wilson HM, Sifakis E, Eliceiri KW.;Collagen fiber centerline tracking in fibrotic tissue via deep neural networks with variational autoencoder-based synthetic training data generation;"The role of fibrillar collagen in the tissue microenvironment is critical in 
disease contexts ranging from cancers to chronic inflammations, as evidenced by 
many studies. Quantifying fibrillar collagen organization has become a powerful 
approach for characterizing the topology of collagen fibers and studying the 
role of collagen fibers in disease progression. We present a deep learning-based 
pipeline to quantify collagen fibers' topological properties in microscopy-based 
collagen images from pathological tissue samples. Our method leverages deep 
neural networks to extract collagen fiber centerlines and deep generative models 
to create synthetic training data, addressing the current shortage of 
large-scale annotations. As a part of this effort, we have created and annotated 
a collagen fiber centerline dataset, with the hope of facilitating further 
research in this field. Quantitative measurements such as fiber orientation, 
alignment, density, and length can be derived based on the centerline extraction 
results. Our pipeline comprises three stages. Initially, a variational 
autoencoder is trained to generate synthetic centerlines possessing controllable 
topological properties. Subsequently, a conditional generative adversarial 
network synthesizes realistic collagen fiber images from the synthetic 
centerlines, yielding a synthetic training set of image-centerline pairs. 
Finally, we train a collagen fiber centerline extraction network using both the 
original and synthetic data. Evaluation using collagen fiber images from 
pancreas, liver, and breast cancer samples collected via second-harmonic 
generation microscopy demonstrates our pipeline's superiority over several 
popular fiber centerline extraction tools. Incorporating synthetic data into 
training further enhances the network's generalizability. Our code is available 
at https://github.com/uw-loci/collagen-fiber-metrics.";2023;Health related;Health related;1
Lin N, Wu S, Wu Z, Ji S.;Efficient Generation of Pretraining Samples for Developing a Deep Learning Brain Injury Model via Transfer Learning;"The large amount of training samples required to develop a deep learning brain 
injury model demands enormous computational resources. Here, we study how a 
transformer neural network (TNN) of high accuracy can be used to efficiently 
generate pretraining samples for a convolutional neural network (CNN) brain 
injury model to reduce computational cost. The samples use synthetic impacts 
emulating real-world events or augmented impacts generated from limited measured 
impacts. First, we verify that the TNN remains highly accurate for the two 
impact types (N_=_100 each; [Formula: see text] of 0.948-0.967 with root mean 
squared error, RMSE,_~_0.01, for voxelized peak strains). The TNN-estimated 
samples (1000-5000 for each data type) are then used to pretrain a CNN, which is 
further finetuned using directly simulated training samples (250-5000). An 
independent measured impact dataset considered of complete capture of impact 
event is used to assess estimation accuracy (N_=_191). We find that pretraining 
can significantly improve CNN accuracy via transfer learning compared to a 
baseline CNN without pretraining. It is most effective when the finetuning 
dataset is relatively small (e.g., 2000-4000 pretraining synthetic or augmented 
samples improves success rate from 0.72 to 0.81 with 500 finetuning samples). 
When finetuning samples reach 3000 or more, no obvious improvement occurs from 
pretraining. These results support using the TNN to rapidly generate pretraining 
samples to facilitate a more efficient training strategy for future deep 
learning brain models, by limiting the number of costly direct simulations from 
an alternative baseline model. This study could contribute to a wider adoption 
of deep learning brain injury models for large-scale predictive modeling and 
ultimately, enhancing safety protocols and protective equipment.";2023;Health related;Not Health related;1
Sanchez G, Lecaignard F, Otman A, Maby E, Mattout J.;Active SAmpling Protocol (ASAP) to Optimize Individual Neurocognitive Hypothesis Testing: A BCI-Inspired Dynamic Experimental Design;"The relatively young field of Brain-Computer Interfaces has promoted the use of 
electrophysiology and neuroimaging in real-time. In the meantime, cognitive 
neuroscience studies, which make extensive use of functional exploration 
techniques, have evolved toward model-based experiments and fine hypothesis 
testing protocols. Although these two developments are mostly unrelated, we 
argue that, brought together, they may trigger an important shift in the way 
experimental paradigms are being designed, which should prove fruitful to both 
endeavors. This change simply consists in using real-time neuroimaging in order 
to optimize advanced neurocognitive hypothesis testing. We refer to this new 
approach as the instantiation of an Active SAmpling Protocol (ASAP). As opposed 
to classical (static) experimental protocols, ASAP implements online model 
comparison, enabling the optimization of design parameters (e.g., stimuli) 
during the course of data acquisition. This follows the well-known principle of 
sequential hypothesis testing. What is radically new, however, is our ability to 
perform online processing of the huge amount of complex data that brain imaging 
techniques provide. This is all the more relevant at a time when physiological 
and psychological processes are beginning to be approached using more realistic, 
generative models which may be difficult to tease apart empirically. Based upon 
Bayesian inference, ASAP proposes a generic and principled way to optimize 
experimental design adaptively. In this perspective paper, we summarize the main 
steps in ASAP. Using synthetic data we illustrate its superiority in selecting 
the right perceptual model compared to a classical design. Finally, we briefly 
discuss its future potential for basic and clinical neuroscience as well as some 
remaining challenges.";2016;Health related;Health related;0
Xiao Q, Qin M, Yin Y.;Skeleton-based Chinese sign language recognition and generation for bidirectional communication between deaf and hearing people;"Chinese sign language (CSL) is one of the most widely used sign language systems 
in the world. As such, the automatic recognition and generation of CSL is a key 
technology enabling bidirectional communication between deaf and hearing people. 
Most previous studies have focused solely on sign language recognition (SLR), 
which only addresses communication in a single direction. As such, there is a 
need for sign language generation (SLG) to enable communication in the other 
direction (i.e., from hearing people to deaf people). To achieve a smoother 
exchange of ideas between these two groups, we propose a skeleton-based CSL 
recognition and generation framework based on a recurrent neural network (RNN), 
to support bidirectional CSL communication. This process can also be extended to 
other sequence-to-sequence information interactions. The core of the proposed 
framework is a two-level probability generative model. Compared with previous 
techniques, this approach offers a more flexible approximate posterior 
distribution, which can produce skeletal sequences of varying styles that are 
recognizable to humans. In addition, the proposed generation method compensated 
for a lack of training data. A series of experiments in bidirectional 
communication were conducted on the large 500 CSL dataset. The proposed 
algorithm achieved high recognition accuracy for both real and synthetic data, 
with a reduced runtime. Furthermore, the generated data improved the performance 
of the discriminator. These results suggest the proposed bidirectional 
communication framework and generation algorithm to be an effective new approach 
to CSL recognition.";2020;Not health related;Not Health related;0
Hufnagel H, Pennec X, Ehrhardt J, Handels H, Ayache N.;Shape analysis using a point-based statistical shape model built on correspondence probabilities;"A fundamental problem when computing statistical shape models is the 
determination of correspondences between the instances of the associated data 
set. Often, homologies between points that represent the surfaces are assumed 
which might lead to imprecise mean shape and variability results. We propose an 
approach where exact correspondences are replaced by evolving correspondence 
probabilities. These are the basis for a novel algorithm that computes a 
generative statistical shape model. We developed an unified MAP framework to 
compute the model parameters ('mean shape' and 'modes of variation') and the 
nuisance parameters which leads to an optimal adaption of the model to the set 
of observations. The registration of the model on the instances is solved using 
the Expectation Maximization--Iterative Closest Point algorithm which is based 
on probabilistic correspondences and proved to be robust and fast. The 
alternated optimization of the MAP explanation with respect to the observation 
and the generative model parameters leads to very efficient and closed-form 
solutions for (almost) all parameters. Experimental results on brain structure 
data sets demonstrate the efficiency and well-posedness of the approach. The 
algorithm is then extended to an automatic classification method using the 
k-means clustering and applied to synthetic data as well as brain structure 
classification problems.";2007;Not health related;Not Health related;0
Hufnagel H, Pennec X, Ehrhardt J, Ayache N, Handels H.;Computation of a probabilistic statistical shape model in a maximum-a-posteriori framework;"OBJECTIVES: When analyzing shapes and shape variabilities, the first step is 
bringing those shapes into correspondence. This is a fundamental problem even 
when solved by manually determining exact correspondences such as landmarks. We 
developed a method to represent a mean shape and a variability model for a 
training data set based on probabilistic correspondence computed between the 
observations.
METHODS: First, the observations are matched on each other with an affine 
transformation found by the Expectation-Maximization Iterative-Closest-Points 
(EM-ICP) registration. We then propose a maximum-a-posteriori (MAP) framework in 
order to compute the statistical shape model (SSM) parameters which result in an 
optimal adaptation of the model to the observations. The optimization of the MAP 
explanation is realized with respect to the observation parameters and the 
generative model parameters in a global criterion and leads to very efficient 
and closed-form solutions for (almost) all parameters.
RESULTS: We compared our probabilistic SSM to a SSM based on one-to-one 
correspondences and the PCA (classical SSM). Experiments on synthetic data 
served to test the performances on non-convex shapes (15 training shapes) which 
have proved difficult in terms of proper correspondence determination. We then 
computed the SSMs for real putamen data (21 training shapes). The evaluation was 
done by measuring the generalization ability as well as the specificity of both 
SSMs and showed that especially shape detail differences are better modeled by 
the probabilistic SSM (Hausdorff distance in generalization ability Re 
approximately 25% smaller).
CONCLUSIONS: The experimental outcome shows the efficiency and advantages of the 
new approach as the probabilistic SSM performs better in modeling shape details 
and differences.";2009;Not health related;Not Health related;0
Yu T, Bidulka L, McKeown MJ, Wang ZJ.;PA-Tran: Learning to Estimate 3D Hand Pose with Partial Annotation;"This paper tackles a novel and challenging problem-3D hand pose estimation (HPE) 
from a single RGB image using partial annotation. Most HPE methods ignore the 
fact that the keypoints could be partially visible (e.g., under occlusions). In 
contrast, we propose a deep-learning framework, PA-Tran, that jointly estimates 
the keypoints status and 3D hand pose from a single RGB image with two dependent 
branches. The regression branch consists of a Transformer encoder which is 
trained to predict a set of target keypoints, given an input set of status, 
position, and visual features embedding from a convolutional neural network 
(CNN); the classification branch adopts a CNN for estimating the keypoints 
status. One key idea of PA-Tran is a selective mask training (SMT) objective 
that uses a binary encoding scheme to represent the status of the keypoints as 
observed or unobserved during training. In addition, by explicitly encoding the 
label status (observed/unobserved), the proposed PA-Tran can efficiently handle 
the condition when only partial annotation is available. Investigating the 
annotation percentage ranging from 50-100%, we show that training with partial 
annotation is more efficient (e.g., achieving the best 6.0 PA-MPJPE when using 
about 85% annotations). Moreover, we provide two new datasets. APDM-Hand, is for 
synthetic hands with APDM sensor accessories, which is designed for a specific 
hand task. PD-APDM-Hand, is a real hand dataset collected from Parkinson's 
Disease (PD) patients with partial annotation. The proposed PA-Tran can achieve 
higher estimation accuracy when evaluated on both proposed datasets and a more 
general hand dataset.";2023;Not health related;Health related;0
Hosseini R, Hassanpour N, Liu LP, Hassoun S.;Pathway-Activity Likelihood Analysis and Metabolite Annotation for Untargeted Metabolomics Using Probabilistic Modeling;"Motivation: Untargeted metabolomics comprehensively characterizes small 
molecules and elucidates activities of biochemical pathways within a biological 
sample. Despite computational advances, interpreting collected measurements and 
determining their biological role remains a challenge. Results: To interpret 
measurements, we present an inference-based approach, termed Probabilistic 
modeling for Untargeted Metabolomics Analysis (PUMA). Our approach captures 
metabolomics measurements and the biological network for the biological sample 
under study in a generative model and uses stochastic sampling to compute 
posterior probability distributions. PUMA predicts the likelihood of pathways 
being active, and then derives probabilistic annotations, which assign chemical 
identities to measurements. Unlike prior pathway analysis tools that analyze 
differentially active pathways, PUMA defines a pathway as active if the 
likelihood that the path generated the observed measurements is above a 
particular (user-defined) threshold. Due to the lack of ""ground truth"" 
metabolomics datasets, where all measurements are annotated and pathway 
activities are known, PUMA is validated on synthetic datasets that are designed 
to mimic cellular processes. PUMA, on average, outperforms pathway enrichment 
analysis by 8%. PUMA is applied to two case studies. PUMA suggests many 
biological meaningful pathways as active. Annotation results were in agreement 
to those obtained using other tools that utilize additional information in the 
form of spectral signatures. Importantly, PUMA annotates many measurements, 
suggesting 23 chemical identities for metabolites that were previously only 
identified as isomers, and a significant number of additional putative 
annotations over spectral database lookups. For an experimentally validated 
50-compound dataset, annotations using PUMA yielded 0.833 precision and 0.676 
recall.";2020;Not health related;Not Health related;0
Yuan J, Chen T, Shen Z, Li B, Xue X.;Unsupervised Object-Centric Learning From Multiple Unspecified Viewpoints;"Visual scenes are extremely diverse, not only because there are infinite 
possible combinations of objects and backgrounds but also because the 
observations of the same scene may vary greatly with the change of viewpoints. 
When observing a multi-object visual scene from multiple viewpoints, humans can 
perceive the scene compositionally from each viewpoint while achieving the 
so-called ""object constancy"" across different viewpoints, even though the exact 
viewpoints are untold. This ability is essential for humans to identify the same 
object while moving and to learn from vision efficiently. It is intriguing to 
design models that have a similar ability. In this paper, we consider a novel 
problem of learning compositional scene representations from multiple 
unspecified (i.e., unknown and unrelated) viewpoints without using any 
supervision and propose a deep generative model which separates latent 
representations into a viewpoint-independent part and a viewpoint-dependent part 
to solve this problem. During the inference, latent representations are randomly 
initialized and iteratively updated by integrating the information in different 
viewpoints with neural networks. Experiments on several specifically designed 
synthetic datasets have shown that the proposed method can effectively learn 
from multiple unspecified viewpoints.";2024;Not health related;Not Health related;0
Li P, Zhao J, Wu J, Deng C, Han Y, Wang H, Yu T.;OPAL: Occlusion Pattern Aware Loss for Unsupervised Light Field Disparity Estimation;"Light field disparity estimation is an essential task in computer vision. 
Currently, supervised learning-based methods have achieved better performance 
than both unsupervised and optimization-based methods. However, the 
generalization capacity of supervised methods on real-world data, where no 
ground truth is available for training, remains limited. In this paper, we argue 
that unsupervised methods can achieve not only much stronger generalization 
capacity on real-world data but also more accurate disparity estimation results 
on synthetic datasets. To fulfill this goal, we present the Occlusion Pattern 
Aware Loss, named OPAL, which successfully extracts and encodes general 
occlusion patterns inherent in the light field for calculating the disparity 
loss. OPAL enables: i) accurate and robust disparity estimation by teaching the 
network how to handle occlusions effectively and ii) significantly reduced 
network parameters required for accurate and efficient estimation. We further 
propose an EPI transformer and a gradient-based refinement module for achieving 
more accurate and pixel-aligned disparity estimation results. Extensive 
experiments demonstrate our method not only significantly improves the accuracy 
compared with SOTA unsupervised methods, but also possesses stronger 
generalization capacity on real-world data compared with SOTA supervised 
methods. Last but not least, the network training and inference efficiency are 
much higher than existing learning-based methods. Our code will be made publicly 
available.";2024;Not health related;Not Health related;0
Fishbaugh J, Prastawa M, Gerig G, Durrleman S.;Geodesic shape regression in the framework of currents;"Shape regression is emerging as an important tool for the statistical analysis 
of time dependent shapes. In this paper, we develop a new generative model which 
describes shape change over time, by extending simple linear regression to the 
space of shapes represented as currents in the large deformation diffeomorphic 
metric mapping (LDDMM) framework. By analogy with linear regression, we estimate 
a baseline shape (intercept) and initial momenta (slope) which fully 
parameterize the geodesic shape evolution. This is in contrast to previous shape 
regression methods which assume the baseline shape is fixed. We further leverage 
a control point formulation, which provides a discrete and low dimensional 
parameterization of large diffeomorphic transformations. This flexible system 
decouples the parameterization of deformations from the specific shape 
representation, allowing the user to define the dimensionality of the 
deformation parameters. We present an optimization scheme that estimates the 
baseline shape, location of the control points, and initial momenta 
simultaneously via a single gradient descent algorithm. Finally, we demonstrate 
our proposed method on synthetic data as well as real anatomical shape 
complexes.";2013;Not health related;Not Health related;0
Sterling A, Rewkowski N, Klatzky RL, Lin MC.;Audio-Material Reconstruction for Virtualized Reality Using a Probabilistic Damping Model;"Modal sound synthesis has been used to create realistic sounds from rigid-body 
objects, but requires accurate real-world material parameters. These material 
parameters can be estimated from recorded sounds of an impacted object, but 
external factors can interfere with accurate parameter estimation. We present a 
novel technique for estimating the damping parameters of materials from recorded 
impact sounds that probabilistically models these external factors. We represent 
the combined effects of material damping, support damping, and sampling 
inaccuracies with a probabilistic generative model, then use maximum likelihood 
estimation to fit a damping model to recorded data. This technique greatly 
reduces the human effort needed and does not require the precise object geometry 
or the exact hit location. We validate the effectiveness of this technique with 
a comprehensive analysis of a synthetic dataset and a perceptual study on object 
identification. We also present a study establishing human performance on the 
same parameter estimation task for comparison.";2019;Not health related;Not Health related;0
Kiebel SJ, Klöppel S, Weiskopf N, Friston KJ.;Dynamic causal modeling: a generative model of slice timing in fMRI;"Dynamic causal modeling (DCM) of functional magnetic resonance imaging (fMRI) 
data allows one to make inferences about the architecture of distributed 
networks in the brain, in terms of effective connectivity. fMRI data are usually 
acquired using echo planar imaging (EPI). EPI sequences typically acquire slices 
at different times over a few seconds. DCM, in its original inception, was not 
informed about these slice timings and assumed that all slices were acquired 
simultaneously. It has been shown that DCM can cope with slice timing 
differences of up to 1 s. However, many fMRI studies employ a repetition time 
(TR) of 3 to 5 s, which precludes a straightforward DCM of these data. We show 
that this limitation can be overcome easily by including slice timing in the 
DCM. Using synthetic data we show that the extended DCM furnishes veridical 
posterior means, even if there are large slice-timing differences. Model 
comparisons show that, in general, the extended DCM out-performs the original 
model. We contrast the modeling of slice timing, in the context of DCM, with the 
less effective approach of 'slice-timing correction', prior to modeling. We 
apply our procedure to real data and show that slice timings are important 
parameters. We conclude that, generally, one should use DCM with slice timing.";2007;Health related;Not Health related;1
Vasylechko SD, Warfield SK, Kurugol S, Afacan O.;Improved myelin water fraction mapping with deep neural networks using synthetically generated 3D data;"We introduce a generative model for synthesis of large scale 3D datasets for 
quantitative parameter mapping of myelin water fraction (MWF). Our model 
combines a MR physics signal decay model with an accurate probabilistic 
multi-component parametric T2 model. We synthetically generate a wide variety of 
high quality signals and corresponding parameters from a wide range of naturally 
occurring prior parameter values. To capture spatial variation, the generative 
signal decay model is combined with a generative spatial model conditioned on 
generic tissue segmentations. Synthesized 3D datasets can be used to train any 
convolutional neural network (CNN) based architecture for MWF estimation. Our 
source code is available at: https://github.com/quin-med-harvard-edu/synthmap 
Reduction of acquisition time at the expense of lower SNR, as well as accuracy 
and repeatability of MWF estimation techniques, are key factors that affect the 
adoption of MWF mapping in clinical practice. We demonstrate that the 
synthetically trained CNN provides superior accuracy over the competing methods 
under the constraints of naturally occurring noise levels as well as on the 
synthetically generated images at low SNR levels. Normalized root mean squared 
error (nRMSE) is less than 7% on synthetic data, which is significantly lower 
than competing methods. Additionally, the proposed method yields a coefficient 
of variation (CoV) that is at least 4x better than the competing method on 
intra-session test-retest reference dataset.";2024;Not health related;Health related;1
Gauvin L, Panisson A, Cattuto C, Barrat A.;Activity clocks: spreading dynamics on temporal networks of human contact;"Dynamical processes on time-varying complex networks are key to understanding 
and modeling a broad variety of processes in socio-technical systems. Here we 
focus on empirical temporal networks of human proximity and we aim at 
understanding the factors that, in simulation, shape the arrival time 
distribution of simple spreading processes. Abandoning the notion of wall-clock 
time in favour of node-specific clocks based on activity exposes robust 
statistical patterns in the arrival times across different social contexts. 
Using randomization strategies and generative models constrained by data, we 
show that these patterns can be understood in terms of heterogeneous inter-event 
time distributions coupled with heterogeneous numbers of events per edge. We 
also show, both empirically and by using a synthetic dataset, that significant 
deviations from the above behavior can be caused by the presence of edge classes 
with strong activity correlations.";2013;Not health related;Not Health related;0
Daunizeau J, Grova C, Marrelec G, Mattout J, Jbabdi S, Pélégrini-Issac M, Lina JM, Benali H.;Symmetrical event-related EEG/fMRI information fusion in a variational Bayesian framework;"In this work, we propose a symmetrical multimodal EEG/fMRI information fusion 
approach dedicated to the identification of event-related bioelectric and 
hemodynamic responses. Unlike existing, asymmetrical EEG/fMRI data fusion 
algorithms, we build a joint EEG/fMRI generative model that explicitly accounts 
for local coupling/uncoupling of bioelectric and hemodynamic activities, which 
are supposed to share a common substrate. Under a dedicated assumption of 
spatio-temporal separability, the spatial profile of the common EEG/fMRI sources 
is introduced as an unknown hierarchical prior on both markers of cerebral 
activity. Thereby, a devoted Variational Bayesian (VB) learning scheme is 
derived to infer common EEG/fMRI sources from a joint EEG/fMRI dataset. This 
yields an estimate of the common spatial profile, which is built as a trade-off 
between information extracted from EEG and fMRI datasets. Furthermore, the 
spatial structure of the EEG/fMRI coupling/uncoupling is learned exclusively 
from the data. The proposed data generative model and devoted VBEM learning 
scheme thus provide an un-supervised well-balanced approach for the fusion of 
EEG/fMRI information. We first demonstrate our approach on synthetic data. 
Results show that, in contrast to classical EEG/fMRI fusion approach, the method 
proved efficient and robust regardless of the EEG/fMRI discordance level. We 
apply the method on EEG/fMRI recordings from a patient with epilepsy, in order 
to identify brain areas involved during the generation of epileptic spikes. The 
results are validated using intracranial EEG measurements.";2007;Health related;Health related;1
Elhabian SY, Agrawal P, Whitaker RT.;OPTIMAL PARAMETER MAP ESTIMATION FOR SHAPE REPRESENTATION: A GENERATIVE APPROACH;"Probabilistic label maps are a useful tool for important medical image analysis 
tasks such as segmentation, shape analysis, and atlas building. Existing methods 
typically rely on blurred signed distance maps or smoothed label maps to model 
uncertainties and shape variabilities, which do not conform to any generative 
model or estimation process, and are therefore suboptimal. In this paper, we 
propose to learn probabilistic label maps using a generative model on given set 
of binary label maps. The proposed approach generalizes well on unseen data 
while simultaneously capturing the variability in the training samples. 
Efficiency of the proposed approach is demonstrated for consensus generation and 
shape-based clustering using synthetic datasets as well as left atrial 
segmentations from late-gadolinium enhancement MRI.";2016;Health related;Health related;1
Sabuncu MR, Balci SK, Shenton ME, Golland P.;Image-driven population analysis through mixture modeling;"We present iCluster, a fast and efficient algorithm that clusters a set of 
images while co-registering them using a parameterized, nonlinear transformation 
model. The output of the algorithm is a small number of template images that 
represent different modes in a population. This is in contrast with traditional, 
hypothesis-driven computational anatomy approaches that assume a single template 
to construct an atlas. We derive the algorithm based on a generative model of an 
image population as a mixture of deformable template images. We validate and 
explore our method in four experiments. In the first experiment, we use 
synthetic data to explore the behavior of the algorithm and inform a design 
choice on parameter settings. In the second experiment, we demonstrate the 
utility of having multiple atlases for the application of localizing temporal 
lobe brain structures in a pool of subjects that contains healthy controls and 
schizophrenia patients. Next, we employ iCluster to partition a data set of 415 
whole brain MR volumes of subjects aged 18 through 96 years into three 
anatomical subgroups. Our analysis suggests that these subgroups mainly 
correspond to age groups. The templates reveal significant structural 
differences across these age groups that confirm previous findings in aging 
research. In the final experiment, we run iCluster on a group of 15 patients 
with dementia and 15 age-matched healthy controls. The algorithm produces two 
modes, one of which contains dementia patients only. These results suggest that 
the algorithm can be used to discover subpopulations that correspond to 
interesting structural or functional ""modes.""";2009;Health related;Health related;1
Luessi M, Babacan SD, Molina R, Booth JR, Katsaggelos AK.;Bayesian symmetrical EEG/fMRI fusion with spatially adaptive priors;"In this paper, we propose a novel symmetrical EEG/fMRI fusion method which 
combines EEG and fMRI by means of a common generative model. We use a total 
variation (TV) prior to model the spatial distribution of the cortical current 
responses and hemodynamic response functions, and utilize spatially adaptive 
temporal priors to model their temporal shapes. The spatial adaptivity of the 
prior model allows for adaptation to the local characteristics of the estimated 
responses and leads to high estimation performance for the cortical current 
distribution and the hemodynamic response functions. We utilize a Bayesian 
formulation with a variational Bayesian framework and obtain a fully automatic 
fusion algorithm. Simulations with synthetic data and experiments with real data 
from a multimodal study on face perception demonstrate the performance of the 
proposed method.";2011;Health related;Not Health related;1
Liu X, Xie Y, Diao S, Tan S, Liang X.;Unsupervised CT Metal Artifact Reduction by Plugging Diffusion Priors in Dual Domains;"During the process of computed tomography (CT), metallic implants often cause 
disruptive artifacts in the reconstructed images, impeding accurate diagnosis. 
Many supervised deep learning-based approaches have been proposed for metal 
artifact reduction (MAR). However, these methods heavily rely on training with 
paired simulated data, which are challenging to acquire. This limitation can 
lead to decreased performance when applying these methods in clinical practice. 
Existing unsupervised MAR methods, whether based on learning or not, typically 
work within a single domain, either in the image domain or the sinogram domain. 
In this paper, we propose an unsupervised MAR method based on the diffusion 
model, a generative model with a high capacity to represent data distributions. 
Specifically, we first train a diffusion model using CT images without metal 
artifacts. Subsequently, we iteratively introduce the diffusion priors in both 
the sinogram domain and image domain to restore the degraded portions caused by 
metal artifacts. Besides, we design temporally dynamic weight masks for the 
image-domian fusion. The dual-domain processing empowers our approach to 
outperform existing unsupervised MAR methods, including another MAR method based 
on diffusion model. The effectiveness has been qualitatively and quantitatively 
validated on synthetic datasets. Moreover, our method demonstrates superior 
visual results among both supervised and unsupervised methods on clinical 
datasets. Codes are available in github.com/DeepXuan/DuDoDp-MAR.";2024;Health related;Health related;0
Liu H, Wei D, Lu D, Tang X, Wang L, Zheng Y.;Simultaneous alignment and surface regression using hybrid 2D-3D networks for 3D coherent layer segmentation of retinal OCT images with full and sparse annotations;"Layer segmentation is important to quantitative analysis of retinal optical 
coherence tomography (OCT). Recently, deep learning based methods have been 
developed to automate this task and yield remarkable performance. However, due 
to the large spatial gap and potential mismatch between the B-scans of an OCT 
volume, all of them were based on 2D segmentation of individual B-scans, which 
may lose the continuity and diagnostic information of the retinal layers in 3D 
space. Besides, most of these methods required dense annotation of the OCT 
volumes, which is labor-intensive and expertise-demanding. This work presents a 
novel framework based on hybrid 2D-3D convolutional neural networks (CNNs) to 
obtain continuous 3D retinal layer surfaces from OCT volumes, which works well 
with both full and sparse annotations. The 2D features of individual B-scans are 
extracted by an encoder consisting of 2D convolutions. These 2D features are 
then used to produce the alignment displacement vectors and layer segmentation 
by two 3D decoders coupled via a spatial transformer module. Two losses are 
proposed to utilize the retinal layers' natural property of being smooth for 
B-scan alignment and layer segmentation, respectively, and are the key to the 
semi-supervised learning with sparse annotation. The entire framework is trained 
end-to-end. To the best of our knowledge, this is the first work that attempts 
3D retinal layer segmentation in volumetric OCT images based on CNNs. 
Experiments on a synthetic dataset and three public clinical datasets show that 
our framework can effectively align the B-scans for potential motion correction, 
and achieves superior performance to state-of-the-art 2D deep learning methods 
in terms of both layer segmentation accuracy and cross-B-scan 3D continuity in 
both fully and semi-supervised settings, thus offering more clinical values than 
previous works.";2024;Health related;Health related;1
Liang T, Fan X, Li Q, Li SY.;Detection of dispersed short tandem repeats using reversible jump Markov chain Monte Carlo;"Tandem repeats occur frequently in biological sequences. They are important for 
studying genome evolution and human disease. A number of methods have been 
designed to detect a single tandem repeat in a sliding window. In this article, 
we focus on the case that an unknown number of tandem repeat segments of the 
same pattern are dispersively distributed in a sequence. We construct a 
probabilistic generative model for the tandem repeats, where the sequence 
pattern is represented by a motif matrix. A Bayesian approach is adopted to 
compute this model. Markov chain Monte Carlo (MCMC) algorithms are used to 
explore the posterior distribution as an effort to infer both the motif matrix 
of tandem repeats and the location of repeat segments. Reversible jump Markov 
chain Monte Carlo (RJMCMC) algorithms are used to address the transdimensional 
model selection problem raised by the variable number of repeat segments. 
Experiments on both synthetic data and real data show that this new approach is 
powerful in detecting dispersed short tandem repeats. As far as we know, it is 
the first work to adopt RJMCMC algorithms in the detection of tandem repeats.";2012;Health related;Health related;0
Dudas D, Dilling TJ, El Naqa I.;Improved outcome models with denoising diffusion;"Purpose: Radiotherapy outcome modelling often suffers from class imbalance in the modelled endpoints. One of the main options to address this issue is by introducing new synthetically generated datapoints, using generative models, such as Denoising Diffusion Probabilistic Models (DDPM). In this study, we implemented DDPM to improve performance of a tumor local control model, trained on imbalanced dataset, and compare this approach with other common techniques.
Methods: A dataset of 535 NSCLC patients treated with SBRT (50 Gy/5 fractions) was used to train a deep learning outcome model for tumor local control prediction. The dataset included complete treatment planning data (planning CT images, 3D planning dose distribution and patient demographics) with sparsely distributed endpoints (6-7 % experiencing local failure). Consequently, we trained a novel conditional 3D DDPM model to generate synthetic treatment planning data. Synthetically generated treatment planning datapoints were used to supplement the real training dataset and the improvement in the model's performance was studied. Obtained results were also compared to other common techniques for class imbalanced training, such as Oversampling, Undersampling, Augmentation, Class Weights, SMOTE and ADASYN.
Results: Synthetic DDPM-generated data were visually trustworthy, with Fréchet inception distance (FID) below 50. Extending the training dataset with the synthetic data improved the model's performance by more than 10%, while other techniques exhibited only about 4% improvement.
Conclusions: DDPM introduces a novel approach to class-imbalanced outcome modelling problems. The model generates realistic synthetic radiotherapy planning data, with a strong potential to increase performance and robustness of outcome models.
Keywords: Class imbalance Deep Learning; Denoising Diffusion Probabilistic Models; Lung cancer; Outcome modelling; Radiotherapy.";2024;Health related;Health related;0
Kim K, Cho K, Jang R, Kyung S, Lee S, Ham S, Choi E, Hong GS, Kim N.;Updated Primer on Generative Artificial Intelligence and Large Language Models in Medical Imaging for Medical Professionals;"The emergence of Chat Generative Pre-trained Transformer (ChatGPT), a chatbot developed by OpenAI, has garnered interest in the application of generative artificial intelligence (AI) models in the medical field. This review summarizes different generative AI models and their potential applications in the field of medicine and explores the evolving landscape of Generative Adversarial Networks and diffusion models since the introduction of generative AI models. These models have made valuable contributions to the field of radiology. Furthermore, this review also explores the significance of synthetic data in addressing privacy concerns and augmenting data diversity and quality within the medical domain, in addition to emphasizing the role of inversion in the investigation of generative models and outlining an approach to replicate this process. We provide an overview of Large Language Models, such as GPTs and bidirectional encoder representations (BERTs), that focus on prominent representatives and discuss recent initiatives involving language-vision models in radiology, including innovative large language and vision assistant for biomedicine (LLaVa-Med), to illustrate their practical application. This comprehensive review offers insights into the wide-ranging applications of generative AI models in clinical research and emphasizes their transformative potential.
Keywords: Artificial intelligence; Generative artificial intelligence; Large language model; Medical imaging; Synthetic data
";2024;Health related;Health related;1
Kikuchi T, Hanaoka S, Nakao T, Takenaga T, Nomura Y, Mori H, Yoshikawa T.;Synthesis of Hybrid Data Consisting of Chest Radiographs and Tabular Clinical Records Using Dual Generative Models for COVID-19 Positive Cases;"To generate synthetic medical data incorporating image-tabular hybrid data by merging an image encoding/decoding model with a table-compatible generative model and assess their utility. We used 1342 cases from the Stony Brook University Covid-19-positive cases, comprising chest X-ray radiographs (CXRs) and tabular clinical data as a private dataset (pDS). We generated a synthetic dataset (sDS) through the following steps: (I) dimensionally reducing CXRs in the pDS using a pretrained encoder of the auto-encoding generative adversarial networks (_GAN) and integrating them with the correspondent tabular clinical data; (II) training the conditional tabular GAN (CTGAN) on this combined data to generate synthetic records, encompassing encoded image features and clinical data; and (III) reconstructing synthetic images from these encoded image features in the sDS using a pretrained decoder of the _GAN. The utility of sDS was assessed by the performance of the prediction models for patient outcomes (deceased or discharged). For the pDS test set, the area under the receiver operating characteristic (AUC) curve was calculated to compare the performance of prediction models trained separately with pDS, sDS, or a combination of both. We created an sDS comprising CXRs with a resolution of 256 _ 256 pixels and tabular data containing 13 variables. The AUC for the outcome was 0.83 when the model was trained with the pDS, 0.74 with the sDS, and 0.87 when combining pDS and sDS for training. Our method is effective for generating synthetic records consisting of both images and tabular clinical data.
Keywords: Auto-encoding GAN; COVID-19; CTGAN; Data sharing; Synthetic data generation";2024;Health related;Health related;1
"Janssen A, Smalbil L, Bennis FC, Cnossen MH, Mathôt RAA; OPTI-CLOT study group and SYMPHONY consortium.";A Generative and Causal Pharmacokinetic Model for Factor VIII in Hemophilia A: A Machine Learning Framework for Continuous Model Refinement;"In rare diseases, such as hemophilia A, the development of accurate population pharmacokinetic (PK) models is often hindered by the limited availability of data. Most PK models are specific to a single recombinant factor VIII (rFVIII) concentrate or measurement assay, and are generally unsuited for answering counterfactual (""what-if"") queries. Ideally, data from multiple hemophilia treatment centers are combined but this is generally difficult as patient data are kept private. In this work, we utilize causal inference techniques to produce a hybrid machine learning (ML) PK model that corrects for differences between rFVIII concentrates and measurement assays. Next, we augment this model with a generative model that can simulate realistic virtual patients as well as impute missing data. This model can be shared instead of actual patient data, resolving privacy issues. The hybrid ML-PK model was trained on chromogenic assay data of lonoctocog alfa and predictive performance was then evaluated on an external data set of patients who received octocog alfa with FVIII levels measured using the one-stage assay. The model presented higher accuracy compared with three previous PK models developed on data similar to the external data set (root mean squared error = 14.6 IU/dL vs. mean of 17.7 IU/dL). Finally, we show that the generative model can be used to accurately impute missing data (< 18% error). In conclusion, the proposed approach introduces interesting new possibilities for model development. In the context of rare disease, the introduction of generative models facilitates sharing of synthetic data, enabling the iterative improvement of population PK models.";2024;Health related;Health related;1
Qin D, Amariucai GT, Qiao D, Guan Y, Fu S.;A comprehensive and reliable feature attribution method: Double-sided remove and reconstruct (DoRaR);The limited transparency of the inner decision-making mechanism in deep neural networks (DNN) and other machine learning (ML) models has hindered their application in several domains. In order to tackle this issue, feature attribution methods have been developed to identify the crucial features that heavily influence decisions made by these black box models. However, many feature attribution methods have inherent downsides. For example, one category of feature attribution methods suffers from the artifacts problem, which feeds out-of-distribution masked inputs directly through the classifier that was originally trained on natural data points. Another category of feature attribution method finds explanations by using jointly trained feature selectors and predictors. While avoiding the artifacts problem, this new category suffers from the Encoding Prediction in the Explanation (EPITE) problem, in which the predictor's decisions rely not on the features, but on the masks that selects those features. As a result, the credibility of attribution results is undermined by these downsides. In this research, we introduce the Double-sided Remove and Reconstruct (DoRaR) feature attribution method based on several improvement methods that addresses these issues. By conducting thorough testing on MNIST, CIFAR10 and our own synthetic dataset, we demonstrate that the DoRaR feature attribution method can effectively bypass the above issues and can aid in training a feature selector that outperforms other state-of-the-art feature attribution methods. Our code is available at https://github.com/dxq21/DoRaR.;2024;Not health related;Not Health related;0
Helmer M, Warrington S, Mohammadi-Nejad AR, Ji JL, Howell A, Rosand B, Anticevic A, Sotiropoulos SN, Murray JD.;On the stability of canonical correlation analysis and partial least squares with application to brain-behavior associations;"Associations between datasets can be discovered through multivariate methods like Canonical Correlation Analysis (CCA) or Partial Least Squares (PLS). A requisite property for interpretability and generalizability of CCA/PLS associations is stability of their feature patterns. However, stability of CCA/PLS in high-dimensional datasets is questionable, as found in empirical characterizations. To study these issues systematically, we developed a generative modeling framework to simulate synthetic datasets. We found that when sample size is relatively small, but comparable to typical studies, CCA/PLS associations are highly unstable and inaccurate; both in their magnitude and importantly in the feature pattern underlying the association. We confirmed these trends across two neuroimaging modalities and in independent datasets with n ≈ 1000 and n = 20,000, and found that only the latter comprised sufficient observations for stable mappings between imaging-derived and behavioral features. We further developed a power calculator to provide sample sizes required for stability and reliability of multivariate analyses. Collectively, we characterize how to limit detrimental effects of overfitting on CCA/PLS stability, and provide recommendations for future studies.";2024;Not health related;Not Health related;0