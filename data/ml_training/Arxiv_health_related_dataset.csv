Title;Abstract;GPT4 ReviewData-Efficient Sleep Staging with Synthetic Time Series Pretraining;"              Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we pr…         _ More           Analyzing electroencephalographic (EEG) time series can be challenging, especially with deep neural networks, due to the large variability among human subjects and often small datasets. To address these challenges, various strategies, such as self-supervised learning, have been suggested, but they typically rely on extensive empirical datasets. Inspired by recent advances in computer vision, we propose a pretraining task termed ""frequency pretraining"" to pretrain a neural network for sleep staging by predicting the frequency content of randomly generated synthetic time series. Our experiments demonstrate that our method surpasses fully supervised learning in scenarios with limited data and few subjects, and matches its performance in regimes with many subjects. Furthermore, our results underline the relevance of frequency information for sleep stage scoring, while also demonstrating that deep neural networks utilize information beyond frequencies to enhance sleep staging performance, which is consistent with previous research. We anticipate that our approach will be advantageous across a broad spectrum of applications where EEG data is limited or derived from a small number of subjects, including the domain of brain-computer interfaces.         _ Less";Not health relatedLearnable Community-Aware Transformer for Brain Connectome Analysis with Token Clustering;              Neuroscientific research has revealed that the complex brain network can be organized into distinct functional communities, each characterized by a cohesive group of regions of interest (ROIs) with strong interconnections. These communities play a crucial role in comprehending the functional organization of the brain and its implications for neurological conditions, including Autism Spectrum Disor…         _ More           Neuroscientific research has revealed that the complex brain network can be organized into distinct functional communities, each characterized by a cohesive group of regions of interest (ROIs) with strong interconnections. These communities play a crucial role in comprehending the functional organization of the brain and its implications for neurological conditions, including Autism Spectrum Disorder (ASD) and biological differences, such as in gender. Traditional models have been constrained by the necessity of predefined community clusters, limiting their flexibility and adaptability in deciphering the brain's functional organization. Furthermore, these models were restricted by a fixed number of communities, hindering their ability to accurately represent the brain's dynamic nature. In this study, we present a token clustering brain transformer-based model ($\texttt{TC-BrainTF}$) for joint community clustering and classification. Our approach proposes a novel token clustering (TC) module based on the transformer architecture, which utilizes learnable prompt tokens with orthogonal loss where each ROI embedding is projected onto the prompt embedding space, effectively clustering ROIs into communities and reducing the dimensions of the node representation via merging with communities. Our results demonstrate that our learnable community-aware model $\texttt{TC-BrainTF}$ offers improved accuracy in identifying ASD and classifying genders through rigorous testing on ABIDE and HCP datasets. Additionally, the qualitative analysis on $\texttt{TC-BrainTF}$ has demonstrated the effectiveness of the designed TC module and its relevance to neuroscience interpretations.         _ Less;Not health relatedGeneral surgery vision transformer: A video pre-trained foundation model for general surgery;"The absence of openly accessible data and specialized foundation models is a major barrier for computational research in surgery. Toward this, (i) we open-source the largest dataset of general surgery videos to-date, consisting of 680 hours of surgical videos, including data from robotic and laparoscopic techniques across 28 procedures; (ii) we propose a technique for video pre-training a general…         _ More           The absence of openly accessible data and specialized foundation models is a major barrier for computational research in surgery. Toward this, (i) we open-source the largest dataset of general surgery videos to-date, consisting of 680 hours of surgical videos, including data from robotic and laparoscopic techniques across 28 procedures; (ii) we propose a technique for video pre-training a general surgery vision transformer (GSViT) on surgical videos based on forward video prediction that can run in real-time for surgical applications, toward which we open-source the code and weights of GSViT; (iii) we also release code and weights for procedure-specific fine-tuned versions of GSViT across 10 procedures; (iv) we demonstrate the performance of GSViT on the Cholec80 phase annotation task, displaying improved performance over state-of-the-art single frame predictors.         _ Less";Not health relatedSpeaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning;Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from…         _ More           Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a transformer framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and contrastive learning for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of dysarthric speech. We evaluated on the Universal Access Speech dataset using leave-one-speaker-out cross-validation, our model demonstrated superior performance over traditional machine learning approaches, with an accuracy of $70.48\%$ and an F1 score of $59.23\%$. Our SALR model also exceeded the previous benchmark for AI-based classification, which used support vector machines, by $16.58\%$. We open the black box of our model by visualising the latent space where we can observe how the model substantially reduces speaker-specific cues and amplifies task-specific ones, thereby showing its robustness. In conclusion, SALR establishes a new benchmark in speaker-independent multi-class dysarthria severity classification using generative AI. The potential implications of our findings for broader clinical applications in automated dysarthria severity assessments.         _ Less;Not health relatedA Protein Structure Prediction Approach Leveraging Transformer and CNN Integration;              Proteins are essential for life, and their structure determines their function. The protein secondary structure is formed by the folding of the protein primary structure, and the protein tertiary structure is formed by the bending and folding of the secondary structure. Therefore, the study of protein secondary structure is very helpful to the overall understanding of protein structure. Although t…         _ More           Proteins are essential for life, and their structure determines their function. The protein secondary structure is formed by the folding of the protein primary structure, and the protein tertiary structure is formed by the bending and folding of the secondary structure. Therefore, the study of protein secondary structure is very helpful to the overall understanding of protein structure. Although the accuracy of protein secondary structure prediction has continuously improved with the development of machine learning and deep learning, progress in the field of protein structure prediction, unfortunately, remains insufficient to meet the large demand for protein information. Therefore, based on the advantages of deep learning-based methods in feature extraction and learning ability, this paper adopts a two-dimensional fusion deep neural network model, DstruCCN, which uses Convolutional Neural Networks (CCN) and a supervised Transformer protein language model for single-sequence protein structure prediction. The training features of the two are combined to predict the protein Transformer binding site matrix, and then the three-dimensional structure is reconstructed using energy minimization.         _ Less;Not health relatedDual-Space Optimization: Improved Molecule Sequence Design by Latent Prompt Transformer;              Designing molecules with desirable properties, such as drug-likeliness and high binding affinities towards protein targets, is a challenging problem. In this paper, we propose the Dual-Space Optimization (DSO) method that integrates latent space sampling and data space selection to solve this problem. DSO iteratively updates a latent space generative model and a synthetic dataset in an optimizatio…         _ More           Designing molecules with desirable properties, such as drug-likeliness and high binding affinities towards protein targets, is a challenging problem. In this paper, we propose the Dual-Space Optimization (DSO) method that integrates latent space sampling and data space selection to solve this problem. DSO iteratively updates a latent space generative model and a synthetic dataset in an optimization process that gradually shifts the generative model and the synthetic data towards regions of desired property values. Our generative model takes the form of a Latent Prompt Transformer (LPT) where the latent vector serves as the prompt of a causal transformer. Our extensive experiments demonstrate effectiveness of the proposed method, which sets new performance benchmarks across single-objective, multi-objective and constrained molecule design tasks.         _ Less;Not health relatedPredicting O-GlcNAcylation Sites in Mammalian Proteins with Transformers and RNNs Trained with a New Loss Function;"Glycosylation, a protein modification, has multiple essential functional and structural roles. O-GlcNAcylation, a subtype of glycosylation, has the potential to be an important target for therapeutics, but methods to reliably predict O-GlcNAcylation sites had not been available until 2023; a 2021 review correctly noted that published models were insufficient and failed to generalize. Moreover, man…         _ More           Glycosylation, a protein modification, has multiple essential functional and structural roles. O-GlcNAcylation, a subtype of glycosylation, has the potential to be an important target for therapeutics, but methods to reliably predict O-GlcNAcylation sites had not been available until 2023; a 2021 review correctly noted that published models were insufficient and failed to generalize. Moreover, many are no longer usable. In 2023, a considerably better RNN model with an F$_1$ score of 36.17% and an MCC of 34.57% on a large dataset was published. This article first sought to improve these metrics using transformer encoders. While transformers displayed high performance on this dataset, their performance was inferior to that of the previously published RNN. We then created a new loss function, which we call the weighted focal differentiable MCC, to improve the performance of classification models. RNN models trained with this new function display superior performance to models trained using the weighted cross-entropy loss; this new function can also be used to fine-tune trained models. A two-cell RNN trained with this loss achieves state-of-the-art performance in O-GlcNAcylation site prediction with an F$_1$ score of 38.82% and an MCC of 38.21% on that large dataset.         _ Less";Not health relatedA novel molecule generative model of VAE combined with Transformer;Recently, molecule generation using deep learning has been actively investigated in drug discovery. In this field, Transformer and VAE are widely used as powerful models, but they are rarely used in combination due to structural and performance mismatch of them. This study proposes a model that combines these two models through structural and parameter optimization in handling diverse molecules. T…         _ More           Recently, molecule generation using deep learning has been actively investigated in drug discovery. In this field, Transformer and VAE are widely used as powerful models, but they are rarely used in combination due to structural and performance mismatch of them. This study proposes a model that combines these two models through structural and parameter optimization in handling diverse molecules. The proposed model shows comparable performance to existing models in generating molecules, and showed by far superior performance in generating molecules with unseen structures. In addition, the proposed model successfully predicted molecular properties using the latent representation of VAE. Ablation studies suggested the advantage of VAE over other generative models like language model in generating novel molecules, and that the molecules can be described by ~32 dimensional variables, much smaller than existing descriptors and models. This study is expected to provide a virtual chemical library containing a wide variety of compounds for virtual screening and to enable efficient screening.         _ Less;Not health relatedFOD-Swin-Net: angular super resolution of fiber orientation distribution using a transformer-based deep model;Identifying and characterizing brain fiber bundles can help to understand many diseases and conditions. An important step in this process is the estimation of fiber orientations using Diffusion-Weighted Magnetic Resonance Imaging (DW-MRI). However, obtaining robust orientation estimates demands high-resolution data, leading to lengthy acquisitions that are not always clinically available. In this…         _ More           Identifying and characterizing brain fiber bundles can help to understand many diseases and conditions. An important step in this process is the estimation of fiber orientations using Diffusion-Weighted Magnetic Resonance Imaging (DW-MRI). However, obtaining robust orientation estimates demands high-resolution data, leading to lengthy acquisitions that are not always clinically available. In this work, we explore the use of automated angular super resolution from faster acquisitions to overcome this challenge. Using the publicly available Human Connectome Project (HCP) DW-MRI data, we trained a transformer-based deep learning architecture to achieve angular super resolution in fiber orientation distribution (FOD). Our patch-based methodology, FOD-Swin-Net, is able to bring a single-shell reconstruction driven from 32 directions to be comparable to a multi-shell 288 direction FOD reconstruction, greatly reducing the number of required directions on initial acquisition. Evaluations of the reconstructed FOD with Angular Correlation Coefficient and qualitative visualizations reveal superior performance than the state-of-the-art in HCP testing data. Open source code for reproducibility is available at https://github.com/MICLab-Unicamp/FOD-Swin-Net.         _ Less;Not health relatedTransformer-based de novo peptide sequencing for data-independent acquisition mass spectrometry;Tandem mass spectrometry (MS/MS) stands as the predominant high-throughput technique for comprehensively analyzing protein content within biological samples. This methodology is a cornerstone driving the advancement of proteomics. In recent years, substantial strides have been made in Data-Independent Acquisition (DIA) strategies, facilitating impartial and non-targeted fragmentation of precursor…         _ More           Tandem mass spectrometry (MS/MS) stands as the predominant high-throughput technique for comprehensively analyzing protein content within biological samples. This methodology is a cornerstone driving the advancement of proteomics. In recent years, substantial strides have been made in Data-Independent Acquisition (DIA) strategies, facilitating impartial and non-targeted fragmentation of precursor ions. The DIA-generated MS/MS spectra present a formidable obstacle due to their inherent high multiplexing nature. Each spectrum encapsulates fragmented product ions originating from multiple precursor peptides. This intricacy poses a particularly acute challenge in de novo peptide/protein sequencing, where current methods are ill-equipped to address the multiplexing conundrum. In this paper, we introduce Casanovo-DIA, a deep-learning model based on transformer architecture. It deciphers peptide sequences from DIA mass spectrometry data. Our results show significant improvements over existing STOA methods, including DeepNovo-DIA and PepNet. Casanovo-DIA enhances precision by 15.14% to 34.8%, recall by 11.62% to 31.94% at the amino acid level, and boosts precision by 59% to 81.36% at the peptide level. Integrating DIA data and our Casanovo-DIA model holds considerable promise to uncover novel peptides and more comprehensive profiling of biological samples. Casanovo-DIA is freely available under the GNU GPL license at https://github.com/Biocomputing-Research-Group/Casanovo-DIA.         _ Less;Not health relatedPersonalised Drug Identifier for Cancer Treatment with Transformers using Auxiliary Information;              Cancer remains a global challenge due to its growing clinical and economic burden. Its uniquely personal manifestation, which makes treatment difficult, has fuelled the quest for personalized treatment strategies. Thus, genomic profiling is increasingly becoming part of clinical diagnostic panels. Effective use of such panels requires accurate drug response prediction (DRP) models, which are chall…         _ More           Cancer remains a global challenge due to its growing clinical and economic burden. Its uniquely personal manifestation, which makes treatment difficult, has fuelled the quest for personalized treatment strategies. Thus, genomic profiling is increasingly becoming part of clinical diagnostic panels. Effective use of such panels requires accurate drug response prediction (DRP) models, which are challenging to build due to limited labelled patient data. Previous methods to address this problem have used various forms of transfer learning. However, they do not explicitly model the variable length sequential structure of the list of mutations in such diagnostic panels. Further, they do not utilize auxiliary information (like patient survival) for model training. We address these limitations through a novel transformer based method, which surpasses the performance of state-of-the-art DRP models on benchmark data. We also present the design of a treatment recommendation system (TRS), which is currently deployed at the National University Hospital, Singapore and is being evaluated in a clinical trial.         _ Less;Not health relatedGenerating Visual Stimuli from EEG Recordings using Transformer-encoder based EEG encoder and GAN;              In this study, we tackle a modern research challenge within the field of perceptual brain decoding, which revolves around synthesizing images from EEG signals using an adversarial deep learning framework. The specific objective is to recreate images belonging to various object categories by leveraging EEG recordings obtained while subjects view those images. To achieve this, we employ a Transforme…         _ More           In this study, we tackle a modern research challenge within the field of perceptual brain decoding, which revolves around synthesizing images from EEG signals using an adversarial deep learning framework. The specific objective is to recreate images belonging to various object categories by leveraging EEG recordings obtained while subjects view those images. To achieve this, we employ a Transformer-encoder based EEG encoder to produce EEG encodings, which serve as inputs to the generator component of the GAN network. Alongside the adversarial loss, we also incorporate perceptual loss to enhance the quality of the generated images.         _ Less;Not health relatedDeep Manifold Transformation for Protein Representation Learning;              Protein representation learning is critical in various tasks in biology, such as drug design and protein structure or function prediction, which has primarily benefited from protein language models and graph neural networks. These models can capture intrinsic patterns from protein sequences and structures through masking and task-related losses. However, the learned protein representations are usu…         _ More           Protein representation learning is critical in various tasks in biology, such as drug design and protein structure or function prediction, which has primarily benefited from protein language models and graph neural networks. These models can capture intrinsic patterns from protein sequences and structures through masking and task-related losses. However, the learned protein representations are usually not well optimized, leading to performance degradation due to limited data, difficulty adapting to new tasks, etc. To address this, we propose a new \underline{d}eep \underline{m}anifold \underline{t}ransformation approach for universal \underline{p}rotein \underline{r}epresentation \underline{l}earning (DMTPRL). It employs manifold learning strategies to improve the quality and adaptability of the learned embeddings. Specifically, we apply a novel manifold learning loss during training based on the graph inter-node similarity. Our proposed DMTPRL method outperforms state-of-the-art baselines on diverse downstream tasks across popular datasets. This validates our approach for learning universal and robust protein representations. We promise to release the code after acceptance.         _ Less;Not health relatedInterpreting Time Series Transformer Models and Sensitivity Analysis of Population Age Groups to COVID-19 Infections;Interpreting deep learning time series models is crucial in understanding the model's behavior and learning patterns from raw data for real-time decision-making. However, the complexity inherent in transformer-based time series models poses challenges in explaining the impact of individual features on predictions. In this study, we leverage recent local interpretation methods to interpret state-of…         _ More           Interpreting deep learning time series models is crucial in understanding the model's behavior and learning patterns from raw data for real-time decision-making. However, the complexity inherent in transformer-based time series models poses challenges in explaining the impact of individual features on predictions. In this study, we leverage recent local interpretation methods to interpret state-of-the-art time series models. To use real-world datasets, we collected three years of daily case data for 3,142 US counties. Firstly, we compare six transformer-based models and choose the best prediction model for COVID-19 infection. Using 13 input features from the last two weeks, we can predict the cases for the next two weeks. Secondly, we present an innovative way to evaluate the prediction sensitivity to 8 population age groups over highly dynamic multivariate infection data. Thirdly, we compare our proposed perturbation-based interpretation method with related work, including a total of eight local interpretation methods. Finally, we apply our framework to traffic and electricity datasets, demonstrating that our approach is generic and can be applied to other time-series domains.         _ Less;Health relatedExploring General Intelligence via Gated Graph Transformer in Functional Connectivity Studies;              Functional connectivity (FC) as derived from fMRI has emerged as a pivotal tool in elucidating the intricacies of various psychiatric disorders and delineating the neural pathways that underpin cognitive and behavioral dynamics inherent to the human brain. While Graph Neural Networks (GNNs) offer a structured approach to represent neuroimaging data, they are limited by their need for a predefined…         _ More           Functional connectivity (FC) as derived from fMRI has emerged as a pivotal tool in elucidating the intricacies of various psychiatric disorders and delineating the neural pathways that underpin cognitive and behavioral dynamics inherent to the human brain. While Graph Neural Networks (GNNs) offer a structured approach to represent neuroimaging data, they are limited by their need for a predefined graph structure to depict associations between brain regions, a detail not solely provided by FCs. To bridge this gap, we introduce the Gated Graph Transformer (GGT) framework, designed to predict cognitive metrics based on FCs. Empirical validation on the Philadelphia Neurodevelopmental Cohort (PNC) underscores the superior predictive prowess of our model, further accentuating its potential in identifying pivotal neural connectivities that correlate with human cognitive processes.         _ Less;Health relatedxTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein;Protein language models have shown remarkable success in learning biological information from protein sequences. However, most existing models are limited by either autoencoding or autoregressive pre-training objectives, which makes them struggle to handle protein understanding and generation tasks concurrently. We propose a unified protein language model, xTrimoPGLM, to address these two types of…         _ More           Protein language models have shown remarkable success in learning biological information from protein sequences. However, most existing models are limited by either autoencoding or autoregressive pre-training objectives, which makes them struggle to handle protein understanding and generation tasks concurrently. We propose a unified protein language model, xTrimoPGLM, to address these two types of tasks simultaneously through an innovative pre-training framework. Our key technical contribution is an exploration of the compatibility and the potential for joint optimization of the two types of objectives, which has led to a strategy for training xTrimoPGLM at an unprecedented scale of 100 billion parameters and 1 trillion training tokens. Our extensive experiments reveal that 1) xTrimoPGLM significantly outperforms other advanced baselines in 18 protein understanding benchmarks across four categories. The model also facilitates an atomic-resolution view of protein structures, leading to an advanced 3D structural prediction model that surpasses existing language model-based tools. 2) xTrimoPGLM not only can generate de novo protein sequences following the principles of natural ones, but also can perform programmable generation after supervised fine-tuning (SFT) on curated sequences. These results highlight the substantial capability and versatility of xTrimoPGLM in understanding and generating protein sequences, contributing to the evolving landscape of foundation models in protein science.         _ Less;Health relatedACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach;Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a…         _ More           Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, developing a reliable and precise prediction model. In this work, we propose an efficient transformer-based framework to identify anticancer peptides for by performing accurate a reliable and precise prediction model. For this purpose, four different transformer models, namely ESM, ProtBert, BioBERT, and SciBERT are employed to detect anticancer peptides from amino acid sequences. To demonstrate the contribution of the proposed framework, extensive experiments are carried on widely-used datasets in the literature, two versions of AntiCp2, cACP-DeepGram, ACP-740. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed framework, ESM, exhibits 96.45 of accuracy for AntiCp2 dataset, 97.66 of accuracy for cACP-DeepGram dataset, and 88.51 of accuracy for ACP-740 dataset, thence determining new state-of-the-art.         _ Less;Health relatedLarge-scale Graph Representation Learning of Dynamic Brain Connectome with Transformers;Graph Transformers have recently been successful in various graph representation learning tasks, providing a number of advantages over message-passing Graph Neural Networks. Utilizing Graph Transformers for learning the representation of the brain functional connectivity network is also gaining interest. However, studies to date have underlooked the temporal dynamics of functional connectivity, wh…         _ More           Graph Transformers have recently been successful in various graph representation learning tasks, providing a number of advantages over message-passing Graph Neural Networks. Utilizing Graph Transformers for learning the representation of the brain functional connectivity network is also gaining interest. However, studies to date have underlooked the temporal dynamics of functional connectivity, which fluctuates over time. Here, we propose a method for learning the representation of dynamic functional connectivity with Graph Transformers. Specifically, we define the connectome embedding, which holds the position, structure, and time information of the functional connectivity graph, and use Transformers to learn its representation across time. We perform experiments with over 50,000 resting-state fMRI samples obtained from three datasets, which is the largest number of fMRI data used in studies by far. The experimental results show that our proposed method outperforms other competitive baselines in gender classification and age regression tasks based on the functional connectivity extracted from the fMRI data.         _ Less;Health relatedPreparing to Integrate Generative Pretrained Transformer Series 4 models into Genetic Variant Assessment Workflows: Assessing Performance, Drift, and Nondeterminism Characteristics Relative to Classifying Functional Evidence in Literature;Background. Large Language Models (LLMs) hold promise for improving genetic variant literature review in clinical testing. We assessed Generative Pretrained Transformer 4's (GPT-4) performance, nondeterminism, and drift to inform its suitability for use in complex clinical processes. Methods. A 2-prompt process for classification of functional evidence was optimized using a development set of 45 a…         _ More           Background. Large Language Models (LLMs) hold promise for improving genetic variant literature review in clinical testing. We assessed Generative Pretrained Transformer 4's (GPT-4) performance, nondeterminism, and drift to inform its suitability for use in complex clinical processes. Methods. A 2-prompt process for classification of functional evidence was optimized using a development set of 45 articles. The prompts asked GPT-4 to supply all functional data present in an article related to a variant or indicate that no functional evidence is present. For articles indicated as containing functional evidence, a second prompt asked GPT-4 to classify the evidence into pathogenic, benign, or intermediate/inconclusive categories. A final test set of 72 manually classified articles was used to test performance. Results. Over a 2.5-month period (Dec 2023-Feb 2024), we observed substantial differences in intraday (nondeterminism) and across day (drift) results, which lessened after 1/18/24. This variability is seen within and across models in the GPT-4 series, affecting different performance statistics to different degrees. Twenty runs after 1/18/24 identified articles containing functional evidence with 92.2% sensitivity, 95.6% positive predictive value (PPV) and 86.3% negative predictive value (NPV). The second prompt's identified pathogenic functional evidence with 90.0% sensitivity, 74.0% PPV and 95.3% NVP and for benign evidence with 88.0% sensitivity, 76.6% PPV and 96.9% NVP. Conclusion. Nondeterminism and drift within LLMs must be assessed and monitored when introducing LLM based functionality into clinical workflows. Failing to do this assessment or accounting for these challenges could lead to incorrect or missing information that is critical for patient care. The performance of our prompts appears adequate to assist in article prioritization but not in automated decision making.         _ Less;Not health relatedDeep Learning-based MRI Reconstruction with Artificial Fourier Transform (AFT)-Net;              The deep complex-valued neural network provides a powerful way to leverage complex number operations and representations, which has succeeded in several phase-based applications. However, most previously published networks have not fully accessed the impact of complex-valued networks in the frequency domain. Here, we introduced a unified complex-valued deep learning framework - artificial Fourier…         _ More           The deep complex-valued neural network provides a powerful way to leverage complex number operations and representations, which has succeeded in several phase-based applications. However, most previously published networks have not fully accessed the impact of complex-valued networks in the frequency domain. Here, we introduced a unified complex-valued deep learning framework - artificial Fourier transform network (AFT-Net) - which combined domain-manifold learning and complex-valued neural networks. The AFT-Net can be readily used to solve the image inverse problems in domain-transform, especially for accelerated magnetic resonance imaging (MRI) reconstruction and other applications. While conventional methods only accept magnitude images, the proposed method takes raw k-space data in the frequency domain as inputs, allowing a mapping between the k-space domain and the image domain to be determined through cross-domain learning. We show that AFT-Net achieves superior accelerated MRI reconstruction and is comparable to existing approaches. Also, our approach can be applied to different tasks like denoised MRS reconstruction and different datasets with various contrasts. The AFT-Net presented here is a valuable preprocessing component for different preclinical studies and provides an innovative alternative for solving inverse problems in imaging and spectroscopy.         _ Less;Health relatedBrain Diffuser with Hierarchical Transformer for MCI Causality Analysis;              Effective connectivity estimation plays a crucial role in understanding the interactions and information flow between different brain regions. However, the functional time series used for estimating effective connentivity is derived from certain software, which may lead to large computing errors because of different parameter settings and degrade the ability to model complex causal relationships b…         _ More           Effective connectivity estimation plays a crucial role in understanding the interactions and information flow between different brain regions. However, the functional time series used for estimating effective connentivity is derived from certain software, which may lead to large computing errors because of different parameter settings and degrade the ability to model complex causal relationships between brain regions. In this paper, a brain diffuser with hierarchical transformer (BDHT) is proposed to estimate effective connectivity for mild cognitive impairment (MCI) analysis. To our best knowledge, the proposed brain diffuer is the first generative model to apply diffusion models in the application of generating and analyzing multimodal brain networks. Specifically, the BDHT leverages the structural connectivity to guide the reverse processes in an efficient way. It makes the denoising process more reliable and guarantees effective connectivity estimation accuracy. To improve denoising quality, the hierarchical denoising transformer is designed to learn multi-scale features in topological space. Furthermore, the GraphConFormer block can concentrate on both global and adjacent connectivity information. By stacking the multi-head attention and graph convolutional network, the proposed model enhances structure-function complementarity and improves the ability in noise estimation. Experimental evaluations of the denoising diffusion model demonstrate its effectiveness in estimating effective connectivity. The method achieves superior performance in terms of accuracy and robustness compared to existing approaches. It can captures both unidirectal and bidirectional interactions between brain regions, providing a comprehensive understanding of the brain's information processing mechanisms.         _ Less;Health relatedEquivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms;Molecular docking is critical to structure-based virtual screening, yet the throughput of such workflows is limited by the expensive optimization of scoring functions involved in most docking algorithms. We explore how machine learning can accelerate this process by learning a scoring function with a functional form that allows for more rapid optimization. Specifically, we define the scoring funct…         _ More           Molecular docking is critical to structure-based virtual screening, yet the throughput of such workflows is limited by the expensive optimization of scoring functions involved in most docking algorithms. We explore how machine learning can accelerate this process by learning a scoring function with a functional form that allows for more rapid optimization. Specifically, we define the scoring function to be the cross-correlation of multi-channel ligand and protein scalar fields parameterized by equivariant graph neural networks, enabling rapid optimization over rigid-body degrees of freedom with fast Fourier transforms. The runtime of our approach can be amortized at several levels of abstraction, and is particularly favorable for virtual screening settings with a common binding pocket. We benchmark our scoring functions on two simplified docking-related tasks: decoy pose scoring and rigid conformer docking. Our method attains similar but faster performance on crystal structures compared to the widely-used Vina and Gnina scoring functions, and is more robust on computationally predicted structures. Code is available at https://github.com/bjing2016/scalar-fields.         _ Less;Health relatedMultiallelic Walsh transforms;              A closed formula multiallelic Walsh (or Hadamard) transform is introduced. Basic results are derived, and a statistical interpretation of some of the resulting linear forms is discussed.                          A closed formula multiallelic Walsh (or Hadamard) transform is introduced. Basic results are derived, and a statistical interpretation of some of the resulting linear forms is discussed.         _ Less;Health relatedJoint covariance property under geometric image transformations for spatio-temporal receptive fields according to the generalized Gaussian derivative model for visual receptive fields;              The influence of natural image transformations on receptive field responses is crucial for modelling visual operations in computer vision and biological vision. In this regard, covariance properties with respect to geometric image transformations in the earliest layers of the visual hierarchy are essential for expressing robust image operations and for formulating invariant visual operations at hi…         _ More           The influence of natural image transformations on receptive field responses is crucial for modelling visual operations in computer vision and biological vision. In this regard, covariance properties with respect to geometric image transformations in the earliest layers of the visual hierarchy are essential for expressing robust image operations and for formulating invariant visual operations at higher levels. This paper defines and proves a joint covariance property under compositions of spatial scaling transformations, spatial affine transformations, Galilean transformations and temporal scaling transformations, which makes it possible to characterize how different types of image transformations interact with each other. Specifically, the derived relations show how the receptive field parameters need to be transformed, in order to match the output from spatio-temporal receptive fields with the underlying spatio-temporal image transformations.         _ Less;Health relatedTo Transformers and Beyond: Large Language Models for the Genome;              In the rapidly evolving landscape of genomics, deep learning has emerged as a useful tool for tackling complex computational challenges. This review focuses on the transformative role of Large Language Models (LLMs), which are mostly based on the transformer architecture, in genomics. Building on the foundation of traditional convolutional neural networks and recurrent neural networks, we explore…         _ More           In the rapidly evolving landscape of genomics, deep learning has emerged as a useful tool for tackling complex computational challenges. This review focuses on the transformative role of Large Language Models (LLMs), which are mostly based on the transformer architecture, in genomics. Building on the foundation of traditional convolutional neural networks and recurrent neural networks, we explore both the strengths and limitations of transformers and other LLMs for genomics. Additionally, we contemplate the future of genomic modeling beyond the transformer architecture based on current trends in research. The paper aims to serve as a guide for computational biologists and computer scientists interested in LLMs for genomic data. We hope the paper can also serve as an educational introduction and discussion for biologists to a fundamental shift in how we will be analyzing genomic data in the future.         _ Less;Health relatedLISBET: a self-supervised Transformer model for the automatic segmentation of social behavior motifs;              Social behavior, defined as the process by which individuals act and react in response to others, is crucial for the function of societies and holds profound implications for mental health. To fully grasp the intricacies of social behavior and identify potential therapeutic targets for addressing social deficits, it is essential to understand its core principles. Although machine learning algorith…         _ More           Social behavior, defined as the process by which individuals act and react in response to others, is crucial for the function of societies and holds profound implications for mental health. To fully grasp the intricacies of social behavior and identify potential therapeutic targets for addressing social deficits, it is essential to understand its core principles. Although machine learning algorithms have made it easier to study specific aspects of complex behavior, current methodologies tend to focus primarily on single-animal behavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral Transformer), a model designed to detect and segment social interactions. Our model eliminates the need for feature selection and extensive human annotation by using self-supervised learning to detect and quantify social behaviors from dynamic body parts tracking data. LISBET can be used in hypothesis-driven mode to automate behavior classification using supervised finetuning, and in discovery-driven mode to segment social behavior motifs using unsupervised learning. We found that motifs recognized using the discovery-driven approach not only closely match the human annotations but also correlate with the electrophysiological activity of dopaminergic neurons in the Ventral Tegmental Area (VTA). We hope LISBET will help the community improve our understanding of social behaviors and their neural underpinnings.         _ Less;Health relatedA Primer for the Walsh Transform;              A mathematical development of the Walsh transform, Walsh basis, and Walsh coefficients is given. The author was prompted to write this by a wish to give a unified treatment of epistatic coordinates as they are used in evolutionary biology. At the end of the article, opinions are expressed regarding the usefulness of these concepts for the practical researcher.                          A mathematical development of the Walsh transform, Walsh basis, and Walsh coefficients is given. The author was prompted to write this by a wish to give a unified treatment of epistatic coordinates as they are used in evolutionary biology. At the end of the article, opinions are expressed regarding the usefulness of these concepts for the practical researcher.         _ Less;Health relatedIntegration of persistent Laplacian and pre-trained transformer for protein solubility changes upon mutation;Protein mutations can significantly influence protein solubility, which results in altered protein functions and leads to various diseases. Despite of tremendous effort, machine learning prediction of protein solubility changes upon mutation remains a challenging task as indicated by the poor scores of normalized Correct Prediction Ratio (CPR). Part of the challenge stems from the fact that there…         _ More           Protein mutations can significantly influence protein solubility, which results in altered protein functions and leads to various diseases. Despite of tremendous effort, machine learning prediction of protein solubility changes upon mutation remains a challenging task as indicated by the poor scores of normalized Correct Prediction Ratio (CPR). Part of the challenge stems from the fact that there is no three-dimensional (3D) structures for the wild-type and mutant proteins. This work integrates persistent Laplacians and pre-trained Transformer for the task. The Transformer, pretrained with hunderds of millions of protein sequences, embeds wild-type and mutant sequences, while persistent Laplacians track the topological invariant change and homotopic shape evolution induced by mutations in 3D protein structures, which are rendered from AlphaFold2. The resulting machine learning model was trained on an extensive data set labeled with three solubility types. Our model outperforms all existing predictive methods and improves the state-of-the-art up to 15%.         _ Less;Health relatedPredicting Transcription Factor Binding Sites using Transformer based Capsule Network;Prediction of binding sites for transcription factors is important to understand how they regulate gene expression and how this regulation can be modulated for therapeutic purposes. Although in the past few years there are significant works addressing this issue, there is still space for improvement. In this regard, a transformer based capsule network viz. DNABERT-Cap is proposed in this work to p…         _ More           Prediction of binding sites for transcription factors is important to understand how they regulate gene expression and how this regulation can be modulated for therapeutic purposes. Although in the past few years there are significant works addressing this issue, there is still space for improvement. In this regard, a transformer based capsule network viz. DNABERT-Cap is proposed in this work to predict transcription factor binding sites mining ChIP-seq datasets. DNABERT-Cap is a bidirectional encoder pre-trained with large number of genomic DNA sequences, empowered with a capsule layer responsible for the final prediction. The proposed model builds a predictor for transcription factor binding sites using the joint optimisation of features encompassing both bidirectional encoder and capsule layer, along with convolutional and bidirectional long-short term memory layers. To evaluate the efficiency of the proposed approach, we use a benchmark ChIP-seq datasets of five cell lines viz. A549, GM12878, Hep-G2, H1-hESC and Hela, available in the ENCODE repository. The results show that the average area under the receiver operating characteristic curve score exceeds 0.91 for all such five cell lines. DNABERT-Cap is also compared with existing state-of-the-art deep learning based predictors viz. DeepARC, DeepTF, CNN-Zeng and DeepBind, and is seen to outperform them.         _ Less;Health relatedMulti-omics Sampling-based Graph Transformer for Synthetic Lethality Prediction;              Synthetic lethality (SL) prediction is used to identify if the co-mutation of two genes results in cell death. The prevalent strategy is to abstract SL prediction as an edge classification task on gene nodes within SL data and achieve it through graph neural networks (GNNs). However, GNNs suffer from limitations in their message passing mechanisms, including over-smoothing and over-squashing issue…         _ More           Synthetic lethality (SL) prediction is used to identify if the co-mutation of two genes results in cell death. The prevalent strategy is to abstract SL prediction as an edge classification task on gene nodes within SL data and achieve it through graph neural networks (GNNs). However, GNNs suffer from limitations in their message passing mechanisms, including over-smoothing and over-squashing issues. Moreover, harnessing the information of non-SL gene relationships within large-scale multi-omics data to facilitate SL prediction poses a non-trivial challenge. To tackle these issues, we propose a new multi-omics sampling-based graph transformer for SL prediction (MSGT-SL). Concretely, we introduce a shallow multi-view GNN to acquire local structural patterns from both SL and multi-omics data. Further, we input gene features that encode multi-view information into the standard self-attention to capture long-range dependencies. Notably, starting with batch genes from SL data, we adopt parallel random walk sampling across multiple omics gene graphs encompassing them. Such sampling effectively and modestly incorporates genes from omics in a structure-aware manner before using self-attention. We showcase the effectiveness of MSGT-SL on real-world SL tasks, demonstrating the empirical benefits gained from the graph transformer and multi-omics data.         _ Less;Health relatedETDock: A Novel Equivariant Transformer for Protein-Ligand Docking;Predicting the docking between proteins and ligands is a crucial and challenging task for drug discovery. However, traditional docking methods mainly rely on scoring functions, and deep learning-based docking approaches usually neglect the 3D spatial information of proteins and ligands, as well as the graph-level features of ligands, which limits their performance. To address these limitations, we…         _ More           Predicting the docking between proteins and ligands is a crucial and challenging task for drug discovery. However, traditional docking methods mainly rely on scoring functions, and deep learning-based docking approaches usually neglect the 3D spatial information of proteins and ligands, as well as the graph-level features of ligands, which limits their performance. To address these limitations, we propose an equivariant transformer neural network for protein-ligand docking pose prediction. Our approach involves the fusion of ligand graph-level features by feature processing, followed by the learning of ligand and protein representations using our proposed TAMformer module. Additionally, we employ an iterative optimization approach based on the predicted distance matrix to generate refined ligand poses. The experimental results on real datasets show that our model can achieve state-of-the-art performance.         _ Less;Health relatedMolecule Design by Latent Prompt Transformer;This paper proposes a latent prompt Transformer model for solving challenging optimization problems such as molecule design, where the goal is to find molecules with optimal values of a target chemical or biological property that can be computed by an existing software. Our proposed model consists of three components. (1) A latent vector whose prior distribution is modeled by a Unet transformation…         _ More           This paper proposes a latent prompt Transformer model for solving challenging optimization problems such as molecule design, where the goal is to find molecules with optimal values of a target chemical or biological property that can be computed by an existing software. Our proposed model consists of three components. (1) A latent vector whose prior distribution is modeled by a Unet transformation of a Gaussian white noise vector. (2) A molecule generation model that generates the string-based representation of molecule conditional on the latent vector in (1). We adopt the causal Transformer model that takes the latent vector in (1) as prompt. (3) A property prediction model that predicts the value of the target property of a molecule based on a non-linear regression on the latent vector in (1). We call the proposed model the latent prompt Transformer model. After initial training of the model on existing molecules and their property values, we then gradually shift the model distribution towards the region that supports desired values of the target property for the purpose of molecule design. Our experiments show that our proposed model achieves state of the art performances on several benchmark molecule design tasks.         _ Less;Health relatedExtension of Transformational Machine Learning: Classification Problems;              This study explores the application and performance of Transformational Machine Learning (TML) in drug discovery. TML, a meta learning algorithm, excels in exploiting common attributes across various domains, thus developing composite models that outperform conventional models. The drug discovery process, which is complex and time-consuming, can benefit greatly from the enhanced prediction accurac…         _ More           This study explores the application and performance of Transformational Machine Learning (TML) in drug discovery. TML, a meta learning algorithm, excels in exploiting common attributes across various domains, thus developing composite models that outperform conventional models. The drug discovery process, which is complex and time-consuming, can benefit greatly from the enhanced prediction accuracy, improved interpretability and greater generalizability provided by TML. We explore the efficacy of different machine learning classifiers, where no individual classifier exhibits distinct superiority, leading to the consideration of ensemble classifiers such as the Random Forest.   Our findings show that TML outperforms base Machine Learning (ML) as the number of training datasets increases, due to its capacity to better approximate the correct hypothesis, overcome local optima, and expand the space of representable functions by combining separate classifiers capabilities. However, this superiority is relative to the resampling methods applied, with Near Miss demonstrating poorer performance due to noisy data, overlapping classes, and nonlinear class boundaries. Conversely, Random Over Sampling (ROS) provides a more robust performance given its resistance to noise and outliers, improved class overlap management, and suitability for nonlinear class boundaries.         _ Less;Health relatedEmbed-Search-Align: DNA Sequence Alignment using Transformer Models;DNA sequence alignment involves assigning short DNA reads to the most probable locations on an extensive reference genome. This process is crucial for various genomic analyses, including variant calling, transcriptomics, and epigenomics. Conventional methods, refined over decades, tackle this challenge in two steps: genome indexing followed by efficient search to locate likely positions for given…         _ More           DNA sequence alignment involves assigning short DNA reads to the most probable locations on an extensive reference genome. This process is crucial for various genomic analyses, including variant calling, transcriptomics, and epigenomics. Conventional methods, refined over decades, tackle this challenge in two steps: genome indexing followed by efficient search to locate likely positions for given reads. Building on the success of Large Language Models (LLM) in encoding text into embeddings, where the distance metric captures semantic similarity, recent efforts have explored whether the same Transformer architecture can produce numerical representations for DNA sequences. Such models have shown early promise in tasks involving classification of short DNA sequences, such as the detection of coding vs non-coding regions, as well as the identification of enhancer and promoter sequences. Performance at sequence classification tasks does not, however, translate to sequence alignment, where it is necessary to conduct a genome-wide search to successfully align every read. We address this open problem by framing it as an Embed-Search-Align task. In this framework, a novel encoder model DNA-ESA generates representations of reads and fragments of the reference, which are projected into a shared vector space where the read-fragment distance is used as surrogate for alignment. In particular, DNA-ESA introduces: (1) Contrastive loss for self-supervised training of DNA sequence representations, facilitating rich sequence-level embeddings, and (2) a DNA vector store to enable search across fragments on a global scale. DNA-ESA is >97% accurate when aligning 250-length reads onto a human reference genome of 3 gigabases (single-haploid), far exceeds the performance of 6 recent DNA-Transformer model baselines and shows task transfer across chromosomes and species.         _ Less;Health relatedInsights Into the Inner Workings of Transformer Models for Protein Function Prediction;              Motivation: We explored how explainable artificial intelligence (XAI) can help to shed light into the inner workings of neural networks for protein function prediction, by extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models, which were finetuned to Gene Ontology term and Enzyme Commission number prediction, can be inspected too…         _ More           Motivation: We explored how explainable artificial intelligence (XAI) can help to shed light into the inner workings of neural networks for protein function prediction, by extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models, which were finetuned to Gene Ontology term and Enzyme Commission number prediction, can be inspected too. Results: The approach enabled us to identify amino acids in the sequences that the transformers pay particular attention to, and to show that these relevant sequence parts reflect expectations from biology and chemistry, both in the embedding layer and inside of the model, where we identified transformer heads with a statistically significant correspondence of attribution maps with ground truth sequence annotations (e.g. transmembrane regions, active sites) across many proteins. Availability and Implementation: Source code can be accessed at https://github.com/markuswenzel/xai-proteins .         _ Less;Health relatedPeptideBERT: A Language Model based on Transformers for Peptide Property Prediction;Recent advances in Language Models have enabled the protein modeling community with a powerful tool since protein sequences can be represented as text. Specifically, by taking advantage of Transformers, sequence-to-property prediction will be amenable without the need for explicit structural data. In this work, inspired by recent progress in Large Language Models (LLMs), we introduce PeptideBERT,…         _ More           Recent advances in Language Models have enabled the protein modeling community with a powerful tool since protein sequences can be represented as text. Specifically, by taking advantage of Transformers, sequence-to-property prediction will be amenable without the need for explicit structural data. In this work, inspired by recent progress in Large Language Models (LLMs), we introduce PeptideBERT, a protein language model for predicting three key properties of peptides (hemolysis, solubility, and non-fouling). The PeptideBert utilizes the ProtBERT pretrained transformer model with 12 attention heads and 12 hidden layers. We then finetuned the pretrained model for the three downstream tasks. Our model has achieved state of the art (SOTA) for predicting Hemolysis, which is a task for determining peptide's potential to induce red blood cell lysis. Our PeptideBert non-fouling model also achieved remarkable accuracy in predicting peptide's capacity to resist non-specific interactions. This model, trained predominantly on shorter sequences, benefits from the dataset where negative examples are largely associated with insoluble peptides. Codes, models, and data used in this study are freely available at: https://github.com/ChakradharG/PeptideBERT         _ Less;Health relatedDynamic Brain Transformer with Multi-level Attention for Functional Brain Network Analysis;              Recent neuroimaging studies have highlighted the importance of network-centric brain analysis, particularly with functional magnetic resonance imaging. The emergence of Deep Neural Networks has fostered a substantial interest in predicting clinical outcomes and categorizing individuals based on brain networks. However, the conventional approach involving static brain network analysis offers limite…         _ More           Recent neuroimaging studies have highlighted the importance of network-centric brain analysis, particularly with functional magnetic resonance imaging. The emergence of Deep Neural Networks has fostered a substantial interest in predicting clinical outcomes and categorizing individuals based on brain networks. However, the conventional approach involving static brain network analysis offers limited potential in capturing the dynamism of brain function. Although recent studies have attempted to harness dynamic brain networks, their high dimensionality and complexity present substantial challenges. This paper proposes a novel methodology, Dynamic bRAin Transformer (DART), which combines static and dynamic brain networks for more effective and nuanced brain function analysis. Our model uses the static brain network as a baseline, integrating dynamic brain networks to enhance performance against traditional methods. We innovatively employ attention mechanisms, enhancing model explainability and exploiting the dynamic brain network's temporal variations. The proposed approach offers a robust solution to the low signal-to-noise ratio of blood-oxygen-level-dependent signals, a recurring issue in direct DNN modeling. It also provides valuable insights into which brain circuits or dynamic networks contribute more to final predictions. As such, DRAT shows a promising direction in neuroimaging studies, contributing to the comprehensive understanding of brain organization and the role of neural circuits.         _ Less;Health relatedGeometry-aware Line Graph Transformer Pre-training for Molecular Property Prediction;Molecular property prediction with deep learning has gained much attention over the past years. Owing to the scarcity of labeled molecules, there has been growing interest in self-supervised learning methods that learn generalizable molecular representations from unlabeled data. Molecules are typically treated as 2D topological graphs in modeling, but it has been discovered that their 3D geometry…         _ More           Molecular property prediction with deep learning has gained much attention over the past years. Owing to the scarcity of labeled molecules, there has been growing interest in self-supervised learning methods that learn generalizable molecular representations from unlabeled data. Molecules are typically treated as 2D topological graphs in modeling, but it has been discovered that their 3D geometry is of great importance in determining molecular functionalities. In this paper, we propose the Geometry-aware line graph transformer (Galformer) pre-training, a novel self-supervised learning framework that aims to enhance molecular representation learning with 2D and 3D modalities. Specifically, we first design a dual-modality line graph transformer backbone to encode the topological and geometric information of a molecule. The designed backbone incorporates effective structural encodings to capture graph structures from both modalities. Then we devise two complementary pre-training tasks at the inter and intra-modality levels. These tasks provide properly supervised information and extract discriminative 2D and 3D knowledge from unlabeled molecules. Finally, we evaluate Galformer against six state-of-the-art baselines on twelve property prediction benchmarks via downstream fine-tuning. Experimental results show that Galformer consistently outperforms all baselines on both classification and regression tasks, demonstrating its effectiveness.         _ Less;Health relatedXVir: A Transformer-Based Architecture for Identifying Viral Reads from Cancer Samples;It is estimated that approximately 15% of cancers worldwide can be linked to viral infections. The viruses that can cause or increase the risk of cancer include human papillomavirus, hepatitis B and C viruses, Epstein-Barr virus, and human immunodeficiency virus, to name a few. The computational analysis of the massive amounts of tumor DNA data, whose collection is enabled by the recent advancemen…         _ More           It is estimated that approximately 15% of cancers worldwide can be linked to viral infections. The viruses that can cause or increase the risk of cancer include human papillomavirus, hepatitis B and C viruses, Epstein-Barr virus, and human immunodeficiency virus, to name a few. The computational analysis of the massive amounts of tumor DNA data, whose collection is enabled by the recent advancements in sequencing technologies, have allowed studies of the potential association between cancers and viral pathogens. However, the high diversity of oncoviral families makes reliable detection of viral DNA difficult and thus, renders such analysis challenging. In this paper, we introduce XVir, a data pipeline that relies on a transformer-based deep learning architecture to reliably identify viral DNA present in human tumors. In particular, XVir is trained on genomic sequencing reads from viral and human genomes and may be used with tumor sequence information to find evidence of viral DNA in human cancers. Results on semi-experimental data demonstrate that XVir is capable of achieving high detection accuracy, generally outperforming state-of-the-art competing methods while being more compact and less computationally demanding.         _ Less;Health relatedRobust Core-Periphery Constrained Transformer for Domain Adaptation;Unsupervised domain adaptation (UDA) aims to learn transferable representation across domains. Recently a few UDA works have successfully applied Transformer-based methods and achieved state-of-the-art (SOTA) results. However, it remains challenging when there exists a large domain gap between the source and target domain. Inspired by humans' exceptional transferability abilities to adapt knowledg…         _ More           Unsupervised domain adaptation (UDA) aims to learn transferable representation across domains. Recently a few UDA works have successfully applied Transformer-based methods and achieved state-of-the-art (SOTA) results. However, it remains challenging when there exists a large domain gap between the source and target domain. Inspired by humans' exceptional transferability abilities to adapt knowledge from familiar to uncharted domains, we try to apply the universally existing organizational structure in the human functional brain networks, i.e., the core-periphery principle to design the Transformer and improve its UDA performance. In this paper, we propose a novel brain-inspired robust core-periphery constrained transformer (RCCT) for unsupervised domain adaptation, which brings a large margin of performance improvement on various datasets. Specifically, in RCCT, the self-attention operation across image patches is rescheduled by an adaptively learned weighted graph with the Core-Periphery structure (CP graph), where the information communication and exchange between images patches are manipulated and controlled by the connection strength, i.e., edge weight of the learned weighted CP graph. Besides, since the data in domain adaptation tasks can be noisy, to improve the model robustness, we intentionally add perturbations to the patches in the latent space to ensure generating robust learned weighted core-periphery graphs. Extensive evaluations are conducted on several widely tested UDA benchmarks. Our proposed RCCT consistently performs best compared to existing works, including 88.3\% on Office-Home, 95.0\% on Office-31, 90.7\% on VisDA-2017, and 46.0\% on DomainNet.         _ Less;Health relatedDeepContrast: Deep Tissue Contrast Enhancement using Synthetic Data Degradations and OOD Model Predictions;              Microscopy images are crucial for life science research, allowing detailed inspection and characterization of cellular and tissue-level structures and functions. However, microscopy data are unavoidably affected by image degradations, such as noise, blur, or others. Many such degradations also contribute to a loss of image contrast, which becomes especially pronounced in deeper regions of thick sa…         _ More           Microscopy images are crucial for life science research, allowing detailed inspection and characterization of cellular and tissue-level structures and functions. However, microscopy data are unavoidably affected by image degradations, such as noise, blur, or others. Many such degradations also contribute to a loss of image contrast, which becomes especially pronounced in deeper regions of thick samples. Today, best performing methods to increase the quality of images are based on Deep Learning approaches, which typically require ground truth (GT) data during training. Our inability to counteract blurring and contrast loss when imaging deep into samples prevents the acquisition of such clean GT data. The fact that the forward process of blurring and contrast loss deep into tissue can be modeled, allowed us to propose a new method that can circumvent the problem of unobtainable GT data. To this end, we first synthetically degraded the quality of microscopy images even further by using an approximate forward model for deep tissue image degradations. Then we trained a neural network that learned the inverse of this degradation function from our generated pairs of raw and degraded images. We demonstrated that networks trained in this way can be used out-of-distribution (OOD) to improve the quality of less severely degraded images, e.g. the raw data imaged in a microscope. Since the absolute level of degradation in such microscopy images can be stronger than the additional degradation introduced by our forward model, we also explored the effect of iterative predictions. Here, we observed that in each iteration the measured image contrast kept improving while detailed structures in the images got increasingly removed. Therefore, dependent on the desired downstream analysis, a balance between contrast improvement and retention of image details has to be found.         _ Less;Health relatedKey Gene Mining in Transcriptional Regulation for Specific Biological Processes with Small Sample Sizes Using Multi-network pipeline Transformer;Gene mining is an important topic in the field of life sciences, but traditional machine learning methods cannot consider the regulatory relationships between genes. Deep learning methods perform poorly in small sample sizes. This study proposed a deep learning method, called TransGeneSelector, that can mine critical regulatory genes involved in certain life processes using a small-sample transcri…         _ More           Gene mining is an important topic in the field of life sciences, but traditional machine learning methods cannot consider the regulatory relationships between genes. Deep learning methods perform poorly in small sample sizes. This study proposed a deep learning method, called TransGeneSelector, that can mine critical regulatory genes involved in certain life processes using a small-sample transcriptome dataset. The method combines a WGAN-GP data augmentation network, a sample filtering network, and a Transformer classifier network, which successfully classified the state (germinating or dry seeds) of Arabidopsis thaliana seed in a dataset of 79 samples, showing performance comparable to that of Random Forests. Further, through the use of SHapley Additive exPlanations method, TransGeneSelector successfully mined genes involved in seed germination. Through the construction of gene regulatory networks and the enrichment analysis of KEGG, as well as RT-qPCR quantitative analysis, it was confirmed that these genes are at a more upstream regulatory level than those Random Forests mined, and the top 11 genes that were uniquely mined by TransGeneSelector were found to be related to the KAI2 signaling pathway, which is of great regulatory importance for germination-related genes. This study provides a practical tool for life science researchers to mine key genes from transcriptome data.         _ Less;Health relatedA vision transformer-based framework for knowledge transfer from multi-modal to mono-modal lymphoma subtyping models;Determining lymphoma subtypes is a crucial step for better patients treatment targeting to potentially increase their survival chances. In this context, the existing gold standard diagnosis method, which is based on gene expression technology, is highly expensive and time-consuming making difficult its accessibility. Although alternative diagnosis methods based on IHC (immunohistochemistry) techno…         _ More           Determining lymphoma subtypes is a crucial step for better patients treatment targeting to potentially increase their survival chances. In this context, the existing gold standard diagnosis method, which is based on gene expression technology, is highly expensive and time-consuming making difficult its accessibility. Although alternative diagnosis methods based on IHC (immunohistochemistry) technologies exist (recommended by the WHO), they still suffer from similar limitations and are less accurate. WSI (Whole Slide Image) analysis by deep learning models showed promising new directions for cancer diagnosis that would be cheaper and faster than existing alternative methods. In this work, we propose a vision transformer-based framework for distinguishing DLBCL (Diffuse Large B-Cell Lymphoma) cancer subtypes from high-resolution WSIs. To this end, we propose a multi-modal architecture to train a classifier model from various WSI modalities. We then exploit this model through a knowledge distillation mechanism for efficiently driving the learning of a mono-modal classifier. Our experimental study conducted on a dataset of 157 patients shows the promising performance of our mono-modal classification model, outperforming six recent methods from the state-of-the-art dedicated for cancer classification. Moreover, the power-law curve, estimated on our experimental data, suggest that with more training data from a reasonable number of additional patients, our model has the potential to achieve diagnostic accuracy comparable to that of IHC technologies.         _ Less;Health relatedExplainable Techniques for Analyzing Flow Cytometry Cell Transformers;              Explainability for Deep Learning Models is especially important for clinical applications, where decisions of automated systems have far-reaching consequences.   While various post-hoc explainable methods, such as attention visualization and saliency maps, already exist for common data modalities, including natural language and images, little work has been done to adapt them to the modality of Flo…         _ More           Explainability for Deep Learning Models is especially important for clinical applications, where decisions of automated systems have far-reaching consequences.   While various post-hoc explainable methods, such as attention visualization and saliency maps, already exist for common data modalities, including natural language and images, little work has been done to adapt them to the modality of Flow CytoMetry (FCM) data.   In this work, we evaluate the usage of a transformer architecture called ReluFormer that ease attention visualization as well as we propose a gradient- and an attention-based visualization technique tailored for FCM. We qualitatively evaluate the visualization techniques for cell classification and polygon regression on pediatric Acute Lymphoblastic Leukemia (ALL) FCM samples. The results outline the model's decision process and demonstrate how to utilize the proposed techniques to inspect the trained model. The gradient-based visualization not only identifies cells that are most significant for a particular prediction but also indicates the directions in the FCM feature space in which changes have the most impact on the prediction. The attention visualization provides insights on the transformer's decision process when handling FCM data. We show that different attention heads specialize by attending to different biologically meaningful sub-populations in the data, even though the model retrieved solely supervised binary classification signals during training.         _ Less;Health relatedProt2Text: Multimodal Protein's Function Generation with GNNs and Transformers;The complex nature of big biological systems pushed some scientists to classify its understanding under the inconceivable missions. Different leveled challenges complicated this task, one of is the prediction of a protein's function. In recent years, significant progress has been made in this field through the development of various machine learning approaches. However, most existing methods formu…         _ More           The complex nature of big biological systems pushed some scientists to classify its understanding under the inconceivable missions. Different leveled challenges complicated this task, one of is the prediction of a protein's function. In recent years, significant progress has been made in this field through the development of various machine learning approaches. However, most existing methods formulate the task as a multi-classification problem, i.e assigning predefined labels to proteins. In this work, we propose a novel approach, \textbf{Prot2Text}, which predicts a protein function's in a free text style, moving beyond the conventional binary or categorical classifications. By combining Graph Neural Networks(GNNs) and Large Language Models(LLMs), in an encoder-decoder framework, our model effectively integrates diverse data types including proteins' sequences, structures, and textual annotations. This multimodal approach allows for a holistic representation of proteins' functions, enabling the generation of detailed and accurate descriptions. To evaluate our model, we extracted a multimodal protein dataset from SwissProt, and demonstrate empirically the effectiveness of Prot2Text. These results highlight the transformative impact of multimodal models, specifically the fusion of GNNs and LLMs, empowering researchers with powerful tools for more accurate prediction of proteins' functions. The code, the models and a demo will be publicly released.         _ Less;Health relatedCommunity-Aware Transformer for Autism Prediction in fMRI Connectome;              Autism spectrum disorder(ASD) is a lifelong neurodevelopmental condition that affects social communication and behavior. Investigating functional magnetic resonance imaging (fMRI)-based brain functional connectome can aid in the understanding and diagnosis of ASD, leading to more effective treatments. The brain is modeled as a network of brain Regions of Interest (ROIs), and ROIs form communities…         _ More           Autism spectrum disorder(ASD) is a lifelong neurodevelopmental condition that affects social communication and behavior. Investigating functional magnetic resonance imaging (fMRI)-based brain functional connectome can aid in the understanding and diagnosis of ASD, leading to more effective treatments. The brain is modeled as a network of brain Regions of Interest (ROIs), and ROIs form communities and knowledge of these communities is crucial for ASD diagnosis. On the one hand, Transformer-based models have proven to be highly effective across several tasks, including fMRI connectome analysis to learn useful representations of ROIs. On the other hand, existing transformer-based models treat all ROIs equally and overlook the impact of community-specific associations when learning node embeddings. To fill this gap, we propose a novel method, Com-BrainTF, a hierarchical local-global transformer architecture that learns intra and inter-community aware node embeddings for ASD prediction task. Furthermore, we avoid over-parameterization by sharing the local transformer parameters for different communities but optimize unique learnable prompt tokens for each community. Our model outperforms state-of-the-art (SOTA) architecture on ABIDE dataset and has high interpretability, evident from the attention module. Our code is available at https://github.com/ubc-tea/Com-BrainTF.         _ Less;Health relatedPerturbing a Neural Network to Infer Effective Connectivity: Evidence from Synthetic EEG Data;Identifying causal relationships among distinct brain areas, known as effective connectivity, holds key insights into the brain's information processing and cognitive functions. Electroencephalogram (EEG) signals exhibit intricate dynamics and inter-areal interactions within the brain. However, methods for characterizing nonlinear causal interactions among multiple brain regions remain relatively…         _ More           Identifying causal relationships among distinct brain areas, known as effective connectivity, holds key insights into the brain's information processing and cognitive functions. Electroencephalogram (EEG) signals exhibit intricate dynamics and inter-areal interactions within the brain. However, methods for characterizing nonlinear causal interactions among multiple brain regions remain relatively underdeveloped. In this study, we proposed a data-driven framework to infer effective connectivity by perturbing the trained neural networks. Specifically, we trained neural networks (i.e., CNN, vanilla RNN, GRU, LSTM, and Transformer) to predict future EEG signals according to historical data and perturbed the networks' input to obtain effective connectivity (EC) between the perturbed EEG channel and the rest of the channels. The EC reflects the causal impact of perturbing one node on others. The performance was tested on the synthetic EEG generated by a biological-plausible Jansen-Rit model. CNN and Transformer obtained the best performance on both 3-channel and 90-channel synthetic EEG data, outperforming the classical Granger causality method. Our work demonstrated the potential of perturbing an artificial neural network, learned to predict future system dynamics, to uncover the underlying causal structure.         _ Less;Health relatedA Study on the Performance of Generative Pre-trained Transformer (GPT) in Simulating Depressed Individuals on the Standardized Depressive Symptom Scale;Background: Depression is a common mental disorder with societal and economic burden. Current diagnosis relies on self-reports and assessment scales, which have reliability issues. Objective approaches are needed for diagnosing depression. Objective: Evaluate the potential of GPT technology in diagnosing depression. Assess its ability to simulate individuals with depression and investigate the inf…         _ More           Background: Depression is a common mental disorder with societal and economic burden. Current diagnosis relies on self-reports and assessment scales, which have reliability issues. Objective approaches are needed for diagnosing depression. Objective: Evaluate the potential of GPT technology in diagnosing depression. Assess its ability to simulate individuals with depression and investigate the influence of depression scales. Methods: Three depression-related assessment tools (HAMD-17, SDS, GDS-15) were used. Two experiments simulated GPT responses to normal individuals and individuals with depression. Compare GPT's responses with expected results, assess its understanding of depressive symptoms, and performance differences under different conditions. Results: GPT's performance in depression assessment was evaluated. It aligned with scoring criteria for both individuals with depression and normal individuals. Some performance differences were observed based on depression severity. GPT performed better on scales with higher sensitivity. Conclusion: GPT accurately simulates individuals with depression and normal individuals during depression-related assessments. Deviations occur when simulating different degrees of depression, limiting understanding of mild and moderate cases. GPT performs better on scales with higher sensitivity, indicating potential for developing more effective depression scales. GPT has important potential in depression assessment, supporting clinicians and patients.         _ Less;Health relatedA Fully Automated and Explainable Algorithm for the Prediction of Malignant Transformation in Oral Epithelial Dysplasia;"Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis given to lesions of the oral cavity. Its grading suffers from significant inter-/intra- observer variability, and does not reliably predict malignancy progression, potentially leading to suboptimal treatment decisions. To address this, we developed a novel artificial intelligence algorithm that can assign an Oral Maligna…         _ More           Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis given to lesions of the oral cavity. Its grading suffers from significant inter-/intra- observer variability, and does not reliably predict malignancy progression, potentially leading to suboptimal treatment decisions. To address this, we developed a novel artificial intelligence algorithm that can assign an Oral Malignant Transformation (OMT) risk score, based on histological patterns in the in Haematoxylin and Eosin stained whole slide images, to quantify the risk of OED progression. The algorithm is based on the detection and segmentation of nuclei within (and around) the epithelium using an in-house segmentation model. We then employed a shallow neural network fed with interpretable morphological/spatial features, emulating histological markers. We conducted internal cross-validation on our development cohort (Sheffield; n = 193 cases) followed by independent validation on two external cohorts (Birmingham and Belfast; n = 92 cases). The proposed OMTscore yields an AUROC = 0.74 in predicting whether an OED progresses to malignancy or not. Survival analyses showed the prognostic value of our OMTscore for predicting malignancy transformation, when compared to the manually-assigned WHO and binary grades. Analysis of the correctly predicted cases elucidated the presence of peri-epithelial and epithelium-infiltrating lymphocytes in the most predictive patches of cases that transformed (p < 0.0001). This is the first study to propose a completely automated algorithm for predicting OED transformation based on interpretable nuclear features, whilst being validated on external datasets. The algorithm shows better-than-human-level performance for prediction of OED malignant transformation and offers a promising solution to the challenges of grading OED in routine clinical practice.         _ Less";Health relatedBeyond the Snapshot: Brain Tokenized Graph Transformer for Longitudinal Brain Functional Connectome Embedding;"Under the framework of network-based neurodegeneration, brain functional connectome (FC)-based Graph Neural Networks (GNN) have emerged as a valuable tool for the diagnosis and prognosis of neurodegenerative diseases such as Alzheimer's disease (AD). However, these models are tailored for brain FC at a single time point instead of characterizing FC trajectory. Discerning how FC evolves with diseas…         _ More           Under the framework of network-based neurodegeneration, brain functional connectome (FC)-based Graph Neural Networks (GNN) have emerged as a valuable tool for the diagnosis and prognosis of neurodegenerative diseases such as Alzheimer's disease (AD). However, these models are tailored for brain FC at a single time point instead of characterizing FC trajectory. Discerning how FC evolves with disease progression, particularly at the predementia stages such as cognitively normal individuals with amyloid deposition or individuals with mild cognitive impairment (MCI), is crucial for delineating disease spreading patterns and developing effective strategies to slow down or even halt disease advancement. In this work, we proposed the first interpretable framework for brain FC trajectory embedding with application to neurodegenerative disease diagnosis and prognosis, namely Brain Tokenized Graph Transformer (Brain TokenGT). It consists of two modules: 1) Graph Invariant and Variant Embedding (GIVE) for generation of node and spatio-temporal edge embeddings, which were tokenized for downstream processing; 2) Brain Informed Graph Transformer Readout (BIGTR) which augments previous tokens with trainable type identifiers and non-trainable node identifiers and feeds them into a standard transformer encoder to readout. We conducted extensive experiments on two public longitudinal fMRI datasets of the AD continuum for three tasks, including differentiating MCI from controls, predicting dementia conversion in MCI, and classification of amyloid positive or negative cognitively normal individuals. Based on brain FC trajectory, the proposed Brain TokenGT approach outperformed all the other benchmark models and at the same time provided excellent interpretability. The code is available at https://github.com/ZijianD/Brain-TokenGT.git         _ Less";Health relatedMedCPT: Contrastive Pre-trained Transformers with Large-scale PubMed Search Logs for Zero-shot Biomedical Information Retrieval;Information retrieval (IR) is essential in biomedical knowledge acquisition and clinical decision support. While recent progress has shown that language model encoders perform better semantic retrieval, training such models requires abundant query-article annotations that are difficult to obtain in biomedicine. As a result, most biomedical IR systems only conduct lexical matching. In response, we…         _ More           Information retrieval (IR) is essential in biomedical knowledge acquisition and clinical decision support. While recent progress has shown that language model encoders perform better semantic retrieval, training such models requires abundant query-article annotations that are difficult to obtain in biomedicine. As a result, most biomedical IR systems only conduct lexical matching. In response, we introduce MedCPT, a first-of-its-kind Contrastively Pre-trained Transformer model for zero-shot semantic IR in biomedicine. To train MedCPT, we collected an unprecedented scale of 255 million user click logs from PubMed. With such data, we use contrastive learning to train a pair of closely-integrated retriever and re-ranker. Experimental results show that MedCPT sets new state-of-the-art performance on six biomedical IR tasks, outperforming various baselines including much larger models such as GPT-3-sized cpt-text-XL. In addition, MedCPT also generates better biomedical article and sentence representations for semantic evaluations. As such, MedCPT can be readily applied to various real-world biomedical IR tasks.         _ Less;Health relatedReconstructing the Hemodynamic Response Function via a Bimodal Transformer;              The relationship between blood flow and neuronal activity is widely recognized, with blood flow frequently serving as a surrogate for neuronal activity in fMRI studies. At the microscopic level, neuronal activity has been shown to influence blood flow in nearby blood vessels. This study introduces the first predictive model that addresses this issue directly at the explicit neuronal population lev…         _ More           The relationship between blood flow and neuronal activity is widely recognized, with blood flow frequently serving as a surrogate for neuronal activity in fMRI studies. At the microscopic level, neuronal activity has been shown to influence blood flow in nearby blood vessels. This study introduces the first predictive model that addresses this issue directly at the explicit neuronal population level. Using in vivo recordings in awake mice, we employ a novel spatiotemporal bimodal transformer architecture to infer current blood flow based on both historical blood flow and ongoing spontaneous neuronal activity. Our findings indicate that incorporating neuronal activity significantly enhances the model's ability to predict blood flow values. Through analysis of the model's behavior, we propose hypotheses regarding the largely unexplored nature of the hemodynamic response to neuronal activity.         _ Less;Health relatedMQ-Coder inspired arithmetic coder for synthetic DNA data storage;"Over the past years, the ever-growing trend on data storage demand, more specifically for ""cold"" data (i.e. rarely accessed), has motivated research for alternative systems of data storage. Because of its biochemical characteristics, synthetic DNA molecules are now considered as serious candidates for this new kind of storage. This paper introduces a novel arithmetic coder for DNA data storage, an…         _ More           Over the past years, the ever-growing trend on data storage demand, more specifically for ""cold"" data (i.e. rarely accessed), has motivated research for alternative systems of data storage. Because of its biochemical characteristics, synthetic DNA molecules are now considered as serious candidates for this new kind of storage. This paper introduces a novel arithmetic coder for DNA data storage, and presents some results on a lossy JPEG 2000 based image compression method adapted for DNA data storage that uses this novel coder.   The DNA coding algorithms presented here have been designed to efficiently compress images, encode them into a quaternary code, and finally store them into synthetic DNA molecules. This work also aims at making the compression models better fit the problematic that we encounter when storing data into DNA, namely the fact that the DNA writing, storing and reading methods are error prone processes.   The main take away of this work is our arithmetic coder and it's integration into a performant image codec.         _ Less";Health relatedParameter-efficient Dysarthric Speech Recognition Using Adapter Fusion and Householder Transformation;              In dysarthric speech recognition, data scarcity and the vast diversity between dysarthric speakers pose significant challenges. While finetuning has been a popular solution, it can lead to overfitting and low parameter efficiency. Adapter modules offer a better solution, with their small size and easy applicability. Additionally, Adapter Fusion can facilitate knowledge transfer from multiple learn…         _ More           In dysarthric speech recognition, data scarcity and the vast diversity between dysarthric speakers pose significant challenges. While finetuning has been a popular solution, it can lead to overfitting and low parameter efficiency. Adapter modules offer a better solution, with their small size and easy applicability. Additionally, Adapter Fusion can facilitate knowledge transfer from multiple learned adapters, but may employ more parameters. In this work, we apply Adapter Fusion for target speaker adaptation and speech recognition, achieving acceptable accuracy with significantly fewer speaker-specific trainable parameters than classical finetuning methods. We further improve the parameter efficiency of the fusion layer by reducing the size of query and key layers and using Householder transformation to reparameterize the value linear layer. Our proposed fusion layer achieves comparable recognition results to the original method with only one third of the parameters.         _ Less;Health relatedGenomic Interpreter: A Hierarchical Genomic Deep Neural Network with 1D Shifted Window Transformer;Given the increasing volume and quality of genomics data, extracting new insights requires interpretable machine-learning models. This work presents Genomic Interpreter: a novel architecture for genomic assay prediction. This model outperforms the state-of-the-art models for genomic assay prediction tasks. Our model can identify hierarchical dependencies in genomic sites. This is achieved through…         _ More           Given the increasing volume and quality of genomics data, extracting new insights requires interpretable machine-learning models. This work presents Genomic Interpreter: a novel architecture for genomic assay prediction. This model outperforms the state-of-the-art models for genomic assay prediction tasks. Our model can identify hierarchical dependencies in genomic sites. This is achieved through the integration of 1D-Swin, a novel Transformer-based block designed by us for modelling long-range hierarchical data. Evaluated on a dataset containing 38,171 DNA segments of 17K base pairs, Genomic Interpreter demonstrates superior performance in chromatin accessibility and gene expression prediction and unmasks the underlying `syntax' of gene regulation.         _ Less;Health relatedGeneralist Equivariant Transformer Towards 3D Molecular Interaction Learning;Many processes in biology and drug discovery involve various 3D interactions between molecules, such as protein and protein, protein and small molecule, etc. Given that different molecules are usually represented in different granularity, existing methods usually encode each type of molecules independently with different models, leaving it defective to learn the universal underlying interaction ph…         _ More           Many processes in biology and drug discovery involve various 3D interactions between molecules, such as protein and protein, protein and small molecule, etc. Given that different molecules are usually represented in different granularity, existing methods usually encode each type of molecules independently with different models, leaving it defective to learn the universal underlying interaction physics. In this paper, we first propose to universally represent an arbitrary 3D complex as a geometric graph of sets, shedding light on encoding all types of molecules with one model. We then propose a Generalist Equivariant Transformer (GET) to effectively capture both domain-specific hierarchies and domain-agnostic interaction physics. To be specific, GET consists of a bilevel attention module, a feed-forward module and a layer normalization module, where each module is E(3) equivariant and specialized for handling sets of variable sizes. Notably, in contrast to conventional pooling-based hierarchical models, our GET is able to retain fine-grained information of all levels. Extensive experiments on the interactions between proteins, small molecules and RNA/DNAs verify the effectiveness and generalization capability of our proposed method across different domains.         _ Less;Health relatedAffinity-based Attention in Self-supervised Transformers Predicts Dynamics of Object Grouping in Humans;              The spreading of attention has been proposed as a mechanism for how humans group features to segment objects. However, such a mechanism has not yet been implemented and tested in naturalistic images. Here, we leverage the feature maps from self-supervised vision Transformers and propose a model of human object-based attention spreading and segmentation. Attention spreads within an object through t…         _ More           The spreading of attention has been proposed as a mechanism for how humans group features to segment objects. However, such a mechanism has not yet been implemented and tested in naturalistic images. Here, we leverage the feature maps from self-supervised vision Transformers and propose a model of human object-based attention spreading and segmentation. Attention spreads within an object through the feature affinity signal between different patches of the image. We also collected behavioral data on people grouping objects in natural images by judging whether two dots are on the same object or on two different objects. We found that our models of affinity spread that were built on feature maps from the self-supervised Transformers showed significant improvement over baseline and CNN based models on predicting reaction time patterns of humans, despite not being trained on the task or with any other object labels. Our work provides new benchmarks for evaluating models of visual representation learning including Transformers.         _ Less;Health relatedOn the role of eigenvalue disparity and coordinate transformations in the reduction of the linear noise approximation;              Eigenvalue disparity, also known as timescale separation, permits the systematic reduction of deterministic models of enzyme kinetics. Geometric singular perturbation theory, of which eigenvalue disparity is central, provides a coordinate-free framework for deriving reduced mass action models in the deterministic realm. Moreover, homologous deterministic reductions are often employed in stochastic…         _ More           Eigenvalue disparity, also known as timescale separation, permits the systematic reduction of deterministic models of enzyme kinetics. Geometric singular perturbation theory, of which eigenvalue disparity is central, provides a coordinate-free framework for deriving reduced mass action models in the deterministic realm. Moreover, homologous deterministic reductions are often employed in stochastic models to reduce the computational complexity required to simulate reactions with the Gillespie algorithm. Interestingly, several detailed studies indicate that timescale separation does not always guarantee the accuracy of reduced stochastic models. In this work, we examine the roles of timescale separation and coordinate transformations in the reduction of the Linear Noise Approximation (LNA) and, unlike previous studies, we do not require the system to be comprised of distinct fast and slow variables. Instead, we adopt a coordinate-free approach. We demonstrate that eigenvalue disparity does not guarantee the accuracy of the reduced LNA, known as the slow scale LNA (ssLNA). However, the inaccuracy of the ssLNA can often be eliminated with a proper coordinate transformation. For planar systems in separated (standard) form, we prove that the error between the variances of the slow variable generated by the LNA and the ssLNA is $\mathcal{O}(\varepsilon)$. We also address a nilpotent Jacobian scenario and use the blow-up method to construct a reduced equation that is accurate near the singular limit in the deterministic regime. However, this reduction in the stochastic regime is far less accurate, which illustrates that eigenvalue disparity plays a central role in stochastic model reduction.         _ Less;Health relatedVaxformer: Antigenicity-controlled Transformer for Vaccine Design Against SARS-CoV-2;The SARS-CoV-2 pandemic has emphasised the importance of developing a universal vaccine that can protect against current and future variants of the virus. The present study proposes a novel conditional protein Language Model architecture, called Vaxformer, which is designed to produce natural-looking antigenicity-controlled SARS-CoV-2 spike proteins. We evaluate the generated protein sequences of…         _ More           The SARS-CoV-2 pandemic has emphasised the importance of developing a universal vaccine that can protect against current and future variants of the virus. The present study proposes a novel conditional protein Language Model architecture, called Vaxformer, which is designed to produce natural-looking antigenicity-controlled SARS-CoV-2 spike proteins. We evaluate the generated protein sequences of the Vaxformer model using DDGun protein stability measure, netMHCpan antigenicity score, and a structure fidelity score with AlphaFold to gauge its viability for vaccine development. Our results show that Vaxformer outperforms the existing state-of-the-art Conditional Variational Autoencoder model to generate antigenicity-controlled SARS-CoV-2 spike proteins. These findings suggest promising opportunities for conditional Transformer models to expand our understanding of vaccine design and their role in mitigating global health challenges. The code used in this study is available at https://github.com/aryopg/vaxformer .         _ Less;Health relatedGenerative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins;We report a flexible language-model based deep learning strategy, applied here to solve complex forward and inverse problems in protein modeling, based on an attention neural network that integrates transformer and graph convolutional architectures in a causal multi-headed graph mechanism, to realize a generative pretrained model. The model is applied to predict secondary structure content (per-re…         _ More           We report a flexible language-model based deep learning strategy, applied here to solve complex forward and inverse problems in protein modeling, based on an attention neural network that integrates transformer and graph convolutional architectures in a causal multi-headed graph mechanism, to realize a generative pretrained model. The model is applied to predict secondary structure content (per-residue level and overall content), protein solubility, and sequencing tasks. Further trained on inverse tasks, the model is rendered capable of designing proteins with these properties as target features. The model is formulated as a general framework, completely prompt-based, and can be adapted for a variety of downstream tasks. We find that adding additional tasks yields emergent synergies that the model exploits in improving overall performance, beyond what would be possible by training a model on each dataset alone. Case studies are presented to validate the method, yielding protein designs specifically focused on structural proteins, but also exploring the applicability in the design of soluble, antimicrobial biomaterials. While our model is trained to ultimately perform 8 distinct tasks, with available datasets it can be extended to solve additional problems. In a broader sense, this work illustrates a form of multiscale modeling that relates a set of ultimate building blocks (here, byte-level utf8 characters that define the nature of the physical system at hand) to complex output. This materiomic scheme captures complex emergent relationships between universal building block and resulting properties via a synergizing learning capacity to express a set of potentialities embedded in the knowledge used in training, via the interplay of universality and diversity.         _ Less;Health relatedTransformer-Based Hierarchical Clustering for Brain Network Analysis;Brain networks, graphical models such as those constructed from MRI, have been widely used in pathological prediction and analysis of brain functions. Within the complex brain system, differences in neuronal connection strengths parcellate the brain into various functional modules (network communities), which are critical for brain analysis. However, identifying such communities within the brain h…         _ More           Brain networks, graphical models such as those constructed from MRI, have been widely used in pathological prediction and analysis of brain functions. Within the complex brain system, differences in neuronal connection strengths parcellate the brain into various functional modules (network communities), which are critical for brain analysis. However, identifying such communities within the brain has been a nontrivial issue due to the complexity of neuronal interactions. In this work, we propose a novel interpretable transformer-based model for joint hierarchical cluster identification and brain network classification. Extensive experimental results on real-world brain network datasets show that with the help of hierarchical clustering, the model achieves increased accuracy and reduced runtime complexity while providing plausible insight into the functional organization of brain regions. The implementation is available at https://github.com/DDVD233/THC.         _ Less;Health relatedG-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar Tree Transformer;Various template-based and template-free approaches have been proposed for single-step retrosynthesis prediction in recent years. While these approaches demonstrate strong performance from a data-driven metrics standpoint, many model architectures do not incorporate underlying chemistry principles. Here, we propose a novel chemistry-aware retrosynthesis prediction framework that combines powerful…         _ More           Various template-based and template-free approaches have been proposed for single-step retrosynthesis prediction in recent years. While these approaches demonstrate strong performance from a data-driven metrics standpoint, many model architectures do not incorporate underlying chemistry principles. Here, we propose a novel chemistry-aware retrosynthesis prediction framework that combines powerful data-driven models with prior domain knowledge. We present a tree-to-sequence transformer architecture that utilizes hierarchical SMILES grammar-based trees, incorporating crucial chemistry information that is often overlooked by SMILES text-based representations, such as local structures and functional groups. The proposed framework, grammar-based molecular attention tree transformer (G-MATT), achieves significant performance improvements compared to baseline retrosynthesis models. G-MATT achieves a promising top-1 accuracy of 51% (top-10 accuracy of 79.1%), invalid rate of 1.5%, and bioactive similarity rate of 74.8% on the USPTO- 50K dataset. Additional analyses of G-MATT attention maps demonstrate the ability to retain chemistry knowledge without relying on excessively complex model architectures.         _ Less;Health relatedBrainNPT: Pre-training of Transformer networks for brain network classification;Deep learning methods have advanced quickly in brain imaging analysis over the past few years, but they are usually restricted by the limited labeled data. Pre-trained model on unlabeled data has presented promising improvement in feature learning in many domains, including natural language processing and computer vision. However, this technique is under-explored in brain network analysis. In this…         _ More           Deep learning methods have advanced quickly in brain imaging analysis over the past few years, but they are usually restricted by the limited labeled data. Pre-trained model on unlabeled data has presented promising improvement in feature learning in many domains, including natural language processing and computer vision. However, this technique is under-explored in brain network analysis. In this paper, we focused on pre-training methods with Transformer networks to leverage existing unlabeled data for brain functional network classification. First, we proposed a Transformer-based neural network, named as BrainNPT, for brain functional network classification. The proposed method leveraged <cls> token as a classification embedding vector for the Transformer model to effectively capture the representation of brain network. Second, we proposed a pre-training framework for BrainNPT model to leverage unlabeled brain network data to learn the structure information of brain networks. The results of classification experiments demonstrated the BrainNPT model without pre-training achieved the best performance with the state-of-the-art models, and the BrainNPT model with pre-training strongly outperformed the state-of-the-art models. The pre-training BrainNPT model improved 8.75% of accuracy compared with the model without pre-training. We further compared the pre-training strategies, analyzed the influence of the parameters of the model, and interpreted the trained model.         _ Less;Health relatedUNADON: Transformer-based model to predict genome-wide chromosome spatial position;The spatial positioning of chromosomes relative to functional nuclear bodies is intertwined with genome functions such as transcription. However, the sequence patterns and epigenomic features that collectively influence chromatin spatial positioning in a genome-wide manner are not well understood. Here, we develop a new transformer-based deep learning model called UNADON, which predicts the genome…         _ More           The spatial positioning of chromosomes relative to functional nuclear bodies is intertwined with genome functions such as transcription. However, the sequence patterns and epigenomic features that collectively influence chromatin spatial positioning in a genome-wide manner are not well understood. Here, we develop a new transformer-based deep learning model called UNADON, which predicts the genome-wide cytological distance to a specific type of nuclear body, as measured by TSA-seq, using both sequence features and epigenomic signals. Evaluations of UNADON in four cell lines (K562, H1, HFFc6, HCT116) show high accuracy in predicting chromatin spatial positioning to nuclear bodies when trained on a single cell line. UNADON also performed well in an unseen cell type. Importantly, we reveal potential sequence and epigenomic factors that affect large-scale chromatin compartmentalization to nuclear bodies. Together, UNADON provides new insights into the principles between sequence features and large-scale chromatin spatial localization, which has important implications for understanding nuclear structure and function.         _ Less;Health relatedA Multi-Institutional Open-Source Benchmark Dataset for Breast Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data;Recently, a new form of magnetic resonance imaging (MRI) called synthetic correlated diffusion (CDI$^s$) imaging was introduced and showed considerable promise for clinical decision support for cancers such as prostate cancer when compared to current gold-standard MRI techniques. However, the efficacy for CDI$^s$ for other forms of cancers such as breast cancer has not been as well-explored nor ha…         _ More           Recently, a new form of magnetic resonance imaging (MRI) called synthetic correlated diffusion (CDI$^s$) imaging was introduced and showed considerable promise for clinical decision support for cancers such as prostate cancer when compared to current gold-standard MRI techniques. However, the efficacy for CDI$^s$ for other forms of cancers such as breast cancer has not been as well-explored nor have CDI$^s$ data been previously made publicly available. Motivated to advance efforts in the development of computer-aided clinical decision support for breast cancer using CDI$^s$, we introduce Cancer-Net BCa, a multi-institutional open-source benchmark dataset of volumetric CDI$^s$ imaging data of breast cancer patients. Cancer-Net BCa contains CDI$^s$ volumetric images from a pre-treatment cohort of 253 patients across ten institutions, along with detailed annotation metadata (the lesion type, genetic subtype, longest diameter on the MRI (MRLD), the Scarff-Bloom-Richardson (SBR) grade, and the post-treatment breast cancer pathologic complete response (pCR) to neoadjuvant chemotherapy). We further examine the demographic and tumour diversity of the Cancer-Net BCa dataset to gain deeper insights into potential biases. Cancer-Net BCa is publicly available as a part of a global open-source initiative dedicated to accelerating advancement in machine learning to aid clinicians in the fight against cancer.         _ Less;Health relatedLearning Internal Representations of 3D Transformations from 2D Projected Inputs;When interacting in a three dimensional world, humans must estimate 3D structure from visual inputs projected down to two dimensional retinal images. It has been shown that humans use the persistence of object shape over motion-induced transformations as a cue to resolve depth ambiguity when solving this underconstrained problem. With the aim of understanding how biological vision systems may inte…         _ More           When interacting in a three dimensional world, humans must estimate 3D structure from visual inputs projected down to two dimensional retinal images. It has been shown that humans use the persistence of object shape over motion-induced transformations as a cue to resolve depth ambiguity when solving this underconstrained problem. With the aim of understanding how biological vision systems may internally represent 3D transformations, we propose a computational model, based on a generative manifold model, which can be used to infer 3D structure from the motion of 2D points. Our model can also learn representations of the transformations with minimal supervision, providing a proof of concept for how humans may develop internal representations on a developmental or evolutionary time scale. Focused on rotational motion, we show how our model infers depth from moving 2D projected points, learns 3D rotational transformations from 2D training stimuli, and compares to human performance on psychophysical structure-from-motion experiments.         _ Less;Health relatedCore-Periphery Principle Guided Redesign of Self-Attention in Transformers;"Designing more efficient, reliable, and explainable neural network architectures is critical to studies that are based on artificial intelligence (AI) techniques. Previous studies, by post-hoc analysis, have found that the best-performing ANNs surprisingly resemble biological neural networks (BNN), which indicates that ANNs and BNNs may share some common principles to achieve optimal performance i…         _ More           Designing more efficient, reliable, and explainable neural network architectures is critical to studies that are based on artificial intelligence (AI) techniques. Previous studies, by post-hoc analysis, have found that the best-performing ANNs surprisingly resemble biological neural networks (BNN), which indicates that ANNs and BNNs may share some common principles to achieve optimal performance in either machine learning or cognitive/behavior tasks. Inspired by this phenomenon, we proactively instill organizational principles of BNNs to guide the redesign of ANNs. We leverage the Core-Periphery (CP) organization, which is widely found in human brain networks, to guide the information communication mechanism in the self-attention of vision transformer (ViT) and name this novel framework as CP-ViT. In CP-ViT, the attention operation between nodes is defined by a sparse graph with a Core-Periphery structure (CP graph), where the core nodes are redesigned and reorganized to play an integrative role and serve as a center for other periphery nodes to exchange information. We evaluated the proposed CP-ViT on multiple public datasets, including medical image datasets (INbreast) and natural image datasets. Interestingly, by incorporating the BNN-derived principle (CP structure) into the redesign of ViT, our CP-ViT outperforms other state-of-the-art ANNs. In general, our work advances the state of the art in three aspects: 1) This work provides novel insights for brain-inspired AI: we can utilize the principles found in BNNs to guide and improve our ANN architecture design; 2) We show that there exist sweet spots of CP graphs that lead to CP-ViTs with significantly improved performance; and 3) The core nodes in CP-ViT correspond to task-related meaningful and important image patches, which can significantly enhance the interpretability of the trained deep model.         _ Less";Health relatedSynthetic Health-related Longitudinal Data with Mixed-type Variables Generated using Diffusion Models;              This paper presents a novel approach to simulating electronic health records (EHRs) using diffusion probabilistic models (DPMs). Specifically, we demonstrate the effectiveness of DPMs in synthesising longitudinal EHRs that capture mixed-type variables, including numeric, binary, and categorical variables. To our knowledge, this represents the first use of DPMs for this purpose. We compared our DPM…         _ More           This paper presents a novel approach to simulating electronic health records (EHRs) using diffusion probabilistic models (DPMs). Specifically, we demonstrate the effectiveness of DPMs in synthesising longitudinal EHRs that capture mixed-type variables, including numeric, binary, and categorical variables. To our knowledge, this represents the first use of DPMs for this purpose. We compared our DPM-simulated datasets to previous state-of-the-art results based on generative adversarial networks (GANs) for two clinical applications: acute hypotension and human immunodeficiency virus (ART for HIV). Given the lack of similar previous studies in DPMs, a core component of our work involves exploring the advantages and caveats of employing DPMs across a wide range of aspects. In addition to assessing the realism of the synthetic datasets, we also trained reinforcement learning (RL) agents on the synthetic data to evaluate their utility for supporting the development of downstream machine learning models. Finally, we estimated that our DPM-simulated datasets are secure and posed a low patient exposure risk for public access.         _ Less;Health relatedThe Multiscale Surface Vision Transformer;              Surface meshes are a favoured domain for representing structural and functional information on the human cortex, but their complex topology and geometry pose significant challenges for deep learning analysis. While Transformers have excelled as domain-agnostic architectures for sequence-to-sequence learning, notably for structures where the translation of the convolution operation is non-trivial,…         _ More           Surface meshes are a favoured domain for representing structural and functional information on the human cortex, but their complex topology and geometry pose significant challenges for deep learning analysis. While Transformers have excelled as domain-agnostic architectures for sequence-to-sequence learning, notably for structures where the translation of the convolution operation is non-trivial, the quadratic cost of the self-attention operation remains an obstacle for many dense prediction tasks. Inspired by some of the latest advances in hierarchical modelling with vision transformers, we introduce the Multiscale Surface Vision Transformer (MS-SiT) as a backbone architecture for surface deep learning. The self-attention mechanism is applied within local-mesh-windows to allow for high-resolution sampling of the underlying data, while a shifted-window strategy improves the sharing of information between windows. Neighbouring patches are successively merged, allowing the MS-SiT to learn hierarchical representations suitable for any prediction task. Results demonstrate that the MS-SiT outperforms existing surface deep learning methods for neonatal phenotyping prediction tasks using the Developing Human Connectome Project (dHCP) dataset. Furthermore, building the MS-SiT backbone into a U-shaped architecture for surface segmentation demonstrates competitive results on cortical parcellation using the UK Biobank (UKB) and manually-annotated MindBoggle datasets. Code and trained models are publicly available at https://github.com/metrics-lab/surface-vision-transformers .         _ Less;Health relatedLightweight Contrastive Protein Structure-Sequence Transformation;              Pretrained protein structure models without labels are crucial foundations for the majority of protein downstream applications. The conventional structure pretraining methods follow the mature natural language pretraining methods such as denoised reconstruction and masked language modeling but usually destroy the real representation of spatial structures. The other common pretraining methods might…         _ More           Pretrained protein structure models without labels are crucial foundations for the majority of protein downstream applications. The conventional structure pretraining methods follow the mature natural language pretraining methods such as denoised reconstruction and masked language modeling but usually destroy the real representation of spatial structures. The other common pretraining methods might predict a fixed set of predetermined object categories, where a restricted supervised manner limits their generality and usability as additional labeled data is required to specify any other protein concepts. In this work, we introduce a novel unsupervised protein structure representation pretraining with a robust protein language model. In particular, we first propose to leverage an existing pretrained language model to guide structure model learning through an unsupervised contrastive alignment. In addition, a self-supervised structure constraint is proposed to further learn the intrinsic information about the structures. With only light training data, the pretrained structure model can obtain better generalization ability. To quantitatively evaluate the proposed structure models, we design a series of rational evaluation methods, including internal tasks (e.g., contact map prediction, distribution alignment quality) and external/downstream tasks (e.g., protein design). The extensive experimental results conducted on multiple tasks and specific datasets demonstrate the superiority of the proposed sequence-structure transformation framework.         _ Less;Health relatedDifficulty in chirality recognition for Transformer architectures learning chemical structures from string;              Recent years have seen rapid development of descriptor generation based on representation learning of extremely diverse molecules, especially those that apply natural language processing (NLP) models to SMILES, a literal representation of molecular structure. However, little research has been done on how these models understand chemical structure. To address this black box, we investigated the rel…         _ More           Recent years have seen rapid development of descriptor generation based on representation learning of extremely diverse molecules, especially those that apply natural language processing (NLP) models to SMILES, a literal representation of molecular structure. However, little research has been done on how these models understand chemical structure. To address this black box, we investigated the relationship between the learning progress of SMILES and chemical structure using a representative NLP model, the Transformer. We show that while the Transformer learns partial structures of molecules quickly, it requires extended training to understand overall structures. Consistently, the accuracy of molecular property predictions using descriptors generated from models at different learning steps was similar from the beginning to the end of training. Furthermore, we found that the Transformer requires particularly long training to learn chirality and sometimes stagnates with low performance due to misunderstanding of enantiomers. These findings are expected to deepen the understanding of NLP models in chemistry.         _ Less;Health relatedReliability of Tumour Classification from Multi-Dimensional DCE-MRI Variables using Data Transformations;Summary mean DCE-MRI variables show a clear dependency between signal and noise variance, which can be shown to reduce the effectiveness of difference assessments. Appropriate transformation of these variables supports statistically efficient and robust comparisons. The capabilities of DCE-MRI based descriptions of hepatic colorectal tumour classification was assessed, with regard to their potenti…         _ More           Summary mean DCE-MRI variables show a clear dependency between signal and noise variance, which can be shown to reduce the effectiveness of difference assessments. Appropriate transformation of these variables supports statistically efficient and robust comparisons. The capabilities of DCE-MRI based descriptions of hepatic colorectal tumour classification was assessed, with regard to their potential for use as imaging biomarkers. Four DCE-MRI parameters were extracted from 102 selected tumour regions. A multi-dimensional statistical distance metric was assessed for the challenging task of comparing intra- and inter- subject tumour differences. Statistical errors were estimated using bootstrap resampling. The potential for tumour classification was assessed via Monte Carlo simulation. Transformation of the variables and fusion into a single chi-squared statistic shows that inter subject variation in hepatic tumours is measurable and significantly greater than intra-subject variation at the group level. However, reliability analysis shows that, at current noise levels, individual tumour assessment is not possible. Appropriate data transforms for DCE-MRI derived parameters produce an improvement in statistical sensitivity compared to conventional approaches. Reliability analysis shows, that even with data transformation, DCI-MRI variables do not currently facilitate good tumour discrimination and a doubling of SNR is needed to support non-trivial levels of classification         _ Less;Health relatedCovariance properties under natural image transformations for the generalized Gaussian derivative model for visual receptive fields;              This paper presents a theory for how geometric image transformations can be handled by a first layer of linear receptive fields, in terms of true covariance properties, which, in turn, enable geometric invariance properties at higher levels in the visual hierarchy. Specifically, we develop this theory for a generalized Gaussian derivative model for visual receptive fields, which is derived in an a…         _ More           This paper presents a theory for how geometric image transformations can be handled by a first layer of linear receptive fields, in terms of true covariance properties, which, in turn, enable geometric invariance properties at higher levels in the visual hierarchy. Specifically, we develop this theory for a generalized Gaussian derivative model for visual receptive fields, which is derived in an axiomatic manner from first principles, that reflect symmetry properties of the environment, complemented by structural assumptions to guarantee internally consistent treatment of image structures over multiple spatio-temporal scales.   It is shown how the studied generalized Gaussian derivative model for visual receptive fields obeys true covariance properties under spatial scaling transformations, spatial affine transformations, Galilean transformations and temporal scaling transformations, implying that a vision system, based on image and video measurements in terms of the receptive fields according to this model, can to first order of approximation handle the image and video deformations between multiple views of objects delimited by smooth surfaces, as well as between multiple views of spatio-temporal events, under varying relative motions between the objects and events in the world and the observer.   We conclude by describing implications of the presented theory for biological vision, regarding connections between the variabilities of the shapes of biological visual receptive fields and the variabilities of spatial and spatio-temporal image structures under natural image transformations.         _ Less;Health relatedPreserving Derivative Information while Transforming Neuronal Curves;              The international neuroscience community is building the first comprehensive atlases of brain cell types to understand how the brain functions from a higher resolution, and more integrated perspective than ever before. In order to build these atlases, subsets of neurons (e.g. serotonergic neurons, prefrontal cortical neurons etc.) are traced in individual brain samples by placing points along dend…         _ More           The international neuroscience community is building the first comprehensive atlases of brain cell types to understand how the brain functions from a higher resolution, and more integrated perspective than ever before. In order to build these atlases, subsets of neurons (e.g. serotonergic neurons, prefrontal cortical neurons etc.) are traced in individual brain samples by placing points along dendrites and axons. Then, the traces are mapped to common coordinate systems by transforming the positions of their points, which neglects how the transformation bends the line segments in between. In this work, we apply the theory of jets to describe how to preserve derivatives of neuron traces up to any order. We provide a framework to compute possible error introduced by standard mapping methods, which involves the Jacobian of the mapping transformation. We show how our first order method improves mapping accuracy in both simulated and real neuron traces under random diffeomorphisms. Our method is freely available in our open-source Python package brainlit.         _ Less;Health relatedBoosting Convolutional Neural Networks' Protein Binding Site Prediction Capacity Using SE(3)-invariant transformers, Transfer Learning and Homology-based Augmentation;Figuring out small molecule binding sites in target proteins, in the resolution of either pocket or residue, is critical in many virtual and real drug-discovery scenarios. Since it is not always easy to find such binding sites based on domain knowledge or traditional methods, different deep learning methods that predict binding sites out of protein structures have been developed in recent years. H…         _ More           Figuring out small molecule binding sites in target proteins, in the resolution of either pocket or residue, is critical in many virtual and real drug-discovery scenarios. Since it is not always easy to find such binding sites based on domain knowledge or traditional methods, different deep learning methods that predict binding sites out of protein structures have been developed in recent years. Here we present a new such deep learning algorithm, that significantly outperformed all state-of-the-art baselines in terms of the both resolutions$\unicode{x2013}$pocket and residue. This good performance was also demonstrated in a case study involving the protein human serum albumin and its binding sites. Our algorithm included new ideas both in the model architecture and in the training method. For the model architecture, it incorporated SE(3)-invariant geometric self-attention layers that operate on top of residue-level CNN outputs. This residue-level processing of the model allowed a transfer learning between the two resolutions, which turned out to significantly improve the binding pocket prediction. Moreover, we developed novel augmentation method based on protein homology, which prevented our model from over-fitting. Overall, we believe that our contribution to the literature is twofold. First, we provided a new computational method for binding site prediction that is relevant to real-world applications, as shown by the good performance on different benchmarks and case study. Second, the novel ideas in our method$\unicode{x2013}$the model architecture, transfer learning and the homology augmentation$\unicode{x2013}$would serve as useful components in future works.         _ Less;Not health relatedEfficiently Training Vision Transformers on Structural MRI Scans for Alzheimer's Disease Detection;Neuroimaging of large populations is valuable to identify factors that promote or resist brain disease, and to assist diagnosis, subtyping, and prognosis. Data-driven models such as convolutional neural networks (CNNs) have increasingly been applied to brain images to perform diagnostic and prognostic tasks by learning robust features. Vision transformers (ViT) - a new class of deep learning archi…         _ More           Neuroimaging of large populations is valuable to identify factors that promote or resist brain disease, and to assist diagnosis, subtyping, and prognosis. Data-driven models such as convolutional neural networks (CNNs) have increasingly been applied to brain images to perform diagnostic and prognostic tasks by learning robust features. Vision transformers (ViT) - a new class of deep learning architectures - have emerged in recent years as an alternative to CNNs for several computer vision applications. Here we tested variants of the ViT architecture for a range of desired neuroimaging downstream tasks based on difficulty, in this case for sex and Alzheimer's disease (AD) classification based on 3D brain MRI. In our experiments, two vision transformer architecture variants achieved an AUC of 0.987 for sex and 0.892 for AD classification, respectively. We independently evaluated our models on data from two benchmark AD datasets. We achieved a performance boost of 5% and 9-10% upon fine-tuning vision transformer models pre-trained on synthetic (generated by a latent diffusion model) and real MRI scans, respectively. Our main contributions include testing the effects of different ViT training strategies including pre-training, data augmentation and learning rate warm-ups followed by annealing, as pertaining to the neuroimaging domain. These techniques are essential for training ViT-like models for neuroimaging applications where training data is usually limited. We also analyzed the effect of the amount of training data utilized on the test-time performance of the ViT via data-model scaling curves.         _ Less;Health relatedTransformer Encoder with Multiscale Deep Learning for Pain Classification Using Physiological Signals;              Pain is a serious worldwide health problem that affects a vast proportion of the population. For efficient pain management and treatment, accurate classification and evaluation of pain severity are necessary. However, this can be challenging as pain is a subjective sensation-driven experience. Traditional techniques for measuring pain intensity, e.g. self-report scales, are susceptible to bias and…         _ More           Pain is a serious worldwide health problem that affects a vast proportion of the population. For efficient pain management and treatment, accurate classification and evaluation of pain severity are necessary. However, this can be challenging as pain is a subjective sensation-driven experience. Traditional techniques for measuring pain intensity, e.g. self-report scales, are susceptible to bias and unreliable in some instances. Consequently, there is a need for more objective and automatic pain intensity assessment strategies. In this paper, we develop PainAttnNet (PAN), a novel transfomer-encoder deep-learning framework for classifying pain intensities with physiological signals as input. The proposed approach is comprised of three feature extraction architectures: multiscale convolutional networks (MSCN), a squeeze-and-excitation residual network (SEResNet), and a transformer encoder block. On the basis of pain stimuli, MSCN extracts short- and long-window information as well as sequential features. SEResNet highlights relevant extracted features by mapping the interdependencies among features. The third module employs a transformer encoder consisting of three temporal convolutional networks (TCN) with three multi-head attention (MHA) layers to extract temporal dependencies from the features. Using the publicly available BioVid pain dataset, we test the proposed PainAttnNet model and demonstrate that our outcomes outperform state-of-the-art models. These results confirm that our approach can be utilized for automated classification of pain intensity using physiological signals to improve pain management and treatment.         _ Less;Health relatedEEG Synthetic Data Generation Using Probabilistic Diffusion Models;              Electroencephalography (EEG) plays a significant role in the Brain Computer Interface (BCI) domain, due to its non-invasive nature, low cost, and ease of use, making it a highly desirable option for widespread adoption by the general public. This technology is commonly used in conjunction with deep learning techniques, the success of which is largely dependent on the quality and quantity of data u…         _ More           Electroencephalography (EEG) plays a significant role in the Brain Computer Interface (BCI) domain, due to its non-invasive nature, low cost, and ease of use, making it a highly desirable option for widespread adoption by the general public. This technology is commonly used in conjunction with deep learning techniques, the success of which is largely dependent on the quality and quantity of data used for training. To address the challenge of obtaining sufficient EEG data from individual participants while minimizing user effort and maintaining accuracy, this study proposes an advanced methodology for data augmentation: generating synthetic EEG data using denoising diffusion probabilistic models. The synthetic data are generated from electrode-frequency distribution maps (EFDMs) of emotionally labeled EEG recordings. To assess the validity of the synthetic data generated, both a qualitative and a quantitative comparison with real EEG data were successfully conducted. This study opens up the possibility for an open\textendash source accessible and versatile toolbox that can process and generate data in both time and frequency dimensions, regardless of the number of channels involved. Finally, the proposed methodology has potential implications for the broader field of neuroscience research by enabling the creation of large, publicly available synthetic EEG datasets without privacy concerns.         _ Less;Health relatedEuler Characteristic Transform Based Topological Loss for Reconstructing 3D Images from Single 2D Slices;The computer vision task of reconstructing 3D images, i.e., shapes, from their single 2D image slices is extremely challenging, more so in the regime of limited data. Deep learning models typically optimize geometric loss functions, which may lead to poor reconstructions as they ignore the structural properties of the shape. To tackle this, we propose a novel topological loss function based on the…         _ More           The computer vision task of reconstructing 3D images, i.e., shapes, from their single 2D image slices is extremely challenging, more so in the regime of limited data. Deep learning models typically optimize geometric loss functions, which may lead to poor reconstructions as they ignore the structural properties of the shape. To tackle this, we propose a novel topological loss function based on the Euler Characteristic Transform. This loss can be used as an inductive bias to aid the optimization of any neural network toward better reconstructions in the regime of limited data. We show the effectiveness of the proposed loss function by incorporating it into SHAPR, a state-of-the-art shape reconstruction model, and test it on two benchmark datasets, viz., Red Blood Cells and Nuclei datasets. We also show a favourable property, namely injectivity and discuss the stability of the topological loss function based on the Euler Characteristic Transform.         _ Less;Health relatedSingle-Cell Multimodal Prediction via Transformers;"The recent development of multimodal single-cell technology has made the possibility of acquiring multiple omics data from individual cells, thereby enabling a deeper understanding of cellular states and dynamics. Nevertheless, the proliferation of multimodal single-cell data also introduces tremendous challenges in modeling the complex interactions among different modalities. The recently advance…         _ More           The recent development of multimodal single-cell technology has made the possibility of acquiring multiple omics data from individual cells, thereby enabling a deeper understanding of cellular states and dynamics. Nevertheless, the proliferation of multimodal single-cell data also introduces tremendous challenges in modeling the complex interactions among different modalities. The recently advanced methods focus on constructing static interaction graphs and applying graph neural networks (GNNs) to learn from multimodal data. However, such static graphs can be suboptimal as they do not take advantage of the downstream task information; meanwhile GNNs also have some inherent limitations when deeply stacking GNN layers. To tackle these issues, in this work, we investigate how to leverage transformers for multimodal single-cell data in an end-to-end manner while exploiting downstream task information. In particular, we propose a scMoFormer framework which can readily incorporate external domain knowledge and model the interactions within each modality and cross modalities. Extensive experiments demonstrate that scMoFormer achieves superior performance on various benchmark datasets. Remarkably, scMoFormer won a Kaggle silver medal with the rank of 24/1221 (Top 2%) without ensemble in a NeurIPS 2022 competition. Our implementation is publicly available at Github.         _ Less";Health relatedMVMTnet: A Multi-variate Multi-modal Transformer for Multi-class Classification of Cardiac Irregularities Using ECG Waveforms and Clinical Notes;Deep learning provides an excellent avenue for optimizing diagnosis and patient monitoring for clinical-based applications, which can critically enhance the response time to the onset of various conditions. For cardiovascular disease, one such condition where the rising number of patients increasingly outweighs the availability of medical resources in different parts of the world, a core challenge…         _ More           Deep learning provides an excellent avenue for optimizing diagnosis and patient monitoring for clinical-based applications, which can critically enhance the response time to the onset of various conditions. For cardiovascular disease, one such condition where the rising number of patients increasingly outweighs the availability of medical resources in different parts of the world, a core challenge is the automated classification of various cardiac abnormalities. Existing deep learning approaches have largely been limited to detecting the existence of an irregularity, as in binary classification, which has been achieved using networks such as CNNs and RNN/LSTMs. The next step is to accurately perform multi-class classification and determine the specific condition(s) from the inherently noisy multi-variate waveform, which is a difficult task that could benefit from (1) a more powerful sequential network, and (2) the integration of clinical notes, which provide valuable semantic and clinical context from human doctors. Recently, Transformers have emerged as the state-of-the-art architecture for forecasting and prediction using time-series data, with their multi-headed attention mechanism, and ability to process whole sequences and learn both long and short-range dependencies. The proposed novel multi-modal Transformer architecture would be able to accurately perform this task while demonstrating the cross-domain effectiveness of Transformers, establishing a method for incorporating multiple data modalities within a Transformer for classification tasks, and laying the groundwork for automating real-time patient condition monitoring in clinical and ER settings.         _ Less;Health relatedTarget Specific De Novo Design of Drug Candidate Molecules with Graph Transformer-based Generative Adversarial Networks;"Discovering novel drug candidate molecules is one of the most fundamental and critical steps in drug development. Generative deep learning models, which create synthetic data given a probability distribution, have been developed with the purpose of picking completely new samples from a partially known space. Generative models offer high potential for designing de novo molecules; however, in order…         _ More           Discovering novel drug candidate molecules is one of the most fundamental and critical steps in drug development. Generative deep learning models, which create synthetic data given a probability distribution, have been developed with the purpose of picking completely new samples from a partially known space. Generative models offer high potential for designing de novo molecules; however, in order for them to be useful in real-life drug development pipelines, these models should be able to design target-specific molecules, which is the next step in this field. In this study, we propose DrugGEN, for the de novo design of drug candidate molecules that interact with selected target proteins. The proposed system represents compounds and protein structures as graphs and processes them via serially connected two generative adversarial networks comprising graph transformers. DrugGEN is trained using a large dataset of compounds from ChEMBL and target-specific bioactive molecules, to design effective and specific inhibitory molecules against the AKT1 protein, which has critical importance for developing treatments against various types of cancer. On fundamental benchmarks, DrugGEN models have either competitive or better performance against other methods. To assess the target-specific generation performance, we conducted further in silico analysis with molecular docking and deep learning-based bioactivity prediction. Results indicate that de novo molecules have high potential for interacting with the AKT1 protein structure in the level of its native ligand. DrugGEN can be used to design completely novel and effective target-specific drug candidate molecules for any druggable protein, given target features and a dataset of experimental bioactivities. Code base, datasets, results and trained models of DrugGEN are available at https://github.com/HUBioDataLab/DrugGEN         _ Less";Health relatedEnergy Transformer;              Our work combines aspects of three promising paradigms in machine learning, namely, attention mechanism, energy-based models, and associative memory. Attention is the power-house driving modern deep learning successes, but it lacks clear theoretical foundations. Energy-based models allow a principled approach to discriminative and generative tasks, but the design of the energy functional is not st…         _ More           Our work combines aspects of three promising paradigms in machine learning, namely, attention mechanism, energy-based models, and associative memory. Attention is the power-house driving modern deep learning successes, but it lacks clear theoretical foundations. Energy-based models allow a principled approach to discriminative and generative tasks, but the design of the energy functional is not straightforward. At the same time, Dense Associative Memory models or Modern Hopfield Networks have a well-established theoretical foundation, and allow an intuitive design of the energy function. We propose a novel architecture, called the Energy Transformer (or ET for short), that uses a sequence of attention layers that are purposely designed to minimize a specifically engineered energy function, which is responsible for representing the relationships between the tokens. In this work, we introduce the theoretical foundations of ET, explore its empirical capabilities using the image completion task, and obtain strong quantitative results on the graph anomaly detection and graph classification tasks.         _ Less;Health relatedSingle Cells Are Spatial Tokens: Transformers for Spatial Transcriptomic Data Imputation;Spatially resolved transcriptomics brings exciting breakthroughs to single-cell analysis by providing physical locations along with gene expression. However, as a cost of the extremely high spatial resolution, the cellular level spatial transcriptomic data suffer significantly from missing values. While a standard solution is to perform imputation on the missing values, most existing methods eithe…         _ More           Spatially resolved transcriptomics brings exciting breakthroughs to single-cell analysis by providing physical locations along with gene expression. However, as a cost of the extremely high spatial resolution, the cellular level spatial transcriptomic data suffer significantly from missing values. While a standard solution is to perform imputation on the missing values, most existing methods either overlook spatial information or only incorporate localized spatial context without the ability to capture long-range spatial information. Using multi-head self-attention mechanisms and positional encoding, transformer models can readily grasp the relationship between tokens and encode location information. In this paper, by treating single cells as spatial tokens, we study how to leverage transformers to facilitate spatial tanscriptomics imputation. In particular, investigate the following two key questions: (1) $\textit{how to encode spatial information of cells in transformers}$, and (2) $\textit{ how to train a transformer for transcriptomic imputation}$. By answering these two questions, we present a transformer-based imputation framework, SpaFormer, for cellular-level spatial transcriptomic data. Extensive experiments demonstrate that SpaFormer outperforms existing state-of-the-art imputation algorithms on three large-scale datasets while maintaining superior computational efficiency.         _ Less;Health relatedV1T: large-scale mouse V1 response prediction using a Vision Transformer;Accurate predictive models of the visual cortex neural response to natural visual stimuli remain a challenge in computational neuroscience. In this work, we introduce V1T, a novel Vision Transformer based architecture that learns a shared visual and behavioral representation across animals. We evaluate our model on two large datasets recorded from mouse primary visual cortex and outperform previou…         _ More           Accurate predictive models of the visual cortex neural response to natural visual stimuli remain a challenge in computational neuroscience. In this work, we introduce V1T, a novel Vision Transformer based architecture that learns a shared visual and behavioral representation across animals. We evaluate our model on two large datasets recorded from mouse primary visual cortex and outperform previous convolution-based models by more than 12.7% in prediction performance. Moreover, we show that the self-attention weights learned by the Transformer correlate with the population receptive fields. Our model thus sets a new benchmark for neural response prediction and can be used jointly with behavioral and neural recordings to reveal meaningful characteristic features of the visual cortex.         _ Less;Health relatedMolecular Geometry-aware Transformer for accurate 3D Atomic System modeling;Molecular dynamic simulations are important in computational physics, chemistry, material, and biology. Machine learning-based methods have shown strong abilities in predicting molecular energy and properties and are much faster than DFT calculations. Molecular energy is at least related to atoms, bonds, bond angles, torsion angles, and nonbonding atom pairs. Previous Transformer models only use a…         _ More           Molecular dynamic simulations are important in computational physics, chemistry, material, and biology. Machine learning-based methods have shown strong abilities in predicting molecular energy and properties and are much faster than DFT calculations. Molecular energy is at least related to atoms, bonds, bond angles, torsion angles, and nonbonding atom pairs. Previous Transformer models only use atoms as inputs which lack explicit modeling of the aforementioned factors. To alleviate this limitation, we propose Moleformer, a novel Transformer architecture that takes nodes (atoms) and edges (bonds and nonbonding atom pairs) as inputs and models the interactions among them using rotational and translational invariant geometry-aware spatial encoding. Proposed spatial encoding calculates relative position information including distances and angles among nodes and edges. We benchmark Moleformer on OC20 and QM9 datasets, and our model achieves state-of-the-art on the initial state to relaxed energy prediction of OC20 and is very competitive in QM9 on predicting quantum chemical properties compared to other Transformer and Graph Neural Network (GNN) methods which proves the effectiveness of the proposed geometry-aware spatial encoding in Moleformer.         _ Less;Health relatedGyri vs. Sulci: Disentangling Brain Core-Periphery Functional Networks via Twin-Transformer;              The human cerebral cortex is highly convoluted into convex gyri and concave sulci. It has been demonstrated that gyri and sulci are significantly different in their anatomy, connectivity, and function, besides exhibiting opposite shape patterns, long-distance axonal fibers connected to gyri are much denser than those connected to sulci, and neural signals on gyri are more complex in low-frequency…         _ More           The human cerebral cortex is highly convoluted into convex gyri and concave sulci. It has been demonstrated that gyri and sulci are significantly different in their anatomy, connectivity, and function, besides exhibiting opposite shape patterns, long-distance axonal fibers connected to gyri are much denser than those connected to sulci, and neural signals on gyri are more complex in low-frequency while sulci are more complex in high-frequency. Although accumulating evidence shows significant differences between gyri and sulci, their primary roles in brain function have not been elucidated yet. To solve this fundamental problem, we design a novel Twin-Transformer framework to unveil the unique functional roles of gyri and sulci as well as their relationship in the whole brain function. Our Twin-Transformer framework adopts two structure-identical (twin) Transformers to disentangle spatial-temporal patterns of gyri and sulci, one focuses on the information of gyri and the other is on sulci. The Gyro-Sulcal interactions, along with the tremendous but widely existing variability across subjects, are characterized in the loss design. We validated our Twin-Transformer on the HCP task-fMRI dataset, for the first time, to elucidate the different roles of gyri and sulci in brain function. Our results suggest that gyri and sulci could work together in a core-periphery network manner, that is, gyri could serve as core networks for information gathering and distributing, while sulci could serve as periphery networks for specific local information processing. These findings have shed new light on our fundamental understanding of the brain's basic structural and functional mechanisms.         _ Less;Health relatedPhaVIP: Phage VIrion Protein classification based on chaos game representation and Vision Transformer;              Motivation: As viruses that mainly infect bacteria, phages are key players across a wide range of ecosystems. Analyzing phage proteins is indispensable for understanding phages' functions and roles in microbiomes. High-throughput sequencing enables us to obtain phages in different microbiomes with low cost. However, compared to the fast accumulation of newly identified phages, phage protein classi…         _ More           Motivation: As viruses that mainly infect bacteria, phages are key players across a wide range of ecosystems. Analyzing phage proteins is indispensable for understanding phages' functions and roles in microbiomes. High-throughput sequencing enables us to obtain phages in different microbiomes with low cost. However, compared to the fast accumulation of newly identified phages, phage protein classification remains difficult. In particular, a fundamental need is to annotate virion proteins, the structural proteins such as major tail, baseplate etc. Although there are experimental methods for virion protein identification, they are too expensive or time-consuming, leaving a large number of proteins unclassified. Thus, there is a great demand to develop a computational method for fast and accurate phage virion protein classification. Results: In this work, we adapted the state-of-the-art image classification model, Vision Transformer, to conduct virion protein classification. By encoding protein sequences into unique images using chaos gaming representation, we can leverage Vision Transformer to learn both local and global features from sequence ``images''. Our method, PhaVIP, has two main functions: classifying PVP and non-PVP sequences and annotating the types of PVP, such as capsid and tail. We tested PhaVIP on several datasets with increasing difficulty and benchmarked it against alternative tools. The experimental results show that PhaVIP has superior performance. After validating the performance of PhaVIP, we investigated two applications that can use the output of PhaVIP: phage taxonomy classification and phage host prediction. The results show the benefit of using classified proteins rather than all proteins.         _ Less;Health relatedSynthesis-driven design of 3D molecules for structure-based drug discovery using geometric transformers;Finding drug-like compounds with high bioactivity is essential for drug discovery, but the task is complicated by the high cost of chemical synthesis and validation. With their outstanding performance in de novo drug design, deep generative models represent promising tools for tackling this challenge. In recently years, 3D molecule generative models have gained increasing attention due to their ab…         _ More           Finding drug-like compounds with high bioactivity is essential for drug discovery, but the task is complicated by the high cost of chemical synthesis and validation. With their outstanding performance in de novo drug design, deep generative models represent promising tools for tackling this challenge. In recently years, 3D molecule generative models have gained increasing attention due to their ability to directly utilize the 3D interaction information between the target and ligand. However, it remains challenging to synthesize the molecules generated by these models, limiting the speed of bioactivity validation and further structure optimization. In this work, we propose DeepLigBuilder+, a deep generative model for 3D molecules that combines structure-based de novo drug design with a reaction-based generation framework. Besides producing 3D molecular structures, the model also proposes synthetic pathways for generated molecules, which greatly assists the retro-synthetic analysis. To achieve this, we developed a new way to enforce the synthesizability constraint using a tree-based organization of purchasable building blocks. This method enjoys high scalability and is compatible with existing atom-based generative models. Additionally, for structure-based design tasks, we developed an SE(3)-equivariant transformer conditioned on the shape and pharmacophore-based inputs, and combine it with the Monte Carlo tree search. Using the ATP-binding pocket of BTK and the NAD+ binding pocket of PHGDH for case studies, we demonstrate that DeepLigBuilder+ is capable of enriching drug-like molecules with high predicted binding affinity and desirable interaction modes while maintaining the synthesizability constraint. We believe that DeepLigBuilder+ is a powerful tool for accelerating the process of drug discovery.         _ Less;Health relatedDetecting Temporal shape changes with the Euler Characteristic Transform;Organoids are multi-cellular structures which are cultured in vitro from stem cells to resemble specific organs (e.g., brain, liver) in their three-dimensional composition. Dynamic changes in the shape and composition of these model systems can be used to understand the effect of mutations and treatments in health and disease. In this paper, we propose a new technique in the field of topological d…         _ More           Organoids are multi-cellular structures which are cultured in vitro from stem cells to resemble specific organs (e.g., brain, liver) in their three-dimensional composition. Dynamic changes in the shape and composition of these model systems can be used to understand the effect of mutations and treatments in health and disease. In this paper, we propose a new technique in the field of topological data analysis for DEtecting Temporal shape changes with the Euler Characteristic Transform (DETECT). DETECT is a rotationally invariant signature of dynamically changing shapes. We demonstrate our method on a data set of segmented videos of mouse small intestine organoid experiments and show that it outperforms classical shape descriptors. We verify our method on a synthetic organoid data set and illustrate how it generalises to 3D. We conclude that DETECT offers rigorous quantification of organoids and opens up computationally scalable methods for distinguishing different growth regimes and assessing treatment effects.         _ Less;Health relatedGeneFormer: Learned Gene Compression using Transformer-based Context Modeling;With the development of gene sequencing technology, an explosive growth of gene data has been witnessed. And the storage of gene data has become an important issue. Traditional gene data compression methods rely on general software like G-zip, which fails to utilize the interrelation of nucleotide sequence. Recently, many researchers begin to investigate deep learning based gene data compression m…         _ More           With the development of gene sequencing technology, an explosive growth of gene data has been witnessed. And the storage of gene data has become an important issue. Traditional gene data compression methods rely on general software like G-zip, which fails to utilize the interrelation of nucleotide sequence. Recently, many researchers begin to investigate deep learning based gene data compression method. In this paper, we propose a transformer-based gene compression method named GeneFormer. Specifically, we first introduce a modified transformer structure to fully explore the nucleotide sequence dependency. Then, we propose fixed-length parallel grouping to accelerate the decoding speed of our autoregressive model. Experimental results on real-world datasets show that our method saves 29.7% bit rate compared with the state-of-the-art method, and the decoding speed is significantly faster than all existing learning-based gene compression methods.         _ Less;Health relatedInformation retrieval in single cell chromatin analysis using TF-IDF transformation methods;              Single-cell sequencing assay for transposase-accessible chromatin (scATAC-seq) assesses genome-wide chromatin accessibility in thousands of cells to reveal regulatory landscapes in high resolutions. However, the analysis presents challenges due to the high dimensionality and sparsity of the data. Several methods have been developed, including transformation techniques of term-frequency inverse-doc…         _ More           Single-cell sequencing assay for transposase-accessible chromatin (scATAC-seq) assesses genome-wide chromatin accessibility in thousands of cells to reveal regulatory landscapes in high resolutions. However, the analysis presents challenges due to the high dimensionality and sparsity of the data. Several methods have been developed, including transformation techniques of term-frequency inverse-document frequency (TF-IDF), dimension reduction methods such as singular value decomposition (SVD), factor analysis, and autoencoders. Yet, a comprehensive study on the mentioned methods has not been fully performed. It is not clear what is the best practice when analyzing scATAC-seq data. We compared several scenarios for transformation and dimension reduction as well as the SVD-based feature analysis to investigate potential enhancements in scATAC-seq information retrieval. Additionally, we investigate if autoencoders benefit from the TF-IDF transformation. Our results reveal that the TF-IDF transformation generally leads to improved clustering and biologically relevant feature extraction.         _ Less;Health relatedDock2D: Synthetic data for the molecular recognition problem;"Predicting the physical interaction of proteins is a cornerstone problem in computational biology. New classes of learning-based algorithms are actively being developed, and are typically trained end-to-end on protein complex structures extracted from the Protein Data Bank. These training datasets tend to be large and difficult to use for prototyping and, unlike image or natural language datasets,…         _ More           Predicting the physical interaction of proteins is a cornerstone problem in computational biology. New classes of learning-based algorithms are actively being developed, and are typically trained end-to-end on protein complex structures extracted from the Protein Data Bank. These training datasets tend to be large and difficult to use for prototyping and, unlike image or natural language datasets, they are not easily interpretable by non-experts. We present Dock2D-IP and Dock2D-IF, two ""toy"" datasets that can be used to select algorithms predicting protein-protein interactions$\unicode{x2014}$or any other type of molecular interactions. Using two-dimensional shapes as input, each example from Dock2D-IP (""interaction pose"") describes the interaction pose of two shapes known to interact and each example from Dock2D-IF (""interaction fact"") describes whether two shapes form a stable complex or not. We propose a number of baseline solutions to the problem and show that the same underlying energy function can be learned either by solving the interaction pose task (formulated as an energy-minimization ""docking"" problem) or the fact-of-interaction task (formulated as a binding free energy estimation problem).         _ Less";Health relatedGPS++: An Optimised Hybrid MPNN/Transformer for Molecular Property Prediction;This technical report presents GPS++, the first-place solution to the Open Graph Benchmark Large-Scale Challenge (OGB-LSC 2022) for the PCQM4Mv2 molecular property prediction task. Our approach implements several key principles from the prior literature. At its core our GPS++ method is a hybrid MPNN/Transformer model that incorporates 3D atom positions and an auxiliary denoising task. The effectiv…         _ More           This technical report presents GPS++, the first-place solution to the Open Graph Benchmark Large-Scale Challenge (OGB-LSC 2022) for the PCQM4Mv2 molecular property prediction task. Our approach implements several key principles from the prior literature. At its core our GPS++ method is a hybrid MPNN/Transformer model that incorporates 3D atom positions and an auxiliary denoising task. The effectiveness of GPS++ is demonstrated by achieving 0.0719 mean absolute error on the independent test-challenge PCQM4Mv2 split. Thanks to Graphcore IPU acceleration, GPS++ scales to deep architectures (16 layers), training at 3 minutes per epoch, and large ensemble (112 models), completing the final predictions in 1 hour 32 minutes, well under the 4 hour inference budget allocated. Our implementation is publicly available at: https://github.com/graphcore/ogb-lsc-pcqm4mv2.         _ Less;Health relatedBatmanNet: Bi-branch Masked Graph Transformer Autoencoder for Molecular Representation;Although substantial efforts have been made using graph neural networks (GNNs) for AI-driven drug discovery (AIDD), effective molecular representation learning remains an open challenge, especially in the case of insufficient labeled molecules. Recent studies suggest that big GNN models pre-trained by self-supervised learning on unlabeled datasets enable better transfer performance in downstream m…         _ More           Although substantial efforts have been made using graph neural networks (GNNs) for AI-driven drug discovery (AIDD), effective molecular representation learning remains an open challenge, especially in the case of insufficient labeled molecules. Recent studies suggest that big GNN models pre-trained by self-supervised learning on unlabeled datasets enable better transfer performance in downstream molecular property prediction tasks. However, the approaches in these studies require multiple complex self-supervised tasks and large-scale datasets, which are time-consuming, computationally expensive, and difficult to pre-train end-to-end. Here, we design a simple yet effective self-supervised strategy to simultaneously learn local and global information about molecules, and further propose a novel bi-branch masked graph transformer autoencoder (BatmanNet) to learn molecular representations. BatmanNet features two tailored complementary and asymmetric graph autoencoders to reconstruct the missing nodes and edges, respectively, from a masked molecular graph. With this design, BatmanNet can effectively capture the underlying structure and semantic information of molecules, thus improving the performance of molecular representation. BatmanNet achieves state-of-the-art results for multiple drug discovery tasks, including molecular properties prediction, drug-drug interaction, and drug-target interaction, on 13 benchmark datasets, demonstrating its great potential and superiority in molecular representation learning.         _ Less;Health relatedIntegrating Transformer and Autoencoder Techniques with Spectral Graph Algorithms for the Prediction of Scarcely Labeled Molecular Data;In molecular and biological sciences, experiments are expensive, time-consuming, and often subject to ethical constraints. Consequently, one often faces the challenging task of predicting desirable properties from small data sets or scarcely-labeled data sets. Although transfer learning can be advantageous, it requires the existence of a related large data set. This work introduces three graph-bas…         _ More           In molecular and biological sciences, experiments are expensive, time-consuming, and often subject to ethical constraints. Consequently, one often faces the challenging task of predicting desirable properties from small data sets or scarcely-labeled data sets. Although transfer learning can be advantageous, it requires the existence of a related large data set. This work introduces three graph-based models incorporating Merriman-Bence-Osher (MBO) techniques to tackle this challenge. Specifically, graph-based modifications of the MBO scheme are integrated with state-of-the-art techniques, including a home-made transformer and an autoencoder, in order to deal with scarcely-labeled data sets. In addition, a consensus technique is detailed. The proposed models are validated using five benchmark data sets. We also provide a thorough comparison to other competing methods, such as support vector machines, random forests, and gradient boosting decision trees, which are known for their good performance on small data sets. The performances of various methods are analyzed using residue-similarity (R-S) scores and R-S indices. Extensive computational experiments and theoretical analysis show that the new models perform very well even when as little as 1% of the data set is used as labeled data.         _ Less;Health relatedEfficient HLA imputation from sequential SNPs data by Transformer;"Human leukocyte antigen (HLA) genes are associated with a variety of diseases, however direct typing of HLA is time and cost consuming. Thus various imputation methods using sequential SNPs data have been proposed based on statistical or deep learning models, e.g. CNN-based model, named DEEP*HLA. However, imputation efficiency is not sufficient for in frequent alleles and a large size of reference…         _ More           Human leukocyte antigen (HLA) genes are associated with a variety of diseases, however direct typing of HLA is time and cost consuming. Thus various imputation methods using sequential SNPs data have been proposed based on statistical or deep learning models, e.g. CNN-based model, named DEEP*HLA. However, imputation efficiency is not sufficient for in frequent alleles and a large size of reference panel is required. Here, we developed a Transformer-based model to impute HLA alleles, named ""HLA Reliable IMputatioN by Transformer (HLARIMNT)"" to take advantage of sequential nature of SNPs data. We validated the performance of HLARIMNT using two different reference panels; Pan-Asian reference panel (n = 530) and Type 1 Diabetes Genetics Consortium (T1DGC) reference panel (n = 5,225), as well as the mixture of those two panels (n = 1,060). HLARIMNT achieved higher accuracy than DEEP*HLA by several indices, especially for infrequent alleles. We also varied the size of data used for training, and HLARIMNT imputed more accurately among any size of training data. These results suggest that Transformer-based model may impute efficiently not only HLA types but also any other gene types from sequential SNPs data.         _ Less";Health relatedSplitting expands the application range of Vision Transformer -- variable Vision Transformer (vViT);"Vision Transformer (ViT) has achieved outstanding results in computer vision. Although there are many Transformer-based architectures derived from the original ViT, the dimension of patches are often the same with each other. This disadvantage leads to a limited application range in the medical field because in the medical field, datasets whose dimension is different from each other; e.g. medical…         _ More           Vision Transformer (ViT) has achieved outstanding results in computer vision. Although there are many Transformer-based architectures derived from the original ViT, the dimension of patches are often the same with each other. This disadvantage leads to a limited application range in the medical field because in the medical field, datasets whose dimension is different from each other; e.g. medical image, patients' personal information, laboratory test and so on. To overcome this limitation, we develop a new derived type of ViT termed variable Vision Transformer (vViT). The aim of this study is to introduce vViT and to apply vViT to radiomics using T1 weighted magnetic resonance image (MRI) of glioma. In the prediction of 365 days of survival among glioma patients using radiomics,vViT achieved 0.83, 0.82, 0.81, and 0.76 in sensitivity, specificity, accuracy, and AUC-ROC, respectively. vViT has the potential to handle different types of medical information at once.         _ Less";Health relatedTransEDRP: Dual Transformer model with Edge Emdedded for Drug Respond Prediction;GNN-based methods have achieved excellent results as a mainstream task in drug response prediction tasks in recent years. Traditional GNN methods use only the atoms in a drug molecule as nodes to obtain the representation of the molecular graph through node information passing, whereas the method using the transformer can only extract information about the nodes. However, the covalent bonding and…         _ More           GNN-based methods have achieved excellent results as a mainstream task in drug response prediction tasks in recent years. Traditional GNN methods use only the atoms in a drug molecule as nodes to obtain the representation of the molecular graph through node information passing, whereas the method using the transformer can only extract information about the nodes. However, the covalent bonding and chirality of a drug molecule have a great influence on the pharmacological properties of the molecule, and these information are implied in the chemical bonds formed by the edges between the atoms. In addition, CNN methods for modelling cell lines genomics sequences can only perceive local rather than global information about the sequence. In order to solve the above problems, we propose the decoupled dual transformer structure with edge embedded for drug respond prediction (TransEDRP), which is used for the representation of cell line genomics and drug respectively. For the drug branch, we encoded the chemical bond information within the molecule as the embedding of the edge in the molecular graph, extracted the global structural and biochemical information of the drug molecule using graph transformer. For the branch of cell lines genomics, we use the multi-headed attention mechanism to globally represent the genomics sequence. Finally, the drug and genomics branches are fused to predict IC50 values through the transformer layer and the fully connected layer, which two branches are different modalities. Extensive experiments have shown that our method is better than the current mainstream approach in all evaluation indicators.         _ Less;Health relatedInteractive cohort exploration for spinocerebellar ataxias using synthetic cohort data for visualization;Motivation: Visualization of data is a crucial step to understanding and deriving hypotheses from clinical data. However, for clinicians, visualization often comes with great effort due to the lack of technical knowledge about data handling and visualization. The application offers an easy-to-use solution with an intuitive design that enables various kinds of plotting functions. The aim was to pro…         _ More           Motivation: Visualization of data is a crucial step to understanding and deriving hypotheses from clinical data. However, for clinicians, visualization often comes with great effort due to the lack of technical knowledge about data handling and visualization. The application offers an easy-to-use solution with an intuitive design that enables various kinds of plotting functions. The aim was to provide an intuitive solution with a low entrance barrier for clinical users. Little to no onboarding is required before creating plots, while the complexity of questions can grow up to specific corner cases. To allow for an easy start and testing with SCAview, we incorporated a synthetic cohort dataset based on real data of rare neurological movement disorders: the most common autosomal-dominantly inherited spinocerebellar ataxias (SCAs) type 1, 2, 3, and 6 (SCA1, 2, 3 and 6). Methods: We created a Django-based backend application that serves the data to a React-based frontend that uses Plotly for plotting. A synthetic cohort was created to deploy a version of SCAview without violating any data protection guidelines. Here, we added normal distributed noise to the data and therefore prevent re-identification while keeping distributions and general correlations. Results: This work presents SCAview, an user-friendly, interactive web-based service that enables data visualization in a clickable interface allowing intuitive graphical handling that aims to enable data visualization in a clickable interface. The service is deployed and can be tested with a synthetic cohort created based on a large, longitudinal dataset from observational studies in the most common SCAs.         _ Less;Health relatedWorking Alliance Transformer for Psychotherapy Dialogue Classification;As a predictive measure of the treatment outcome in psychotherapy, the working alliance measures the agreement of the patient and the therapist in terms of their bond, task and goal. Long been a clinical quantity estimated by the patients' and therapists' self-evaluative reports, we believe that the working alliance can be better characterized using natural language processing technique directly i…         _ More           As a predictive measure of the treatment outcome in psychotherapy, the working alliance measures the agreement of the patient and the therapist in terms of their bond, task and goal. Long been a clinical quantity estimated by the patients' and therapists' self-evaluative reports, we believe that the working alliance can be better characterized using natural language processing technique directly in the dialogue transcribed in each therapy session. In this work, we propose the Working Alliance Transformer (WAT), a Transformer-based classification model that has a psychological state encoder which infers the working alliance scores by projecting the embedding of the dialogues turns onto the embedding space of the clinical inventory for working alliance. We evaluate our method in a real-world dataset with over 950 therapy sessions with anxiety, depression, schizophrenia and suicidal patients and demonstrate an empirical advantage of using information about the therapeutic states in this sequence classification task of psychotherapy dialogues.         _ Less;Health relatedGlobal technology access in biolabs -- from DIY trend to an open source transformation;              This article illustrates how open hardware solutions are implemented by researchers as a strategy to access technology for cutting-edge research. Specifically, it is discussed what kind of open technologies are most enabling in scientific environments characterized by economic and infrastructural constraints. It is demonstrated that do-it-yourself (DIY) technologies are already wide spread, in par…         _ More           This article illustrates how open hardware solutions are implemented by researchers as a strategy to access technology for cutting-edge research. Specifically, it is discussed what kind of open technologies are most enabling in scientific environments characterized by economic and infrastructural constraints. It is demonstrated that do-it-yourself (DIY) technologies are already wide spread, in particular in countries with lower science funding, which in turn is the basis for the development of open technologies. Beyond financial accessibility, open hardware can be transformational to the technology access of laboratories through advantages in local production and direct knowledge transfer. Central drivers of the adoption of appropriate technologies in biolabs globally are open sharing, digital fabrication, local production, standard parts use, and detailed documentation.         _ Less;Health relatedA Transformer-based Generative Model for De Novo Molecular Design;In the scope of drug discovery, the molecular design aims to identify novel compounds from the chemical space where the potential drug-like molecules are estimated to be in the order of 10^60 - 10^100. Since this search task is computationally intractable due to the unbounded search space, deep learning draws a lot of attention as a new way of generating unseen molecules. As we seek compounds with…         _ More           In the scope of drug discovery, the molecular design aims to identify novel compounds from the chemical space where the potential drug-like molecules are estimated to be in the order of 10^60 - 10^100. Since this search task is computationally intractable due to the unbounded search space, deep learning draws a lot of attention as a new way of generating unseen molecules. As we seek compounds with specific target proteins, we propose a Transformer-based deep model for de novo target-specific molecular design. The proposed method is capable of generating both drug-like compounds (without specified targets) and target-specific compounds. The latter are generated by enforcing different keys and values of the multi-head attention for each target. In this way, we allow the generation of SMILES strings to be conditional on the specified target. Experimental results demonstrate that our method is capable of generating both valid drug-like compounds and target-specific compounds. Moreover, the sampled compounds from conditional model largely occupy the real target-specific molecules' chemical space and also cover a significant fraction of novel compounds.         _ Less;Health relatedA Transformer-based deep neural network model for SSVEP classification;"Steady-state visual evoked potential (SSVEP) is one of the most commonly used control signal in the brain-computer interface (BCI) systems. However, the conventional spatial filtering methods for SSVEP classification highly depend on the subject-specific calibration data. The need for the methods that can alleviate the demand for the calibration data become urgent. In recent years, developing the…         _ More           Steady-state visual evoked potential (SSVEP) is one of the most commonly used control signal in the brain-computer interface (BCI) systems. However, the conventional spatial filtering methods for SSVEP classification highly depend on the subject-specific calibration data. The need for the methods that can alleviate the demand for the calibration data become urgent. In recent years, developing the methods that can work in inter-subject classification scenario has become a promising new direction. As the popular deep learning model nowadays, Transformer has excellent performance and has been used in EEG signal classification tasks. Therefore, in this study, we propose a deep learning model for SSVEP classification based on Transformer structure in inter-subject classification scenario, termed as SSVEPformer, which is the first application of the transformer to the classification of SSVEP. Inspired by previous studies, the model adopts the frequency spectrum of SSVEP data as input, and explores the spectral and spatial domain information for classification. Furthermore, to fully utilize the harmonic information, an extended SSVEPformer based on the filter bank technology (FB-SSVEPformer) is proposed to further improve the classification performance. Experiments were conducted using two open datasets (Dataset 1: 10 subjects, 12-class task; Dataset 2: 35 subjects, 40-class task) in the inter-subject classification scenario. The experimental results show that the proposed models could achieve better results in terms of classification accuracy and information transfer rate, compared with other baseline methods. The proposed model validates the feasibility of deep learning models based on Transformer structure for SSVEP classification task, and could serve as a potential model to alleviate the calibration procedure in the practical application of SSVEP-based BCI systems.         _ Less";Health relatedOne Transformer Can Understand Both 2D & 3D Molecular Data;Unlike vision and language data which usually has a unique format, molecules can naturally be characterized using different chemical formulations. One can view a molecule as a 2D graph or define it as a collection of atoms located in a 3D space. For molecular representation learning, most previous works designed neural networks only for a particular data format, making the learned models likely to…         _ More           Unlike vision and language data which usually has a unique format, molecules can naturally be characterized using different chemical formulations. One can view a molecule as a 2D graph or define it as a collection of atoms located in a 3D space. For molecular representation learning, most previous works designed neural networks only for a particular data format, making the learned models likely to fail for other data formats. We believe a general-purpose neural network model for chemistry should be able to handle molecular tasks across data modalities. To achieve this goal, in this work, we develop a novel Transformer-based Molecular model called Transformer-M, which can take molecular data of 2D or 3D formats as input and generate meaningful semantic representations. Using the standard Transformer as the backbone architecture, Transformer-M develops two separated channels to encode 2D and 3D structural information and incorporate them with the atom features in the network modules. When the input data is in a particular format, the corresponding channel will be activated, and the other will be disabled. By training on 2D and 3D molecular data with properly designed supervised signals, Transformer-M automatically learns to leverage knowledge from different data modalities and correctly capture the representations. We conducted extensive experiments for Transformer-M. All empirical results show that Transformer-M can simultaneously achieve strong performance on 2D and 3D tasks, suggesting its broad applicability. The code and models will be made publicly available at https://github.com/lsj2408/Transformer-M.         _ Less;Health relatedTailoring Molecules for Protein Pockets: a Transformer-based Generative Solution for Structured-based Drug Design;Structure-based drug design is drawing growing attentions in computer-aided drug discovery. Compared with the virtual screening approach where a pre-defined library of compounds are computationally screened, de novo drug design based on the structure of a target protein can provide novel drug candidates. In this paper, we present a generative solution named TamGent (Target-aware molecule generator…         _ More           Structure-based drug design is drawing growing attentions in computer-aided drug discovery. Compared with the virtual screening approach where a pre-defined library of compounds are computationally screened, de novo drug design based on the structure of a target protein can provide novel drug candidates. In this paper, we present a generative solution named TamGent (Target-aware molecule generator with Transformer) that can directly generate candidate drugs from scratch for a given target, overcoming the limits imposed by existing compound libraries. Following the Transformer framework (a state-of-the-art framework in deep learning), we design a variant of Transformer encoder to process 3D geometric information of targets and pre-train the Transformer decoder on 10 million compounds from PubChem for candidate drug generation. Systematical evaluation on candidate compounds generated for targets from DrugBank shows that both binding affinity and drugability are largely improved. TamGent outperforms previous baselines in terms of both effectiveness and efficiency. The method is further verified by generating candidate compounds for the SARS-CoV-2 main protease and the oncogenic mutant KRAS G12C. The results show that our method not only re-discovers previously verified drug molecules , but also generates novel molecules with better docking scores, expanding the compound pool and potentially leading to the discovery of novel drugs.         _ Less;Health relatedTime-distance vision transformers in lung cancer diagnosis from longitudinal computed tomography;Features learned from single radiologic images are unable to provide information about whether and how much a lesion may be changing over time. Time-dependent features computed from repeated images can capture those changes and help identify malignant lesions by their temporal behavior. However, longitudinal medical imaging presents the unique challenge of sparse, irregular time intervals in data…         _ More           Features learned from single radiologic images are unable to provide information about whether and how much a lesion may be changing over time. Time-dependent features computed from repeated images can capture those changes and help identify malignant lesions by their temporal behavior. However, longitudinal medical imaging presents the unique challenge of sparse, irregular time intervals in data acquisition. While self-attention has been shown to be a versatile and efficient learning mechanism for time series and natural images, its potential for interpreting temporal distance between sparse, irregularly sampled spatial features has not been explored. In this work, we propose two interpretations of a time-distance vision transformer (ViT) by using (1) vector embeddings of continuous time and (2) a temporal emphasis model to scale self-attention weights. The two algorithms are evaluated based on benign versus malignant lung cancer discrimination of synthetic pulmonary nodules and lung screening computed tomography studies from the National Lung Screening Trial (NLST). Experiments evaluating the time-distance ViTs on synthetic nodules show a fundamental improvement in classifying irregularly sampled longitudinal images when compared to standard ViTs. In cross-validation on screening chest CTs from the NLST, our methods (0.785 and 0.786 AUC respectively) significantly outperform a cross-sectional approach (0.734 AUC) and match the discriminative performance of the leading longitudinal medical imaging algorithm (0.779 AUC) on benign versus malignant classification. This work represents the first self-attention-based framework for classifying longitudinal medical images. Our code is available at https://github.com/tom1193/time-distance-transformer.         _ Less;Health relatedPredicting microsatellite instability and key biomarkers in colorectal cancer from H&E-stained images: Achieving SOTA predictive performance with fewer data using Swin Transformer;Artificial intelligence (AI) models have been developed for predicting clinically relevant biomarkers, including microsatellite instability (MSI), for colorectal cancers (CRC). However, the current deep-learning networks are data-hungry and require large training datasets, which are often lacking in the medical domain. In this study, based on the latest Hierarchical Vision Transformer using Shifte…         _ More           Artificial intelligence (AI) models have been developed for predicting clinically relevant biomarkers, including microsatellite instability (MSI), for colorectal cancers (CRC). However, the current deep-learning networks are data-hungry and require large training datasets, which are often lacking in the medical domain. In this study, based on the latest Hierarchical Vision Transformer using Shifted Windows (Swin-T), we developed an efficient workflow for biomarkers in CRC (MSI, hypermutation, chromosomal instability, CpG island methylator phenotype, BRAF, and TP53 mutation) that only required relatively small datasets, but achieved the state-of-the-art (SOTA) predictive performance. Our Swin-T workflow not only substantially outperformed published models in an intra-study cross-validation experiment using TCGA-CRC-DX dataset (N = 462), but also showed excellent generalizability in cross-study external validation and delivered a SOTA AUROC of 0.90 for MSI using the MCO dataset for training (N = 1065) and the same TCGA-CRC-DX for testing. Similar performance (AUROC=0.91) was achieved by Echle and colleagues using approximately 8000 training samples (ResNet18) on the same testing dataset. Swin-T was extremely efficient using small training datasets and exhibits robust predictive performance with only 200-500 training samples. These data indicate that Swin-T may be 5-10 times more efficient than the current state-of-the-art algorithms for MSI based on ResNet18 and ShuffleNet. Furthermore, the Swin-T models showed promise as pre-screening tests for MSI status and BRAF mutation status, which could exclude and reduce the samples before the subsequent standard testing in a cascading diagnostic workflow to allow turnaround time reduction and cost saving.         _ Less;Health relatedCoViT: Real-time phylogenetics for the SARS-CoV-2 pandemic using Vision Transformers;Real-time viral genome detection, taxonomic classification and phylogenetic analysis are critical for efficient tracking and control of viral pandemics such as Covid-19. However, the unprecedented and still growing amounts of viral genome data create a computational bottleneck, which effectively prevents the real-time pandemic tracking. For genomic tracing to work effectively, each new viral genom…         _ More           Real-time viral genome detection, taxonomic classification and phylogenetic analysis are critical for efficient tracking and control of viral pandemics such as Covid-19. However, the unprecedented and still growing amounts of viral genome data create a computational bottleneck, which effectively prevents the real-time pandemic tracking. For genomic tracing to work effectively, each new viral genome sequence must be placed in its pangenomic context. Re-inferring the full phylogeny of SARS-CoV-2, with datasets containing millions of samples, is prohibitively slow even using powerful computational resources. We are attempting to alleviate the computational bottleneck by modifying and applying Vision Transformer, a recently developed neural network model for image recognition, to taxonomic classification and placement of viral genomes, such as SARS-CoV-2. Our solution, CoViT, places SARS-CoV-2 genome accessions onto SARS-CoV-2 phylogenetic tree with the accuracy of 94.2%. Since CoViT is a classification neural network, it provides more than one likely placement. Specifically, one of the two most likely placements suggested by CoViT is correct with the probability of 97.9%. The probability of the correct placement to be found among the five most likely placements generated by CoViT is 99.8%. The placement time is 0.055s per individual genome running on NVIDIAs GeForce RTX 2080 Ti GPU. We make CoViT available to research community through GitHub: https://github.com/zuherJahshan/covit.         _ Less;Health relatedA Transformer-based Neural Language Model that Synthesizes Brain Activation Maps from Free-Form Text Queries;Neuroimaging studies are often limited by the number of subjects and cognitive processes that can be feasibly interrogated. However, a rapidly growing number of neuroscientific studies have collectively accumulated an extensive wealth of results. Digesting this growing literature and obtaining novel insights remains to be a major challenge, since existing meta-analytic tools are constrained to key…         _ More           Neuroimaging studies are often limited by the number of subjects and cognitive processes that can be feasibly interrogated. However, a rapidly growing number of neuroscientific studies have collectively accumulated an extensive wealth of results. Digesting this growing literature and obtaining novel insights remains to be a major challenge, since existing meta-analytic tools are constrained to keyword queries. In this paper, we present Text2Brain, an easy to use tool for synthesizing brain activation maps from open-ended text queries. Text2Brain was built on a transformer-based neural network language model and a coordinate-based meta-analysis of neuroimaging studies. Text2Brain combines a transformer-based text encoder and a 3D image generator, and was trained on variable-length text snippets and their corresponding activation maps sampled from 13,000 published studies. In our experiments, we demonstrate that Text2Brain can synthesize meaningful neural activation patterns from various free-form textual descriptions. Text2Brain is available at https://braininterpreter.com as a web-based tool for efficiently searching through the vast neuroimaging literature and generating new hypotheses.         _ Less;Health relatedTCR: A Transformer Based Deep Network for Predicting Cancer Drugs Response;              Predicting clinical outcomes to anti-cancer drugs on a personalized basis is challenging in cancer treatment due to the heterogeneity of tumors. Traditional computational efforts have been made to model the effect of drug response on individual samples depicted by their molecular profile, yet overfitting occurs because of the high dimension for omics data, hindering models from clinical applicatio…         _ More           Predicting clinical outcomes to anti-cancer drugs on a personalized basis is challenging in cancer treatment due to the heterogeneity of tumors. Traditional computational efforts have been made to model the effect of drug response on individual samples depicted by their molecular profile, yet overfitting occurs because of the high dimension for omics data, hindering models from clinical application. Recent research shows that deep learning is a promising approach to build drug response models by learning alignment patterns between drugs and samples. However, existing studies employed the simple feature fusion strategy and only considered the drug features as a whole representation while ignoring the substructure information that may play a vital role when aligning drugs and genes. Hereby in this paper, we propose TCR (Transformer based network for Cancer drug Response) to predict anti-cancer drug response. By utilizing an attention mechanism, TCR is able to learn the interactions between drug atom/sub-structure and molecular signatures efficiently in our study. Furthermore, a dual loss function and cross sampling strategy were designed to improve the prediction power of TCR. We show that TCR outperformed all other methods under various data splitting strategies on all evaluation matrices (some with significant improvement). Extensive experiments demonstrate that TCR shows significantly improved generalization ability on independent in-vitro experiments and in-vivo real patient data. Our study highlights the prediction power of TCR and its potential value for cancer drug repurpose and precision oncology treatment.         _ Less;Health relatedMuRiT: Efficient Computation of Pathwise Persistence Barcodes in Multi-Filtered Flag Complexes via Vietoris-Rips Transformations;Multi-parameter persistent homology naturally arises in applications of persistent topology to data that come with extra information depending on additional parameters, like for example time series data. We introduce the concept of a Vietoris-Rips transformation, a method that reduces the computation of the one-parameter persistent homology of pathwise subcomplexes in multi-filtered flag complexes…         _ More           Multi-parameter persistent homology naturally arises in applications of persistent topology to data that come with extra information depending on additional parameters, like for example time series data. We introduce the concept of a Vietoris-Rips transformation, a method that reduces the computation of the one-parameter persistent homology of pathwise subcomplexes in multi-filtered flag complexes to the computation of the Vietoris-Rips persistent homology of certain semimetric spaces. The corresponding pathwise persistence barcodes track persistence features of the ambient multi-filtered complex and can in particular be used to recover the rank invariant in multi-parameter persistent homology. We present MuRiT, a scalable algorithm that computes the pathwise persistence barcodes of multi-filtered flag complexes by means of Vietoris-Rips transformations. Moreover, we provide an efficient software implementation of the MuRiT algorithm which resorts to Ripser for the actual computation of Vietoris-Rips persistence barcodes. To demonstrate the applicability of MuRiT to real-world datasets, we establish MuRiT as part of our CoVtRec pipeline for the surveillance of the convergent evolution of the coronavirus SARS-CoV-2 in the current COVID-19 pandemic.         _ Less;Health relatedPre-training Transformers for Molecular Property Prediction Using Reaction Prediction;Molecular property prediction is essential in chemistry, especially for drug discovery applications. However, available molecular property data is often limited, encouraging the transfer of information from related data. Transfer learning has had a tremendous impact in fields like Computer Vision and Natural Language Processing signaling for its potential in molecular property prediction. We prese…         _ More           Molecular property prediction is essential in chemistry, especially for drug discovery applications. However, available molecular property data is often limited, encouraging the transfer of information from related data. Transfer learning has had a tremendous impact in fields like Computer Vision and Natural Language Processing signaling for its potential in molecular property prediction. We present a pre-training procedure for molecular representation learning using reaction data and use it to pre-train a SMILES Transformer. We fine-tune and evaluate the pre-trained model on 12 molecular property prediction tasks from MoleculeNet within physical chemistry, biophysics, and physiology and show a statistically significant positive effect on 5 of the 12 tasks compared to a non-pre-trained baseline model.         _ Less;Health relatedTransformer based Models for Unsupervised Anomaly Segmentation in Brain MR Images;The quality of patient care associated with diagnostic radiology is proportionate to a physician workload. Segmentation is a fundamental limiting precursor to both diagnostic and therapeutic procedures. Advances in machine learning (ML) aim to increase diagnostic efficiency by replacing a single application with generalized algorithms. The goal of unsupervised anomaly detection (UAD) is to identif…         _ More           The quality of patient care associated with diagnostic radiology is proportionate to a physician workload. Segmentation is a fundamental limiting precursor to both diagnostic and therapeutic procedures. Advances in machine learning (ML) aim to increase diagnostic efficiency by replacing a single application with generalized algorithms. The goal of unsupervised anomaly detection (UAD) is to identify potential anomalous regions unseen during training, where convolutional neural network (CNN) based autoencoders (AEs) and variational autoencoders (VAEs) are considered a de facto approach for reconstruction based-anomaly segmentation. The restricted receptive field in CNNs limits the CNN to model the global context. Hence, if the anomalous regions cover large parts of the image, the CNN-based AEs are not capable of bringing a semantic understanding of the image. Meanwhile, vision transformers (ViTs) have emerged as a competitive alternative to CNNs. It relies on the self-attention mechanism that can relate image patches to each other. We investigate in this paper Transformer capabilities in building AEs for the reconstruction-based UAD task to reconstruct a coherent and more realistic image. We focus on anomaly segmentation for brain magnetic resonance imaging (MRI) and present five Transformer-based models while enabling segmentation performance comparable to or superior to state-of-the-art (SOTA) models. The source code is made publicly available on GitHub: https://github.com/ahmedgh970/Transformers_Unsupervised_Anomaly_Segmentation.git.         _ Less;Health relatedCross-Modal Transformer GAN: A Brain Structure-Function Deep Fusing Framework for Alzheimer's Disease;              Cross-modal fusion of different types of neuroimaging data has shown great promise for predicting the progression of Alzheimer's Disease(AD). However, most existing methods applied in neuroimaging can not efficiently fuse the functional and structural information from multi-modal neuroimages. In this work, a novel cross-modal transformer generative adversarial network(CT-GAN) is proposed to fuse f…         _ More           Cross-modal fusion of different types of neuroimaging data has shown great promise for predicting the progression of Alzheimer's Disease(AD). However, most existing methods applied in neuroimaging can not efficiently fuse the functional and structural information from multi-modal neuroimages. In this work, a novel cross-modal transformer generative adversarial network(CT-GAN) is proposed to fuse functional information contained in resting-state functional magnetic resonance imaging (rs-fMRI) and structural information contained in Diffusion Tensor Imaging (DTI). The developed bi-attention mechanism can match functional information to structural information efficiently and maximize the capability of extracting complementary information from rs-fMRI and DTI. By capturing the deep complementary information between structural features and functional features, the proposed CT-GAN can detect the AD-related brain connectivity, which could be used as a bio-marker of AD. Experimental results show that the proposed model can not only improve classification performance but also detect the AD-related brain connectivity effectively.         _ Less;Health relatedTransformer Neural Networks Attending to Both Sequence and Structure for Protein Prediction Tasks;              The increasing number of protein sequences decoded from genomes is opening up new avenues of research on linking protein sequence to function with transformer neural networks. Recent research has shown that the number of known protein sequences supports learning useful, task-agnostic sequence representations via transformers. In this paper, we posit that learning joint sequence-structure represent…         _ More           The increasing number of protein sequences decoded from genomes is opening up new avenues of research on linking protein sequence to function with transformer neural networks. Recent research has shown that the number of known protein sequences supports learning useful, task-agnostic sequence representations via transformers. In this paper, we posit that learning joint sequence-structure representations yields better representations for function-related prediction tasks. We propose a transformer neural network that attends to both sequence and tertiary structure. We show that such joint representations are more powerful than sequence-based representations only, and they yield better performance on superfamily membership across various metrics.         _ Less;Health relatedSeeing the forest and the tree: Building representations of both individual and collective dynamics with transformers;"              Complex time-varying systems are often studied by abstracting away from the dynamics of individual components to build a model of the population-level dynamics from the start. However, when building a population-level description, it can be easy to lose sight of each individual and how they contribute to the larger picture. In this paper, we present a novel transformer architecture for learning fr…         _ More           Complex time-varying systems are often studied by abstracting away from the dynamics of individual components to build a model of the population-level dynamics from the start. However, when building a population-level description, it can be easy to lose sight of each individual and how they contribute to the larger picture. In this paper, we present a novel transformer architecture for learning from time-varying data that builds descriptions of both the individual as well as the collective population dynamics. Rather than combining all of our data into our model at the onset, we develop a separable architecture that operates on individual time-series first before passing them forward; this induces a permutation-invariance property and can be used to transfer across systems of different size and order. After demonstrating that our model can be applied to successfully recover complex interactions and dynamics in many-body systems, we apply our approach to populations of neurons in the nervous system. On neural activity datasets, we show that our model not only yields robust decoding performance, but also provides impressive performance in transfer across recordings of different animals without any neuron-level correspondence. By enabling flexible pre-training that can be transferred to neural recordings of different size and order, our work provides a first step towards creating a foundation model for neural decoding.         _ Less";Health relatedSTNDT: Modeling Neural Population Activity with a Spatiotemporal Transformer;              Modeling neural population dynamics underlying noisy single-trial spiking activities is essential for relating neural observation and behavior. A recent non-recurrent method - Neural Data Transformers (NDT) - has shown great success in capturing neural dynamics with low inference latency without an explicit dynamical model. However, NDT focuses on modeling the temporal evolution of the population…         _ More           Modeling neural population dynamics underlying noisy single-trial spiking activities is essential for relating neural observation and behavior. A recent non-recurrent method - Neural Data Transformers (NDT) - has shown great success in capturing neural dynamics with low inference latency without an explicit dynamical model. However, NDT focuses on modeling the temporal evolution of the population activity while neglecting the rich covariation between individual neurons. In this paper we introduce SpatioTemporal Neural Data Transformer (STNDT), an NDT-based architecture that explicitly models responses of individual neurons in the population across time and space to uncover their underlying firing rates. In addition, we propose a contrastive learning loss that works in accordance with mask modeling objective to further improve the predictive performance. We show that our model achieves state-of-the-art performance on ensemble level in estimating neural activities across four neural datasets, demonstrating its capability to capture autonomous and non-autonomous dynamics spanning different cortical regions while being completely agnostic to the specific behaviors at hand. Furthermore, STNDT spatial attention mechanism reveals consistently important subsets of neurons that play a vital role in driving the response of the entire population, providing interpretability and key insights into how the population of neurons performs computation.         _ Less;Health relatedKPGT: Knowledge-Guided Pre-training of Graph Transformer for Molecular Property Prediction;              Designing accurate deep learning models for molecular property prediction plays an increasingly essential role in drug and material discovery. Recently, due to the scarcity of labeled molecules, self-supervised learning methods for learning generalizable and transferable representations of molecular graphs have attracted lots of attention. In this paper, we argue that there exist two major issues…         _ More           Designing accurate deep learning models for molecular property prediction plays an increasingly essential role in drug and material discovery. Recently, due to the scarcity of labeled molecules, self-supervised learning methods for learning generalizable and transferable representations of molecular graphs have attracted lots of attention. In this paper, we argue that there exist two major issues hindering current self-supervised learning methods from obtaining desired performance on molecular property prediction, that is, the ill-defined pre-training tasks and the limited model capacity. To this end, we introduce Knowledge-guided Pre-training of Graph Transformer (KPGT), a novel self-supervised learning framework for molecular graph representation learning, to alleviate the aforementioned issues and improve the performance on the downstream molecular property prediction tasks. More specifically, we first introduce a high-capacity model, named Line Graph Transformer (LiGhT), which emphasizes the importance of chemical bonds and is mainly designed to model the structural information of molecular graphs. Then, a knowledge-guided pre-training strategy is proposed to exploit the additional knowledge of molecules to guide the model to capture the abundant structural and semantic information from large-scale unlabeled molecular graphs. Extensive computational tests demonstrated that KPGT can offer superior performance over current state-of-the-art methods on several molecular property prediction tasks.         _ Less;Health relatedSurface Analysis with Vision Transformers;              The extension of convolutional neural networks (CNNs) to non-Euclidean geometries has led to multiple frameworks for studying manifolds. Many of those methods have shown design limitations resulting in poor modelling of long-range associations, as the generalisation of convolutions to irregular surfaces is non-trivial. Recent state-of-the-art performance of Vision Transformers (ViTs) demonstrates…         _ More           The extension of convolutional neural networks (CNNs) to non-Euclidean geometries has led to multiple frameworks for studying manifolds. Many of those methods have shown design limitations resulting in poor modelling of long-range associations, as the generalisation of convolutions to irregular surfaces is non-trivial. Recent state-of-the-art performance of Vision Transformers (ViTs) demonstrates that a general-purpose architecture, which implements self-attention, could replace the local feature learning operations of CNNs. Motivated by the success of attention-modelling in computer vision, we extend ViTs to surfaces by reformulating the task of surface learning as a sequence-to-sequence problem and propose a patching mechanism for surface meshes. We validate the performance of the proposed Surface Vision Transformer (SiT) on two brain age prediction tasks in the developing Human Connectome Project (dHCP) dataset and investigate the impact of pre-training on model performance. Experiments show that the SiT outperforms many surface CNNs, while indicating some evidence of general transformation invariance. Code available at https://github.com/metrics-lab/surface-vision-transformers         _ Less;Health relatedProbabilistic Transformer: Modelling Ambiguities and Distributions for RNA Folding and Molecule Design;Our world is ambiguous and this is reflected in the data we use to train our algorithms. This is particularly true when we try to model natural processes where collected data is affected by noisy measurements and differences in measurement techniques. Sometimes, the process itself is ambiguous, such as in the case of RNA folding, where the same nucleotide sequence can fold into different structure…         _ More           Our world is ambiguous and this is reflected in the data we use to train our algorithms. This is particularly true when we try to model natural processes where collected data is affected by noisy measurements and differences in measurement techniques. Sometimes, the process itself is ambiguous, such as in the case of RNA folding, where the same nucleotide sequence can fold into different structures. This suggests that a predictive model should have similar probabilistic characteristics to match the data it models. Therefore, we propose a hierarchical latent distribution to enhance one of the most successful deep learning models, the Transformer, to accommodate ambiguities and data distributions. We show the benefits of our approach (1) on a synthetic task that captures the ability to learn a hidden data distribution, (2) with state-of-the-art results in RNA folding that reveal advantages on highly ambiguous data, and (3) demonstrating its generative capabilities on property-based molecule design by implicitly learning the underlying distributions and outperforming existing work.         _ Less;Health relatedDProQ: A Gated-Graph Transformer for Protein Complex Structure Assessment;Proteins interact to form complexes to carry out essential biological functions. Computational methods have been developed to predict the structures of protein complexes. However, an important challenge in protein complex structure prediction is to estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be…         _ More           Proteins interact to form complexes to carry out essential biological functions. Computational methods have been developed to predict the structures of protein complexes. However, an important challenge in protein complex structure prediction is to estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. We challenge this significant task with DProQ, which introduces a gated neighborhood-modulating Graph Transformer (GGT) designed to predict the quality of 3D protein complex structures. Notably, we incorporate node and edge gates within a novel Graph Transformer framework to control information flow during graph message passing. We train and evaluate DProQ on four newly-developed datasets that we make publicly available in this work. Our rigorous experiments demonstrate that DProQ achieves state-of-the-art performance in ranking protein complex structures.         _ Less;Health relatedChemical transformer compression for accelerating both training and inference of molecular modeling;Transformer models have been developed in molecular science with excellent performance in applications including quantitative structure-activity relationship (QSAR) and virtual screening (VS). Compared with other types of models, however, they are large, which results in a high hardware requirement to abridge time for both training and inference processes. In this work, cross-layer parameter shari…         _ More           Transformer models have been developed in molecular science with excellent performance in applications including quantitative structure-activity relationship (QSAR) and virtual screening (VS). Compared with other types of models, however, they are large, which results in a high hardware requirement to abridge time for both training and inference processes. In this work, cross-layer parameter sharing (CLPS), and knowledge distillation (KD) are used to reduce the sizes of transformers in molecular science. Both methods not only have competitive QSAR predictive performance as compared to the original BERT model, but also are more parameter efficient. Furthermore, by integrating CLPS and KD into a two-state chemical network, we introduce a new deep lite chemical transformer model, DeLiCaTe. DeLiCaTe captures general-domains as well as task-specific knowledge, which lead to a 4x faster rate of both training and inference due to a 10- and 3-times reduction of the number of parameters and layers, respectively. Meanwhile, it achieves comparable performance in QSAR and VS modeling. Moreover, we anticipate that the model compression strategy provides a pathway to the creation of effective generative transformer models for organic drug and material design.         _ Less;Health relatedAntigenic cooperation in Viral Populations: Transformation of Functions of Intra-Host Viral Variants;              In this paper we study intra-host viral adaptation by antigenic cooperation - a mechanism of immune escape that serves as an alternative to the standard mechanism of escape by continuous genomic diversification and allows to explain a number of experimental observations associated with the establishment of chronic infections by highly mutable viruses. Within this mechanism, the topology of a cross…         _ More           In this paper we study intra-host viral adaptation by antigenic cooperation - a mechanism of immune escape that serves as an alternative to the standard mechanism of escape by continuous genomic diversification and allows to explain a number of experimental observations associated with the establishment of chronic infections by highly mutable viruses. Within this mechanism, the topology of a cross-immunoreactivity network forces intra-host viral variants to specialize for complementary roles and adapt to host's immune response as a quasi-social ecosystem. Here we study dynamical changes in immune adaptation caused by evolutionary and epidemiological events. First, we show that the emergence of a viral variant with altered antigenic features may result in a rapid re-arrangement of the viral ecosystem and a change in the roles played by existing viral variants. In particular, it may push the population under immune escape by genomic diversification towards the stable state of adaptation by antigenic cooperation. Next, we study the effect of a viral transmission between two chronically infected hosts, which results in merging of two intra-host viral populations in the state of stable immune-adapted equilibrium. In this case, we also describe how the newly formed viral population adapts to the host's environment by changing the functions of its members. The results are obtained analytically for minimal cross-immunoreactivity networks and numerically for larger populations.         _ Less;Health relatedDisentangling Spatial-Temporal Functional Brain Networks via Twin-Transformers;              How to identify and characterize functional brain networks (BN) is fundamental to gain system-level insights into the mechanisms of brain organizational architecture. Current functional magnetic resonance (fMRI) analysis highly relies on prior knowledge of specific patterns in either spatial (e.g., resting-state network) or temporal (e.g., task stimulus) domain. In addition, most approaches aim to…         _ More           How to identify and characterize functional brain networks (BN) is fundamental to gain system-level insights into the mechanisms of brain organizational architecture. Current functional magnetic resonance (fMRI) analysis highly relies on prior knowledge of specific patterns in either spatial (e.g., resting-state network) or temporal (e.g., task stimulus) domain. In addition, most approaches aim to find group-wise common functional networks, individual-specific functional networks have been rarely studied. In this work, we propose a novel Twin-Transformers framework to simultaneously infer common and individual functional networks in both spatial and temporal space, in a self-supervised manner. The first transformer takes space-divided information as input and generates spatial features, while the second transformer takes time-related information as input and outputs temporal features. The spatial and temporal features are further separated into common and individual ones via interactions (weights sharing) and constraints between the two transformers. We applied our TwinTransformers to Human Connectome Project (HCP) motor task-fMRI dataset and identified multiple common brain networks, including both task-related and resting-state networks (e.g., default mode network). Interestingly, we also successfully recovered a set of individual-specific networks that are not related to task stimulus and only exist at the individual level.         _ Less;Health relatedSpatio-Temporal Analysis of Transformer based Architecture for Attention Estimation from EEG;              For many years now, understanding the brain mechanism has been a great research subject in many different fields. Brain signal processing and especially electroencephalogram (EEG) has recently known a growing interest both in academia and industry. One of the main examples is the increasing number of Brain-Computer Interfaces (BCI) aiming to link brains and computers. In this paper, we present a n…         _ More           For many years now, understanding the brain mechanism has been a great research subject in many different fields. Brain signal processing and especially electroencephalogram (EEG) has recently known a growing interest both in academia and industry. One of the main examples is the increasing number of Brain-Computer Interfaces (BCI) aiming to link brains and computers. In this paper, we present a novel framework allowing us to retrieve the attention state, i.e degree of attention given to a specific task, from EEG signals. While previous methods often consider the spatial relationship in EEG through electrodes and process them in recurrent or convolutional based architecture, we propose here to also exploit the spatial and temporal information with a transformer-based network that has already shown its supremacy in many machine-learning (ML) related studies, e.g. machine translation. In addition to this novel architecture, an extensive study on the feature extraction methods, frequential bands and temporal windows length has also been carried out. The proposed network has been trained and validated on two public datasets and achieves higher results compared to state-of-the-art models. As well as proposing better results, the framework could be used in real applications, e.g. Attention Deficit Hyperactivity Disorder (ADHD) symptoms or vigilance during a driving assessment.         _ Less;Health relatedTransformer-Based Self-Supervised Learning for Emotion Recognition;              In order to exploit representations of time-series signals, such as physiological signals, it is essential that these representations capture relevant information from the whole signal. In this work, we propose to use a Transformer-based model to process electrocardiograms (ECG) for emotion recognition. Attention mechanisms of the Transformer can be used to build contextualized representations for…         _ More           In order to exploit representations of time-series signals, such as physiological signals, it is essential that these representations capture relevant information from the whole signal. In this work, we propose to use a Transformer-based model to process electrocardiograms (ECG) for emotion recognition. Attention mechanisms of the Transformer can be used to build contextualized representations for a signal, giving more importance to relevant parts. These representations may then be processed with a fully-connected network to predict emotions. To overcome the relatively small size of datasets with emotional labels, we employ self-supervised learning. We gathered several ECG datasets with no labels of emotion to pre-train our model, which we then fine-tuned for emotion recognition on the AMIGOS dataset. We show that our approach reaches state-of-the-art performances for emotion recognition using ECG signals on AMIGOS. More generally, our experiments show that transformers and pre-training are promising strategies for emotion recognition with physiological signals.         _ Less;Health relatedComparison of EEG based epilepsy diagnosis using neural networks and wavelet transform;              Epilepsy is one of the common neurological disorders characterized by recurrent and uncontrollable seizures, which seriously affect the life of patients. In many cases, electroencephalograms signal can provide important physiological information about the activity of the human brain which can be used to diagnose epilepsy. However, visual inspection of a large number of electroencephalogram signals…         _ More           Epilepsy is one of the common neurological disorders characterized by recurrent and uncontrollable seizures, which seriously affect the life of patients. In many cases, electroencephalograms signal can provide important physiological information about the activity of the human brain which can be used to diagnose epilepsy. However, visual inspection of a large number of electroencephalogram signals is very time-consuming and can often lead to inconsistencies in physicians' diagnoses. Quantification of abnormalities in brain signals can indicate brain conditions and pathology so the electroencephalogram (EEG) signal plays a key role in the diagnosis of epilepsy. In this article, an attempt has been made to create a single instruction for diagnosing epilepsy, which consists of two steps. In the first step, a low-pass filter was used to preprocess the data and three separate mid-pass filters for different frequency bands and a multilayer neural network were designed. In the second step, the wavelet transform technique was used to process data. In particular, this paper proposes a multilayer perceptron neural network classifier for the diagnosis of epilepsy, that requires normal data and epilepsy data for education, but this classifier can recognize normal disorders, epilepsy, and even other disorders taught in educational examples. Also, the value of using electroencephalogram signal has been evaluated in two ways: using wavelet transform and non-using wavelet transform. Finally, the evaluation results indicate a relatively uniform impact factor on the use or non-use of wavelet transform on the improvement of epilepsy data functions, but in the end, it was shown that the use of perceptron multilayer neural network can provide a higher accuracy coefficient for experts.         _ Less;Health relatedSurface Vision Transformers: Flexible Attention-Based Modelling of Biomedical Surfaces;              Recent state-of-the-art performances of Vision Transformers (ViT) in computer vision tasks demonstrate that a general-purpose architecture, which implements long-range self-attention, could replace the local feature learning operations of convolutional neural networks. In this paper, we extend ViTs to surfaces by reformulating the task of surface learning as a sequence-to-sequence learning problem…         _ More           Recent state-of-the-art performances of Vision Transformers (ViT) in computer vision tasks demonstrate that a general-purpose architecture, which implements long-range self-attention, could replace the local feature learning operations of convolutional neural networks. In this paper, we extend ViTs to surfaces by reformulating the task of surface learning as a sequence-to-sequence learning problem, by proposing patching mechanisms for general surface meshes. Sequences of patches are then processed by a transformer encoder and used for classification or regression. We validate our method on a range of different biomedical surface domains and tasks: brain age prediction in the developing Human Connectome Project (dHCP), fluid intelligence prediction in the Human Connectome Project (HCP), and coronary artery calcium score classification using surfaces from the Scottish Computed Tomography of the Heart (SCOT-HEART) dataset, and investigate the impact of pretraining and data augmentation on model performance. Results suggest that Surface Vision Transformers (SiT) demonstrate consistent improvement over geometric deep learning methods for brain age and fluid intelligence prediction and achieve comparable performance on calcium score classification to standard metrics used in clinical practice. Furthermore, analysis of transformer attention maps offers clear and individualised predictions of the features driving each task. Code is available on Github: https://github.com/metrics-lab/surface-vision-transformers         _ Less;Health relatedSurface Vision Transformers: Attention-Based Modelling applied to Cortical Analysis;              The extension of convolutional neural networks (CNNs) to non-Euclidean geometries has led to multiple frameworks for studying manifolds. Many of those methods have shown design limitations resulting in poor modelling of long-range associations, as the generalisation of convolutions to irregular surfaces is non-trivial. Motivated by the success of attention-modelling in computer vision, we translat…         _ More           The extension of convolutional neural networks (CNNs) to non-Euclidean geometries has led to multiple frameworks for studying manifolds. Many of those methods have shown design limitations resulting in poor modelling of long-range associations, as the generalisation of convolutions to irregular surfaces is non-trivial. Motivated by the success of attention-modelling in computer vision, we translate convolution-free vision transformer approaches to surface data, to introduce a domain-agnostic architecture to study any surface data projected onto a spherical manifold. Here, surface patching is achieved by representing spherical data as a sequence of triangular patches, extracted from a subdivided icosphere. A transformer model encodes the sequence of patches via successive multi-head self-attention layers while preserving the sequence resolution. We validate the performance of the proposed Surface Vision Transformer (SiT) on the task of phenotype regression from cortical surface metrics derived from the Developing Human Connectome Project (dHCP). Experiments show that the SiT generally outperforms surface CNNs, while performing comparably on registered and unregistered data. Analysis of transformer attention maps offers strong potential to characterise subtle cognitive developmental patterns.         _ Less;Health relatedDPST: De Novo Peptide Sequencing with Amino-Acid-Aware Transformers;"De novo peptide sequencing aims to recover amino acid sequences of a peptide from tandem mass spectrometry (MS) data. Existing approaches for de novo analysis enumerate MS evidence for all amino acid classes during inference. It leads to over-trimming on receptive fields of MS data and restricts MS evidence associated with following undecoded amino acids. Our approach, DPST, circumvents these limi…         _ More           De novo peptide sequencing aims to recover amino acid sequences of a peptide from tandem mass spectrometry (MS) data. Existing approaches for de novo analysis enumerate MS evidence for all amino acid classes during inference. It leads to over-trimming on receptive fields of MS data and restricts MS evidence associated with following undecoded amino acids. Our approach, DPST, circumvents these limitations with two key components: (1) A confidence value aggregation encoder to sketch spectrum representations according to amino-acid-based connectivity among MS; (2) A global-local fusion decoder to progressively assimilate contextualized spectrum representations with a predefined preconception of localized MS evidence and amino acid priors. Our components originate from a closed-form solution and selectively attend to informative amino-acid-aware MS representations. Through extensive empirical studies, we demonstrate the superiority of DPST, showing that it outperforms state-of-the-art approaches by a margin of 12% - 19% peptide accuracy.         _ Less";Health relatedTransforming Gait: Video-Based Spatiotemporal Gait Analysis;Human pose estimation from monocular video is a rapidly advancing field that offers great promise to human movement science and rehabilitation. This potential is tempered by the smaller body of work ensuring the outputs are clinically meaningful and properly calibrated. Gait analysis, typically performed in a dedicated lab, produces precise measurements including kinematics and step timing. Using…         _ More           Human pose estimation from monocular video is a rapidly advancing field that offers great promise to human movement science and rehabilitation. This potential is tempered by the smaller body of work ensuring the outputs are clinically meaningful and properly calibrated. Gait analysis, typically performed in a dedicated lab, produces precise measurements including kinematics and step timing. Using over 7000 monocular video from an instrumented gait analysis lab, we trained a neural network to map 3D joint trajectories and the height of individuals onto interpretable biomechanical outputs including gait cycle timing and sagittal plane joint kinematics and spatiotemporal trajectories. This task specific layer produces accurate estimates of the timing of foot contact and foot off events. After parsing the kinematic outputs into individual gait cycles, it also enables accurate cycle-by-cycle estimates of cadence, step time, double and single support time, walking speed and step length.         _ Less;Health relatedJoint rotational invariance and adversarial training of a dual-stream Transformer yields state of the art Brain-Score for Area V4;"Modern high-scoring models of vision in the brain score competition do not stem from Vision Transformers. However, in this paper, we provide evidence against the unexpected trend of Vision Transformers (ViT) being not perceptually aligned with human visual representations by showing how a dual-stream Transformer, a CrossViT$~\textit{a la}$ Chen et al. (2021), under a joint rotationally-invariant a…         _ More           Modern high-scoring models of vision in the brain score competition do not stem from Vision Transformers. However, in this paper, we provide evidence against the unexpected trend of Vision Transformers (ViT) being not perceptually aligned with human visual representations by showing how a dual-stream Transformer, a CrossViT$~\textit{a la}$ Chen et al. (2021), under a joint rotationally-invariant and adversarial optimization procedure yields 2nd place in the aggregate Brain-Score 2022 competition(Schrimpf et al., 2020b) averaged across all visual categories, and at the time of the competition held 1st place for the highest explainable variance of area V4. In addition, our current Transformer-based model also achieves greater explainable variance for areas V4, IT and Behaviour than a biologically-inspired CNN (ResNet50) that integrates a frontal V1-like computation module (Dapello et al.,2020). To assess the contribution of the optimization scheme with respect to the CrossViT architecture, we perform several additional experiments on differently optimized CrossViT's regarding adversarial robustness, common corruption benchmarks, mid-ventral stimuli interpretation and feature inversion. Against our initial expectations, our family of results provides tentative support for an $\textit{""All roads lead to Rome""}$ argument enforced via a joint optimization rule even for non biologically-motivated models of vision such as Vision Transformers. Code is available at https://github.com/williamberrios/BrainScore-Transformers         _ Less";Health relatedSelf-Supervised Vision Transformers Learn Visual Concepts in Histopathology;Tissue phenotyping is a fundamental task in learning objective characterizations of histopathologic biomarkers within the tumor-immune microenvironment in cancer pathology. However, whole-slide imaging (WSI) is a complex computer vision in which: 1) WSIs have enormous image resolutions with precludes large-scale pixel-level efforts in data curation, and 2) diversity of morphological phenotypes res…         _ More           Tissue phenotyping is a fundamental task in learning objective characterizations of histopathologic biomarkers within the tumor-immune microenvironment in cancer pathology. However, whole-slide imaging (WSI) is a complex computer vision in which: 1) WSIs have enormous image resolutions with precludes large-scale pixel-level efforts in data curation, and 2) diversity of morphological phenotypes results in inter- and intra-observer variability in tissue labeling. To address these limitations, current efforts have proposed using pretrained image encoders (transfer learning from ImageNet, self-supervised pretraining) in extracting morphological features from pathology, but have not been extensively validated. In this work, we conduct a search for good representations in pathology by training a variety of self-supervised models with validation on a variety of weakly-supervised and patch-level tasks. Our key finding is in discovering that Vision Transformers using DINO-based knowledge distillation are able to learn data-efficient and interpretable features in histology images wherein the different attention heads learn distinct morphological phenotypes. We make evaluation code and pretrained weights publicly-available at: https://github.com/Richarizardd/Self-Supervised-ViT-Path.         _ Less;Health relatedRegression Transformer: Concurrent sequence regression and generation for molecular language modeling;              Despite significant progress of generative models in the natural sciences, their controllability remains challenging. One fundamentally missing aspect of molecular or protein generative models is an inductive bias that can reflect continuous properties of interest. To that end, we propose the Regression Transformer (RT), a novel method that abstracts regression as a conditional sequence modeling p…         _ More           Despite significant progress of generative models in the natural sciences, their controllability remains challenging. One fundamentally missing aspect of molecular or protein generative models is an inductive bias that can reflect continuous properties of interest. To that end, we propose the Regression Transformer (RT), a novel method that abstracts regression as a conditional sequence modeling problem. This introduces a new paradigm of multitask language models which seamlessly bridge sequence regression and conditional sequence generation.   We thoroughly demonstrate that, despite using a nominal-scale training objective, the RT matches or surpasses the performance of conventional regression models in property prediction tasks of small molecules, proteins and chemical reactions. Critically, priming the same model with continuous properties yields a highly competitive conditional generative model that outperforms specialized approaches in a substructure-constrained, property-driven molecule generation benchmark. Our dichotomous approach is facilitated by a novel, alternating training scheme that enables the model to decorate seed sequences by desired properties, e.g., to optimize reaction yield.   In sum, the RT is the first report of a multitask model that concurrently excels at predictive and generative tasks in biochemistry. This finds particular application in property-driven, local exploration of the chemical or protein space and could pave the road toward foundation models in material design.   The code to reproduce all experiments of the paper is available at: https://github.com/IBM/regression-transformer         _ Less;Health relatedDiffusion Tensor Estimation with Transformer Neural Networks;Diffusion tensor imaging (DTI) is a widely used method for studying brain white matter development and degeneration. However, standard DTI estimation methods depend on a large number of high-quality measurements. This would require long scan times and can be particularly difficult to achieve with certain patient populations such as neonates. Here, we propose a method that can accurately estimate t…         _ More           Diffusion tensor imaging (DTI) is a widely used method for studying brain white matter development and degeneration. However, standard DTI estimation methods depend on a large number of high-quality measurements. This would require long scan times and can be particularly difficult to achieve with certain patient populations such as neonates. Here, we propose a method that can accurately estimate the diffusion tensor from only six diffusion-weighted measurements. Our method achieves this by learning to exploit the relationships between the diffusion signals and tensors in neighboring voxels. Our model is based on transformer networks, which represent the state of the art in modeling the relationship between signals in a sequence. In particular, our model consists of two such networks. The first network estimates the diffusion tensor based on the diffusion signals in a neighborhood of voxels. The second network provides more accurate tensor estimations by learning the relationships between the diffusion signals as well as the tensors estimated by the first network in neighboring voxels. Our experiments with three datasets show that our proposed method achieves highly accurate estimations of the diffusion tensor and is significantly superior to three competing methods. Estimations produced by our method with six diffusion-weighted measurements are comparable with those of standard estimation methods with 30-88 diffusion-weighted measurements. Hence, our method promises shorter scan times and more reliable assessment of brain white matter, particularly in non-cooperative patients such as neonates and infants.         _ Less;Health relatedAccurate identification of bacteriophages from metagenomic data using Transformer;Motivation: Bacteriophages are viruses infecting bacteria. Being key players in microbial communities, they can regulate the composition/function of microbiome by infecting their bacterial hosts and mediating gene transfer. Recently, metagenomic sequencing, which can sequence all genetic materials from various microbiome, has become a popular means for new phage discovery. However, accurate and co…         _ More           Motivation: Bacteriophages are viruses infecting bacteria. Being key players in microbial communities, they can regulate the composition/function of microbiome by infecting their bacterial hosts and mediating gene transfer. Recently, metagenomic sequencing, which can sequence all genetic materials from various microbiome, has become a popular means for new phage discovery. However, accurate and comprehensive detection of phages from the metagenomic data remains difficult. High diversity/abundance, and limited reference genomes pose major challenges for recruiting phage fragments from metagenomic data. Existing alignment-based or learning-based models have either low recall or precision on metagenomic data. Results: In this work, we adopt the state-of-the-art language model, Transformer, to conduct contextual embedding for phage contigs. By constructing a protein-cluster vocabulary, we can feed both the protein composition and the proteins' positions from each contig into the Transformer. The Transformer can learn the protein organization and associations using the self-attention mechanism and predicts the label for test contigs. We rigorously tested our developed tool named PhaMer on multiple datasets with increasing difficulty, including quality RefSeq genomes, short contigs, simulated metagenomic data, mock metagenomic data, and the public IMG/VR dataset. All the experimental results show that PhaMer outperforms the state-of-the-art tools. In the real metagenomic data experiment, PhaMer improves the F1-score of phage detection by 27\%.         _ Less;Health relatedLerna: Transformer Architectures for Configuring Error Correction Tools for Short- and Long-Read Genome Sequencing;"Sequencing technologies are prone to errors, making error correction (EC) necessary for downstream applications. EC tools need to be manually configured for optimal performance. We find that the optimal parameters (e.g., k-mer size) are both tool- and dataset-dependent. Moreover, evaluating the performance (i.e., Alignment-rate or Gain) of a given tool usually relies on a reference genome, but qua…         _ More           Sequencing technologies are prone to errors, making error correction (EC) necessary for downstream applications. EC tools need to be manually configured for optimal performance. We find that the optimal parameters (e.g., k-mer size) are both tool- and dataset-dependent. Moreover, evaluating the performance (i.e., Alignment-rate or Gain) of a given tool usually relies on a reference genome, but quality reference genomes are not always available. We introduce Lerna for the automated configuration of k-mer-based EC tools. Lerna first creates a language model (LM) of the uncorrected genomic reads; then, calculates the perplexity metric to evaluate the corrected reads for different parameter choices. Next, it finds the one that produces the highest alignment rate without using a reference genome. The fundamental intuition of our approach is that the perplexity metric is inversely correlated with the quality of the assembly after error correction. Results: First, we show that the best k-mer value can vary for different datasets, even for the same EC tool. Second, we show the gains of our LM using its component attention-based transformers. We show the model's estimation of the perplexity metric before and after error correction. The lower the perplexity after correction, the better the k-mer size. We also show that the alignment rate and assembly quality computed for the corrected reads are strongly negatively correlated with the perplexity, enabling the automated selection of k-mer values for better error correction, and hence, improved assembly quality. Additionally, we show that our attention-based models have significant runtime improvement for the entire pipeline -- 18X faster than previous works, due to parallelizing the attention mechanism and the use of JIT compilation for GPU inferencing.         _ Less";Health relatedAnalyzing population dynamics models via Sumudu transform;              This study demonstrates how to construct the solutions of a more general form of population dynamics models via a blend of variational iterative method with Sumudu transform. In this paper, population growth models are formulated in the form of delay differential equations of pantograph type which is a general form for the existing models. Innovative ways are presented for obtaining the solutions…         _ More           This study demonstrates how to construct the solutions of a more general form of population dynamics models via a blend of variational iterative method with Sumudu transform. In this paper, population growth models are formulated in the form of delay differential equations of pantograph type which is a general form for the existing models. Innovative ways are presented for obtaining the solutions of population growth models where other analytic methods fail. Stimulating procedures for finding patterns and regularities in seemingly chaotic processes have been elucidated in this paper. How, when and why the changes in population sizes occur can be deduced through this study.         _ Less;Health relatedRelating transformers to models and neural representations of the hippocampal formation;"              Many deep neural network architectures loosely based on brain networks have recently been shown to replicate neural firing patterns observed in the brain. One of the most exciting and promising novel architectures, the Transformer neural network, was developed without the brain in mind. In this work, we show that transformers, when equipped with recurrent position encodings, replicate the precisel…         _ More           Many deep neural network architectures loosely based on brain networks have recently been shown to replicate neural firing patterns observed in the brain. One of the most exciting and promising novel architectures, the Transformer neural network, was developed without the brain in mind. In this work, we show that transformers, when equipped with recurrent position encodings, replicate the precisely tuned spatial representations of the hippocampal formation; most notably place and grid cells. Furthermore, we show that this result is no surprise since it is closely related to current hippocampal models from neuroscience. We additionally show the transformer version offers dramatic performance gains over the neuroscience version. This work continues to bind computations of artificial and brain networks, offers a novel understanding of the hippocampal-cortical interaction, and suggests how wider cortical areas may perform complex tasks beyond current neuroscience models such as language comprehension.         _ Less";Health relatedA Novel Heart Disease Classification Algorithm based on Fourier Transform and Persistent Homology;              Classification and prediction of heart disease is a significant problem to realize medical treatment and life protection. In this paper, persistent homology is involved to analyze electrocardiograms and a novel heart disease classification method is proposed. Each electrocardiogram becomes a point cloud by sliding windows and fast Fourier transform embedding. The obtained point cloud reveals perio…         _ More           Classification and prediction of heart disease is a significant problem to realize medical treatment and life protection. In this paper, persistent homology is involved to analyze electrocardiograms and a novel heart disease classification method is proposed. Each electrocardiogram becomes a point cloud by sliding windows and fast Fourier transform embedding. The obtained point cloud reveals periodicity and stability characteristics of electrocardiograms. By persistent homology, three topological features including normalized persistent entropy, maximum life of time and maximum life of Betty number are extracted. These topological features show the structural differences between different types of electrocardiograms and display encouraging potentiality in classification of heart disease.         _ Less;Health relatedDoes the Brain Infer Invariance Transformations from Graph Symmetries?;              The invariance of natural objects under perceptual changes is possibly encoded in the brain by symmetries in the graph of synaptic connections. The graph can be established via unsupervised learning in a biologically plausible process across different perceptual modalities. This hypothetical encoding scheme is supported by the correlation structure of naturalistic audio and image data and it predi…         _ More           The invariance of natural objects under perceptual changes is possibly encoded in the brain by symmetries in the graph of synaptic connections. The graph can be established via unsupervised learning in a biologically plausible process across different perceptual modalities. This hypothetical encoding scheme is supported by the correlation structure of naturalistic audio and image data and it predicts a neural connectivity architecture which is consistent with many empirical observations about primary sensory cortex.         _ Less;Health relatedMassFormer: Tandem Mass Spectrum Prediction for Small Molecules using Graph Transformers;              Tandem mass spectra capture fragmentation patterns that provide key structural information about a molecule. Although mass spectrometry is applied in many areas, the vast majority of small molecules lack experimental reference spectra. For over seventy years, spectrum prediction has remained a key challenge in the field. Existing deep learning methods do not leverage global structure in the molecu…         _ More           Tandem mass spectra capture fragmentation patterns that provide key structural information about a molecule. Although mass spectrometry is applied in many areas, the vast majority of small molecules lack experimental reference spectra. For over seventy years, spectrum prediction has remained a key challenge in the field. Existing deep learning methods do not leverage global structure in the molecule, potentially resulting in difficulties when generalizing to new data. In this work we propose a new model, MassFormer, for accurately predicting tandem mass spectra. MassFormer uses a graph transformer architecture to model long-distance relationships between atoms in the molecule. The transformer module is initialized with parameters obtained through a chemical pre-training task, then fine-tuned on spectral data. MassFormer outperforms competing approaches for spectrum prediction on multiple datasets, and is able to recover prior knowledge about the effect of collision energy on the spectrum. By employing gradient-based attribution methods, we demonstrate that the model can identify relationships between fragment peaks. To further highlight MassFormer's utility, we show that it can match or exceed existing prediction-based methods on two spectrum identification tasks. We provide open-source implementations of our model and baseline approaches, with the goal of encouraging future research in this area.         _ Less;Health relatedDeciphering the Language of Nature: A transformer-based language model for deleterious mutations in proteins;              Various machine-learning models, including deep neural network models, have already been developed to predict deleteriousness of missense (non-synonymous) mutations. Potential improvements to the current state of the art, however, may still benefit from a fresh look at the biological problem using more sophisticated self-adaptive machine-learning approaches. Recent advances in the natural language…         _ More           Various machine-learning models, including deep neural network models, have already been developed to predict deleteriousness of missense (non-synonymous) mutations. Potential improvements to the current state of the art, however, may still benefit from a fresh look at the biological problem using more sophisticated self-adaptive machine-learning approaches. Recent advances in the natural language processing field show transformer models-a type of deep neural network-to be particularly powerful at modeling sequence information with context dependence. In this study, we introduce MutFormer, a transformer-based model for the prediction of deleterious missense mutations, which uses reference and mutated protein sequences from the human genome as the primary features. MutFormer takes advantage of a combination of self-attention layers and convolutional layers to learn both long-range and short-range dependencies between amino acid mutations in a protein sequence. In this study, we first pre-trained MutFormer on reference protein sequences and mutated protein sequences resulting from common genetic variants observed in human populations. We next examined different fine-tuning methods to successfully apply the model to deleteriousness prediction of missense mutations. Finally, we evaluated MutFormer's performance on multiple testing data sets. We found that MutFormer showed similar or improved performance over a variety of existing tools, including those that used conventional machine-learning approaches. We conclude that MutFormer successfully considers sequence features that are not explored in previous studies and could potentially complement existing computational predictions or empirically generated functional scores to improve our understanding of disease variants.         _ Less;Health relatedScalable Bayesian divergence time estimation with ratio transformations;Divergence time estimation is crucial to provide temporal signals for dating biologically important events, from species divergence to viral transmissions in space and time. With the advent of high-throughput sequencing, recent Bayesian phylogenetic studies have analyzed hundreds to thousands of sequences. Such large-scale analyses challenge divergence time reconstruction by requiring inference on…         _ More           Divergence time estimation is crucial to provide temporal signals for dating biologically important events, from species divergence to viral transmissions in space and time. With the advent of high-throughput sequencing, recent Bayesian phylogenetic studies have analyzed hundreds to thousands of sequences. Such large-scale analyses challenge divergence time reconstruction by requiring inference on highly-correlated internal node heights that often become computationally infeasible. To overcome this limitation, we explore a ratio transformation that maps the original N - 1 internal node heights into a space of one height parameter and N - 2 ratio parameters. To make analyses scalable, we develop a collection of linear-time algorithms to compute the gradient and Jacobian-associated terms of the log-likelihood with respect to these ratios. We then apply Hamiltonian Monte Carlo sampling with the ratio transform in a Bayesian framework to learn the divergence times in four pathogenic virus phylogenies: West Nile virus, rabies virus, Lassa virus and Ebola virus. Our method both resolves a mixing issue in the West Nile virus example and improves inference efficiency by at least 5-fold for the Lassa and rabies virus examples. Our method also makes it now computationally feasible to incorporate mixed-effects molecular clock models for the Ebola virus example, confirms the findings from the original study and reveals clearer multimodal distributions of the divergence times of some clades of interest.         _ Less;Health relatedImproved Drug-target Interaction Prediction with Intermolecular Graph Transformer;The identification of active binding drugs for target proteins (termed as drug-target interaction prediction) is the key challenge in virtual screening, which plays an essential role in drug discovery. Although recent deep learning-based approaches achieved better performance than molecular docking, existing models often neglect certain aspects of the intermolecular information, hindering the perf…         _ More           The identification of active binding drugs for target proteins (termed as drug-target interaction prediction) is the key challenge in virtual screening, which plays an essential role in drug discovery. Although recent deep learning-based approaches achieved better performance than molecular docking, existing models often neglect certain aspects of the intermolecular information, hindering the performance of prediction. We recognize this problem and propose a novel approach named Intermolecular Graph Transformer (IGT) that employs a dedicated attention mechanism to model intermolecular information with a three-way Transformer-based architecture. IGT outperforms state-of-the-art approaches by 9.1% and 20.5% over the second best for binding activity and binding pose prediction respectively, and shows superior generalization ability to unseen receptor proteins. Furthermore, IGT exhibits promising drug screening ability against SARS-CoV-2 by identifying 83.1% active drugs that have been validated by wet-lab experiments with near-native predicted binding poses.         _ Less;Health relatedGeometric Transformers for Protein Interface Contact Prediction;Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving g…         _ More           Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.         _ Less;Health relatedMolformer: Motif-based Transformer on 3D Heterogeneous Molecular Graphs;Procuring expressive molecular representations underpins AI-driven molecule design and scientific discovery. The research mainly focuses on atom-level homogeneous molecular graphs, ignoring the rich information in subgraphs or motifs. However, it has been widely accepted that substructures play a dominant role in identifying and determining molecular properties. To address such issues, we formulat…         _ More           Procuring expressive molecular representations underpins AI-driven molecule design and scientific discovery. The research mainly focuses on atom-level homogeneous molecular graphs, ignoring the rich information in subgraphs or motifs. However, it has been widely accepted that substructures play a dominant role in identifying and determining molecular properties. To address such issues, we formulate heterogeneous molecular graphs (HMGs), and introduce a novel architecture to exploit both molecular motifs and 3D geometry. Precisely, we extract functional groups as motifs for small molecules and employ reinforcement learning to adaptively select quaternary amino acids as motif candidates for proteins. Then HMGs are constructed with both atom-level and motif-level nodes. To better accommodate those HMGs, we introduce a variant of Transformer named Molformer, which adopts a heterogeneous self-attention layer to distinguish the interactions between multi-level nodes. Besides, it is also coupled with a multi-scale mechanism to capture fine-grained local patterns with increasing contextual scales. An attentive farthest point sampling algorithm is also proposed to obtain the molecular representations. We validate Molformer across a broad range of domains, including quantum chemistry, physiology, and biophysics. Extensive experiments show that Molformer outperforms or achieves the comparable performance of several state-of-the-art baselines. Our work provides a promising way to utilize informative motifs from the perspective of multi-level graph construction.         _ Less;Health relatedFDH knockout and TsFDH transformation lead to enhanced growth rate of Escherichia coli;Increased Atmospheric CO2 to over 400 ppm has prompted global climate irregularities. Reducing the released CO2 from biotechnological processes could remediate these phenomena. In this study, we sought to find a solution to reduce the amount of CO2 in the process of growth and reproduction by preventing the conversion of formic acid into CO2. The (bio)chemical conversion of formic acid to CO2 is a…         _ More           Increased Atmospheric CO2 to over 400 ppm has prompted global climate irregularities. Reducing the released CO2 from biotechnological processes could remediate these phenomena. In this study, we sought to find a solution to reduce the amount of CO2 in the process of growth and reproduction by preventing the conversion of formic acid into CO2. The (bio)chemical conversion of formic acid to CO2 is a key reaction. Therefore, we compared the growth of BL21, being a subfamily of K12, alongside two strains in which two different genes related to the formate metabolism were deleted, in complex and simple media. Experimental results were entirely consistent with metabolic predictions. Subsequently, the knockout bacteria grew more efficiently than BL21. Interestingly, TsFDH, a formate dehydrogenase with the tendency of converting CO2 to formate, increased the growth of all strains compared with cells without the TsFDH. Most mutants grew in a simple medium containing glycerol, which showed that glycerol is the preferred carbon source compared to glucose for the growth of E. coli. These results explain the reasons for the inconsistency of predictions in previous metabolic models that declared glycerol as a suitable carbon source for the growth of E. coli but failed to achieve it in practice. To conduct a more mechanistic evaluation of our observations, RNA sequencing data analysis was conducted on an E. coli RNA-seq dataset. The gene expression correlation outcome revealed the increased expression levels of several genes related to protein biosynthesis and glycerol degradation as a possible explanation of our observations.         _ Less;Health relatedReconstructing group wavelet transform from feature maps with a reproducing kernel iteration;In this paper we consider the problem of reconstructing an image that is downsampled in the space of its $SE(2)$ wavelet transform, which is motivated by classical models of simple cells receptive fields and feature preference maps in primary visual cortex. We prove that, whenever the problem is solvable, the reconstruction can be obtained by an elementary project and replace iterative scheme base…         _ More           In this paper we consider the problem of reconstructing an image that is downsampled in the space of its $SE(2)$ wavelet transform, which is motivated by classical models of simple cells receptive fields and feature preference maps in primary visual cortex. We prove that, whenever the problem is solvable, the reconstruction can be obtained by an elementary project and replace iterative scheme based on the reproducing kernel arising from the group structure, and show numerical results on real images.         _ Less;Health relatedSingle-Read Reconstruction for DNA Data Storage Using Transformers;As the global need for large-scale data storage is rising exponentially, existing storage technologies are approaching their theoretical and functional limits in terms of density and energy consumption, making DNA based storage a potential solution for the future of data storage. Several studies introduced DNA based storage systems with high information density (petabytes/gram). However, DNA synth…         _ More           As the global need for large-scale data storage is rising exponentially, existing storage technologies are approaching their theoretical and functional limits in terms of density and energy consumption, making DNA based storage a potential solution for the future of data storage. Several studies introduced DNA based storage systems with high information density (petabytes/gram). However, DNA synthesis and sequencing technologies yield erroneous outputs. Algorithmic approaches for correcting these errors depend on reading multiple copies of each sequence and result in excessive reading costs. The unprecedented success of Transformers as a deep learning architecture for language modeling has led to its repurposing for solving a variety of tasks across various domains. In this work, we propose a novel approach for single-read reconstruction using an encoder-decoder Transformer architecture for DNA based data storage. We address the error correction process as a self-supervised sequence-to-sequence task and use synthetic noise injection to train the model using only the decoded reads. Our approach exploits the inherent redundancy of each decoded file to learn its underlying structure. To demonstrate our proposed approach, we encode text, image and code-script files to DNA, produce errors with high-fidelity error simulator, and reconstruct the original files from the noisy reads. Our model achieves lower error rates when reconstructing the original data from a single read of each DNA strand compared to state-of-the-art algorithms using 2-3 copies. This is the first demonstration of using deep learning models for single-read reconstruction in DNA based storage which allows for the reduction of the overall cost of the process. We show that this approach is applicable for various domains and can be generalized to new domains as well.         _ Less;Health relatedGene Transformer: Transformers for the Gene Expression-based Classification of Lung Cancer Subtypes;Adenocarcinoma and squamous cell carcinoma constitute approximately 40% and 30% of all lung cancer subtypes, respectively, and display broad heterogeneity in terms of clinical and molecular responses to therapy. Molecular subtyping has enabled precision medicine to overcome these challenges and provide significant biological insights to predict prognosis and improve clinical decision making. Over…         _ More           Adenocarcinoma and squamous cell carcinoma constitute approximately 40% and 30% of all lung cancer subtypes, respectively, and display broad heterogeneity in terms of clinical and molecular responses to therapy. Molecular subtyping has enabled precision medicine to overcome these challenges and provide significant biological insights to predict prognosis and improve clinical decision making. Over the past decade, conventional ML algorithms and DL-based CNNs have been espoused for the classification of cancer subtypes from gene expression datasets. However, these methods are potentially biased toward identification of cancer biomarkers. Recently proposed transformer-based architectures that leverage the self-attention mechanism encode high throughput gene expressions and learn representations that are computationally complex and parametrically expensive. However, compared to the datasets for natural language processing applications, gene expression consists of several hundreds of thousands of genes from a limited number of observations, making it difficult to efficiently train transformers for bioinformatics applications. Hence, we propose an end-to-end deep learning approach, Gene Transformer, which addresses the complexity of high-dimensional gene expression with a multi-head self-attention module by identifying relevant biomarkers across multiple cancer subtypes without requiring feature selection as a prerequisite for the current classification algorithms. The proposed architecture achieved an overall improved performance for all evaluation metrics and had fewer misclassification errors than the commonly used traditional classification algorithms. The classification results show that Gene Transformer can be an efficient approach for classifying cancer subtypes, indicating that any improvement in deep learning models in computational biology can also be reflected well in this domain.         _ Less;Health relatedAutomated Identification of Cell Populations in Flow Cytometry Data with Transformers;Acute Lymphoblastic Leukemia (ALL) is the most frequent hematologic malignancy in children and adolescents. A strong prognostic factor in ALL is given by the Minimal Residual Disease (MRD), which is a measure for the number of leukemic cells persistent in a patient. Manual MRD assessment from Multiparameter Flow Cytometry (FCM) data after treatment is time-consuming and subjective. In this work, w…         _ More           Acute Lymphoblastic Leukemia (ALL) is the most frequent hematologic malignancy in children and adolescents. A strong prognostic factor in ALL is given by the Minimal Residual Disease (MRD), which is a measure for the number of leukemic cells persistent in a patient. Manual MRD assessment from Multiparameter Flow Cytometry (FCM) data after treatment is time-consuming and subjective. In this work, we present an automated method to compute the MRD value directly from FCM data. We present a novel neural network approach based on the transformer architecture that learns to directly identify blast cells in a sample. We train our method in a supervised manner and evaluate it on publicly available ALL FCM data from three different clinical centers. Our method reaches a median F1 score of ~0.94 when evaluated on 519 B-ALL samples and shows better results than existing methods on 4 different datasets         _ Less;Health relatedRepresentation learning for neural population activity with Neural Data Transformers;Neural population activity is theorized to reflect an underlying dynamical structure. This structure can be accurately captured using state space models with explicit dynamics, such as those based on recurrent neural networks (RNNs). However, using recurrence to explicitly model dynamics necessitates sequential processing of data, slowing real-time applications such as brain-computer interfaces. H…         _ More           Neural population activity is theorized to reflect an underlying dynamical structure. This structure can be accurately captured using state space models with explicit dynamics, such as those based on recurrent neural networks (RNNs). However, using recurrence to explicitly model dynamics necessitates sequential processing of data, slowing real-time applications such as brain-computer interfaces. Here we introduce the Neural Data Transformer (NDT), a non-recurrent alternative. We test the NDT's ability to capture autonomous dynamical systems by applying it to synthetic datasets with known dynamics and data from monkey motor cortex during a reaching task well-modeled by RNNs. The NDT models these datasets as well as state-of-the-art recurrent models. Further, its non-recurrence enables 3.9ms inference, well within the loop time of real-time applications and more than 6 times faster than recurrent baselines on the monkey reaching dataset. These results suggest that an explicit dynamics model is not necessary to model autonomous neural population dynamics. Code: https://github.com/snel-repo/neural-data-transformers         _ Less;Health relatedLegendre transformation and information geometry for the maximum entropy theory of ecology;              Here I investigate some mathematical aspects of the maximum entropy theory of ecology (METE). In particular I address the geometrical structure of METE endowed by information geometry. As novel results, the macrostate entropy is calculated analytically by the Legendre transformation of the log-normalizer in METE. This result allows for the calculation of the metric terms in the information geometr…         _ More           Here I investigate some mathematical aspects of the maximum entropy theory of ecology (METE). In particular I address the geometrical structure of METE endowed by information geometry. As novel results, the macrostate entropy is calculated analytically by the Legendre transformation of the log-normalizer in METE. This result allows for the calculation of the metric terms in the information geometry arising from METE and, by consequence, the covariance matrix between METE variables.         _ Less;Health relatedBeat-to-Beat Fetal Heart Rate Analysis Using Portable Medical Device and Wavelet Transformation Technique;A beat-to-beat Tele-fetal Monitoring and comparison with clinical data are studied with a wavelet transformation approach. Tele-fetal monitoring is a big progress toward a wearable medical device for a pregnant woman capable of obtaining prenatal care at home. We apply a wavelet transformation algorithm for fetal cardiac monitoring using a portable fetal Doppler medical device. Choosing an appropr…         _ More           A beat-to-beat Tele-fetal Monitoring and comparison with clinical data are studied with a wavelet transformation approach. Tele-fetal monitoring is a big progress toward a wearable medical device for a pregnant woman capable of obtaining prenatal care at home. We apply a wavelet transformation algorithm for fetal cardiac monitoring using a portable fetal Doppler medical device. Choosing an appropriate mother wavelet, 85 different mother wavelets are investigated. The efficiency of the proposed method is evaluated using two data sets including public and clinical. From publicly available data on PhysioBank, and simultaneous clinical measurement, we prove that the comparison between obtained fetal heart rate by the algorithm and the baselines yields a promising accuracy beyond 95%. Finally, we conclude that the proposed algorithm would be a robust technique for any similar tele-fetal monitoring approach.         _ Less;Health relatedUnsupervised Brain Anomaly Detection and Segmentation with Transformers;Pathological brain appearances may be so heterogeneous as to be intelligible only as anomalies, defined by their deviation from normality rather than any specific pathological characteristic. Amongst the hardest tasks in medical imaging, detecting such anomalies requires models of the normal brain that combine compactness with the expressivity of the complex, long-range interactions that character…         _ More           Pathological brain appearances may be so heterogeneous as to be intelligible only as anomalies, defined by their deviation from normality rather than any specific pathological characteristic. Amongst the hardest tasks in medical imaging, detecting such anomalies requires models of the normal brain that combine compactness with the expressivity of the complex, long-range interactions that characterise its structural organisation. These are requirements transformers have arguably greater potential to satisfy than other current candidate architectures, but their application has been inhibited by their demands on data and computational resource. Here we combine the latent representation of vector quantised variational autoencoders with an ensemble of autoregressive transformers to enable unsupervised anomaly detection and segmentation defined by deviation from healthy brain imaging data, achievable at low computational cost, within relative modest data regimes. We compare our method to current state-of-the-art approaches across a series of experiments involving synthetic and real pathological lesions. On real lesions, we train our models on 15,000 radiologically normal participants from UK Biobank, and evaluate performance on four different brain MR datasets with small vessel disease, demyelinating lesions, and tumours. We demonstrate superior anomaly detection performance both image-wise and pixel-wise, achievable without post-processing. These results draw attention to the potential of transformers in this most challenging of imaging tasks.         _ Less;Health relatedA Similarity-preserving Neural Network Trained on Transformed Images Recapitulates Salient Features of the Fly Motion Detection Circuit;              Learning to detect content-independent transformations from data is one of the central problems in biological and artificial intelligence. An example of such problem is unsupervised learning of a visual motion detector from pairs of consecutive video frames. Rao and Ruderman formulated this problem in terms of learning infinitesimal transformation operators (Lie group generators) via minimizing im…         _ More           Learning to detect content-independent transformations from data is one of the central problems in biological and artificial intelligence. An example of such problem is unsupervised learning of a visual motion detector from pairs of consecutive video frames. Rao and Ruderman formulated this problem in terms of learning infinitesimal transformation operators (Lie group generators) via minimizing image reconstruction error. Unfortunately, it is difficult to map their model onto a biologically plausible neural network (NN) with local learning rules. Here we propose a biologically plausible model of motion detection. We also adopt the transformation-operator approach but, instead of reconstruction-error minimization, start with a similarity-preserving objective function. An online algorithm that optimizes such an objective function naturally maps onto an NN with biologically plausible learning rules. The trained NN recapitulates major features of the well-studied motion detector in the fly. In particular, it is consistent with the experimental observation that local motion detectors combine information from at least three adjacent pixels, something that contradicts the celebrated Hassenstein-Reichardt model.         _ Less;Health relatedOn Utility and Privacy in Synthetic Genomic Data;              The availability of genomic data is essential to progress in biomedical research, personalized medicine, etc. However, its extreme sensitivity makes it problematic, if not outright impossible, to publish or share it. As a result, several initiatives have been launched to experiment with synthetic genomic data, e.g., using generative models to learn the underlying distribution of the real data and…         _ More           The availability of genomic data is essential to progress in biomedical research, personalized medicine, etc. However, its extreme sensitivity makes it problematic, if not outright impossible, to publish or share it. As a result, several initiatives have been launched to experiment with synthetic genomic data, e.g., using generative models to learn the underlying distribution of the real data and generate artificial datasets that preserve its salient characteristics without exposing it. This paper provides the first evaluation of both utility and privacy protection of six state-of-the-art models for generating synthetic genomic data. We assess the performance of the synthetic data on several common tasks, such as allele population statistics and linkage disequilibrium. We then measure privacy through the lens of membership inference attacks, i.e., inferring whether a record was part of the training data. Our experiments show that no single approach to generate synthetic genomic data yields both high utility and strong privacy across the board. Also, the size and nature of the training dataset matter. Moreover, while some combinations of datasets and models produce synthetic data with distributions close to the real data, there often are target data points that are vulnerable to membership inference. Looking forward, our techniques can be used by practitioners to assess the risks of deploying synthetic genomic data in the wild and serve as a benchmark for future work.         _ Less;Health relatedGraph Transformation for Enzymatic Mechanisms;Motivation: The design of enzymes is as challenging as it is consequential for making chemical synthesis in medical and industrial applications more efficient, cost-effective and environmentally friendly. While several aspects of this complex problem are computationally assisted, the drafting of catalytic mechanisms, i.e. the specification of the chemical steps-and hence intermediate states-that t…         _ More           Motivation: The design of enzymes is as challenging as it is consequential for making chemical synthesis in medical and industrial applications more efficient, cost-effective and environmentally friendly. While several aspects of this complex problem are computationally assisted, the drafting of catalytic mechanisms, i.e. the specification of the chemical steps-and hence intermediate states-that the enzyme is meant to implement, is largely left to human expertise. The ability to capture specific chemistries of multi-step catalysis in a fashion that enables its computational construction and design is therefore highly desirable and would equally impact the elucidation of existing enzymatic reactions whose mechanisms are unknown. Results: We use the mathematical framework of graph transformation to express the distinction between rules and reactions in chemistry. We derive about 1000 rules for amino acid side chain chemistry from the M-CSA database, a curated repository of enzymatic mechanisms. Using graph transformation we are able to propose hundreds of hypothetical catalytic mechanisms for a large number of unrelated reactions in the Rhea database. We analyze these mechanisms to find that they combine in chemically sound fashion individual steps from a variety of known multi-step mechanisms, showing that plausible novel mechanisms for catalysis can be constructed computationally.         _ Less;Health relatedBENDR: using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG data;              Deep neural networks (DNNs) used for brain-computer-interface (BCI) classification are commonly expected to learn general features when trained across a variety of contexts, such that these features could be fine-tuned to specific contexts. While some success is found in such an approach, we suggest that this interpretation is limited and an alternative would better leverage the newly (publicly) a…         _ More           Deep neural networks (DNNs) used for brain-computer-interface (BCI) classification are commonly expected to learn general features when trained across a variety of contexts, such that these features could be fine-tuned to specific contexts. While some success is found in such an approach, we suggest that this interpretation is limited and an alternative would better leverage the newly (publicly) available massive EEG datasets. We consider how to adapt techniques and architectures used for language modelling (LM), that appear capable of ingesting awesome amounts of data, towards the development of encephalography modelling (EM) with DNNs in the same vein. We specifically adapt an approach effectively used for automatic speech recognition, which similarly (to LMs) uses a self-supervised training objective to learn compressed representations of raw data signals. After adaptation to EEG, we find that a single pre-trained model is capable of modelling completely novel raw EEG sequences recorded with differing hardware, and different subjects performing different tasks. Furthermore, both the internal representations of this model and the entire architecture can be fine-tuned to a variety of downstream BCI and EEG classification tasks, outperforming prior work in more task-specific (sleep stage classification) self-supervision.         _ Less;Health relatedAutomating LC-MS/MS mass chromatogram quantification. Wavelet transform based peak detection and automated estimation of peak boundaries and signal-to-noise ratio using signal processing methods;While there are many different methods for peak detection, no automatic methods for marking peak boundaries to calculate area under the curve (AUC) and signal-to-noise ratio (SNR) estimation exist. An algorithm for the automation of liquid chromatography tandem mass spectrometry (LC-MS/MS) mass chromatogram quantification was developed and validated. Continuous wavelet transformation and other dig…         _ More           While there are many different methods for peak detection, no automatic methods for marking peak boundaries to calculate area under the curve (AUC) and signal-to-noise ratio (SNR) estimation exist. An algorithm for the automation of liquid chromatography tandem mass spectrometry (LC-MS/MS) mass chromatogram quantification was developed and validated. Continuous wavelet transformation and other digital signal processing methods were used in a multi-step procedure to calculate concentrations of six different analytes. To evaluate the performance of the algorithm, the results of the manual quantification of 446 hair samples with 6 different steroid hormones by two experts were compared to the algorithm results. The proposed approach of automating mass chromatogram quantification is reliable and valid. The algorithm returns less nondetectables than human raters. Based on signal to noise ratio, human non-detectables could be correctly classified with a diagnostic performance of AUC = 0.95. The algorithm presented here allows fast, automated, reliable, and valid computational peak detection and quantification in LC- MS/MS.         _ Less;Health relatedOn the Fourier transform of a quantitative trait: Implications for compressive sensing;              This paper explores the genotype-phenotype relationship. It outlines conditions under which the dependence of a quantitative trait on the genome might be predictable, based on measurement of a limited subset of genotypes. It uses the theory of real-valued Boolean functions in a systematic way to translate trait data into the Fourier domain. Important trait features, such as the roughness of the tr…         _ More           This paper explores the genotype-phenotype relationship. It outlines conditions under which the dependence of a quantitative trait on the genome might be predictable, based on measurement of a limited subset of genotypes. It uses the theory of real-valued Boolean functions in a systematic way to translate trait data into the Fourier domain. Important trait features, such as the roughness of the trait landscape or the modularity of a trait have a simple Fourier interpretation. Ruggedness at a gene location corresponds to high sensitivity to mutation, while a modular organization of gene activity reduces such sensitivity.   Traits where rugged loci are rare will naturally compress gene data in the Fourier domain, leading to a sparse representation of trait data, concentrated in identifiable, low-level coefficients. This Fourier representation of a trait organizes epistasis in a form which is isometric to the trait data. As Fourier matrices are known to be maximally incoherent with the standard basis, this permits employing compressive sensing techniques to work from data sets that are relatively small -- sometimes even of polynomial size -- compared to the exponentially large sets of possible genomes.   This theory provides a theoretical underpinning for systematic use of Boolean function machinery to dissect the dependency of a trait on the genome and environment.         _ Less;Health relatedReduction in the complexity of 1D 1H-NMR spectra by the use of Frequency to Information Transformation;Analysis of 1H-NMR spectra is often hindered by large variations that occur during the collection of these spectra. Large solvent and standard peaks, base line drift and negative peaks (due to improper phasing) are among some of these variations. Furthermore, some instrument dependent alterations, such as incorrect shimming, are also embedded in the recorded spectrum. The unpredictable nature of t…         _ More           Analysis of 1H-NMR spectra is often hindered by large variations that occur during the collection of these spectra. Large solvent and standard peaks, base line drift and negative peaks (due to improper phasing) are among some of these variations. Furthermore, some instrument dependent alterations, such as incorrect shimming, are also embedded in the recorded spectrum. The unpredictable nature of these alterations of the signal has rendered the automated and instrument independent computer analysis of these spectra unreliable. In this paper, a novel method of extracting the information content of a signal (in this paper, frequency domain 1H-NMR spectrum), called the frequency-information transformation (FIT), is presented and compared to a previously used method (SPUTNIK). FIT can successfully extract the relevant information to a pattern matching task present in a signal, while discarding the remainder of a signal by transforming a Fourier transformed signal into an information spectrum (IS). This technique exhibits the ability of decreasing the inter-class correlation coefficients while increasing the intra-class correlation coefficients. Different spectra of the same molecule, in other words, will resemble more to each other while the spectra of different molecules will look more different from each other. This feature allows easier automated identification and analysis of molecules based on their spectral signatures using computer algorithms.         _ Less;Health relatedRemediation of bentazone contaminated water by Trametes versicolor: characterization, identification of transformation products, and implementation in a trickle-bed reactor under non-sterile conditions;Bentazone, an herbicide widely applied in rice and cereal crops, is widespread in the aquatic environment. This study evaluated the capacity of Trametes versicolor to remove bentazone from water. The fungus was able to completely remove bentazone after three days at Erlenmeyer-scale incubation. Both laccase and cytochrome P450 enzymatic systems were involved in bentazone degradation. A total of 19…         _ More           Bentazone, an herbicide widely applied in rice and cereal crops, is widespread in the aquatic environment. This study evaluated the capacity of Trametes versicolor to remove bentazone from water. The fungus was able to completely remove bentazone after three days at Erlenmeyer-scale incubation. Both laccase and cytochrome P450 enzymatic systems were involved in bentazone degradation. A total of 19 transformation products (TPs) were identified to be formed during the process. The reactions involved in their formation included hydroxylations, oxidations, methylations, N-nitrosation, and dimerization. A laccase mediated radical mechanism was proposed for TP formation. In light of the results obtained at the Erlenmeyer scale, a trickle-bed reactor with T. versicolor immobilized on pine wood chips was set up to evaluate its stability during bentazone removal under non-sterile conditions. After 30 days of sequencing batch operation, an average bentazone removal of 48 % was obtained, with a considerable contribution of adsorption onto the lignocellulosic support material. Bacterial contamination, which is the bottleneck in the implementation of fungal bioreactors, was successfully addressed by this particular system according to its maintained performance. This research is a pioneering step forward to the implementation of fungal bioremediation on a real scale.         _ Less;Not health relatedAttention-Based Transformers for Instance Segmentation of Cells in Microstructures;              Detecting and segmenting object instances is a common task in biomedical applications. Examples range from detecting lesions on functional magnetic resonance images, to the detection of tumours in histopathological images and extracting quantitative single-cell information from microscopy imagery, where cell segmentation is a major bottleneck. Attention-based transformers are state-of-the-art in a…         _ More           Detecting and segmenting object instances is a common task in biomedical applications. Examples range from detecting lesions on functional magnetic resonance images, to the detection of tumours in histopathological images and extracting quantitative single-cell information from microscopy imagery, where cell segmentation is a major bottleneck. Attention-based transformers are state-of-the-art in a range of deep learning fields. They have recently been proposed for segmentation tasks where they are beginning to outperforming other methods. We present a novel attention-based cell detection transformer (Cell-DETR) for direct end-to-end instance segmentation. While the segmentation performance is on par with a state-of-the-art instance segmentation method, Cell-DETR is simpler and faster. We showcase the method's contribution in a the typical use case of segmenting yeast in microstructured environments, commonly employed in systems or synthetic biology. For the specific use case, the proposed method surpasses the state-of-the-art tools for semantic segmentation and additionally predicts the individual object instances. The fast and accurate instance segmentation performance increases the experimental information yield for a posteriori data processing and makes online monitoring of experiments and closed-loop optimal experimental design feasible.         _ Less;Health relatedTransformer Based Molecule Encoding for Property Prediction;              Neural methods of molecule property prediction require efficient encoding of structure and property relationship to be accurate. Recent work using graph algorithms shows limited generalization in the latent molecule encoding space. We build a Transformer-based molecule encoder and property predictor network with novel input featurization that performs significantly better than existing methods. We…         _ More           Neural methods of molecule property prediction require efficient encoding of structure and property relationship to be accurate. Recent work using graph algorithms shows limited generalization in the latent molecule encoding space. We build a Transformer-based molecule encoder and property predictor network with novel input featurization that performs significantly better than existing methods. We adapt our model to semi-supervised learning to further perform well on the limited experimental data usually available in practice.         _ Less;Health relatedPubSqueezer: A Text-Mining Web Tool to Transform Unstructured Documents into Structured Data;The amount of scientific papers published every day is daunting and constantly increasing. Keeping up with literature represents a challenge. If one wants to start exploring new topics it is hard to have a big picture without reading lots of articles. Furthermore, as one reads through literature, making mental connections is crucial to ask new questions which might lead to discoveries. In this wor…         _ More           The amount of scientific papers published every day is daunting and constantly increasing. Keeping up with literature represents a challenge. If one wants to start exploring new topics it is hard to have a big picture without reading lots of articles. Furthermore, as one reads through literature, making mental connections is crucial to ask new questions which might lead to discoveries. In this work, I present a web tool which uses a Text Mining strategy to transform large collections of unstructured biomedical articles into structured data. Generated results give a quick overview on complex topics which can possibly suggest not explicitly reported information. In particular, I show two Data Science analyses. First, I present a literature based rare diseases network build using this tool in the hope that it will help clarify some aspects of these less popular pathologies. Secondly, I show how a literature based analysis conducted with PubSqueezer results allows to describe known facts about SARS-CoV-2. In one sentence, data generated with PubSqueezer make it easy to use scientific literate in any computational analysis such as machine learning, natural language processing etc.   Availability: http://www.pubsqueezer.com         _ Less;Health relatedPeak Detection On Data Independent Acquisition Mass Spectrometry Data With Semisupervised Convolutional Transformers;"              Liquid Chromatography coupled to Mass Spectrometry (LC-MS) based methods are commonly used for high-throughput, quantitative measurements of the proteome (i.e. the set of all proteins in a sample at a given time). Targeted LC-MS produces data in the form of a two-dimensional time series spectrum, with the mass to charge ratio of analytes (m/z) on one axis, and the retention time from the chromatog…         _ More           Liquid Chromatography coupled to Mass Spectrometry (LC-MS) based methods are commonly used for high-throughput, quantitative measurements of the proteome (i.e. the set of all proteins in a sample at a given time). Targeted LC-MS produces data in the form of a two-dimensional time series spectrum, with the mass to charge ratio of analytes (m/z) on one axis, and the retention time from the chromatography on the other. The elution of a peptide of interest produces highly specific patterns across multiple fragment ion traces (extracted ion chromatograms, or XICs). In this paper, we formulate this peak detection problem as a multivariate time series segmentation problem, and propose a novel approach based on the Transformer architecture. Here we augment Transformers, which are capable of capturing long distance dependencies with a global view, with Convolutional Neural Networks (CNNs), which can capture local context important to the task at hand, in the form of Transformers with Convolutional Self-Attention. We further train this model in a semisupervised manner by adapting state of the art semisupervised image classification techniques for multi-channel time series data. Experiments on a representative LC-MS dataset are benchmarked using manual annotations to showcase the encouraging performance of our method; it outperforms baseline neural network architectures and is competitive against the current state of the art in automated peak detection.         _ Less";Health relatedBeyond Chemical 1D knowledge using Transformers;In the present paper we evaluated efficiency of the recent Transformer-CNN models to predict target properties based on the augmented stereochemical SMILES. We selected a well-known Cliff activity dataset as well as a Dipole moment dataset and compared the effect of three representations for R/S stereochemistry in SMILES. The considered representations were SMILES without stereochemistry (noChiSMI…         _ More           In the present paper we evaluated efficiency of the recent Transformer-CNN models to predict target properties based on the augmented stereochemical SMILES. We selected a well-known Cliff activity dataset as well as a Dipole moment dataset and compared the effect of three representations for R/S stereochemistry in SMILES. The considered representations were SMILES without stereochemistry (noChiSMI), classical relative stereochemistry encoding (RelChiSMI) and an alternative version with absolute stereochemistry encoding (AbsChiSMI). The inclusion of R/S in SMILES representation allowed simplify the assignment of the respective information based on SMILES representation, but did not always show advantages on regression or classification tasks. Interestingly, we did not see degradation of the performance of Transformer-CNN models when the stereochemical information was not present in SMILES. Moreover, these models showed higher or similar performance compared to descriptor-based models based on 3D structures. These observations are an important step in NLP modeling of 3D chemical tasks. An open challenge remains whether Transformer-CNN can efficiently embed 3D knowledge from SMILES input and whether a better representation could further increase the accuracy of this approach.         _ Less;Health relatedGNN-PT: Enhanced Prediction of Compound-protein Interactions by Integrating Protein Transformer;              The prediction of protein interactions (CPIs) is crucial for the in-silico screening step in drug discovery. Recently, many end-to-end representation learning methods using deep neural networks have achieved significantly better performance than traditional machine learning algorithms. Much effort has focused on the compound representation or the information extraction from the compound-protein in…         _ More           The prediction of protein interactions (CPIs) is crucial for the in-silico screening step in drug discovery. Recently, many end-to-end representation learning methods using deep neural networks have achieved significantly better performance than traditional machine learning algorithms. Much effort has focused on the compound representation or the information extraction from the compound-protein interaction to improve the model capability by taking the advantage of the neural attention mechanism. However, previous studies have paid little attention to representing the protein sequences, in which the long-range interactions of residue pairs are essential for characterizing the structural properties arising from the protein folding. We incorporate the self-attention mechanism into the protein representation module for CPI modeling, which aims at capturing the long-range interaction information within proteins. The proposed module concerning protein representation, called Protein Transformer, with an integration with an existing CPI model, has shown a significant improvement in the prediction performance when compared with several existing CPI models.         _ Less;Health relatedMeasuring the average cell size and width of its distribution in cellular tissues using Fourier Transform;We present an in-depth investigation of a fully automated Fourier-based analysis to determine the cell size and the width of its distribution in 3D biological tissues. The results are thoroughly tested using generated images, and we offer valuable criteria for image acquisition settings to optimize accuracy. We demonstrate that the most important parameter is the number of cells in the field of vi…         _ More           We present an in-depth investigation of a fully automated Fourier-based analysis to determine the cell size and the width of its distribution in 3D biological tissues. The results are thoroughly tested using generated images, and we offer valuable criteria for image acquisition settings to optimize accuracy. We demonstrate that the most important parameter is the number of cells in the field of view, and we show that accurate measurements can already be made on volume only containing 3x3x3 cells. The resolution in $z$ is also not so important and a reduced number of in-depth images, of order of one per cell, already provides a measure of the mean cell size with less than 5\% error. The technique thus appears to be a very promising tool for very fast live local volume cell measurement in 3D tissues \textit{in vivo} while strongly limiting photobleaching and phototoxicity issues.         _ Less;Health relatedANGUS: Real-time manipulation of vocal roughness for emotional speech transformations;"Vocal arousal, the non-linear acoustic features taken on by human and animal vocalizations when highly aroused, has an important communicative function because it signals aversive states such as fear, pain or distress. In this work, we present a computationally-efficient, real-time voice transformation algorithm, ANGUS, which uses amplitude modulation and time-domain filtering to simulate roughnes…         _ More           Vocal arousal, the non-linear acoustic features taken on by human and animal vocalizations when highly aroused, has an important communicative function because it signals aversive states such as fear, pain or distress. In this work, we present a computationally-efficient, real-time voice transformation algorithm, ANGUS, which uses amplitude modulation and time-domain filtering to simulate roughness, an important component of vocal arousal, in arbitrary voice recordings. In a series of 4 studies, we show that ANGUS allows parametric control over the spectral features of roughness like the presence of sub-harmonics and noise; that ANGUS increases the emotional negativity perceived by listeners, to a comparable level as a non-real-time analysis/resynthesis algorithm from the state-of-the-art; that listeners cannot distinguish transformed and non-transformed sounds above chance level; and that ANGUS has a similar emotional effect on animal vocalizations and musical instrument sounds than on human vocalizations. A real-time implementation of ANGUS is made available as open-source software, for use in experimental emotion reseach and affective computing.         _ Less";Health relatedA short letter on the dot product between rotated Fourier transforms;"Spatial Semantic Pointers (SSPs) have recently emerged as a powerful tool for representing and transforming continuous space, with numerous applications to cognitive modelling and deep learning. Fundamental to SSPs is the notion of ""similarity"" between vectors representing different points in $n$-dimensional space -- typically the dot product or cosine similarity between vectors with rotated unit-…         _ More           Spatial Semantic Pointers (SSPs) have recently emerged as a powerful tool for representing and transforming continuous space, with numerous applications to cognitive modelling and deep learning. Fundamental to SSPs is the notion of ""similarity"" between vectors representing different points in $n$-dimensional space -- typically the dot product or cosine similarity between vectors with rotated unit-length complex coefficients in the Fourier domain. The similarity measure has previously been conjectured to be a Gaussian function of Euclidean distance. Contrary to this conjecture, we derive a simple trigonometric formula relating spatial displacement to similarity, and prove that, in the case where the Fourier coefficients are uniform i.i.d., the expected similarity is a product of normalized sinc functions: $\prod_{k=1}^{n} \operatorname{sinc} \left( a_k \right)$, where $\mathbf{a} \in \mathbb{R}^n$ is the spatial displacement between the two $n$-dimensional points. This establishes a direct link between space and the similarity of SSPs, which in turn helps bolster a useful mathematical framework for architecting neural networks that manipulate spatial structures.         _ Less";Health relatedSelf-Supervised Graph Transformer on Large-Scale Molecular Data;"How to obtain informative representations of molecules is a crucial prerequisite in AI-driven drug design and discovery. Recent researches abstract molecules as graphs and employ Graph Neural Networks (GNNs) for molecular representation learning. Nevertheless, two issues impede the usage of GNNs in real scenarios: (1) insufficient labeled molecules for supervised training; (2) poor generalization…         _ More           How to obtain informative representations of molecules is a crucial prerequisite in AI-driven drug design and discovery. Recent researches abstract molecules as graphs and employ Graph Neural Networks (GNNs) for molecular representation learning. Nevertheless, two issues impede the usage of GNNs in real scenarios: (1) insufficient labeled molecules for supervised training; (2) poor generalization capability to new-synthesized molecules. To address them both, we propose a novel framework, GROVER, which stands for Graph Representation frOm self-superVised mEssage passing tRansformer. With carefully designed self-supervised tasks in node-, edge- and graph-level, GROVER can learn rich structural and semantic information of molecules from enormous unlabelled molecular data. Rather, to encode such complex information, GROVER integrates Message Passing Networks into the Transformer-style architecture to deliver a class of more expressive encoders of molecules. The flexibility of GROVER allows it to be trained efficiently on large-scale molecular dataset without requiring any supervision, thus being immunized to the two issues mentioned above. We pre-train GROVER with 100 million parameters on 10 million unlabelled molecules -- the biggest GNN and the largest training dataset in molecular representation learning. We then leverage the pre-trained GROVER for molecular property prediction followed by task-specific fine-tuning, where we observe a huge improvement (more than 6% on average) from current state-of-the-art methods on 11 challenging benchmarks. The insights we gained are that well-designed self-supervision losses and largely-expressive pre-trained models enjoy the significant potential on performance boosting.         _ Less";Health relatedSynthetic Observational Health Data with GANs: from slow adoption to a boom in medical research and ultimately digital twins?;After being collected for patient care, Observational Health Data (OHD) can further benefit patient well-being by sustaining the development of health informatics and medical research. Vast potential is unexploited because of the fiercely private nature of patient-related data and regulations to protect it.   Generative Adversarial Networks (GANs) have recently emerged as a groundbreaking way to l…         _ More           After being collected for patient care, Observational Health Data (OHD) can further benefit patient well-being by sustaining the development of health informatics and medical research. Vast potential is unexploited because of the fiercely private nature of patient-related data and regulations to protect it.   Generative Adversarial Networks (GANs) have recently emerged as a groundbreaking way to learn generative models that produce realistic synthetic data. They have revolutionized practices in multiple domains such as self-driving cars, fraud detection, digital twin simulations in industrial sectors, and medical imaging.   The digital twin concept could readily apply to modelling and quantifying disease progression. In addition, GANs posses many capabilities relevant to common problems in healthcare: lack of data, class imbalance, rare diseases, and preserving privacy. Unlocking open access to privacy-preserving OHD could be transformative for scientific research. In the midst of COVID-19, the healthcare system is facing unprecedented challenges, many of which of are data related for the reasons stated above.   Considering these facts, publications concerning GAN applied to OHD seemed to be severely lacking. To uncover the reasons for this slow adoption, we broadly reviewed the published literature on the subject. Our findings show that the properties of OHD were initially challenging for the existing GAN algorithms (unlike medical imaging, for which state-of-the-art model were directly transferable) and the evaluation synthetic data lacked clear metrics.   We find more publications on the subject than expected, starting slowly in 2017, and since then at an increasing rate. The difficulties of OHD remain, and we discuss issues relating to evaluation, consistency, benchmarking, data modelling, and reproducibility.         _ Less;Health relatedLearning Deep Models from Synthetic Data for Extracting Dolphin Whistle Contours;We present a learning-based method for extracting whistles of toothed whales (Odontoceti) in hydrophone recordings. Our method represents audio signals as time-frequency spectrograms and decomposes each spectrogram into a set of time-frequency patches. A deep neural network learns archetypical patterns (e.g., crossings, frequency modulated sweeps) from the spectrogram patches and predicts time-fre…         _ More           We present a learning-based method for extracting whistles of toothed whales (Odontoceti) in hydrophone recordings. Our method represents audio signals as time-frequency spectrograms and decomposes each spectrogram into a set of time-frequency patches. A deep neural network learns archetypical patterns (e.g., crossings, frequency modulated sweeps) from the spectrogram patches and predicts time-frequency peaks that are associated with whistles. We also developed a comprehensive method to synthesize training samples from background environments and train the network with minimal human annotation effort. We applied the proposed learn-from-synthesis method to a subset of the public Detection, Classification, Localization, and Density Estimation (DCLDE) 2011 workshop data to extract whistle confidence maps, which we then processed with an existing contour extractor to produce whistle annotations. The F1-score of our best synthesis method was 0.158 greater than our baseline whistle extraction algorithm (~25% improvement) when applied to common dolphin (Delphinus spp.) and bottlenose dolphin (Tursiops truncatus) whistles.         _ Less;Health relatedAlchemical Transformations for Concerted Hydration Free Energy Estimation with Explicit Solvation;              We present a family of alchemical perturbation potentials that enable the calculation of hydration free energies of small to medium-sized molecules in a concerted single alchemical coupling step instead of the commonly used sequence of two distinct coupling steps for Lennard-Jones and electrostatic interactions. The perturbation potentials are based on the softplus function of the solute-solvent i…         _ More           We present a family of alchemical perturbation potentials that enable the calculation of hydration free energies of small to medium-sized molecules in a concerted single alchemical coupling step instead of the commonly used sequence of two distinct coupling steps for Lennard-Jones and electrostatic interactions. The perturbation potentials are based on the softplus function of the solute-solvent interaction energy designed to focus sampling near entropic bottlenecks along the alchemical pathway. We present a general framework to optimize the parameters of alchemical perturbation potentials of this kind. The optimization procedure is based on the $_$-function formalism and the maximum-likelihood parameter estimation procedure we developed earlier to avoid the occurrence of multi-modal distributions of the coupling energy along the alchemical path. A novel soft-core function applied to the overall solute-solvent interaction energy rather than individual interatomic pair potentials critical for this result is also presented. Because it does not require modifications of core force and energy routines, the soft-core formulation can be easily deployed in molecular dynamics simulation codes. We illustrate the method by applying it to the estimation of the hydration free energy in water droplets of compounds of varying size and complexity. In each case, we show that convergence of the hydration free energy is achieved rapidly. This work paves the way for the ongoing development of more streamlined algorithms to estimate free energies of molecular binding with explicit solvation.         _ Less;Health relatedMolTrans: Molecular Interaction Transformer for Drug Target Interaction Prediction;"Drug target interaction (DTI) prediction is a foundational task for in silico drug discovery, which is costly and time-consuming due to the need of experimental search over large drug compound space. Recent years have witnessed promising progress for deep learning in DTI predictions. However, the following challenges are still open: (1) the sole data-driven molecular representation learning approa…         _ More           Drug target interaction (DTI) prediction is a foundational task for in silico drug discovery, which is costly and time-consuming due to the need of experimental search over large drug compound space. Recent years have witnessed promising progress for deep learning in DTI predictions. However, the following challenges are still open: (1) the sole data-driven molecular representation learning approaches ignore the sub-structural nature of DTI, thus produce results that are less accurate and difficult to explain; (2) existing methods focus on limited labeled data while ignoring the value of massive unlabelled molecular data. We propose a Molecular Interaction Transformer (MolTrans) to address these limitations via: (1) knowledge inspired sub-structural pattern mining algorithm and interaction modeling module for more accurate and interpretable DTI prediction; (2) an augmented transformer encoder to better extract and capture the semantic relations among substructures extracted from massive unlabeled biomedical data. We evaluate MolTrans on real world data and show it improved DTI prediction performance compared to state-of-the-art baselines.         _ Less";Health relatedPrinciple components analysis for seizures prediction using wavelet transform;Epilepsy is a disease in which frequent seizures occur due to abnormal activity of neurons. Patients affected by this disease can be treated with the help of medicines or surgical procedures. However, both of these methods are not quite useful. The only method to treat epilepsy patients effectively is to predict the seizure before its onset. It has been observed that abnormal activity in the brain…         _ More           Epilepsy is a disease in which frequent seizures occur due to abnormal activity of neurons. Patients affected by this disease can be treated with the help of medicines or surgical procedures. However, both of these methods are not quite useful. The only method to treat epilepsy patients effectively is to predict the seizure before its onset. It has been observed that abnormal activity in the brain signals starts before the occurrence of seizure known as the preictal state. Many researchers have proposed machine learning models for prediction of epileptic seizures by detecting the start of preictal state. However, pre-processing, feature extraction and classification remains a great challenge in the prediction of preictal state. Therefore, we propose a model that uses common spatial pattern filtering and wavelet transform for preprocessing, principal component analysis for feature extraction and support vector machines for detecting preictal state. We have applied our model on 23 subjects and an average sensitivity of 93.1% has been observed for 84 seizures.         _ Less;Health relatedA Numerical Transform of Random Forest Regressors corrects Systematically-Biased Predictions;"              Over the past decade, random forest models have become widely used as a robust method for high-dimensional data regression tasks. In part, the popularity of these models arises from the fact that they require little hyperparameter tuning and are not very susceptible to overfitting. Random forest regression models are comprised of an ensemble of decision trees that independently predict the value o…         _ More           Over the past decade, random forest models have become widely used as a robust method for high-dimensional data regression tasks. In part, the popularity of these models arises from the fact that they require little hyperparameter tuning and are not very susceptible to overfitting. Random forest regression models are comprised of an ensemble of decision trees that independently predict the value of a (continuous) dependent variable; predictions from each of the trees are ultimately averaged to yield an overall predicted value from the forest. Using a suite of representative real-world datasets, we find a systematic bias in predictions from random forest models. We find that this bias is recapitulated in simple synthetic datasets, regardless of whether or not they include irreducible error (noise) in the data, but that models employing boosting do not exhibit this bias. Here we demonstrate the basis for this problem, and we use the training data to define a numerical transformation that fully corrects it. Application of this transformation yields improved predictions in every one of the real-world and synthetic datasets evaluated in our study.         _ Less";Health relatedFate of priority pharmaceuticals and their main metabolites and transformation products in microalgae-based wastewater treatment systems;The present study evaluates the removal capacity of two high rate algae ponds (HRAPs) to eliminate 12 pharmaceuticals (PhACs) and 26 of their corresponding main metabolites and transformation products. The efficiency of these ponds, operating with and without primary treatment, was compared in order to study their capacity under the best performance conditions (highest solar irradiance). Concentra…         _ More           The present study evaluates the removal capacity of two high rate algae ponds (HRAPs) to eliminate 12 pharmaceuticals (PhACs) and 26 of their corresponding main metabolites and transformation products. The efficiency of these ponds, operating with and without primary treatment, was compared in order to study their capacity under the best performance conditions (highest solar irradiance). Concentrations of all the target compounds were determined in both water and biomass samples. Removal rates ranged from moderate (40-60%) to high (>60%) for most of them, with the exception of the psychiatric drugs carbamazepine, the beta-blocking agent metoprolol and its metabolite, metoprolol acid. O-desmethylvenlafaxine, despite its very low biodegradability in conventional wastewater treatment plants, was removed to certain extent (13-39%) Biomass concentrations suggested that bioadsorption/bioaccumulation to microalgae biomass was decisive regarding the elimination of some non-biodegradable compounds such as venlafaxine and its main metabolites. HRAP treatment with and without primary treatment did not yield significant differences in terms of PhACs removal efficiency. The implementation of HRAPs as secondary treatment is a viable alternative to CAS in terms of overall wastewater treatment (including organic micropollutants), with generally higher removal performances and implying a green, low-cost and more sustainable technology.         _ Less;Health relatedDeep Neural Networks for the Correction of Mie Scattering in Fourier-Transformed Infrared Spectra of Biological Samples;              Infrared spectra obtained from cell or tissue specimen have commonly been observed to involve a significant degree of (resonant) Mie scattering, which often overshadows biochemically relevant spectral information by a non-linear, non-additive spectral component in Fourier transformed infrared (FTIR) spectroscopic measurements. Correspondingly, many successful machine learning approaches for FTIR s…         _ More           Infrared spectra obtained from cell or tissue specimen have commonly been observed to involve a significant degree of (resonant) Mie scattering, which often overshadows biochemically relevant spectral information by a non-linear, non-additive spectral component in Fourier transformed infrared (FTIR) spectroscopic measurements. Correspondingly, many successful machine learning approaches for FTIR spectra have relied on preprocessing procedures that computationally remove the scattering components from an infrared spectrum. We propose an approach to approximate this complex preprocessing function using deep neural networks. As we demonstrate, the resulting model is not just several orders of magnitudes faster, which is important for real-time clinical applications, but also generalizes strongly across different tissue types. Furthermore, our proposed method overcomes the trade-off between computation time and the corrected spectrum being biased towards an artificial reference spectrum.         _ Less;Health relatedTransform-Domain Classification of Human Cells based on DNA Methylation Datasets;A novel method to classify human cells is presented in this work based on the transform-domain method on DNA methylation data. DNA methylation profile variations are observed in human cells with the progression of disease stages, and the proposal is based on this DNA methylation variation to classify normal and disease cells including cancer cells. The cancer cell types investigated in this work c…         _ More           A novel method to classify human cells is presented in this work based on the transform-domain method on DNA methylation data. DNA methylation profile variations are observed in human cells with the progression of disease stages, and the proposal is based on this DNA methylation variation to classify normal and disease cells including cancer cells. The cancer cell types investigated in this work cover hepatocellular (sample size n = 40), colorectal (n = 44), lung (n = 70) and endometrial (n = 87) cancer cells. A new pipeline is proposed integrating the DNA methylation intensity measurements on all the CpG islands by the transformation of Walsh-Hadamard Transform (WHT). The study reveals the three-step properties of the DNA methylation transform-domain data and the step values of association with the cell status. Further assessments have been carried out on the proposed machine learning pipeline to perform classification of the normal and cancer tissue cells. A number of machine learning classifiers are compared for whole sequence and WHT sequence classification based on public Whole-Genome Bisulfite Sequencing (WGBS) DNA methylation datasets. The WHT-based method can speed up the computation time by more than one order of magnitude compared with whole original sequence classification, while maintaining comparable classification accuracy by the selected machine learning classifiers. The proposed method has broad applications in expedited disease and normal human cell classifications by the epigenome and genome datasets.         _ Less;Health relatedDetection of large-scale noisy multi-periodic patterns with discrete double Fourier transform;              In many processes, the variations in underlying characteristics can be approximated by noisy multi-periodic patterns. If large-scale patterns are superimposed by a noise with long-range correlations, the detection of multi-periodic patterns becomes especially challenging. To solve this problem, we developed a discrete double Fourier transform (DDFT). DDFT is based on the equidistance property of h…         _ More           In many processes, the variations in underlying characteristics can be approximated by noisy multi-periodic patterns. If large-scale patterns are superimposed by a noise with long-range correlations, the detection of multi-periodic patterns becomes especially challenging. To solve this problem, we developed a discrete double Fourier transform (DDFT). DDFT is based on the equidistance property of harmonics generated by multi-periodic patterns in the discrete Fourier transform (DFT) spectra. As the large-scale patterns generate long enough equidistant series, they can be detected by the iteration of the primary DFT. DDFT is defined as Fourier transform of intensity spectral harmonics or of their functions. It comprises widely used cepstrum transform as a particular case. We present also the relevant analytical criteria for the assessment of statistical significance of peak harmonics in DDFT spectra in the presence of noise. DDFT technique was tested by extensive numerical simulations. The practical applications of DDFT technique are illustrated by the analysis of variations in solar wind speed related to solar rotation and by the study of large-scale multi-periodic patterns in DNA sequences. The latter application can be considered as generic example for the general spectral analysis of symbolic sequences. The results are compared with those obtained by the cepstrum transform. The mutual combination of DFT and DDFT provides an efficient technique to search for noisy large-scale multi-periodic patterns.         _ Less;Health relatedPhase mapping for cardiac unipolar electrograms with neural network instead of phase transformation;              A phase mapping is an approach to processing signals of electrograms recorded from the surface of cardiac tissue. The main concept of phase mapping is the application of the phase transformation with the aim to obtain signals with useful properties. In our study, we propose to use a simple sawtooth signal instead of a phase signal for processing of electrogram data and building of the phase maps.…         _ More           A phase mapping is an approach to processing signals of electrograms recorded from the surface of cardiac tissue. The main concept of phase mapping is the application of the phase transformation with the aim to obtain signals with useful properties. In our study, we propose to use a simple sawtooth signal instead of a phase signal for processing of electrogram data and building of the phase maps. We denote transformation that can provide this signal as a phase-like transformation (PLT). PLT defined via a convolutional neural network that is trained on a dataset from computer models of cardiac tissue electrophysiology. The proposed approaches were validated on data from the detailed personalized model of the human torso electrophysiology. This paper includes visualization of the phase map based on PLT and shows the robustness of the proposed approaches in the analysis of the complex non-stationary periodic activity of the excitable cardiac tissue.         _ Less;Health relatedTransformer-CNN: Fast and Reliable tool for QSAR;We present SMILES-embeddings derived from the internal encoder state of a Transformer [1] model trained to canonize SMILES as a Seq2Seq problem. Using a CharNN [2] architecture upon the embeddings results in higher quality interpretable QSAR/QSPR models on diverse benchmark datasets including regression and classification tasks. The proposed Transformer-CNN method uses SMILES augmentation for trai…         _ More           We present SMILES-embeddings derived from the internal encoder state of a Transformer [1] model trained to canonize SMILES as a Seq2Seq problem. Using a CharNN [2] architecture upon the embeddings results in higher quality interpretable QSAR/QSPR models on diverse benchmark datasets including regression and classification tasks. The proposed Transformer-CNN method uses SMILES augmentation for training and inference, and thus the prognosis is based on an internal consensus. That both the augmentation and transfer learning are based on embeddings allows the method to provide good results for small datasets. We discuss the reasons for such effectiveness and draft future directions for the development of the method. The source code and the embeddings needed to train a QSAR model are available on https://github.com/bigchem/transformer-cnn. The repository also has a standalone program for QSAR prognosis which calculates individual atoms contributions, thus interpreting the model's result. OCHEM [3] environment (https://ochem.eu) hosts the on-line implementation of the method proposed.         _ Less;Health relatedFetal Head and Abdomen Measurement Using Convolutional Neural Network, Hough Transform, and Difference of Gaussian Revolved along Elliptical Path (Dogell) Algorithm;              The number of fetal-neonatal death in Indonesia is still high compared to developed countries. This is caused by the absence of maternal monitoring during pregnancy. This paper presents an automated measurement for fetal head circumference (HC) and abdominal circumference (AC) from the ultrasonography (USG) image. This automated measurement is beneficial to detect early fetal abnormalities during…         _ More           The number of fetal-neonatal death in Indonesia is still high compared to developed countries. This is caused by the absence of maternal monitoring during pregnancy. This paper presents an automated measurement for fetal head circumference (HC) and abdominal circumference (AC) from the ultrasonography (USG) image. This automated measurement is beneficial to detect early fetal abnormalities during the pregnancy period. We used the convolutional neural network (CNN) method, to preprocess the USG data. After that, we approximate the head and abdominal circumference using the Hough transform algorithm and the difference of Gaussian Revolved along Elliptical Path (Dogell) Algorithm. We used the data set from national hospitals in Indonesia and for the accuracy measurement, we compared our results to the annotated images measured by professional obstetricians. The result shows that by using CNN, we reduced errors caused by a noisy image. We found that the Dogell algorithm performs better than the Hough transform algorithm in both time and accuracy. This is the first HC and AC approximation that used the CNN method to preprocess the data.         _ Less;Not health relatedSource localization of the EEG human brainwaves activities via all the different mother wavelets families for stationary wavelet transform decomposition;The source localization of the human brain activities is an important resource for the recognition of cognitive state, medical disorders and a better understanding of the brain in general. In this study, we have compared 51 mother wavelets from 7 different wavelet families in a Stationary Wavelet transform (SWT) decomposition of an EEG signal. This process includes Haar, Symlets, Daubechies, Coifl…         _ More           The source localization of the human brain activities is an important resource for the recognition of cognitive state, medical disorders and a better understanding of the brain in general. In this study, we have compared 51 mother wavelets from 7 different wavelet families in a Stationary Wavelet transform (SWT) decomposition of an EEG signal. This process includes Haar, Symlets, Daubechies, Coiflets, Discrete Meyer, Biorthogonal and reverse Biorthogonal wavelet families in extracting five different brainwave sub-bands for a source localization. For this process, we used the Independent Component Analysis (ICA) for feature extraction followed by the Boundary Element Model (BEM) and the Equivalent Current Dipole (ECD) for the forward and inverse problem solutions. The evaluation results in investigating the optimal mother wavelet for source localization eventually identified the sym 20 mother wavelet as the best choice followed by bior 6.8 and coif 5.         _ Less;Health relatedUniversal Transforming Geometric Network;The recurrent geometric network (RGN), the first end-to-end differentiable neural architecture for protein structure prediction, is a competitive alternative to existing models. However, the RGN's use of recurrent neural networks (RNNs) as internal representations results in long training time and unstable gradients. And because of its sequential nature, it is less effective at learning global dep…         _ More           The recurrent geometric network (RGN), the first end-to-end differentiable neural architecture for protein structure prediction, is a competitive alternative to existing models. However, the RGN's use of recurrent neural networks (RNNs) as internal representations results in long training time and unstable gradients. And because of its sequential nature, it is less effective at learning global dependencies among amino acids than existing transformer architectures. We propose the Universal Transforming Geometric Network (UTGN), an end-to-end differentiable model that uses the encoder portion of the Universal Transformer architecture as an alternative for internal representations. Our experiments show that compared to RGN, UTGN achieve a $1.7$ \si{\angstrom} improvement on the free modeling portion and a $0.7$ \si{\angstrom} improvement on the template based modeling of the CASP12 competition.         _ Less;Health relatedPain Detection with fNIRS-Measured Brain Signals: A Personalized Machine Learning Approach Using the Wavelet Transform and Bayesian Hierarchical Modeling with Dirichlet Process Priors;              Currently self-report pain ratings are the gold standard in clinical pain assessment. However, the development of objective automatic measures of pain could substantially aid pain diagnosis and therapy. Recent neuroimaging studies have shown the potential of functional near-infrared spectroscopy (fNIRS) for pain detection. This is a brain-imaging technique that provides non-invasive, long-term mea…         _ More           Currently self-report pain ratings are the gold standard in clinical pain assessment. However, the development of objective automatic measures of pain could substantially aid pain diagnosis and therapy. Recent neuroimaging studies have shown the potential of functional near-infrared spectroscopy (fNIRS) for pain detection. This is a brain-imaging technique that provides non-invasive, long-term measurements of cortical hemoglobin concentration changes. In this study, we focused on fNIRS signals acquired exclusively from the prefrontal cortex, which can be accessed unobtrusively, and derived an algorithm for the detection of the presence of pain using Bayesian hierarchical modelling with wavelet features. This approach allows personalization of the inference process by accounting for inter-participant variability in pain responses. Our work highlights the importance of adopting a personalized approach and supports the use of fNIRS for pain assessment.         _ Less;Health relatedCellular State Transformations using Generative Adversarial Networks;              We introduce a novel method to unite deep learning with biology by which generative adversarial networks (GANs) generate transcriptome perturbations and reveal condition-defining gene expression patterns. We find that a generator conditioned to perturb any input gene expression profile simulates a realistic transition between source and target RNA expression states. The perturbed samples follow a…         _ More           We introduce a novel method to unite deep learning with biology by which generative adversarial networks (GANs) generate transcriptome perturbations and reveal condition-defining gene expression patterns. We find that a generator conditioned to perturb any input gene expression profile simulates a realistic transition between source and target RNA expression states. The perturbed samples follow a similar distribution to original samples from the dataset, also suggesting these are biologically meaningful perturbations. Finally, we show that it is possible to identify the genes most positively and negatively perturbed by the generator and that the enriched biological function of the perturbed genes are realistic. We call the framework the Transcriptome State Perturbation Generator (TSPG), which is open source software available at https://github.com/ctargon/TSPG.         _ Less;Health relatedBrain Maturation Study during Adolescence Using Graph Laplacian Learning Based Fourier Transform;Objective: Longitudinal neuroimaging studies have demonstrated that adolescence is the crucial developmental epoch of continued brain growth and change. A large number of researchers dedicate to uncovering the mechanisms about brain maturity during adolescence. Motivated by both achievement in graph signal processing and recent evidence that some brain areas act as hubs connecting functionally spe…         _ More           Objective: Longitudinal neuroimaging studies have demonstrated that adolescence is the crucial developmental epoch of continued brain growth and change. A large number of researchers dedicate to uncovering the mechanisms about brain maturity during adolescence. Motivated by both achievement in graph signal processing and recent evidence that some brain areas act as hubs connecting functionally specialized systems, we proposed an approach to detect these regions from spectral analysis perspective. In particular, as human brain undergoes substantial development throughout adolescence, we addressed the challenge by evaluating the functional network difference among age groups from functional magnetic resonance imaging (fMRI) observations. Methods: We treated these observations as graph signals defined on the parcellated functional brain regions and applied graph Laplacian learning based Fourier Transform (GLFT) to transform the original graph signals into frequency domain. Eigen-analysis was conducted afterwards to study the behavior of the corresponding brain regions, which enables the characterization of brain maturation. Result: We first evaluated our method on the synthetic data and further applied the method to resting and task state fMRI imaging data from Philadelphia Neurodevelopmental Cohort (PNC) dataset, comprised of normally developing adolescents from 8 to 22. The model provided a highest accuracy of 95.69% in distinguishing different adolescence stages. Conclusion: We detected 13 hubs from resting state fMRI and 16 hubs from task state fMRI that are highly related to brain maturation process. Significance: The proposed GLFT method is powerful in extracting the brain connectivity patterns and identifying hub regions with a high prediction power         _ Less;Health relatedAnalysis of evoked EMG using wavelet transformation;Evoked EMG M-responses obtained from the thenar muscle in the palm by electrical stimulation of the median nerve demonstrate a well-established smooth bipolar shape for normal healthy subjects while kinks are observed in certain neurological disorders, particularly in cervical spondylotic neuropathy. A first differentiation failed to identify these kinks because of comparable values obtained for n…         _ More           Evoked EMG M-responses obtained from the thenar muscle in the palm by electrical stimulation of the median nerve demonstrate a well-established smooth bipolar shape for normal healthy subjects while kinks are observed in certain neurological disorders, particularly in cervical spondylotic neuropathy. A first differentiation failed to identify these kinks because of comparable values obtained for normally rising and falling segments of the smooth regions, and due to noise. In this study, the usefulness of the wavelet transform (WT), that provides localized measures of non-stationary signals is investigated. The Haar WT was used to analyze a total of 36 M-responses recorded from the median nerves of 6 normal subjects (having smooth shape) and 12 subjects with assumed neurological disorders (having kinks), for two points of stimulation on the same nerve. Features in the time-scale representation of the M-responses were studied using WT to distinguish smooth M-responses from ones with kinks. Variations in the coefficient line of the WT were also studied to allow visualization of WT at different scales (inverse of frequency). The high and low frequency regions in the WT came out distinctively which helped identifications of kinks even of very subtle ones in the M-responses which were difficult to obtain using the differentiated signal. In conclusion, the wavelet analysis may be a technique of choice in identifying kinks in M-responses in relation to time, thus enhancing the accuracy of neurological diagnosis.         _ Less;Health relatedCombining Mathematical Morphology and the Hilbert Transform for Fully Automatic Nuclei Detection in Fluorescence Microscopy;              Accurate and reliable nuclei identification is an essential part of quantification in microscopy. A range of mathematical and machine learning approaches are used but all methods have limitations. Such limitations include sensitivity to user parameters or a need for pre-processing in classical approaches or the requirement for relatively large amounts of training data in deep learning approaches.…         _ More           Accurate and reliable nuclei identification is an essential part of quantification in microscopy. A range of mathematical and machine learning approaches are used but all methods have limitations. Such limitations include sensitivity to user parameters or a need for pre-processing in classical approaches or the requirement for relatively large amounts of training data in deep learning approaches. Here we demonstrate a new approach for nuclei detection that combines mathematical morphology with the Hilbert transform to detect the centres, sizes and orientations of elliptical objects. We evaluate this approach on datasets from the Broad Bioimage Benchmark Collection and compare it to established algorithms and previously published results. We show this new approach to outperform established classical approaches and be comparable in performance to deep-learning approaches. We believe this approach to be a competitive algorithm for nuclei detection in microscopy.         _ Less;Health relatedChanging cell mechanics -- a precondition for malignant transformation of oral squamous carcinoma cells;Oral squamous cell carcinomas (OSCC) are the 6th most common cancer and the diagnosis is often belated for a curative treatment. The reliable and early differentiation between healthy and diseased cells is the main aim of this study in order to improve the quality of the treatment and to understand tumour pathogenesis. Here, the optical stretcher is used to analyse mechanical properties of cells a…         _ More           Oral squamous cell carcinomas (OSCC) are the 6th most common cancer and the diagnosis is often belated for a curative treatment. The reliable and early differentiation between healthy and diseased cells is the main aim of this study in order to improve the quality of the treatment and to understand tumour pathogenesis. Here, the optical stretcher is used to analyse mechanical properties of cells and their potential to serve as a marker for malignancy. Stretching experiments revealed for the first time that cells of primary OSCCs were deformed by 2.9 % rendering them softer than cells of healthy mucosa which were deformed only by 1.9 %. Furthermore, the relaxation behaviour of the cells revealed that these malignant cells exhibit a faster contraction than their benign counterparts. This suggests that deformability as well as relaxation behaviour can be used as distinct parameters to evaluate emerging differences between these benign and malignant cells. Since many studies in cancer research are performed with cancer cell lines rather than primary cells, we have compared the deformability and relaxation of both types, showing that long time culturing leads to softening of cells. The higher degree of deformability and relaxation behaviour can enable cancer cells to traverse tissue emphasizing that changes in cell architecture may be a potential precondition for malignant transformation. Respecting the fact that even short culture times have an essential effect on the significance of the results, the use of primary cells for further research is recommended. The distinction between malignant and benign cells would enable an early confirmation of cancer diagnoses by testing cell samples of suspect oral lesions.         _ Less;Health relatedFrom genome to phenome: Predicting multiple cancer phenotypes based on somatic genomic alterations via the genomic impact transformer;Cancers are mainly caused by somatic genomic alterations (SGAs) that perturb cellular signaling systems and eventually activate oncogenic processes. Therefore, understanding the functional impact of SGAs is a fundamental task in cancer biology and precision oncology. Here, we present a deep neural network model with encoder-decoder architecture, referred to as genomic impact transformer (GIT), to…         _ More           Cancers are mainly caused by somatic genomic alterations (SGAs) that perturb cellular signaling systems and eventually activate oncogenic processes. Therefore, understanding the functional impact of SGAs is a fundamental task in cancer biology and precision oncology. Here, we present a deep neural network model with encoder-decoder architecture, referred to as genomic impact transformer (GIT), to infer the functional impact of SGAs on cellular signaling systems through modeling the statistical relationships between SGA events and differentially expressed genes (DEGs) in tumors. The model utilizes a multi-head self-attention mechanism to identify SGAs that likely cause DEGs, or in other words, differentiating potential driver SGAs from passenger ones in a tumor. GIT model learns a vector (gene embedding) as an abstract representation of functional impact for each SGA-affected gene. Given SGAs of a tumor, the model can instantiate the states of the hidden layer, providing an abstract representation (tumor embedding) reflecting characteristics of perturbed molecular/cellular processes in the tumor, which in turn can be used to predict multiple phenotypes. We apply the GIT model to 4,468 tumors profiled by The Cancer Genome Atlas (TCGA) project. The attention mechanism enables the model to better capture the statistical relationship between SGAs and DEGs than conventional methods, and distinguishes cancer drivers from passengers. The learned gene embeddings capture the functional similarity of SGAs perturbing common pathways. The tumor embeddings are shown to be useful for tumor status representation, and phenotype prediction including patient survival time and drug response of cancer cell lines.         _ Less;Health relatedSimulating Brain Signals: Creating Synthetic EEG Data via Neural-Based Generative Models for Improved SSVEP Classification;Despite significant recent progress in the area of Brain-Computer Interface (BCI), there are numerous shortcomings associated with collecting Electroencephalography (EEG) signals in real-world environments. These include, but are not limited to, subject and session data variance, long and arduous calibration processes and predictive generalisation issues across different subjects or sessions. This…         _ More           Despite significant recent progress in the area of Brain-Computer Interface (BCI), there are numerous shortcomings associated with collecting Electroencephalography (EEG) signals in real-world environments. These include, but are not limited to, subject and session data variance, long and arduous calibration processes and predictive generalisation issues across different subjects or sessions. This implies that many downstream applications, including Steady State Visual Evoked Potential (SSVEP) based classification systems, can suffer from a shortage of reliable data. Generating meaningful and realistic synthetic data can therefore be of significant value in circumventing this problem. We explore the use of modern neural-based generative models trained on a limited quantity of EEG data collected from different subjects to generate supplementary synthetic EEG signal vectors, subsequently utilised to train an SSVEP classifier. Extensive experimental analysis demonstrates the efficacy of our generated data, leading to improvements across a variety of evaluations, with the crucial task of cross-subject generalisation improving by over 35% with the use of such synthetic data.         _ Less;Health relatedCollective stresses drive competition between monolayers of normal and Ras-transformed cells;              We study the competition for space between two cell lines that differ only in the expression of the Ras oncogene. The two cell populations are initially separated and set to migrate antagonistically towards an in-between stripe of free substrate. After contact, their interface moves towards the population of normal cells. We interpret the velocity and traction force data taken before and after con…         _ More           We study the competition for space between two cell lines that differ only in the expression of the Ras oncogene. The two cell populations are initially separated and set to migrate antagonistically towards an in-between stripe of free substrate. After contact, their interface moves towards the population of normal cells. We interpret the velocity and traction force data taken before and after contact thanks to a hydrodynamic description of collectively migrating cohesive cell sheets. The kinematics of cells, before and after contact, allows us to estimate the relative material parameters for both cell lines. As predicted by the model, the transformed cell population with larger collective stresses pushes the wild type cell population.         _ Less;Health relatedFast determination of coarse grained cell anisotropy and size in epithelial tissue images using Fourier transform;"Mechanical strain and stress play a major role in biological processes such as wound healing or morphogenesis. To assess this role quantitatively, fixed or live images of tissues are acquired at a cellular precision in large fields of views. To exploit these data, large numbers of cells have to be analyzed to extract cell shape anisotropy and cell size. Most frequently, this is performed through d…         _ More           Mechanical strain and stress play a major role in biological processes such as wound healing or morphogenesis. To assess this role quantitatively, fixed or live images of tissues are acquired at a cellular precision in large fields of views. To exploit these data, large numbers of cells have to be analyzed to extract cell shape anisotropy and cell size. Most frequently, this is performed through detailed individual cell contour determination, using so-called segmentation computer programs, complemented if necessary by manual detection and error corrections. However, a coarse grained and faster technique can be recommended in at least three situations. First, when detailed information on individual cell contours is not required, for instance in studies which require only coarse-grained average information on cell anisotropy. Second, as an exploratory step to determine whether full segmentation can be potentially useful. Third, when segmentation is too difficult, for instance due to poor image quality or too large a cell number. We developed a user-friendly, Fourier transform-based image analysis pipeline. It is fast (typically $10^4$ cells per minute with a current laptop computer) and suitable for time, space or ensemble averages. We validate it on one set of artificial images and on two sets of fully segmented images, one from a Drosophila pupa and the other from a chicken embryo; the pipeline results are robust. Perspectives include \textit{in vitro} tissues, non-biological cellular patterns such as foams, and $xyz$ stacks.         _ Less";Health relatedSolving a non-linear model of HIV infection for CD4+T cells by combining Laplace transformation and Homotopy analysis method;The aim of this paper is to find the approximate solution of HIV infection model of CD4+T cells. For this reason, the homotopy analysis transform method (HATM) is applied. The presented method is combination of traditional homotopy analysis method (HAM) and the Laplace transformation. The convergence of presented method is discussed by preparing a theorem which shows the capabilities of method. Th…         _ More           The aim of this paper is to find the approximate solution of HIV infection model of CD4+T cells. For this reason, the homotopy analysis transform method (HATM) is applied. The presented method is combination of traditional homotopy analysis method (HAM) and the Laplace transformation. The convergence of presented method is discussed by preparing a theorem which shows the capabilities of method. The numerical results are shown for different values of iterations. Also, the regions of convergence are demonstrated by plotting several h-curves. Furthermore in order to show the efficiency and accuracy of method, the residual error for different iterations are presented.         _ Less;Health relatedCombining Alchemical Transformation with Physical Pathway to Accurately Compute Absolute Binding Free Energy;We present a new method that combines alchemical transformation with physical pathway to accurately and efficiently compute the absolute binding free energy of receptor-ligand complex. Currently, the double decoupling method (DDM) and the potential of mean force approach (PMF) methods are widely used to compute the absolute binding free energy of biomolecules. The DDM relies on alchemically decoup…         _ More           We present a new method that combines alchemical transformation with physical pathway to accurately and efficiently compute the absolute binding free energy of receptor-ligand complex. Currently, the double decoupling method (DDM) and the potential of mean force approach (PMF) methods are widely used to compute the absolute binding free energy of biomolecules. The DDM relies on alchemically decoupling the ligand from its environments, which can be computationally challenging for large ligands and charged ligands because of the large magnitude of the decoupling free energies involved. On the other hand, the PMF approach uses physical pathway to extract the ligand out of the binding site, thus avoids the alchemical decoupling of the ligand. However, the PMF method has its own drawback because of the reliance on a ligand binding/unbinding pathway free of steric obstruction from the receptor atoms. Therefore, in the presence of deeply buried ligand functional groups the convergence of the PMF calculation can be very slow leading to large errors in the computed binding free energy. Here we develop a new method called AlchemPMF by combining alchemical transformation with physical pathway to overcome the major drawback in the PMF method. We have tested the new approach on the binding of a charged ligand to an allosteric site on HIV-1 Integrase. After 20 ns of simulation per umbrella sampling window, the new method yields absolute binding free energies within ~1 kcal/mol from the experimental result, whereas the standard PMF approach and the DDM calculations result in errors of ~5 kcal/mol and > 2 kcal/mol, respectively. Furthermore, the binding free energy computed using the new method is associated with smaller statistical error compared with those obtained from the existing methods.         _ Less;Health relatedThe Function Transformation Omics - Funomics;"There are no two identical leaves in the world, so how to find effective markers or features to distinguish them is an important issue. Function transformation, such as f(x,y) and f(x,y,z), can transform two, three, or multiple input/observation variables (in biology, it generally refers to the observed/measured value of biomarkers, biological characteristics, or other indicators) into a new outpu…         _ More           There are no two identical leaves in the world, so how to find effective markers or features to distinguish them is an important issue. Function transformation, such as f(x,y) and f(x,y,z), can transform two, three, or multiple input/observation variables (in biology, it generally refers to the observed/measured value of biomarkers, biological characteristics, or other indicators) into a new output variable (new characteristics or indicators). This provided us a chance to re-cognize objective things or relationships beyond the original measurements. For example, Body Mass Index, which transform weight and high into a new indicator BMI=x/y^2 (where x is weight and y is high), is commonly used in to gauge obesity. Here, we proposed a new system, Funomics (Function Transformation Omics), for understanding the world in a different perspective. Funome can be understood as a set of math functions consist of basic elementary functions (such as power functions and exponential functions) and basic mathematical operations (such as addition, subtraction). By scanning the whole Funome, researchers can identify some special functions (called handsome functions) which can generate the novel important output variable (characteristics or indicators). We also start ""the Funome project"" to develop novel methods, function library and analysis software for Funome studies. The Funome project will accelerate the discovery of new useful indicators or characteristics, will improve the utilization efficiency of directly measured data, and will enhance our ability to understand the world. The analysis tools and data resources about the Funome project can be found gradually at http://www.funome.com.         _ Less";Health relatedAutomated identification of flagella from videomicroscopy via the medial axis transform;              Ubiquitous in eukaryotic organisms, the flagellum is a well-studied organelle that is well-known to be responsible for motility in a variety of organisms. Commonly necessitated in their study is the capability to image and subsequently track the movement of one or more flagella using videomicroscopy, requiring digital isolation and location of the flagellum within a sequence of frames. Such a proc…         _ More           Ubiquitous in eukaryotic organisms, the flagellum is a well-studied organelle that is well-known to be responsible for motility in a variety of organisms. Commonly necessitated in their study is the capability to image and subsequently track the movement of one or more flagella using videomicroscopy, requiring digital isolation and location of the flagellum within a sequence of frames. Such a process in general currently requires some researcher input, providing some manual estimate or reliance on an experiment-specific heuristic to correctly identify and track the motion of a flagellum. Here we present a fully-automated method of flagellum identification from videomicroscopy based on the fact that the flagella are of approximately constant width when viewed by microscopy. We demonstrate the effectiveness of the algorithm by application to captured videomicroscopy of Leishmania mexicana, a parasitic monoflagellate of the family Trypanosomatidae. ImageJ Macros for flagellar identification are provided, and high accuracy and remarkable throughput are achieved via this unsupervised method, obtaining results comparable in quality to previous studies of closely-related species but achieved without the need for precursory measurements or the development of a specialised heuristic, enabling in general the automated generation of digitised kinematic descriptions of flagellar beating from videomicroscopy.         _ Less;Health relatedDynamic modulation of external conditions can transform chemistry into logic gates;              We introduce a new method for transforming chemical systems into desired logical operators (e.g. NAND-gates) or similar signal-manipulation components. The method is based upon open-loop dynamic regulation, where external conditions such as feed-rate, lighting conditions, etc. are modulated according to a prescribed temporal sequence that is independent of the input to the network. The method is f…         _ More           We introduce a new method for transforming chemical systems into desired logical operators (e.g. NAND-gates) or similar signal-manipulation components. The method is based upon open-loop dynamic regulation, where external conditions such as feed-rate, lighting conditions, etc. are modulated according to a prescribed temporal sequence that is independent of the input to the network. The method is first introduced using a simple didactic model. We then show its application in transforming a well-stirred cubic autocatalytic reaction (often referred to as the Selkov-Gray-Scott model) into a logical NAND-gate. We also comment on the applicability of the method to biological and other systems.         _ Less;Health relatedAddressing Class Imbalance in Classification Problems of Noisy Signals by using Fourier Transform Surrogates;Randomizing the Fourier-transform (FT) phases of temporal-spatial data generates surrogates that approximate examples from the data-generating distribution. We propose such FT surrogates as a novel tool to augment and analyze training of neural networks and explore the approach in the example of sleep-stage classification. By computing FT surrogates of raw EEG, EOG, and EMG signals of under-repres…         _ More           Randomizing the Fourier-transform (FT) phases of temporal-spatial data generates surrogates that approximate examples from the data-generating distribution. We propose such FT surrogates as a novel tool to augment and analyze training of neural networks and explore the approach in the example of sleep-stage classification. By computing FT surrogates of raw EEG, EOG, and EMG signals of under-represented sleep stages, we balanced the CAPSLPDB sleep database. We then trained and tested a convolutional neural network for sleep stage classification, and found that our surrogate-based augmentation improved the mean F1-score by 7%. As another application of FT surrogates, we formulated an approach to compute saliency maps for individual sleep epochs. The visualization is based on the response of inferred class probabilities under replacement of short data segments by partial surrogates. To quantify how well the distributions of the surrogates and the original data match, we evaluated a trained classifier on surrogates of correctly classified examples, and summarized these conditional predictions in a confusion matrix. We show how such conditional confusion matrices can qualitatively explain the performance of surrogates in class balancing. The FT-surrogate augmentation approach may improve classification on noisy signals if carefully adapted to the data distribution under analysis.         _ Less;Health relatedApproximate Analytical Solution of a Cancer Immunotherapy Model by the Application of Differential Transform and Adomian Decomposition Methods;Immunotherapy plays a major role in tumour treatment, in comparison with other methods of dealing with cancer. The Kirschner-Panetta (KP) model of cancer immunotherapy describes the interaction between tumour cells, effector cells and interleukin-2 which are clinically utilized as medical treatment. The model selects a rich concept of immune-tumour dynamics. In this paper, approximate analytical s…         _ More           Immunotherapy plays a major role in tumour treatment, in comparison with other methods of dealing with cancer. The Kirschner-Panetta (KP) model of cancer immunotherapy describes the interaction between tumour cells, effector cells and interleukin-2 which are clinically utilized as medical treatment. The model selects a rich concept of immune-tumour dynamics. In this paper, approximate analytical solutions to KP model are represented by using the differential transform and Adomian decomposition. The complicated nonlinearity of the KP system causes the application of these two methods to require more involved calculations. The approximate analytical solutions to the model are compared with the results obtained by numerical fourth order Runge-Kutta method.         _ Less;Health related"Pediatric lymphoma may develop by ""one-step"" cell transformation of a lymphoid cell";"Lymphomas are a large group of neoplasms developed from lymphoid cells (LCs) in lymph nodes (LNs) or lymphoid tissues (LTs). Some forms of lymphomas, including Burkitt lymphoma (BL), ALK+ anaplastic large cell lymphoma (ALK+-ALCL), and T-cell lymphoblastic lymphoma/leukemia (T-LBL), occur mainly in children and teenagers. Hodgkin's lymphoma (HL) has a peak incidence at age 20s. To understand pedia…         _ More           Lymphomas are a large group of neoplasms developed from lymphoid cells (LCs) in lymph nodes (LNs) or lymphoid tissues (LTs). Some forms of lymphomas, including Burkitt lymphoma (BL), ALK+ anaplastic large cell lymphoma (ALK+-ALCL), and T-cell lymphoblastic lymphoma/leukemia (T-LBL), occur mainly in children and teenagers. Hodgkin's lymphoma (HL) has a peak incidence at age 20s. To understand pediatric lymphoma, we have recently proposed two hypotheses on the causes and the mechanism of cell transformation of a LC. Hypothesis A is: repeated bone-remodeling during bone-growth and bone-repair may be a source of cell injuries of marrow cells including hematopoietic stem cells (HSCs), myeloid cells, and LCs, and thymic involution may be a source of damage to the developing T-cells in thymus. Hypothesis B is: a LC may have three pathways on transformation: a slow, a rapid, and an accelerated. In this paper, we discuss pediatric lymphomas by this hypothesis. Having a peak incidence at young age, BL, T-LBL, ALK+-ALCL, and HL develop more likely as a result of rapid transformation of a LC. In BL, ALK+-ALCL, and HL, the cell transformations may be triggered by severe viral infections. In T-LBL, the cell transformation may be related to thymic involution. Occurring in both adults and children, diffuse large B-cell lymphoma (DLBCL) may develop via slow or accelerated pathway. In conclusion, pediatric lymphoma may develop as a result of ""one-step"" cell transformation of a LC, and severe viral infections may be the main trigger for the rapid transformation of a LC in a LN/LT.         _ Less";Health relatedAcute lymphoblastic leukemia may develop as a result of rapid transformation of a lymphoblast triggered by repeated bone-remodeling during bone-growth;"              Acute lymphoblastic leukemia (ALL) and chronic lymphocytic leukemia (CLL) are two major forms of leukemia that arise from lymphoid cells (LCs). ALL occurs mostly in children and CLL occurs mainly in old people. However, the Philadelphia-chromosome-positive ALL (Ph+-ALL) and the Ph-like ALL occur in both children and adults. To understand childhood leukemia/lymphoma, we have recently proposed two h…         _ More           Acute lymphoblastic leukemia (ALL) and chronic lymphocytic leukemia (CLL) are two major forms of leukemia that arise from lymphoid cells (LCs). ALL occurs mostly in children and CLL occurs mainly in old people. However, the Philadelphia-chromosome-positive ALL (Ph+-ALL) and the Ph-like ALL occur in both children and adults. To understand childhood leukemia/lymphoma, we have recently proposed two hypotheses on the causes and the mechanism of cell transformation of a LC. Hypothesis A is: repeated bone-remodeling during bone-growth and bone-repair may be a source of cell injuries of marrow cells including hematopoietic stem cells (HSCs), myeloid cells, and LCs. Hypothesis B is: a LC may have three pathways on transformation: a slow, a rapid, and an accelerated. We discuss in the present paper the developing mechanisms of ALL and CLL by these hypotheses. Having a peak incidence in young children, ALL may develop mainly as a result of rapid cell transformation of a lymphoblast (or pro-lymphocyte). Differently, Ph+-ALL and Ph-like ALL may develop as results of transformation of a lymphoblast via accelerated pathway. Occurring mainly in adults, CLL may be a result of transformation of a memory B-cell via slow pathway. By causing cell injuries of HSCs and LCs, repeated bone-remodeling during bone-growth and bone-repair may be related to the cell transformation of a LC. In conclusion, ALL may develop as a result of cell transformation of a lymphoblast via rapid or accelerated pathway; and repeated bone-remodeling during bone-growth may be a trigger for the cell transformation of a lymphoblast in a child.         _ Less";Health relatedThree pathways of cell transformation of lymphoid cell: a slow, a rapid, and an accelerated;"              Lymphoid leukemia (LL) and lymphoma are neoplasms developed from lymphoid cells (LCs). To understand why different forms of LL/lymphoma occur at different ages, we analyzed the effects of different types of DNA changes on a LC and the cellular characteristics of LCs. Point DNA mutations (PDMs) and chromosome changes (CCs) are the two major types of DNA changes. CCs have three subtypes by their eff…         _ More           Lymphoid leukemia (LL) and lymphoma are neoplasms developed from lymphoid cells (LCs). To understand why different forms of LL/lymphoma occur at different ages, we analyzed the effects of different types of DNA changes on a LC and the cellular characteristics of LCs. Point DNA mutations (PDMs) and chromosome changes (CCs) are the two major types of DNA changes. CCs have three subtypes by their effects on a LC: great-effect CCs (GECCs), mild-effect CCs (MECCs), and intermediate-effect CCs (IECCs). PDMs and MECCs are mostly mild thus can accumulate in cells. Some of the PDMs/MECCs contribute to cell transformation. A GECC affects one or more genes and can alone drive cell transformation. An IECC affects one or more genes and participates in cell transformation. Due to cellular characteristics, a LC may have higher survivability from DNA changes and require obtaining fewer cancerous properties for transformation than a tissue cell. Hence, a LC can be more rapidly transformed by a CC. On this basis, we hypothesize that a LC may have three pathways on transformation: a slow, a rapid, and an accelerated. Slow pathway is driven by accumulation of PDMs/MECCs. Rapid pathway is driven by a GECC in ""one step"". Accelerated pathway is driven by accumulation of PDMs/MECCs/IECC(s). Cell transformations of a LC via different pathways occur at different ages. A transformation via slow pathway occurs mainly in adults. A transformation via rapid pathway occurs at any age and has no increasing incidence with age. A transformation via accelerated pathway occurs also at any age but has increasing incidence with age. In conclusion, a LC may have three pathways on cell transformation, and the occurring age of LL/lymphoma may be determined by the transforming pathway of a LC.         _ Less";Not health relatedCharacterizing Allegheny County Opioid Overdoses with an Interactive Data Explorer and Synthetic Prediction Tool;              The United States has an opioid epidemic, and Pennsylvania's Allegheny County is among the worst. This motivates a deeper exploration of what characterizes the epidemic, such as what are risk factors for people who ultimately overdose and die due to opioids. We show that some interesting trends and factors can be identified from openly available autopsy data, and demonstrate the power of building…         _ More           The United States has an opioid epidemic, and Pennsylvania's Allegheny County is among the worst. This motivates a deeper exploration of what characterizes the epidemic, such as what are risk factors for people who ultimately overdose and die due to opioids. We show that some interesting trends and factors can be identified from openly available autopsy data, and demonstrate the power of building an interactive data exploration tool for policy makers. However, there is still a pressing need to incorporate further demographic factors. We show this by using synthetic Electronic Medical Record (EMR) data to simulate the predictive power of random forests and neural networks when given additional loosely correlated features. In addition, we give examples of useful feature extraction that enable model enhancement without sacrificing privacy.         _ Less;Health relatedMeanings, Metaphors, and Morphisms: Theory of Indeterminate Natural Transformation (TINT);"              In the present paper, we propose a new theory named ""Theory of indeterminate natural transformation (TINT)"" to investigate the dynamical creation of meanings as association relationships between images, focusing on the metaphor comprehension as an example. TINT models the meaning creation as a kind of stochastic processes based on the mathematical structure defined by association relationships as…         _ More           In the present paper, we propose a new theory named ""Theory of indeterminate natural transformation (TINT)"" to investigate the dynamical creation of meanings as association relationships between images, focusing on the metaphor comprehension as an example. TINT models the meaning creation as a kind of stochastic processes based on the mathematical structure defined by association relationships as morphisms in category theory, so as to represent the indeterminate nature of structure-structure interactions between the systems of the meanings of images. Such interactions are formulated in terms of so-called coslice categories and functors as structure-preserving correspondence between them. The relationship between such functors is ""indeterminate natural transformation"", the central notion in TINT, which models the creation of meanings in a precise manner. For instance, the process of metaphor comprehension is modeled by the construction of indeterminate natural transformation from a canonically defined functor which we call the base-of-metaphor functor.         _ Less";Not health relatedTranslating the Architectural Complexity of the Colon or Polyp into a Sinusoid Wave for Classification via the Fast Fourier Transform;There is no method to quantify the spatial complexity within colon polyps. This paper describes a spatial transformation that translates the tissue architecture within a polyp, or a normal colon lining, into a complex sinusoid wave composed of discrete points. This sinusoid wave can then undergo the Fast Fourier Transform to obtain a spectrum of frequencies that represents the sinusoid wave. This…         _ More           There is no method to quantify the spatial complexity within colon polyps. This paper describes a spatial transformation that translates the tissue architecture within a polyp, or a normal colon lining, into a complex sinusoid wave composed of discrete points. This sinusoid wave can then undergo the Fast Fourier Transform to obtain a spectrum of frequencies that represents the sinusoid wave. This spectrum can then serve as a signature of the spatial complexity [an index] within the polyp. By overlaying vertical lines that radiate from the bottom middle [like a fold-out fan] of an image of a polyp stained by hematoxylin and eosin, the image is segmented into sectors. Each vertical line also forms an angle with the horizontal axis of the image, ranging from 0 degrees to 180 degrees rising counter clockwise. Each vertical line will intersect with various features of the polyp [border of lumens, border of epithelial lining]. Each of these intersections is a point that can be characterized by its distance from the origin [this distance is also a magnitude of that point]. Thus, each intersection between radial line and polyp feature can be mapped by polar coordinates [radius length, angle measure]. By summing the distance of all points along the same radial line, each radial line that divides the image becomes one value. Plotting these values [y variable] against the angle of each radial line from the horizontal axis [x variable] results in a sinusoid wave consisting of discrete points. This method is referred to as the Linearized Compressed Polar Coordinates [LCPC] Transform. The LCPC transform, in conjunction with the Fast Fourier Transform, can reduce the complexity of visually hidden histological grades in colon polyps into categories of similar wave frequencies [each histological grade has a signature consisting of a handful of frequencies].         _ Less;Health relatedTransformation of arbitrary distributions to the normal distribution with application to EEG test-retest reliability;Many variables in the social, physical, and biosciences, including neuroscience, are non-normally distributed. To improve the statistical properties of such data, or to allow parametric testing, logarithmic or logit transformations are often used. Box-Cox transformations or ad hoc methods are sometimes used for parameters for which no transformation is known to approximate normality. However, thes…         _ More           Many variables in the social, physical, and biosciences, including neuroscience, are non-normally distributed. To improve the statistical properties of such data, or to allow parametric testing, logarithmic or logit transformations are often used. Box-Cox transformations or ad hoc methods are sometimes used for parameters for which no transformation is known to approximate normality. However, these methods do not always give good agreement with the Gaussian. A transformation is discussed that maps probability distributions as closely as possible to the normal distribution, with exact agreement for continuous distributions. To illustrate, the transformation is applied to a theoretical distribution, and to quantitative electroencephalographic (qEEG) measures from repeat recordings of 32 subjects which are highly non-normal. Agreement with the Gaussian was better than using logarithmic, logit, or Box-Cox transformations. Since normal data have previously been shown to have better test-retest reliability than non-normal data under fairly general circumstances, the implications of our transformation for the test-retest reliability of parameters were investigated. Reliability was shown to improve with the transformation, where the improvement was comparable to that using Box-Cox. An advantage of the general transformation is that it does not require laborious optimization over a range of parameters or a case-specific choice of form.         _ Less;Health relatedChemical Transformation Motifs - Modelling Pathways as Integer Hyperflows;              We present an elaborate framework for formally modelling pathways in chemical reaction networks on a mechanistic level. Networks are modelled mathematically as directed multi-hypergraphs, with vertices corresponding to molecules and hyperedges to reactions. Pathways are modelled as integer hyperflows and we expand the network model by detailed routing constraints. In contrast to the more tradition…         _ More           We present an elaborate framework for formally modelling pathways in chemical reaction networks on a mechanistic level. Networks are modelled mathematically as directed multi-hypergraphs, with vertices corresponding to molecules and hyperedges to reactions. Pathways are modelled as integer hyperflows and we expand the network model by detailed routing constraints. In contrast to the more traditional approaches like Flux Balance Analysis or Elementary Mode analysis we insist on integer-valued flows. While this choice makes it necessary to solve possibly hard integer linear programs, it has the advantage that more detailed mechanistic questions can be formulated. It is thus possible to query networks for general transformation motifs, and to automatically enumerate optimal and near-optimal pathways. Similarities and differences between our work and traditional approaches in metabolic network analysis are discussed in detail. To demonstrate the applicability of the mathematical framework to real-life problems we first explore the design space of possible non-oxidative glycolysis pathways and show that recent manually designed pathways can be further optimised. We then use a model of sugar chemistry to investigate pathways in the autocatalytic formose process. A graph transformation-based approach is used to automatically generate the reaction networks of interest.         _ Less;Health relatedUsing the Fast Fourier Transform in Binding Free Energy Calculations;According to implicit ligand theory, the standard binding free energy is an exponential average of the binding potential of mean force (BPMF), an exponential average of the interaction energy between the ligand apo ensemble and a rigid receptor. Here, we use the Fast Fourier Transform (FFT) to efficiently estimate BPMFs by calculating interaction energies as rigid ligand configurations from the ap…         _ More           According to implicit ligand theory, the standard binding free energy is an exponential average of the binding potential of mean force (BPMF), an exponential average of the interaction energy between the ligand apo ensemble and a rigid receptor. Here, we use the Fast Fourier Transform (FFT) to efficiently estimate BPMFs by calculating interaction energies as rigid ligand configurations from the apo ensemble are discretely translated across rigid receptor conformations. Results for standard binding free energies between T4 lysozyme and 141 small organic molecules are in good agreement with previous alchemical calculations based on (1) a flexible complex (R ~ 0.9 for 24 systems) and (2) flexible ligand with multiple rigid receptor configurations (R ~ 0.8 for 141 systems). While the FFT is routinely used for molecular docking, to our knowledge this is the first time that the algorithm has been used for rigorous binding free energy calculations.         _ Less;Health relatedData-Driven Tree Transforms and Metrics;              We consider the analysis of high dimensional data given in the form of a matrix with columns consisting of observations and rows consisting of features. Often the data is such that the observations do not reside on a regular grid, and the given order of the features is arbitrary and does not convey a notion of locality. Therefore, traditional transforms and metrics cannot be used for data organiza…         _ More           We consider the analysis of high dimensional data given in the form of a matrix with columns consisting of observations and rows consisting of features. Often the data is such that the observations do not reside on a regular grid, and the given order of the features is arbitrary and does not convey a notion of locality. Therefore, traditional transforms and metrics cannot be used for data organization and analysis. In this paper, our goal is to organize the data by defining an appropriate representation and metric such that they respect the smoothness and structure underlying the data. We also aim to generalize the joint clustering of observations and features in the case the data does not fall into clear disjoint groups. For this purpose, we propose multiscale data-driven transforms and metrics based on trees. Their construction is implemented in an iterative refinement procedure that exploits the co-dependencies between features and observations. Beyond the organization of a single dataset, our approach enables us to transfer the organization learned from one dataset to another and to integrate several datasets together. We present an application to breast cancer gene expression analysis: learning metrics on the genes to cluster the tumor samples into cancer sub-types and validating the joint organization of both the genes and the samples. We demonstrate that using our approach to combine information from multiple gene expression cohorts, acquired by different profiling technologies, improves the clustering of tumor samples.         _ Less;Health relatedRobust transformations of firing patterns for neural networks;              As a promising computational paradigm, occurrence of critical states in artificial and biological neural networks has attracted wide-spread attention. An often-made explicit or implicit assumption is that one single critical state is responsible for two separate notions of criticality (avalanche criticality and dynamical edge of chaos criticality). Previously, we provided an isolated counter-examp…         _ More           As a promising computational paradigm, occurrence of critical states in artificial and biological neural networks has attracted wide-spread attention. An often-made explicit or implicit assumption is that one single critical state is responsible for two separate notions of criticality (avalanche criticality and dynamical edge of chaos criticality). Previously, we provided an isolated counter-example for co-occurrence. Here, we reveal a persistent paradigm of structural transitions that such networks undergo, as the overall connectivity strength is varied over its biologically meaningful range. Among these transitions, only one avalanche critical point emerges, with edge of chaos failing to co-occur. Our observations are based on ensembles of networks obtained from variations of network configuration and their neurons. This suggests that not only non-coincidence of criticality, but also the persistent paradigm of network structural changes in function of the overall connectivity strength, could be generic features of a large class of biological neural networks.         _ Less;Health relatedCoalescent-based species tree estimation: a stochastic Farris transform;The reconstruction of a species phylogeny from genomic data faces two significant hurdles: 1) the trees describing the evolution of each individual gene--i.e., the gene trees--may differ from the species phylogeny and 2) the molecular sequences corresponding to each gene often provide limited information about the gene trees themselves. In this paper we consider an approach to species tree reconst…         _ More           The reconstruction of a species phylogeny from genomic data faces two significant hurdles: 1) the trees describing the evolution of each individual gene--i.e., the gene trees--may differ from the species phylogeny and 2) the molecular sequences corresponding to each gene often provide limited information about the gene trees themselves. In this paper we consider an approach to species tree reconstruction that addresses both these hurdles. Specifically, we propose an algorithm for phylogeny reconstruction under the multispecies coalescent model with a standard model of site substitution. The multispecies coalescent is commonly used to model gene tree discordance due to incomplete lineage sorting, a well-studied population-genetic effect.   In previous work, an information-theoretic trade-off was derived in this context between the number of loci, $m$, needed for an accurate reconstruction and the length of the locus sequences, $k$. It was shown that to reconstruct an internal branch of length $f$, one needs $m$ to be of the order of $1/[f^{2} \sqrt{k}]$. That previous result was obtained under the molecular clock assumption, i.e., under the assumption that mutation rates (as well as population sizes) are constant across the species phylogeny.   Here we generalize this result beyond the restrictive molecular clock assumption, and obtain a new reconstruction algorithm that has the same data requirement (up to log factors). Our main contribution is a novel reduction to the molecular clock case under the multispecies coalescent. As a corollary, we also obtain a new identifiability result of independent interest: for any species tree with $n \geq 3$ species, the rooted species tree can be identified from the distribution of its unrooted weighted gene trees even in the absence of a molecular clock.         _ Less;Health relatedMultiscale Granger causality analysis by à trous wavelet transform;              Since interactions in neural systems occur across multiple temporal scales, it is likely that information flow will exhibit a multiscale structure, thus requiring a multiscale generalization of classical temporal precedence causality analysis like Granger's approach. However, the computation of multiscale measures of information dynamics is complicated by theoretical and practical issues such as f…         _ More           Since interactions in neural systems occur across multiple temporal scales, it is likely that information flow will exhibit a multiscale structure, thus requiring a multiscale generalization of classical temporal precedence causality analysis like Granger's approach. However, the computation of multiscale measures of information dynamics is complicated by theoretical and practical issues such as filtering and undersampling: to overcome these problems, we propose a wavelet-based approach for multiscale Granger causality (GC) analysis, which is characterized by the following properties: (i) only the candidate driver variable is wavelet transformed (ii) the decomposition is performed using the à trous wavelet transform with cubic B-spline filter. We measure GC, at a given scale, by including the wavelet coefficients of the driver times series, at that scale, in the regression model of the target. To validate our method, we apply it to publicly available scalp EEG signals, and we find that the condition of closed eyes, at rest, is characterized by an enhanced GC among channels at slow scales w.r.t. eye open condition, whilst the standard Granger causality is not significantly different in the two conditions.         _ Less;Health relatedA fast method for the detection of vascular structure in images, based on the continuous wavelet transform with the Morlet wavelet having a low central frequency;              A manual measurement of blood vessels diameter is a conventional component of routine visual assessment of microcirculation, say, during optical capillaroscopy. However, many modern optical methods for blood flow measurements demand the reliable procedure for a fully automated detection of vessels and estimation of their diameter that is a challenging task. Specifically, if one measure the velocit…         _ More           A manual measurement of blood vessels diameter is a conventional component of routine visual assessment of microcirculation, say, during optical capillaroscopy. However, many modern optical methods for blood flow measurements demand the reliable procedure for a fully automated detection of vessels and estimation of their diameter that is a challenging task. Specifically, if one measure the velocity of red blood cells by means of laser speckle imaging, then visual measurements become impossible, while the velocity-based estimation has their own limitations. One of promising approaches is based on fast switching of illumination type, but it drastically reduces the observation time, and hence, the achievable quality of images. In the present work we address this problem proposing an alternative method for the processing of noisy images of vascular structure, which extracts the mask denoting locations of vessels, based on the application of the continuous wavelet transform with the Morlet wavelet having small central frequencies. Such a method combines a reasonable accuracy with the possibility of fast direct implementation to images. Discussing the latter, we describe in details a new MATLAB program code realization for the CWT with the Morlet wavelet, which does not use loops completely replaced with element-by-element operations that drastically reduces the computation time.         _ Less;Not health relatedOn parameters transformations for emulating sparse priors using variational-Laplace inference;"So-called sparse estimators arise in the context of model fitting, when one a priori assumes that only a few (unknown) model parameters deviate from zero. Sparsity constraints can be useful when the estimation problem is under-determined, i.e. when number of model parameters is much higher than the number of data points. Typically, such constraints are enforced by minimizing the L1 norm, which yie…         _ More           So-called sparse estimators arise in the context of model fitting, when one a priori assumes that only a few (unknown) model parameters deviate from zero. Sparsity constraints can be useful when the estimation problem is under-determined, i.e. when number of model parameters is much higher than the number of data points. Typically, such constraints are enforced by minimizing the L1 norm, which yields the so-called LASSO estimator. In this work, we propose a simple parameter transform that emulates sparse priors without sacrificing the simplicity and robustness of L2-norm regularization schemes. We show how L1 regularization can be obtained with a ""sparsify"" remapping of parameters under normal Bayesian priors, and we demonstrate the ensuing variational Laplace approach using Monte-Carlo simulations.         _ Less";Health relatedLarge-scale chromosome folding versus genomic DNA sequences: A discrete double Fourier transform technique;Using state-of-the-art techniques combining imaging methods and high-throughput genomic mapping tools leaded to the significant progress in detailing chromosome architecture of various organisms. However, a gap still remains between the rapidly growing structural data on the chromosome folding and the large-scale genome organization. Could a part of information on the chromosome folding be obtaine…         _ More           Using state-of-the-art techniques combining imaging methods and high-throughput genomic mapping tools leaded to the significant progress in detailing chromosome architecture of various organisms. However, a gap still remains between the rapidly growing structural data on the chromosome folding and the large-scale genome organization. Could a part of information on the chromosome folding be obtained directly from underlying genomic DNA sequences abundantly stored in the databanks? To answer this question, we developed an original discrete double Fourier transform (DDFT). DDFT serves for the detection of large-scale genome regularities associated with domains/units at the different levels of hierarchical chromosome folding. The method is versatile and can be applied to both genomic DNA sequences and corresponding physico-chemical parameters such as base-pairing free energy. The latter characteristic is closely related to the replication and transcription and can also be used for the assessment of temperature or supercoiling effects on the chromosome folding. We tested the method on the genome of Escherichia coli K-12 and found good correspondence with the annotated domains/units established experimentally. As a brief illustration of further abilities of DDFT, the study of large-scale genome organization for bacteriophage PHIX174 and bacterium Caulobacter crescentus was also added. The combined experimental, modeling, and bioinformatic DDFT analysis should yield more complete knowledge on the chromosome architecture and genome organization.         _ Less;Health relatedTopological transformations in proteins: effects of heating and proximity of an interface;              Using a structure-based coarse-grained model of proteins, we study the mechanism of unfolding of knotted proteins through heating. We find that the dominant mechanisms of unfolding depend on the temperature applied and are generally distinct from those identified for folding at its optimal temperature. In particular, for shallowly knotted proteins, folding usually involves formation of two loops w…         _ More           Using a structure-based coarse-grained model of proteins, we study the mechanism of unfolding of knotted proteins through heating. We find that the dominant mechanisms of unfolding depend on the temperature applied and are generally distinct from those identified for folding at its optimal temperature. In particular, for shallowly knotted proteins, folding usually involves formation of two loops whereas unfolding through high-temperature heating is dominated by untying of single loops. Untying the knots is found to generally precede unfolding unless the protein is deeply knotted and the heating temperature exceeds a threshold value. We then use a phenomenological model of the air-water interface to show that such an interface can untie shallow knots, but it can also make knots in proteins that are natively unknotted.         _ Less;Health relatedProtein-protein docking by generalized Fourier transforms on 5D rotational manifolds;Energy evaluation using fast Fourier transforms enables sampling billions of putative complex structures and hence revolutionized rigid protein-protein docking. However, in current methods efficient acceleration is achieved only in either the translational or the rotational subspace. Developing an efficient and accurate docking method that expands FFT based sampling to 5 rotational coordinates is…         _ More           Energy evaluation using fast Fourier transforms enables sampling billions of putative complex structures and hence revolutionized rigid protein-protein docking. However, in current methods efficient acceleration is achieved only in either the translational or the rotational subspace. Developing an efficient and accurate docking method that expands FFT based sampling to 5 rotational coordinates is an extensively studied but still unsolved problem. The algorithm presented here retains the accuracy of earlier methods but yields at least tenfold speedup. The improvement is due to two innovations. First, the search space is treated as the product manifold $\mathbf{SO(3)x(SO(3)\setminus S^1)}$, where $\mathbf{SO(3)}$ is the rotation group representing the space of the rotating ligand, and $\mathbf{(SO(3)\setminus S^1)}$ is the space spanned by the two Euler angles that define the orientation of the vector from the center of the fixed receptor toward the center of the ligand. This representation enables the use of efficient FFT methods developed for $\mathbf{SO(3)}$. Second, we select the centers of highly populated clusters of docked structures, rather than the lowest energy conformations, as predictions of the complex, and hence there is no need for very high accuracy in energy evaluation. Therefore it is sufficient to use a limited number of spherical basis functions in the Fourier space, which increases the efficiency of sampling while retaining the accuracy of docking results. A major advantage of the method is that, in contrast to classical approaches, increasing the number of correlation function terms is computationally inexpensive, which enables using complex energy functions for scoring.         _ Less;Health relatedA Fractional Differential Transformation Solution Method for the Assessment, Monitoring, Control, and Evaluation of HIV/AIDS Confirmed Status with Vertical Transmission in Nigeria;HIV is a deadly virus transmitted either through having of unprotected sex, mother to child transmission, sharing of unsterilized objects that is capable of making cut or wounds on the body, through blood or bodily fluid transmission. AIDS has no permanent cure but remedies that help in suppressing the power effect of the virus are available. Previous studies has shown that the epidemic claimed mo…         _ More           HIV is a deadly virus transmitted either through having of unprotected sex, mother to child transmission, sharing of unsterilized objects that is capable of making cut or wounds on the body, through blood or bodily fluid transmission. AIDS has no permanent cure but remedies that help in suppressing the power effect of the virus are available. Previous studies has shown that the epidemic claimed more lives via vertical transmission, mother-to-child transmission, blood transfusion, sexual intercourse and injection drug users. The associated models were derived using diagnosis and treatments records of confirmed status of HIV/AIDS clients. A new model analysis were proposed that could handle cases of HIV/AIDS routes of transmission and treatments via vertical, mother-to-child, blood transfusion, sexual intercourse, injection drug users that were not considered in previous studies. The new model was solved using Fractional Differential Transformation by Caputo sense algorithm. The new model is a major contribution for optimal assessment, monitoring, evaluation, control and management of HIV/AIDS, with 75% accuracy.         _ Less;Not health relatedRenormalization Group Transformation for Hamiltonian Dynamical Systems in Biological Networks;              We apply the renormalization group theory to the dynamical systems with the simplest example of basic biological motifs. This includes the interpretation of complex networks as the perturbation to simple network. This is the first step to build our original framework to infer the properties of biological networks, and the basis work to see its effectiveness to actual complex systems.                          We apply the renormalization group theory to the dynamical systems with the simplest example of basic biological motifs. This includes the interpretation of complex networks as the perturbation to simple network. This is the first step to build our original framework to infer the properties of biological networks, and the basis work to see its effectiveness to actual complex systems.         _ Less;Health relatedExtract fetal ECG from single-lead abdominal ECG by de-shape short time Fourier transform and nonlocal median;"The multiple fundamental frequency detection problem and the source separation problem from a single-channel signal containing multiple oscillatory components and a nonstationary noise are both challenging tasks. To extract the fetal electrocardiogram (ECG) from a single-lead maternal abdominal ECG, we face both challenges. In this paper, we propose a novel method to extract the fetal ECG signal f…         _ More           The multiple fundamental frequency detection problem and the source separation problem from a single-channel signal containing multiple oscillatory components and a nonstationary noise are both challenging tasks. To extract the fetal electrocardiogram (ECG) from a single-lead maternal abdominal ECG, we face both challenges. In this paper, we propose a novel method to extract the fetal ECG signal from the single channel maternal abdominal ECG signal, without any additional measurement. The algorithm is composed of three main ingredients. First, the maternal and fetal heart rates are estimated by the de-shape short time Fourier transform, which is a recently proposed nonlinear time-frequency analysis technique; second, the beat tracking technique is applied to accurately obtain the maternal and fetal R peaks; third, the maternal and fetal ECG waveforms are established by the nonlocal median. The algorithm is evaluated on a simulated fetal ECG signal database ({\em fecgsyn} database), and tested on two real databases with the annotation provided by experts ({\em adfecgdb} database and {\em CinC2013} database). In general, the algorithm could be applied to solve other detection and source separation problems, and reconstruct the time-varying wave-shape function of each oscillatory component.         _ Less";Health relatedMulti-View Treelet Transform;              Current multi-view factorization methods make assumptions that are not acceptable for many kinds of data, and in particular, for graphical data with hierarchical structure. At the same time, current hierarchical methods work only in the single-view setting. We generalize the Treelet Transform to the Multi-View Treelet Transform (MVTT) to allow for the capture of hierarchical structure when multipl…         _ More           Current multi-view factorization methods make assumptions that are not acceptable for many kinds of data, and in particular, for graphical data with hierarchical structure. At the same time, current hierarchical methods work only in the single-view setting. We generalize the Treelet Transform to the Multi-View Treelet Transform (MVTT) to allow for the capture of hierarchical structure when multiple views are available. Further, we show how this generalization is consistent with the existing theory and how it might be used in denoising empirical networks and in computing the shared response of functional brain data.         _ Less;Health relatedMetric dynamics for membrane transformation through regulated cell proliferation;              This study develops an equation for describing three-dimensional membrane transformation through proliferation of its component cells regulated by morphogen density distributions on the membrane. The equation is developed in a two-dimensional coordinate system mapped on the membrane, referred to as the membrane coordinates. When the membrane expands, the membrane coordinates expand in the same man…         _ More           This study develops an equation for describing three-dimensional membrane transformation through proliferation of its component cells regulated by morphogen density distributions on the membrane. The equation is developed in a two-dimensional coordinate system mapped on the membrane, referred to as the membrane coordinates. When the membrane expands, the membrane coordinates expand in the same manner so that the membrane is invariant in the coordinates. In the membrane coordinate system, the transformation of membrane is described with a time-derivative equation for metric tensors. By defining relationships between morphogen density distributions and the direction and rate of cell division, trajectories of membrane transformation are obtained in terms of the morphogen distributions. An example of the membrane transformation is shown numerically.         _ Less;Health relatedReconstruction algorithms for a class of restricted ray transforms without added singularities;Let $X$ and $X^*$ denote a restricted ray transform along curves and a corresponding backprojection operator, respectively. Theoretical analysis of reconstruction from the data $Xf$ is usually based on a study of the composition $X^* D X$, where $D$ is some local operator (usually a derivative). If $X^*$ is chosen appropriately, then $X^* D X$ is a Fourier Integral Operator (FIO) with singular sym…         _ More           Let $X$ and $X^*$ denote a restricted ray transform along curves and a corresponding backprojection operator, respectively. Theoretical analysis of reconstruction from the data $Xf$ is usually based on a study of the composition $X^* D X$, where $D$ is some local operator (usually a derivative). If $X^*$ is chosen appropriately, then $X^* D X$ is a Fourier Integral Operator (FIO) with singular symbol. The singularity of the symbol leads to the appearance of artifacts (added singularities) that can be as strong as the original (or, useful) singularities. By choosing $D$ in a special way one can reduce the strength of added singularities, but it is impossible to get rid of them completely.   In the paper we follow a similar approach, but make two changes. First, we replace $D$ with a nonlocal operator $\tilde D$ that integrates $Xf$ along a curve in the data space. The result $\tilde D Xf$ resembles the generalized Radon transform $R$ of $f$. The function $\tilde D Xf$ is defined on pairs $(x_0,_)\in U\times S^2$, where $U\subset\mathbb R^3$ is an open set containing the support of $f$, and $S^2$ is the unit sphere in $\mathbb R^3$. Second, we replace $X^*$ with a backprojection operator $R^*$ that integrates with respect to $_$ over $S^2$. It turns out that if $\tilde D$ and $R^*$ are appropriately selected, then the composition $R^* \tilde D X$ is an elliptic pseudodifferential operator of order zero with principal symbol 1. Thus, we obtain an approximate reconstruction formula that recovers all the singularities correctly and does not produce artifacts. The advantage of our approach is that by inserting $\tilde D$ we get access to the frequency variable $_$. In particular, we can incorporate suitable cut-offs in $R^*$ to eliminate bad directions $_$, which lead to added singularities.         _ Less;Health relatedA Software Package for Chemically Inspired Graph Transformation;              Chemical reaction networks can be automatically generated from graph grammar descriptions, where rewrite rules model reaction patterns. Because a molecule graph is connected and reactions in general involve multiple molecules, the rewriting must be performed on multisets of graphs. We present a general software package for this type of graph rewriting system, which can be used for modelling chemic…         _ More           Chemical reaction networks can be automatically generated from graph grammar descriptions, where rewrite rules model reaction patterns. Because a molecule graph is connected and reactions in general involve multiple molecules, the rewriting must be performed on multisets of graphs. We present a general software package for this type of graph rewriting system, which can be used for modelling chemical systems. The package contains a C++ library with algorithms for working with transformation rules in the Double Pushout formalism, e.g., composition of rules and a domain specific language for programming graph language generation. A Python interface makes these features easily accessible. The package also has extensive procedures for automatically visualising not only graphs and rewrite rules, but also Double Pushout diagrams and graph languages in form of directed hypergraphs. The software is available as an open source package, and interactive examples can be found on the accompanying webpage.         _ Less;Health relatedTransforming phylogenetic networks: Moving beyond tree space;              Phylogenetic networks are a generalization of phylogenetic trees that are used to represent reticulate evolution. Unrooted phylogenetic networks form a special class of such networks, which naturally generalize unrooted phylogenetic trees. In this paper we define two operations on unrooted phylogenetic networks, one of which is a generalization of the well-known nearest-neighbor interchange (NNI)…         _ More           Phylogenetic networks are a generalization of phylogenetic trees that are used to represent reticulate evolution. Unrooted phylogenetic networks form a special class of such networks, which naturally generalize unrooted phylogenetic trees. In this paper we define two operations on unrooted phylogenetic networks, one of which is a generalization of the well-known nearest-neighbor interchange (NNI) operation on phylogenetic trees. We show that any unrooted phylogenetic network can be transformed into any other such network using only these operations. This generalizes the well-known fact that any phylogenetic tree can be transformed into any other such tree using only NNI operations. It also allows us to define a generalization of tree space and to define some new metrics on unrooted phylogenetic networks. To prove our main results, we employ some fascinating new connections between phylogenetic networks and cubic graphs that we have recently discovered. Our results should be useful in developing new strategies to search for optimal phylogenetic networks, a topic that has recently generated some interest in the literature, as well as for providing new ways to compare networks.         _ Less;Health relatedThe demodulated band transform;              Background: Windowed Fourier decompositions (WFD) are widely used in measuring stationary and non-stationary spectral phenomena and in describing pairwise relationships among multiple signals. Although a variety of WFDs see frequent application in electrophysiological research, including the short-time Fourier transform, continuous wavelets, band-pass filtering and multitaper-based approaches, eac…         _ More           Background: Windowed Fourier decompositions (WFD) are widely used in measuring stationary and non-stationary spectral phenomena and in describing pairwise relationships among multiple signals. Although a variety of WFDs see frequent application in electrophysiological research, including the short-time Fourier transform, continuous wavelets, band-pass filtering and multitaper-based approaches, each carries certain drawbacks related to computational efficiency and spectral leakage. This work surveys the advantages of a WFD not previously applied in electrophysiological settings.   New Methods: A computationally efficient form of complex demodulation, the demodulated band transform (DBT), is described.   Results: DBT is shown to provide an efficient approach to spectral estimation with minimal susceptibility to spectral leakage. In addition, it lends itself well to adaptive filtering of non-stationary narrowband noise.   Comparison with existing methods: A detailed comparison with alternative WFDs is offered, with an emphasis on the relationship between DBT and Thomson's multitaper. DBT is shown to perform favorably in combining computational efficiency with minimal introduction of spectral leakage.   Conclusion: DBT is ideally suited to efficient estimation of both stationary and non-stationary spectral and cross-spectral statistics with minimal susceptibility to spectral leakage. These qualities are broadly desirable in many settings.         _ Less;Health relatedAsymptotic Green's function for the stochastic reproduction of competing variants via Fisher's angular transformation;              The Wright-Fisher Fokker-Planck equation describes the stochastic dynamics of self-reproducing, competing variants at fixed population size. We use Fisher's angular transformation, which defines a natural length for this stochastic process, to remove the co-ordinate dependence of it's diffusive dynamics, resulting in simple Brownian motion in an unstable potential, driving variants to extinction o…         _ More           The Wright-Fisher Fokker-Planck equation describes the stochastic dynamics of self-reproducing, competing variants at fixed population size. We use Fisher's angular transformation, which defines a natural length for this stochastic process, to remove the co-ordinate dependence of it's diffusive dynamics, resulting in simple Brownian motion in an unstable potential, driving variants to extinction or fixation. This insight allows calculation of very accurate asymptotic formula for the Green's function under neutrality and selection, using a novel heuristic Gaussian approximation.         _ Less;Health relatedComputational implementation of the inverse continuous wavelet transform without a requirement of the admissibility condition;Recently, it has been proven [R. Soc. Open Sci. 1 (2014) 140124] that the continuous wavelet transform with non-admissible kernels (approximate wavelets) allows for an existence of the exact inverse transform. Here we consider the computational possibility for the realization of this approach. We provide modified simpler explanation of the reconstruction formula, restricted on the practical case o…         _ More           Recently, it has been proven [R. Soc. Open Sci. 1 (2014) 140124] that the continuous wavelet transform with non-admissible kernels (approximate wavelets) allows for an existence of the exact inverse transform. Here we consider the computational possibility for the realization of this approach. We provide modified simpler explanation of the reconstruction formula, restricted on the practical case of real valued finite (or periodic/periodized) samples and the standard (restricted) Morlet wavelet as a practically important example of an approximate wavelet. The provided examples of applications includes the test function and the non-stationary electro-physical signals arising in the problem of neuroscience.         _ Less;Health relatedModulation of transforming growth factor beta signalling pathway genes by transforming growth factor beta in human osteoarthritic chondrocytes: involvement of Sp1 in both early and late response cells to transforming growth factor beta;Transforming growth factor beta (TGF$_$) plays a central role in morphogenesis, growth, and cell differentiation. This cytokine is particularly important in cartilage where it regulates cell proliferation and extracellular matrix synthesis. While the action of TGF$_$ on chondrocyte metabolism has been extensively catalogued, the modulation of specific genes that function as mediators of TGF$_$ sig…         _ More           Transforming growth factor beta (TGF$_$) plays a central role in morphogenesis, growth, and cell differentiation. This cytokine is particularly important in cartilage where it regulates cell proliferation and extracellular matrix synthesis. While the action of TGF$_$ on chondrocyte metabolism has been extensively catalogued, the modulation of specific genes that function as mediators of TGF$_$ signalling is poorly defined. In the current study, elements of the Smad component of the TGF$_$ intracellular signalling system and TGF$_$ receptors were characterised in human chondrocytes upon TGF$_$1 treatment. Human articular chondrocytes were incubated with TGF$_$1. Then, mRNA and protein levels of TGF$_$ receptors and Smads were analysed by RT-PCR and western blot analysis. The role of specific protein 1 (Sp1) was investigated by gain and loss of function (inhibitor, siRNA, expression vector). We showed that TGF$_$1 regulates mRNA levels of its own receptors, and of Smad3 and Smad7. It modulates TGF$_$ receptors post-transcriptionally by affecting their mRNA stability, but does not change the Smad-3 and Smad-7 mRNA half-life span, suggesting a potential transcriptional effect on these genes. Moreover, the transcriptional factor Sp1, which is downregulated by TGF$_$1, is involved in the repression of both TGF$_$ receptors but not in the modulation of Smad3 and Smad7. Interestingly, Sp1 ectopic expression permitted also to maintain a similar expression pattern to early response to TGF$_$ at 24 hours of treatment. It restored the induction of Sox9 and COL2A1 and blocked the late response (repression of aggrecan, induction of COL1A1 and COL10A1). These data help to better understand the negative feedback loop in the TGF$_$ signalling system, and enlighten an interesting role of Sp1 to regulate TGF$_$ response.         _ Less;Health relatedCell transformation in tumor-development: a result of accumulation of Misrepairs of DNA through many generations of cells;              Development of a tumor is known to be a result of accumulation of DNA changes in somatic cells. However, the processes of how DNA changes are produced and how they accumulate in somatic cells are not clear. DNA changes include two types: point DNA mutations and chromosome changes. However, point DNA mutations (DNA mutations) are the main type of DNA changes that can remain and accumulate in cells.…         _ More           Development of a tumor is known to be a result of accumulation of DNA changes in somatic cells. However, the processes of how DNA changes are produced and how they accumulate in somatic cells are not clear. DNA changes include two types: point DNA mutations and chromosome changes. However, point DNA mutations (DNA mutations) are the main type of DNA changes that can remain and accumulate in cells. Severe DNA injuries are the causes for DNA mutations. However, Misrepair of DNA is an essential process for transforming a DNA injury into a survivable and inheritable DNA mutation. In somatic cells, Misrepair of DNA is the main source of DNA mutations. Since the surviving chance of a cell by Misrepair of DNA is low, accumulation of DNA mutations can take place only possibly in the cells that can proliferate. Tumors can only develop in the tissues that are regenerable. The accumulation of Misrepairs of DNA needs to proceed in many generations of cells, and cell transformation from a normal cell into a tumor cell is a slow and long process. However, once a cell is transformed especially when it is malignantly transformed, the deficiency of DNA repair and the rapid cell proliferation will accelerate the accumulation of DNA mutations. The process of accumulation of DNA mutations is actually the process of aging of a genome DNA. Repeated cell injuries and repeated cell regenerations are the two preconditions for tumor-development. For cancer prevention, a moderate and flexible living style is advised.         _ Less;Health relatedLabel-free identification of individual bacteria using Fourier transform light scattering;              Rapid identification of bacterial species is crucial in medicine and food hygiene. In order to achieve rapid and label-free identification of bacterial species at the single bacterium level, we propose and experimentally demonstrate an optical method based on Fourier transform light scattering (FTLS) measurements and statistical classification. For individual rod-shaped bacteria belonging to four…         _ More           Rapid identification of bacterial species is crucial in medicine and food hygiene. In order to achieve rapid and label-free identification of bacterial species at the single bacterium level, we propose and experimentally demonstrate an optical method based on Fourier transform light scattering (FTLS) measurements and statistical classification. For individual rod-shaped bacteria belonging to four bacterial species (Listeria monocytogenes, Escherichia coli, Lactobacillus casei, and Bacillus subtilis), two-dimensional angle-resolved light scattering maps are precisely measured using FTLS technique. The scattering maps are then systematically analyzed, employing statistical classification in order to extract the unique fingerprint patterns for each species, so that a new unidentified bacterium can be identified by a single light scattering measurement. The single-bacterial and label-free nature of our method suggests wide applicability for rapid point-of-care bacterial diagnosis.         _ Less;Health relatedGenetic Analysis of Transformed Phenotypes;"              Linear mixed models (LMMs) are a powerful and established tool for studying genotype-phenotype relationships. A limiting assumption of LMMs is that the residuals are Gaussian distributed, a requirement that rarely holds in practice. Violations of this assumption can lead to false conclusions and losses in power, and hence it is common practice to pre-process the phenotypic values to make them Ga…         _ More             Linear mixed models (LMMs) are a powerful and established tool for studying genotype-phenotype relationships. A limiting assumption of LMMs is that the residuals are Gaussian distributed, a requirement that rarely holds in practice. Violations of this assumption can lead to false conclusions and losses in power, and hence it is common practice to pre-process the phenotypic values to make them Gaussian, for instance by applying logarithmic or other non-linear transformations. Unfortunately, different phenotypes require different specific transformations, and choosing a ""good"" transformation is in general challenging and subjective. Here, we present an extension of the LMM that estimates an optimal transformation from the observed data. In extensive simulations and applications to real data from human, mouse and yeast we show that using such optimal transformations lead to increased power in genome-wide association studies and higher accuracy in heritability estimates and phenotype predictions.         _ Less";Health relatedNumerical Solution of the Model for HIV Infection of Cd4+T Cells by Using Multistage Differential Transform Method;The Multistage Differential Transform Method (MDTM) is employed to solve the model for HIV infection of CD4+T cells. Comparing the numerical results to those obtained by the classical fourth order Runge-Kutta method showed the preciseness and efficacy of the multistep differential transform method. The study shows that the method is a powerful and promising tool for solving coupled systems of diff…         _ More           The Multistage Differential Transform Method (MDTM) is employed to solve the model for HIV infection of CD4+T cells. Comparing the numerical results to those obtained by the classical fourth order Runge-Kutta method showed the preciseness and efficacy of the multistep differential transform method. The study shows that the method is a powerful and promising tool for solving coupled systems of differential equations.         _ Less;Health relatedOn the properties of input-to-output transformations in networks of perceptrons;              Information processing in certain neuronal networks in the brain can be considered as a map of binary vectors, where ones (spikes) and zeros (no spikes) of input neurons are transformed into spikes and no spikes of output neurons. A simple but fundamental characteristic of such a map is how it transforms distances between input vectors. In particular what is the mean distance between output vector…         _ More           Information processing in certain neuronal networks in the brain can be considered as a map of binary vectors, where ones (spikes) and zeros (no spikes) of input neurons are transformed into spikes and no spikes of output neurons. A simple but fundamental characteristic of such a map is how it transforms distances between input vectors. In particular what is the mean distance between output vectors given certain distance between input vectors? Using combinatorial approach we found an exact solution to this problem for networks of perceptrons with binary weights. he resulting formulas allow for precise analysis how network connectivity and neuronal excitability affect the transformation of distances between the vectors of neuronal spiking. As an application, we considered a simple network model of information processing in the hippocampus, a brain area critically implicated in learning and memory, and found a combination of parameters for which the output neurons discriminated similar and distinct inputs most effectively. A decrease of threshold values of the output neurons, which in biological networks may be associated with decreased inhibition, impaired optimality of discrimination.         _ Less;Health relatedDynamical Disequilibrium, Transformation, and the Evolution and Development of Sustainable Worldviews;"              This chapter begins by outlining a promising, new theoretical framework for the process by which human culture evolves inspired by the views of complexity theorists on the problem of how life began. Elements of culture, like species, evolve over time; that is, they exhibit cumulative change that is adaptive in nature. By studying how biological evolution got started, we gain insight into not just…         _ More           This chapter begins by outlining a promising, new theoretical framework for the process by which human culture evolves inspired by the views of complexity theorists on the problem of how life began. Elements of culture, like species, evolve over time; that is, they exhibit cumulative change that is adaptive in nature. By studying how biological evolution got started, we gain insight into not just the specifics of biological evolution, but also general insights into the initiation of any evolutionary process that may be applicable to culture. We then explore the implications of this new framework for culture on the transformative processes of individuals. Specifically, we will address what this emerging perspective on cultural evolution implies for to go about attaining a sustainable worldview; that is, a web of habits, understandings, and ways of approaching situations that is conducive to the development of a sustainable world.         _ Less";Not health relatedLearning Features and their Transformations by Spatial and Temporal Spherical Clustering;              Learning features invariant to arbitrary transformations in the data is a requirement for any recognition system, biological or artificial. It is now widely accepted that simple cells in the primary visual cortex respond to features while the complex cells respond to features invariant to different transformations. We present a novel two-layered feedforward neural model that learns features in the…         _ More           Learning features invariant to arbitrary transformations in the data is a requirement for any recognition system, biological or artificial. It is now widely accepted that simple cells in the primary visual cortex respond to features while the complex cells respond to features invariant to different transformations. We present a novel two-layered feedforward neural model that learns features in the first layer by spatial spherical clustering and invariance to transformations in the second layer by temporal spherical clustering. Learning occurs in an online and unsupervised manner following the Hebbian rule. When exposed to natural videos acquired by a camera mounted on a cat's head, the first and second layer neurons in our model develop simple and complex cell-like receptive field properties. The model can predict by learning lateral connections among the first layer neurons. A topographic map to their spatial features emerges by exponentially decaying the flow of activation with distance from one neuron to another in the first layer that fire in close temporal proximity, thereby minimizing the pooling length in an online manner simultaneously with feature learning.         _ Less;Health relatedTransformation of stimulus correlations by the retina;              Redundancies and correlations in the responses of sensory neurons seem to waste neural resources but can carry cues about structured stimuli and may help the brain to correct for response errors. To assess how the retina negotiates this tradeoff, we measured simultaneous responses from populations of ganglion cells presented with natural and artificial stimuli that varied greatly in correlation st…         _ More           Redundancies and correlations in the responses of sensory neurons seem to waste neural resources but can carry cues about structured stimuli and may help the brain to correct for response errors. To assess how the retina negotiates this tradeoff, we measured simultaneous responses from populations of ganglion cells presented with natural and artificial stimuli that varied greatly in correlation structure. We found that pairwise correlations in the retinal output remained similar across stimuli with widely different spatio-temporal correlations including white noise and natural movies. Meanwhile, purely spatial correlations tended to increase correlations in the retinal response. Responding to more correlated stimuli, ganglion cells had faster temporal kernels and tended to have stronger surrounds. These properties of individual cells, along with gain changes that opposed changes in effective contrast at the ganglion cell input, largely explained the similarity of pairwise correlations across stimuli where receptive field measurements were possible.         _ Less;Health relatedNon-linear relationship of cell hit and transformation probabilities in low dose of inhaled radon progenies;Cellular hit probabilities of alpha particles emitted by inhaled radon progenies in sensitive bronchial epithelial cell nuclei were simulated at low exposure levels to obtain useful data for the rejection or in support of the linear-non-threshold (LNT) hypothesis. In this study, local distributions of deposited inhaled radon progenies in airway bifurcation models were computed at exposure conditio…         _ More           Cellular hit probabilities of alpha particles emitted by inhaled radon progenies in sensitive bronchial epithelial cell nuclei were simulated at low exposure levels to obtain useful data for the rejection or in support of the linear-non-threshold (LNT) hypothesis. In this study, local distributions of deposited inhaled radon progenies in airway bifurcation models were computed at exposure conditions, which are characteristic of homes and uranium mines. Then, maximum local deposition enhancement factors at bronchial airway bifurcations, expressed as the ratio of local to average deposition densities, were determined to characterize the inhomogeneity of deposition and to elucidate their effect on resulting hit probabilities. The results obtained suggest that in the vicinity of the carinal regions of the central airways the probability of multiple hits can be quite high even at low average doses. Assuming a uniform distribution of activity there are practically no multiple hits and the hit probability as a function of dose exhibits a linear shape in the low dose range. The results are quite the opposite in the case of hot spots revealed by realistic deposition calculations, where practically all cells receive multiple hits and the hit probability as a function of dose is non-linear in the average dose range of 10-100 mGy.         _ Less;Health relatedCritical case stochastic phylogenetic tree model via the Laplace transform;Birth-and-death models are now a common mathematical tool to describe branching patterns observed in real-world phylogenetic trees. Liggett and Schinazi (2009) is one such example. The authors propose a simple birth-and-death model that is compatible with phylogenetic trees of both influenza and HIV, depending on the birth rate parameter. An interesting special case of this model is the critical c…         _ More           Birth-and-death models are now a common mathematical tool to describe branching patterns observed in real-world phylogenetic trees. Liggett and Schinazi (2009) is one such example. The authors propose a simple birth-and-death model that is compatible with phylogenetic trees of both influenza and HIV, depending on the birth rate parameter. An interesting special case of this model is the critical case where the birth rate equals the death rate. This is a non-trivial situation and to study its asymptotic behaviour we employed the Laplace transform. With this we correct the proof of Liggett and Schinazi (2009) in the critical case.         _ Less;Health relatedLarge-scale compression of genomic sequence databases with the Burrows-Wheeler transform;Motivation   The Burrows-Wheeler transform (BWT) is the foundation of many algorithms for compression and indexing of text data, but the cost of computing the BWT of very large string collections has prevented these techniques from being widely applied to the large sets of sequences often encountered as the outcome of DNA sequencing experiments. In previous work, we presented a novel algorithm tha…         _ More           Motivation   The Burrows-Wheeler transform (BWT) is the foundation of many algorithms for compression and indexing of text data, but the cost of computing the BWT of very large string collections has prevented these techniques from being widely applied to the large sets of sequences often encountered as the outcome of DNA sequencing experiments. In previous work, we presented a novel algorithm that allows the BWT of human genome scale data to be computed on very moderate hardware, thus enabling us to investigate the BWT as a tool for the compression of such datasets.   Results   We first used simulated reads to explore the relationship between the level of compression and the error rate, the length of the reads and the level of sampling of the underlying genome and compare choices of second-stage compression algorithm.   We demonstrate that compression may be greatly improved by a particular reordering of the sequences in the collection and give a novel `implicit sorting' strategy that enables these benefits to be realised without the overhead of sorting the reads. With these techniques, a 45x coverage of real human genome sequence data compresses losslessly to under 0.5 bits per base, allowing the 135.3Gbp of sequence to fit into only 8.2Gbytes of space (trimming a small proportion of low-quality bases from the reads improves the compression still further).   This is more than 4 times smaller than the size achieved by a standard BWT-based compressor (bzip2) on the untrimmed reads, but an important further advantage of our approach is that it facilitates the building of compressed full text indexes such as the FM-index on large-scale DNA sequence collections.         _ Less;Health relatedMechanisms of kinetic trapping in self-assembly and phase transformation;              In self-assembly processes, kinetic trapping effects often hinder the formation of thermodynamically stable ordered states. In a model of viral capsid assembly and in the phase transformation of a lattice gas, we show how simulations in a self-assembling steady state can be used to identify two distinct mechanisms of kinetic trapping. We argue that one of these mechanisms can be adequately capture…         _ More           In self-assembly processes, kinetic trapping effects often hinder the formation of thermodynamically stable ordered states. In a model of viral capsid assembly and in the phase transformation of a lattice gas, we show how simulations in a self-assembling steady state can be used to identify two distinct mechanisms of kinetic trapping. We argue that one of these mechanisms can be adequately captured by kinetic rate equations, while the other involves a breakdown of theories that rely on cluster size as a reaction coordinate. We discuss how these observations might be useful in designing and optimising self-assembly reactions.         _ Less;Health relatedDetection of mixed-culture growth in the total biomass data by wavelet transforms;              We have shown elsewhere that the presence of mixed-culture growth of microbial species in fermentation processes can be detected with high accuracy by employing the wavelet transform. This is achieved because the crosses in the different growth processes contributing to the total biomass signal appear as singularities that are very well evidenced through their singularity cones in the wavelet tran…         _ More           We have shown elsewhere that the presence of mixed-culture growth of microbial species in fermentation processes can be detected with high accuracy by employing the wavelet transform. This is achieved because the crosses in the different growth processes contributing to the total biomass signal appear as singularities that are very well evidenced through their singularity cones in the wavelet transform. However, we used very simple two-species cases. In this work, we extend the wavelet method to a more complicated illustrative fermentation case of three microbial species for which we employ several wavelets of different number of vanishing moments in order to eliminate possible numerical artifacts. Working in this way allows to filter in a more precise way the numerical values of the Hölder exponents. Therefore, we were able to determine the characteristic Hölder exponents for the corresponding crossing singularities of the microbial growth processes and their stability logarithmic scale ranges up to the first decimal in the value of the characteristic exponents. Since calibrating the mixed microbial growth by means of their Hölder exponents could have potential industrial applications, the dependence of the Hölder exponents on the kinetic and physical parameters of the growth models remains as a future experimental task         _ Less;Health relatedData Driven Computing by the Morphing Fast Fourier Transform Ensemble Kalman Filter in Epidemic Spread Simulations;              The FFT EnKF data assimilation method is proposed and applied to a stochastic cell simulation of an epidemic, based on the S-I-R spread model. The FFT EnKF combines spatial statistics and ensemble filtering methodologies into a localized and computationally inexpensive version of EnKF with a very small ensemble, and it is further combined with the morphing EnKF to assimilate changes in the positio…         _ More           The FFT EnKF data assimilation method is proposed and applied to a stochastic cell simulation of an epidemic, based on the S-I-R spread model. The FFT EnKF combines spatial statistics and ensemble filtering methodologies into a localized and computationally inexpensive version of EnKF with a very small ensemble, and it is further combined with the morphing EnKF to assimilate changes in the position of the epidemic.         _ Less;Health relatedAge, Sex, and Genetic Architecture of Human Gene Expression in EBV Transformed Cell Lines;Individual expression profiles from EBV transformed cell lines are an emerging resource for genomic investigation. In this study we characterize the effects of age, sex, and genetic variation on gene expression by surveying public datasets of such profiles. We establish that the expression space of cell lines maintains genetic as well as non-germline information, in an individual-specific and cr…         _ More             Individual expression profiles from EBV transformed cell lines are an emerging resource for genomic investigation. In this study we characterize the effects of age, sex, and genetic variation on gene expression by surveying public datasets of such profiles. We establish that the expression space of cell lines maintains genetic as well as non-germline information, in an individual-specific and cross-tissue manner. Age of donor is associated with the expression of 949 genes in the derived cell line. Age-associated genes include over-representation of immune-related genes, specifically MHC Class I genes, a phenomenon that replicates across tissues and organisms. Sex associated genes in these cell lines include likely candidates, such as genes that escape X-inactivation,testis specific expressed genes, androgen and estrogen specific genes, but also gene families previously unknown to be sex associated such as common microRNA targets (MIR-490, V_ARP1_01, MIR-489). Finally, we report 494 transcripts whose expression levels are associated with a genetic variant in cis, overlapping and validating previous reports. Incorporating age in analysis of association facilitates additional discovery of trans-acting regulatory genetic variants. Our findings promote expression profiling of transformed cell lines as a vehicle for understanding cellular systems beyond the specific lines.         _ Less;Not health relatedUnderstanding forest dynamics and plantation transformation using a simple size-structured model;              Concerns about biodiversity and the long-term stability of forest ecosystems have lead to changing attitudes with respect to plantations. These artificial communities are ubiquitous, yet provide reduced habitat value in comparison to their naturally established counterparts, key factors being high density, homogeneous spatial structure, and their even-sized/aged nature.   Transformation (manipul…         _ More             Concerns about biodiversity and the long-term stability of forest ecosystems have lead to changing attitudes with respect to plantations. These artificial communities are ubiquitous, yet provide reduced habitat value in comparison to their naturally established counterparts, key factors being high density, homogeneous spatial structure, and their even-sized/aged nature.   Transformation (manipulation of plantations to produce stands more reminiscent of natural ones) represents a major challenge for forest managers, and the shift from even- to uneven-aged stand management is far from simple. Tree species' attributes, too, vary dramatically. This study aims to identify generic aspects of forest population dynamics, in order to understand the temporal evolution of single species forest stands from an initial plantation lattice structure, into an ``old-growth'' state.   This is achieved using a size-structured model, which implements simple rules to simulate the growth and fate of individuals in a spatial arena. We parameterise and discuss model behaviour in the context of available plantation and semi-natural data from Caledonian Scots Pine stands. We move on to illustrate the use of the model in predicting the outcome of silviculture, and discuss results in the context of stand transformation.         _ Less;Health relatedNih-3T3 Fibroblast Studied by Fourier Transform Infrared Spectroscopy;              This paper has been withdrawn by the author due to a crucial sign error in some equations                           This paper has been withdrawn by the author due to a crucial sign error in some equations         _ Less;Health relatedAveraging Transformations of Synaptic Potentials on Networks;              The problem of the transformation of microscopic information to the macroscopic level is an intriguing challenge in computational neuroscience, but also of general mathematical importance. Here, a phenomenological mathematical model is introduced that simulates the internal information processing of brain compartments. Synaptic potentials are integrated over small number of realistically coupled…         _ More             The problem of the transformation of microscopic information to the macroscopic level is an intriguing challenge in computational neuroscience, but also of general mathematical importance. Here, a phenomenological mathematical model is introduced that simulates the internal information processing of brain compartments. Synaptic potentials are integrated over small number of realistically coupled neurons to obtain macroscopic quantities. The striatal complex, an important part of the basal ganglia circuit in the brain for regulating motor activity, has been investigated as an example for the validation of the model.         _ Less;Health relatedTransformation from spots to waves in a model of actin pattern formation;              Actin networks in certain single-celled organisms exhibit a complex pattern-forming dynamics that starts with the appearance of static spots of actin on the cell cortex. Spots soon become mobile, executing persistent random walks, and eventually give rise to traveling waves of actin. Here we describe a possible physical mechanism for this distinctive set of dynamic transformations, by equipping…         _ More             Actin networks in certain single-celled organisms exhibit a complex pattern-forming dynamics that starts with the appearance of static spots of actin on the cell cortex. Spots soon become mobile, executing persistent random walks, and eventually give rise to traveling waves of actin. Here we describe a possible physical mechanism for this distinctive set of dynamic transformations, by equipping an excitable reaction-diffusion model with a field describing the spatial orientation of its chief constituent (which we consider to be actin). The interplay of anisotropic actin growth and spatial inhibition drives a transformation at fixed parameter values from static spots to moving spots to waves.         _ Less;Health relatedFourier transform inequalities for phylogenetic trees;"Phylogenetic invariants are not the only constraints on site-pattern frequency vectors for phylogenetic trees. A mutation matrix, by its definition, is the exponential of a matrix with non-negative off-diagonal entries; this positivity requirement implies non-trivial constraints on the site-pattern frequency vectors. We call these additional constraints ``edge-parameter inequalities.'' In this p…         _ More             Phylogenetic invariants are not the only constraints on site-pattern frequency vectors for phylogenetic trees. A mutation matrix, by its definition, is the exponential of a matrix with non-negative off-diagonal entries; this positivity requirement implies non-trivial constraints on the site-pattern frequency vectors. We call these additional constraints ``edge-parameter inequalities.'' In this paper, we first motivate the edge-parameter inequalities by considering a pathological site-pattern frequency vector corresponding to a quartet tree with a negative internal edge. This site-pattern frequency vector nevertheless satisfies all of the constraints described up to now in the literature. We next describe two complete sets of edge-parameter inequalities for the group-based models; these constraints are square-free monomial inequalities in the Fourier transformed coordinates. These inequalities, along with the phylogenetic invariants, form a complete description of the set of site-pattern frequency vectors corresponding to \emph{bona fide} trees. Said in mathematical language, this paper explicitly presents two finite lists of inequalities in Fourier coordinates of the form ``monomial $\leq 1$,'' each list characterizing the phylogenetically relevant semialgebraic subsets of the phylogenetic varieties.         _ Less";Health relatedThe Hilbert transform of horizontal gaze position during natural image classification by saccades;Eye movements are a behavioral response that can be involved in tasks as complicated as natural image classification. This report confirms that pro- and anti-saccades can be used by a volunteer to designate target (animal) or non-target images that were centered 16 degrees off the fixation point. With more than 86% correct responses, 11 participants responded to targets in 470 milliseconds on av…         _ More             Eye movements are a behavioral response that can be involved in tasks as complicated as natural image classification. This report confirms that pro- and anti-saccades can be used by a volunteer to designate target (animal) or non-target images that were centered 16 degrees off the fixation point. With more than 86% correct responses, 11 participants responded to targets in 470 milliseconds on average, starting as quick as 245 milliseconds. Furthermore, tracking the gaze position is considered a powerful method in the studies of recognition as the saccade response times, ocular dynamics and the events around the response time can be calculated from the data sampled 240 times per second. The Hilbert transform is applied to obtain the analytic signal from the horizontal gaze position. Its amplitude and phase are used to describe differences between saccades that may testify to the recognition process.         _ Less;Health relatedDoes Logarithm Transformation of Microarray Data Affect Ranking Order of Differentially Expressed Genes?;"A common practice in microarray analysis is to transform the microarray raw data (light intensity) by a logarithmic transformation, and the justification for this transformation is to make the distribution more symmetric and Gaussian-like. Since this transformation is not universally practiced in all microarray analysis, we examined whether the discrepancy of this treatment of raw data affect th…         _ More             A common practice in microarray analysis is to transform the microarray raw data (light intensity) by a logarithmic transformation, and the justification for this transformation is to make the distribution more symmetric and Gaussian-like. Since this transformation is not universally practiced in all microarray analysis, we examined whether the discrepancy of this treatment of raw data affect the ""high level"" analysis result. In particular, whether the differentially expressed genes as obtained by $t$-test, regularized t-test, or logistic regression have altered rank orders due to presence or absence of the transformation. We show that as much as 20%--40% of significant genes are ""discordant"" (significant only in one form of the data and not in both), depending on the test being used and the threshold value for claiming significance. The t-test is more likely to be affected by logarithmic transformation than logistic regression, and regularized $t$-test more affected than t-test. On the other hand, the very top ranking genes (e.g. up to top 20--50 genes, depending on the test) are not affected by the logarithmic transformation.         _ Less";Health relatedThe promoters of human cell cycle genes integrate signals from two tumor suppressive pathways during cellular transformation;Deciphering regulatory events that drive malignant transformation represents a major challenge for systems biology. Here we analyzed genome-wide transcription profiling of an in-vitro transformation process. We focused on a cluster of genes whose expression levels increased as a function of p53 and p16INK4A tumor suppressors inactivation. This cluster predominantly consists of cell cycle genes a…         _ More             Deciphering regulatory events that drive malignant transformation represents a major challenge for systems biology. Here we analyzed genome-wide transcription profiling of an in-vitro transformation process. We focused on a cluster of genes whose expression levels increased as a function of p53 and p16INK4A tumor suppressors inactivation. This cluster predominantly consists of cell cycle genes and constitutes a signature of a diversity of cancers. By linking expression profiles of the genes in the cluster with the dynamic behavior of p53 and p16INK4A, we identified a promoter architecture that integrates signals from the two tumor suppressive channels and that maps their activity onto distinct levels of expression of the cell cycle genes, which in turn, correspond to different cellular proliferation rates. Taking components of the mitotic spindle as an example, we experimentally verified our predictions that p53-mediated transcriptional repression of several of these novel targets is dependent on the activities of p21, NFY and E2F. Our study demonstrates how a well-controlled transformation process allows linking between gene expression, promoter architecture and activity of upstream signaling molecules.         _ Less;Health relatedConformational transformations of DNA macromolecule in heteronomous conformation;To understand the mechanism of TATA-box conformational transformations we model structure mobility and find the types of conformational excitations of DNA macromolecule in heteronomous conformation. We have constructed the two-component model for describing DNA conformational transformation with simultaneous transitions in the furanos rings of the monomer link. Internal component describes the c…         _ More             To understand the mechanism of TATA-box conformational transformations we model structure mobility and find the types of conformational excitations of DNA macromolecule in heteronomous conformation. We have constructed the two-component model for describing DNA conformational transformation with simultaneous transitions in the furanos rings of the monomer link. Internal component describes the change of the base pair position in the double helix. External component describes the displacement of mass center of the monomer link. Nonlinearity of the system is accounted with a form of potential energy describing C3'-C2' and C2'-C3' sugars transitions in monomer link, and interrelation between monomer conformational transition and macromolecule deformation. The comparison of our results with experimental data allows to confirm that the localized conformational excitations may realise in DNA TATA-box. These excitations cause the deformation of the macromolecule fragment.         _ Less;Health relatedClustering under the line graph transformation: Application to reaction network;Many real networks can be understood as two complementary networks with two kind of nodes. This is the case of metabolic networks where the first network has chemical compounds as nodes and the second one has nodes as reactions. The second network can be related to the first one by a technique called line graph transformation (i.e., edges in an initial network are transformed into nodes). Recent…         _ More             Many real networks can be understood as two complementary networks with two kind of nodes. This is the case of metabolic networks where the first network has chemical compounds as nodes and the second one has nodes as reactions. The second network can be related to the first one by a technique called line graph transformation (i.e., edges in an initial network are transformed into nodes). Recently, the main topological properties of the metabolic networks have been properly described by means of a hierarchical model. In our work, we apply the line graph transformation to a hierarchical network and the clustering coefficient $C(k)$ is calculated for the transformed network, where $k$ is the node degree. While $C(k)$ follows the scaling law $C(k)\sim k^{-1.1}$ for the initial hierarchical network, $C(k)$ scales weakly as $k^{0.08}$ for the transformed network. These results indicate that the reaction network can be identified as a degree-independent clustering network.         _ Less;Health relatedAn ordinary differential equation model for the multistep transformation to cancer;              Cancer is viewed as a multistep process whereby a normal cell is transformed into a cancer cell through the acquisition of mutations. We reduce the complexities of cancer progression to a simple set of underlying rules that govern the transformation of normal cells to malignant cells. In doing so, we derive an ordinary differential equation model that explores how the balance of angiogenesis, ce…         _ More             Cancer is viewed as a multistep process whereby a normal cell is transformed into a cancer cell through the acquisition of mutations. We reduce the complexities of cancer progression to a simple set of underlying rules that govern the transformation of normal cells to malignant cells. In doing so, we derive an ordinary differential equation model that explores how the balance of angiogenesis, cell death rates, genetic instability, and replication rates give rise to different kinetics in the development of cancer. The key predictions of the model are that cancer develops fastest through a particular ordering of mutations and that mutations in genes that maintain genomic integrity would be the most deleterious type of mutations to inherit. In addition, we perform a sensitivity analysis on the parameters included in the model to determine the probable contribution of each. This paper presents a novel approach to viewing the genetic basis of cancer from a systems biology perspective and provides the groundwork for other models that can be directly tied to clinical and molecular data.         _ Less;Health relatedModeling DNA Conformational Transformations on the Mesoscopic Scales;              The approach for the description of the DNA conformational transformations on the mesoscopic scales in the frame of the double helix is presented. Due to consideration of the joint motions of DNA structural elements along the conformational pathways the models for different transformations may be constructed in the unifying two-component form. One component of the model is the degree of freedom…         _ More             The approach for the description of the DNA conformational transformations on the mesoscopic scales in the frame of the double helix is presented. Due to consideration of the joint motions of DNA structural elements along the conformational pathways the models for different transformations may be constructed in the unifying two-component form. One component of the model is the degree of freedom of the elastic rod and another component -- the effective coordinate of the conformational transformation. The internal and external model components are interrelated, as it is characteristic for the DNA structure organization. It is shown that the kinetic energy of the conformational transformation of heterogeneous DNA may be put in homogeneous form. In the frame of the developed approach the static excitations of the DNA structure under the transitions between the stable states are found for internal and external components. The comparison of the data obtained with the experiment on intrinsic DNA deformability shows good qualitative agreement. The conclusion is made that the found excitations in the DNA structure may be classificated as the static conformational solitons.         _ Less;Health related